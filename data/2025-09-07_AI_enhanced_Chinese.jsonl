{"id": "2509.03563", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.03563", "abs": "https://arxiv.org/abs/2509.03563", "authors": ["Quan Quan", "Jiwen Xu", "Runxiao Liu", "Yi Ding", "Jiaxing Che", "Kai-Yuan Cai"], "title": "Self-Organizing Aerial Swarm Robotics for Resilient Load Transportation : A Table-Mechanics-Inspired Approach", "comment": null, "summary": "In comparison with existing approaches, which struggle with scalability,\ncommunication dependency, and robustness against dynamic failures, cooperative\naerial transportation via robot swarms holds transformative potential for\nlogistics and disaster response. Here, we present a physics-inspired\ncooperative transportation approach for flying robot swarms that imitates the\ndissipative mechanics of table-leg load distribution. By developing a\ndecentralized dissipative force model, our approach enables autonomous\nformation stabilization and adaptive load allocation without the requirement of\nexplicit communication. Based on local neighbor robots and the suspended\npayload, each robot dynamically adjusts its position. This is similar to\nenergy-dissipating table leg reactions. The stability of the resultant control\nsystem is rigorously proved. Simulations demonstrate that the tracking errors\nof the proposed approach are 20%, 68%, 55.5%, and 21.9% of existing approaches\nunder the cases of capability variation, cable uncertainty, limited vision, and\npayload variation, respectively. In real-world experiments with six flying\nrobots, the cooperative aerial transportation system achieved a 94% success\nrate under single-robot failure, disconnection events, 25% payload variation,\nand 40% cable length uncertainty, demonstrating strong robustness under outdoor\nwinds up to Beaufort scale 4. Overall, this physics-inspired approach bridges\nswarm intelligence and mechanical stability principles, offering a scalable\nframework for heterogeneous aerial systems to collectively handle complex\ntransportation tasks in communication-constrained environments.", "AI": {"tldr": "基于物理温度模拟桌腿负荷分配机制，提出一种无需显式通信的分布式飞行机群协作运输方法，具有较强的可扩展性和动态故障耐受能力。", "motivation": "解决现有协作运输方法在可扩展性、通信依赖性和动态故障耐受能力方面的挑战，为物流和灾难应急领域提供变革性解决方案。", "method": "发展了一种分布式耗散力模型，模仿桌腿负荷分配的耗散机制。每个飞行器根据本地邻居和悬挂负荷动态调整位置，无需显式通信。控制系统稳定性经严格证明。", "result": "模拟显示在能力变化、线缆不确定性、视觉限制和负荷变化情况下，跟踪误差分别仅为现有方法的20%、68%、55.5%和21.9%。实验中6台飞行器在单机故障、断开事件、25%负荷变化和40%线缆长度不确定性下达到94%成功率，在海洋风力等级4级外部环境下体现强壁耐受性。", "conclusion": "该物理受启发的方法埋通了群智能与机械稳定性原理，为异构空中系统提供了一种可扩展框架，能够在通信受限环境丫集体处理复杂运输任务。"}}
{"id": "2509.03638", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.03638", "abs": "https://arxiv.org/abs/2509.03638", "authors": ["David Alvear", "George Turkiyyah", "Shinkyu Park"], "title": "Cooperative Grasping for Collective Object Transport in Constrained Environments", "comment": null, "summary": "We propose a novel framework for decision-making in cooperative grasping for\ntwo-robot object transport in constrained environments. The core of the\nframework is a Conditional Embedding (CE) model consisting of two neural\nnetworks that map grasp configuration information into an embedding space. The\nresulting embedding vectors are then used to identify feasible grasp\nconfigurations that allow two robots to collaboratively transport an object. To\nensure generalizability across diverse environments and object geometries, the\nneural networks are trained on a dataset comprising a range of environment maps\nand object shapes. We employ a supervised learning approach with negative\nsampling to ensure that the learned embeddings effectively distinguish between\nfeasible and infeasible grasp configurations. Evaluation results across a wide\nrange of environments and objects in simulations demonstrate the model's\nability to reliably identify feasible grasp configurations. We further validate\nthe framework through experiments on a physical robotic platform, confirming\nits practical applicability.", "AI": {"tldr": "一种基于条件嵌入模型的新案框架，用于在约束环境中为双机器人协作抓取物体运输做决策，通过嵌入空间映射识别可行抓取配置。", "motivation": "解决在约束环境中双机器人协作抓取物体运输的决策问题，需要一种能够处理多样化环境和物体形状的通用方法。", "method": "使用由两个神经网络组成的条件嵌入(CE)模型，将抓取配置信息映射到嵌入空间，然后利用嵌入向量识别可行抓取配置。采用监督学习和负样本采样进行训练。", "result": "在模拟环境中对各种环境和物体进行评估，模型能够可靠地识别可行抓取配置。物理机器人平台实验进一步验证了其实际应用性。", "conclusion": "该框架通过嵌入空间方法有效解决了双机器人协作抓取运输的决策问题，具有良好的通用性和实际应用价值。"}}
{"id": "2509.03658", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.03658", "abs": "https://arxiv.org/abs/2509.03658", "authors": ["Antonio Guillen-Perez"], "title": "Efficient Virtuoso: A Latent Diffusion Transformer Model for Goal-Conditioned Trajectory Planning", "comment": null, "summary": "The ability to generate a diverse and plausible distribution of future\ntrajectories is a critical capability for autonomous vehicle planning systems.\nWhile recent generative models have shown promise, achieving high fidelity,\ncomputational efficiency, and precise control remains a significant challenge.\nIn this paper, we present the \\textbf{Efficient Virtuoso}, a conditional latent\ndiffusion model for goal-conditioned trajectory planning. Our approach\nintroduces a novel two-stage normalization pipeline that first scales\ntrajectories to preserve their geometric aspect ratio and then normalizes the\nresulting PCA latent space to ensure a stable training target. The denoising\nprocess is performed efficiently in this low-dimensional latent space by a\nsimple MLP denoiser, which is conditioned on a rich scene context fused by a\npowerful Transformer-based StateEncoder. We demonstrate that our method\nachieves state-of-the-art performance on the Waymo Open Motion Dataset,\nreaching a \\textbf{minADE of 0.25}. Furthermore, through a rigorous ablation\nstudy on goal representation, we provide a key insight: while a single endpoint\ngoal can resolve strategic ambiguity, a richer, multi-step sparse route is\nessential for enabling the precise, high-fidelity tactical execution that\nmirrors nuanced human driving behavior.", "AI": {"tldr": "Efficient Virtuoso是一个基于条件潜在扩散模型的轨迹规划方法，通过两阶段归一化管道和低维潜在空间去噪，在Waymo数据集上达到0.25 minADE的SOTA性能。", "motivation": "解决自动驾驶规划系统中生成多样化且合理的未来轨迹分布的问题，同时实现高保真度、计算效率和精确控制。", "method": "提出条件潜在扩散模型，采用两阶段归一化管道：先缩放轨迹保持几何纵横比，再对PCA潜在空间归一化；使用简单MLP去噪器在低维潜在空间高效去噪，基于Transformer的StateEncoder融合丰富场景上下文。", "result": "在Waymo Open Motion Dataset上达到最先进性能，minADE为0.25；通过目标表示消融研究发现，多步稀疏路径比单端点目标更能实现精确的高保真度战术执行。", "conclusion": "该方法在轨迹规划中实现了高保真度和计算效率的平衡，多步稀疏路径表示对于模拟人类驾驶行为的精确战术执行至关重要。"}}
{"id": "2509.03690", "categories": ["cs.RO", "I.2.9"], "pdf": "https://arxiv.org/pdf/2509.03690", "abs": "https://arxiv.org/abs/2509.03690", "authors": ["Kelvin Daniel Gonzalez Amador"], "title": "Low-Cost Open-Source Ambidextrous Robotic Hand with 23 Direct-Drive servos for American Sign Language Alphabet", "comment": "9 pages, 8 figures, 4 tables. Submitted as preprint", "summary": "Accessible communication through sign language is vital for deaf communities,\n1 yet robotic solutions are often costly and limited. This study presents\nVulcanV3, a low- 2 cost, open-source, 3D-printed ambidextrous robotic hand\ncapable of reproducing the full 3 American Sign Language (ASL) alphabet (52\nsigns for right- and left-hand configurations). 4 The system employs 23\ndirect-drive servo actuators for precise finger and wrist movements, 5\ncontrolled by an Arduino Mega with dual PCA9685 modules. Unlike most humanoid\nupper- 6 limb systems, which rarely employ direct-drive actuation, VulcanV3\nachieves complete ASL 7 coverage with a reversible design. All CAD files and\ncode are released under permissive 8 open-source licenses to enable\nreplication. Empirical tests confirmed accurate reproduction 9 of all 52 ASL\nhandshapes, while a participant study (n = 33) achieved 96.97% recognition 10\naccuracy, improving to 98.78% after video demonstration. VulcanV3 advances\nassistive 11 robotics by combining affordability, full ASL coverage, and\nambidexterity in an openly 12 shared platform, contributing to accessible\ncommunication technologies and inclusive 13 innovation.", "AI": {"tldr": "VulcanV3是一个低成本、开源、3D打印的双手机器人手，能够完整再现美国手语字母表的所有52个手势，识别准确率达到96.97%", "motivation": "为聋人社区提供可访问的沟通解决方案，现有机器人方案成本高且功能有限", "method": "使用23个直接驱动伺服执行器实现精确手指和手腕运动，由Arduino Mega和双PCA9685模块控制，采用可逆设计", "result": "实验测试确认准确再现所有52个ASL手形，参与者研究(n=33)达到96.97%识别准确率，视频演示后提升至98.78%", "conclusion": "VulcanV3通过结合经济性、完整ASL覆盖和双手灵活性，在开放共享平台上推进辅助机器人技术，为可访问通信技术和包容性创新做出贡献"}}
{"id": "2509.03804", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.03804", "abs": "https://arxiv.org/abs/2509.03804", "authors": ["Ad-Deen Mahbub", "Md Ragib Shaharear"], "title": "Real-Time Buoyancy Estimation for AUV Simulations Using Convex Hull-Based Submerged Volume Calculation", "comment": "7 pages, 10 figures", "summary": "Accurate real-time buoyancy modeling is essential for high-fidelity\nAutonomous Underwater Vehicle (AUV) simulations, yet NVIDIA Isaac Sim lacks a\nnative buoyancy system, requiring external solutions for precise underwater\nphysics. This paper presents a novel convex hull-based approach to dynamically\ncompute the submerged volume of an AUV in real time. By extracting mesh\ngeometry from the simulation environment and calculating the hull portion\nintersecting the water level along the z-axis, our method enhances accuracy\nover traditional geometric approximations. A cross-sectional area extension\nreduces computational overhead, enabling efficient buoyant force updates that\nadapt to orientation, depth, and sinusoidal wave fluctuations (+-0.3 m). Tested\non a custom AUV design for SAUVC 2025, this approach delivers real-time\nperformance and scalability, improving simulation fidelity for underwater\nrobotics research without precomputed hydrodynamic models.", "AI": {"tldr": "本文提出了一种基于凸包的方法，用于在NVIDIA Isaac Sim中实时计算AUV的沉水体积，解决了该模拟平台缺乏原生浮力系统的问题。", "motivation": "NVIDIA Isaac Sim缺乏原生的浮力系统，而准确的实时浮力模型对高保真度的AUV模拟至关重要。", "method": "通过提取模拟环境中的网格几何，计算水平面沿z轴交叉的船舶部分，采用凸包基础方法动态计算沉水体积，并通过截面积扩展降低计算开销。", "result": "该方法在SAUVC 2025自定义AUV设计上进行了测试，能够适应位置、深度和正弦波动（±0.3 m），实现了实时性能和可扩展性。", "conclusion": "这种新颖方法提高了水下机器人模拟的保真度，无需预先计算液动力学模型，为水下机器人研究提供了更准确的模拟环境。"}}
{"id": "2509.03842", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03842", "abs": "https://arxiv.org/abs/2509.03842", "authors": ["Guanglu Jia", "Ceng Zhang", "Gregory S. Chirikjian"], "title": "INGRID: Intelligent Generative Robotic Design Using Large Language Models", "comment": "15 pages, 6 figures", "summary": "The integration of large language models (LLMs) into robotic systems has\naccelerated progress in embodied artificial intelligence, yet current\napproaches remain constrained by existing robotic architectures, particularly\nserial mechanisms. This hardware dependency fundamentally limits the scope of\nrobotic intelligence. Here, we present INGRID (Intelligent Generative Robotic\nDesign), a framework that enables the automated design of parallel robotic\nmechanisms through deep integration with reciprocal screw theory and kinematic\nsynthesis methods. We decompose the design challenge into four progressive\ntasks: constraint analysis, kinematic joint generation, chain construction, and\ncomplete mechanism design. INGRID demonstrates the ability to generate novel\nparallel mechanisms with both fixed and variable mobility, discovering\nkinematic configurations not previously documented in the literature. We\nvalidate our approach through three case studies demonstrating how INGRID\nassists users in designing task-specific parallel robots based on desired\nmobility requirements. By bridging the gap between mechanism theory and machine\nlearning, INGRID enables researchers without specialized robotics training to\ncreate custom parallel mechanisms, thereby decoupling advances in robotic\nintelligence from hardware constraints. This work establishes a foundation for\nmechanism intelligence, where AI systems actively design robotic hardware,\npotentially transforming the development of embodied AI systems.", "AI": {"tldr": "INGRID是一个通过深度学习与螺旋理论、运动学综合方法结合的框架，能够自动设计并联机器人机构，突破传统串行机构的硬件限制。", "motivation": "当前基于大语言模型的机器人系统仍受限于现有机器人架构（特别是串行机构），这种硬件依赖性从根本上限制了机器人智能的发展范围。", "method": "将设计挑战分解为四个渐进任务：约束分析、运动学关节生成、链构建和完整机构设计，结合螺旋理论和运动学综合方法。", "result": "INGRID能够生成具有固定和可变自由度的新型并联机构，发现了文献中未记载的运动学配置，并通过三个案例研究验证了其帮助用户设计任务特定并联机器人的能力。", "conclusion": "INGRID弥合了机构理论与机器学习之间的差距，使没有专业机器人培训的研究人员能够创建定制并联机构，从而将机器人智能的进步与硬件约束解耦，为机构智能奠定了基础。"}}
{"id": "2509.03859", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.03859", "abs": "https://arxiv.org/abs/2509.03859", "authors": ["Haichao Zhang", "Haonan Yu", "Le Zhao", "Andrew Choi", "Qinxun Bai", "Yiqing Yang", "Wei Xu"], "title": "Learning Multi-Stage Pick-and-Place with a Legged Mobile Manipulator", "comment": "Project: https://horizonrobotics.github.io/gail/SLIM", "summary": "Quadruped-based mobile manipulation presents significant challenges in\nrobotics due to the diversity of required skills, the extended task horizon,\nand partial observability. After presenting a multi-stage pick-and-place task\nas a succinct yet sufficiently rich setup that captures key desiderata for\nquadruped-based mobile manipulation, we propose an approach that can train a\nvisuo-motor policy entirely in simulation, and achieve nearly 80\\% success in\nthe real world. The policy efficiently performs search, approach, grasp,\ntransport, and drop into actions, with emerged behaviors such as re-grasping\nand task chaining. We conduct an extensive set of real-world experiments with\nablation studies highlighting key techniques for efficient training and\neffective sim-to-real transfer. Additional experiments demonstrate deployment\nacross a variety of indoor and outdoor environments. Demo videos and additional\nresources are available on the project page:\nhttps://horizonrobotics.github.io/gail/SLIM.", "AI": {"tldr": "提出了一种在仿真中训练视觉运动策略的方法，用于四足机器人的移动抓取任务，在真实世界中达到近80%的成功率，能够执行搜索、接近、抓取、运输和放置等动作。", "motivation": "四足机器人的移动操作面临技能多样性、长任务周期和部分可观测性等挑战，需要开发能够在仿真中训练并有效迁移到真实世界的策略。", "method": "采用多阶段拾取放置任务作为测试平台，开发视觉运动策略在仿真中训练，通过关键技术实现高效的仿真到真实迁移。", "result": "在真实世界中达到近80%的成功率，表现出重新抓取和任务链式执行等涌现行为，在多种室内外环境中成功部署。", "conclusion": "该方法证明了在仿真中训练视觉运动策略并有效迁移到真实世界的可行性，为四足机器人的复杂移动操作任务提供了有效解决方案。"}}
{"id": "2509.03889", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.03889", "abs": "https://arxiv.org/abs/2509.03889", "authors": ["Neha Sunil", "Megha Tippur", "Arnau Saumell", "Edward Adelson", "Alberto Rodriguez"], "title": "Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance", "comment": "Accepted at CoRL 2025. Project website:\n  https://mhtippur.github.io/inairclothmanipulation/", "summary": "Manipulating clothing is challenging due to complex configurations, variable\nmaterial dynamics, and frequent self-occlusion. Prior systems often flatten\ngarments or assume visibility of key features. We present a dual-arm\nvisuotactile framework that combines confidence-aware dense visual\ncorrespondence and tactile-supervised grasp affordance to operate directly on\ncrumpled and suspended garments. The correspondence model is trained on a\ncustom, high-fidelity simulated dataset using a distributional loss that\ncaptures cloth symmetries and generates correspondence confidence estimates.\nThese estimates guide a reactive state machine that adapts folding strategies\nbased on perceptual uncertainty. In parallel, a visuotactile grasp affordance\nnetwork, self-supervised using high-resolution tactile feedback, determines\nwhich regions are physically graspable. The same tactile classifier is used\nduring execution for real-time grasp validation. By deferring action in\nlow-confidence states, the system handles highly occluded table-top and in-air\nconfigurations. We demonstrate our task-agnostic grasp selection module in\nfolding and hanging tasks. Moreover, our dense descriptors provide a reusable\nintermediate representation for other planning modalities, such as extracting\ngrasp targets from human video demonstrations, paving the way for more\ngeneralizable and scalable garment manipulation.", "AI": {"tldr": "一种结合视觉-触觉的双臂框架，通过自信度感知的密集对应关系和触觉监督的抓取能力来操作混乱垂挂的衣物，处理了有自遮挡的衬桌和空中配置。", "motivation": "衣物操作面临复杂配置、变化材料动态和频繁自遮挡的挑战，之前系统常假设关键特征可见或将衣物展平。", "method": "使用分布损失训练自信度感知的密集对应模型，通过反应状态机根据感知不确定性调整折叠策略，并使用高分辨率触觉反馈自监督的触觉抓取能力网络。", "result": "系统能够处理高度遮挡的桌面和空中配置，在折叠和挂放任务中展示了任务无关的抓取选择能力，密集描述符为其他规划模态提供了可重用中间表示。", "conclusion": "该框架通过结合视觉-触觉感知和自适应性策略，提高了衣物操作的通用性和可扩展性，为更普遍的服装操作研究铺平了道路。"}}
{"id": "2509.04016", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.04016", "abs": "https://arxiv.org/abs/2509.04016", "authors": ["Branimir Ćaran", "Vladimir Milić", "Marko Švaco", "Bojan Jerbić"], "title": "Odometry Calibration and Pose Estimation of a 4WIS4WID Mobile Wall Climbing Robot", "comment": "ACCEPTED FOR IEEE EUROPEAN CONFERENCE ON MOBILE ROBOTS 2025. PREPRINT\n  VERSION. ACCEPTED JUNE, 2025 AND PRESENTED SEPTEMBER, 2025", "summary": "This paper presents the design of a pose estimator for a four wheel\nindependent steer four wheel independent drive (4WIS4WID) wall climbing mobile\nrobot, based on the fusion of multimodal measurements, including wheel\nodometry, visual odometry, and an inertial measurement unit (IMU) data using\nExtended Kalman Filter (EKF) and Unscented Kalman Filter (UKF). The pose\nestimator is a critical component of wall climbing mobile robots, as their\noperational environment involves carrying precise measurement equipment and\nmaintenance tools in construction, requiring information about pose on the\nbuilding at the time of measurement. Due to the complex geometry and material\nproperties of building facades, the use of traditional localization sensors\nsuch as laser, ultrasonic, or radar is often infeasible for wall-climbing\nrobots. Moreover, GPS-based localization is generally unreliable in these\nenvironments because of signal degradation caused by reinforced concrete and\nelectromagnetic interference. Consequently, robot odometry remains the primary\nsource of velocity and position information, despite being susceptible to drift\ncaused by both systematic and non-systematic errors. The calibrations of the\nrobot's systematic parameters were conducted using nonlinear optimization and\nLevenberg-Marquardt methods as Newton-Gauss and gradient-based model fitting\nmethods, while Genetic algorithm and Particle swarm were used as\nstochastic-based methods for kinematic parameter calibration. Performance and\nresults of the calibration methods and pose estimators were validated in detail\nwith experiments on the experimental mobile wall climbing robot.", "AI": {"tldr": "提出基于EKF和UKF的多模态测量融合位姿估计器，用于4WIS4WID爬墙机器人，解决复杂建筑立面环境下的定位问题", "motivation": "爬墙机器人在建筑维护中需要精确位姿信息，但传统定位传感器（激光、超声波、雷达）在复杂建筑立面上不可行，GPS信号也因钢筋混凝土和电磁干扰而不可靠，轮式里程计易产生漂移误差", "method": "使用扩展卡尔曼滤波(EKF)和无迹卡尔曼滤波(UKF)融合轮式里程计、视觉里程计和IMU数据；采用非线性优化和Levenberg-Marquardt方法进行系统参数标定，使用遗传算法和粒子群算法进行运动学参数标定", "result": "在实验性爬墙移动机器人上详细验证了标定方法和位姿估计器的性能与结果", "conclusion": "多模态传感器融合方法为爬墙机器人在复杂建筑环境中的精确定位提供了有效解决方案"}}
{"id": "2509.04018", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.04018", "abs": "https://arxiv.org/abs/2509.04018", "authors": ["Yifan Yang", "Zhixiang Duan", "Tianshi Xie", "Fuyu Cao", "Pinxi Shen", "Peili Song", "Piaopiao Jin", "Guokang Sun", "Shaoqing Xu", "Yangwei You", "Jingtai Liu"], "title": "FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction", "comment": null, "summary": "Robotic manipulation is a fundamental component of automation. However,\ntraditional perception-planning pipelines often fall short in open-ended tasks\ndue to limited flexibility, while the architecture of a single end-to-end\nVision-Language-Action (VLA) offers promising capabilities but lacks crucial\nmechanisms for anticipating and recovering from failure. To address these\nchallenges, we propose FPC-VLA, a dual-model framework that integrates VLA with\na supervisor for failure prediction and correction. The supervisor evaluates\naction viability through vision-language queries and generates corrective\nstrategies when risks arise, trained efficiently without manual labeling. A\nsimilarity-guided fusion module further refines actions by leveraging past\npredictions. Evaluation results on multiple simulation platforms (SIMPLER and\nLIBERO) and robot embodiments (WidowX, Google Robot, Franka) show that FPC-VLA\noutperforms state-of-the-art models in both zero-shot and fine-tuned settings.\nBy activating the supervisor only at keyframes, our approach significantly\nincreases task success rates with minimal impact on execution time. Successful\nreal-world deployments on diverse, long-horizon tasks confirm FPC-VLA's strong\ngeneralization and practical utility for building more reliable autonomous\nsystems.", "AI": {"tldr": "FPC-VLA是一个双模型框架，将视觉-语言-动作模型与故障预测和纠正监督器集成，通过视觉语言查询评估动作可行性并生成纠正策略，显著提高了任务成功率。", "motivation": "传统感知-规划流水线在开放任务中灵活性不足，而单端到端VLA模型缺乏故障预测和恢复机制，需要更可靠的自主系统。", "method": "提出FPC-VLA双模型框架，包含VLA模型和监督器，监督器通过视觉语言查询评估动作可行性并生成纠正策略，采用相似性引导融合模块优化动作，仅在关键帧激活监督器以减少执行时间影响。", "result": "在多个仿真平台和机器人实体上评估显示，FPC-VLA在零样本和微调设置下均优于最先进模型，任务成功率显著提升，执行时间影响最小，并在真实世界长时程任务中成功部署。", "conclusion": "FPC-VLA通过集成故障预测和纠正机制，展示了强大的泛化能力和实际效用，为构建更可靠的自主系统提供了有效解决方案。"}}
{"id": "2509.04061", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.04061", "abs": "https://arxiv.org/abs/2509.04061", "authors": ["Ventseslav Yordanov", "Simon Schäfer", "Alexander Mann", "Stefan Kowalewski", "Bassam Alrifaee", "Lutz Eckstein"], "title": "Integrated Wheel Sensor Communication using ESP32 -- A Contribution towards a Digital Twin of the Road System", "comment": "6 pages, 2 figures, this work was submitted to and accepted by IEEE\n  International Conference on Intelligent Transportation Systems (ITSC) 2025", "summary": "While current onboard state estimation methods are adequate for most driving\nand safety-related applications, they do not provide insights into the\ninteraction between tires and road surfaces. This paper explores a novel\ncommunication concept for efficiently transmitting integrated wheel sensor data\nfrom an ESP32 microcontroller. Our proposed approach utilizes a\npublish-subscribe system, surpassing comparable solutions in the literature\nregarding data transmission volume. We tested this approach on a drum tire test\nrig with our prototype sensors system utilizing a diverse selection of sample\nfrequencies between 1 Hz and 32 000 Hz to demonstrate the efficacy of our\ncommunication concept. The implemented prototype sensor showcases minimal data\nloss, approximately 0.1 % of the sampled data, validating the reliability of\nour developed communication system. This work contributes to advancing\nreal-time data acquisition, providing insights into optimizing integrated wheel\nsensor communication.", "AI": {"tldr": "这篇论文提出了一种基于ESP32微控制器的新题订阅通信方案，用于高效传输集成轮氧传感器数据，以获取轮胎与路面相互作用的深度见解。", "motivation": "当前车载状态估计方法无法揭示轮胎与路面之间的相互作用，需要一种高效的数据传输方案来获取这些关键信息。", "method": "使用ESP32微控制器构建原型传感器系统，采用新题订阅通信方案，在漫测试骨架上进行测试，采样频率1Hz到32000Hz不等。", "result": "实现的原型传感器显示了极小的数据丢失（约0.1%），验证了通信系统的可靠性，在数据传输量方面超越了文献中的相关解决方案。", "conclusion": "这项工作推进了实时数据获取技术，为优化集成轮氧传感器通信提供了重要见解，有助于深入理解轮胎与路面相互作用。"}}
