<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 83]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Robotic Fire Risk Detection based on Dynamic Knowledge Graph Reasoning: An LLM-Driven Approach with Graph Chain-of-Thought](https://arxiv.org/abs/2509.00054)
*Haimei Pan,Jiyun Zhang,Qinxi Wei,Xiongnan Jin,Chen Xinkai,Jie Cheng*

Main category: cs.RO

TL;DR: 基于知识图谱和大语言模型构建的IOG框架，通过实时场景图像生成感知驱动的风险图谱，实现火灾早期风险检测和可解释的应急响应规划


<details>
  <summary>Details</summary>
Motivation: 当前火灾预防和救援研究面临感知不完整、态势认知不足和响应延迟等挑战，需要提升机器人在火灾场景中的智能感知和响应规划能力

Method: 首先利用大语言模型构建火灾知识图谱，整合防火指南和救援任务信息；然后提出IOG框架，结合知识图谱的结构化信息和大型多模态模型，从实时图像生成风险图谱

Result: 大量仿真和真实实验表明，IOG在火灾风险检测和救援决策方面具有良好的适用性和实际应用价值

Conclusion: IOG框架有效提升了机器人在火灾场景中的智能感知能力和应急响应规划水平，为火灾预防和救援提供了新的技术解决方案

Abstract: Fire is a highly destructive disaster, but effective prevention can
significantly reduce its likelihood of occurrence. When it happens, deploying
emergency robots in fire-risk scenarios can help minimize the danger to human
responders. However, current research on pre-disaster warnings and
disaster-time rescue still faces significant challenges due to incomplete
perception, inadequate fire situational awareness, and delayed response. To
enhance intelligent perception and response planning for robots in fire
scenarios, we first construct a knowledge graph (KG) by leveraging large
language models (LLMs) to integrate fire domain knowledge derived from fire
prevention guidelines and fire rescue task information from robotic emergency
response documents. We then propose a new framework called Insights-on-Graph
(IOG), which integrates the structured fire information of KG and Large
Multimodal Models (LMMs). The framework generates perception-driven risk graphs
from real-time scene imagery to enable early fire risk detection and provide
interpretable emergency responses for task module and robot component
configuration based on the evolving risk situation. Extensive simulations and
real-world experiments show that IOG has good applicability and practical
application value in fire risk detection and rescue decision-making.

</details>


### [2] [U2UData-2: A Scalable Swarm UAVs Autonomous Flight Dataset for Long-horizon Tasks](https://arxiv.org/abs/2509.00055)
*Tongtong Feng,Xin Wang,Feilin Han,Leping Zhang,Wenwu Zhu*

Main category: cs.RO

TL;DR: U2UData-2是首个面向长时域任务的大规模无人机集群自主飞行数据集和平台，包含12个场景、720条轨迹、120小时数据，支持野生动物保护等LH任务验证。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于数据集，只能处理特定基础任务，无法应对真实世界长时域任务的长期依赖、状态保持和动态目标变化等挑战。

Method: 构建包含15架无人机自主协同飞行的数据集，开发可定制模拟器、无人机、传感器和算法的在线平台，支持一键部署和闭环验证。

Result: 创建了包含432万LiDAR帧和1296万RGB帧的大规模数据集，涵盖亮度、温度、湿度等多种环境参数，并提供9个SOTA模型的基准测试。

Conclusion: U2UData-2填补了长时域无人机集群自主飞行数据集的空白，为真实世界部署提供了重要的数据集和验证平台支撑。

Abstract: Swarm UAV autonomous flight for Long-Horizon (LH) tasks is crucial for
advancing the low-altitude economy. However, existing methods focus only on
specific basic tasks due to dataset limitations, failing in real-world
deployment for LH tasks. LH tasks are not mere concatenations of basic tasks,
requiring handling long-term dependencies, maintaining persistent states, and
adapting to dynamic goal shifts. This paper presents U2UData-2, the first
large-scale swarm UAV autonomous flight dataset for LH tasks and the first
scalable swarm UAV data online collection and algorithm closed-loop
verification platform. The dataset is captured by 15 UAVs in autonomous
collaborative flights for LH tasks, comprising 12 scenes, 720 traces, 120
hours, 600 seconds per trajectory, 4.32M LiDAR frames, and 12.96M RGB frames.
This dataset also includes brightness, temperature, humidity, smoke, and
airflow values covering all flight routes. The platform supports the
customization of simulators, UAVs, sensors, flight algorithms, formation modes,
and LH tasks. Through a visual control window, this platform allows users to
collect customized datasets through one-click deployment online and to verify
algorithms by closed-loop simulation. U2UData-2 also introduces an LH task for
wildlife conservation and provides comprehensive benchmarks with 9 SOTA models.
U2UData-2 can be found at https://fengtt42.github.io/U2UData-2/.

</details>


### [3] [Correspondence-Free, Function-Based Sim-to-Real Learning for Deformable Surface Control](https://arxiv.org/abs/2509.00060)
*Yingjun Tian,Guoxin Fang,Renbo Su,Aoran Lyu,Neelotpal Dutta,Simeon Gill,Andrew Weightman,Charlie C. L. Wang*

Main category: cs.RO

TL;DR: 提出了一种基于函数的无对应点模拟到真实学习方法，用于控制可变形自由曲面，无需依赖标记点对应关系，通过神经网络学习变形函数空间和置信度映射。


<details>
  <summary>Details</summary>
Motivation: 传统模拟到真实转换方法严重依赖具有完整对应关系的标记点，限制了在无对应点或标记点缺失情况下的应用。

Method: 同时学习由神经网络参数化的变形函数空间和置信度映射，可将模拟形状映射到真实对应物，支持3D扫描点云或运动捕捉系统输入。

Result: 方法在视觉设备和四种气动软机器人上展示了多功能性和适应性，包括可变形膜、机器人模型和两个软操纵器。

Conclusion: 该方法实现了无缝的模拟到真实转换，可集成到基于神经网络的逆向运动学和形状控制计算流程中。

Abstract: This paper presents a correspondence-free, function-based sim-to-real
learning method for controlling deformable freeform surfaces. Unlike
traditional sim-to-real transfer methods that strongly rely on marker points
with full correspondences, our approach simultaneously learns a deformation
function space and a confidence map -- both parameterized by a neural network
-- to map simulated shapes to their real-world counterparts. As a result, the
sim-to-real learning can be conducted by input from either a 3D scanner as
point clouds (without correspondences) or a motion capture system as marker
points (tolerating missed markers). The resultant sim-to-real transfer can be
seamlessly integrated into a neural network-based computational pipeline for
inverse kinematics and shape control. We demonstrate the versatility and
adaptability of our method on both vision devices and across four pneumatically
actuated soft robots: a deformable membrane, a robotic mannequin, and two soft
manipulators.

</details>


### [4] [OpenTie: Open-vocabulary Sequential Rebar Tying System](https://arxiv.org/abs/2509.00064)
*Mingze Liu,Sai Fan,Haozhen Li,Haobo Liang,Yixing Yuan,Yanke Wang*

Main category: cs.RO

TL;DR: OpenTie是一个无需训练的3D钢筋绑扎框架，使用RGB到点云生成和开放词汇检测技术，通过双目相机和机械臂实现高精度水平与垂直钢筋绑扎。


<details>
  <summary>Details</summary>
Motivation: 现有钢筋绑扎产品和研究主要关注平面钢筋设置且需要模型训练，无法满足复杂场景需求，需要开发无需训练且能处理3D场景的解决方案。

Method: 采用RGB到点云生成技术和开放词汇检测方法，通过双目相机捕获图像，基于提示的目标检测方法在点云生成后处理的过滤图像上实现高精度检测。

Result: 系统在真实世界钢筋设置实验中验证了有效性，能够灵活处理水平和垂直钢筋绑扎任务。

Conclusion: OpenTie框架成功解决了无需模型训练的3D钢筋绑扎问题，在实际应用中表现出良好的效果和灵活性。

Abstract: Robotic practices on the construction site emerge as an attention-attracting
manner owing to their capability of tackle complex challenges, especially in
the rebar-involved scenarios. Most of existing products and research are mainly
focused on flat rebar setting with model training demands. To fulfill this gap,
we propose OpenTie, a 3D training-free rebar tying framework utilizing a
RGB-to-point-cloud generation and an open-vocabulary detection. We implements
the OpenTie via a robotic arm with a binocular camera and guarantees a high
accuracy by applying the prompt-based object detection method on the image
filtered by our propose post-processing procedure based a image to point cloud
generation framework. The system is flexible for horizontal and vertical rebar
tying tasks and the experiments on the real-world rebar setting verifies that
the effectiveness of the system in practice.

</details>


### [5] [Contact-Aided Navigation of Flexible Robotic Endoscope Using Deep Reinforcement Learning in Dynamic Stomach](https://arxiv.org/abs/2509.00319)
*Chi Kit Ng,Huxin Gao,Tian-Ao Ren,Jiewen Lai,Hongliang Ren*

Main category: cs.RO

TL;DR: 基于深度强化学习的接触辅助导航策略，利用力反馈在可变形胃环境中实现柔性内窥镜的高精度导航


<details>
  <summary>Details</summary>
Motivation: 柔性内窥镜在动态胃环境中导航具有挑战性，需要学习利用与可变形胃壁的接触来达到目标位置

Method: 使用基于物理的有限元方法模拟可变形胃环境，采用近端策略优化算法训练接触辅助导航策略

Result: 在静态和动态胃环境中达到100%成功率（平均误差1.6mm），在具有更强外部干扰的未见场景中保持85%成功率

Conclusion: 基于深度强化学习的接触辅助导航策略显著提升了柔性内窥镜的导航性能，优于现有方法

Abstract: Navigating a flexible robotic endoscope (FRE) through the gastrointestinal
tract is critical for surgical diagnosis and treatment. However, navigation in
the dynamic stomach is particularly challenging because the FRE must learn to
effectively use contact with the deformable stomach walls to reach target
locations. To address this, we introduce a deep reinforcement learning (DRL)
based Contact-Aided Navigation (CAN) strategy for FREs, leveraging contact
force feedback to enhance motion stability and navigation precision. The
training environment is established using a physics-based finite element method
(FEM) simulation of a deformable stomach. Trained with the Proximal Policy
Optimization (PPO) algorithm, our approach achieves high navigation success
rates (within 3 mm error between the FRE's end-effector and target) and
significantly outperforms baseline policies. In both static and dynamic stomach
environments, the CAN agent achieved a 100% success rate with 1.6 mm average
error, and it maintained an 85% success rate in challenging unseen scenarios
with stronger external disturbances. These results validate that the DRL-based
CAN strategy substantially enhances FRE navigation performance over prior
methods.

</details>


### [6] [Hybrid Perception and Equivariant Diffusion for Robust Multi-Node Rebar Tying](https://arxiv.org/abs/2509.00065)
*Zhitao Wang,Yirong Xiong,Roberto Horowitz,Yanke Wang,Yuxing Han*

Main category: cs.RO

TL;DR: 提出了一种结合几何感知和SE(3)等变去噪扩散的混合方法，用于自动化钢筋绑扎任务，仅需少量训练数据即可实现高效的多节点绑扎。


<details>
  <summary>Details</summary>
Motivation: 钢筋绑扎是钢筋混凝土施工中重复性高且具有人体工程学风险的关键任务，现有机器人方法在拥挤钢筋节点中准确估计绑扎姿态面临挑战。

Method: 结合密度聚类(DBSCAN)、几何特征提取和PCA进行钢筋分割和节点识别，使用Diffusion-EDFs运动规划器基于5-10个演示样本生成优化的末端执行器姿态序列。

Result: 在单层、多层和杂乱配置的钢筋网格上验证，展示了高成功率的节点检测和准确的顺序绑扎性能，显著降低了数据需求。

Conclusion: 混合感知和扩散驱动规划方法具有增强现场施工任务自动化的潜力，可同时提高安全性和劳动效率。

Abstract: Rebar tying is a repetitive but critical task in reinforced concrete
construction, typically performed manually at considerable ergonomic risk.
Recent advances in robotic manipulation hold the potential to automate the
tying process, yet face challenges in accurately estimating tying poses in
congested rebar nodes. In this paper, we introduce a hybrid perception and
motion planning approach that integrates geometry-based perception with
Equivariant Denoising Diffusion on SE(3) (Diffusion-EDFs) to enable robust
multi-node rebar tying with minimal training data. Our perception module
utilizes density-based clustering (DBSCAN), geometry-based node feature
extraction, and principal component analysis (PCA) to segment rebar bars,
identify rebar nodes, and estimate orientation vectors for sequential ranking,
even in complex, unstructured environments. The motion planner, based on
Diffusion-EDFs, is trained on as few as 5-10 demonstrations to generate
sequential end-effector poses that optimize collision avoidance and tying
efficiency. The proposed system is validated on various rebar meshes, including
single-layer, multi-layer, and cluttered configurations, demonstrating high
success rates in node detection and accurate sequential tying. Compared with
conventional approaches that rely on large datasets or extensive manual
parameter tuning, our method achieves robust, efficient, and adaptable
multi-node tying while significantly reducing data requirements. This result
underscores the potential of hybrid perception and diffusion-driven planning to
enhance automation in on-site construction tasks, improving both safety and
labor efficiency.

</details>


### [7] [Jacobian Exploratory Dual-Phase Reinforcement Learning for Dynamic Endoluminal Navigation of Deformable Continuum Robots](https://arxiv.org/abs/2509.00329)
*Yu Tian,Chi Kit Ng,Hongliang Ren*

Main category: cs.RO

TL;DR: 提出了JEDP-RL框架，通过分阶段雅可比估计和策略执行来解决可变形连续体机器人的规划问题，相比PPO基线方法在收敛速度、导航效率和泛化能力方面都有显著提升


<details>
  <summary>Details</summary>
Motivation: 可变形连续体机器人(DCRs)由于非线性变形力学和部分状态可观测性，违反了传统强化学习方法的马尔可夫假设，而基于雅可比的方法虽然为刚性机械臂提供了理论基础，但直接应用于DCRs受到时变运动学和欠驱动变形动力学的限制

Method: 提出Jacobian Exploratory Dual-Phase RL (JEDP-RL)框架，将规划分解为分阶段的雅可比估计和策略执行。在每个训练步骤中，首先执行小规模局部探索动作来估计变形雅可比矩阵，然后用雅可比特征增强状态表示以恢复近似的马尔可夫性

Result: 在SOFA手术动态模拟中，JEDP-RL相比PPO基线表现出三个关键优势：1)收敛速度：策略收敛速度快3.2倍；2)导航效率：到达目标所需的步骤减少25%；3)泛化能力：在材料属性变化下达到92%的成功率，在未见过的组织环境中达到83%的成功率（比PPO高33%）

Conclusion: JEDP-RL框架通过结合局部探索和雅可比特征增强，有效解决了DCRs的非马尔可夫规划问题，在多个性能指标上显著优于传统PPO方法，展示了在复杂变形环境中的优越性能

Abstract: Deformable continuum robots (DCRs) present unique planning challenges due to
nonlinear deformation mechanics and partial state observability, violating the
Markov assumptions of conventional reinforcement learning (RL) methods. While
Jacobian-based approaches offer theoretical foundations for rigid manipulators,
their direct application to DCRs remains limited by time-varying kinematics and
underactuated deformation dynamics. This paper proposes Jacobian Exploratory
Dual-Phase RL (JEDP-RL), a framework that decomposes planning into phased
Jacobian estimation and policy execution. During each training step, we first
perform small-scale local exploratory actions to estimate the deformation
Jacobian matrix, then augment the state representation with Jacobian features
to restore approximate Markovianity. Extensive SOFA surgical dynamic
simulations demonstrate JEDP-RL's three key advantages over proximal policy
optimization (PPO) baselines: 1) Convergence speed: 3.2x faster policy
convergence, 2) Navigation efficiency: requires 25% fewer steps to reach the
target, and 3) Generalization ability: achieve 92% success rate under material
property variations and achieve 83% (33% higher than PPO) success rate in the
unseen tissue environment.

</details>


### [8] [A Comparative Study of Spline-Based Trajectory Reconstruction Methods Across Varying Automatic Vehicle Location Data Densities](https://arxiv.org/abs/2509.00119)
*Jake Robbennolt,Sirajum Munira,Stephen D. Boyles*

Main category: cs.RO

TL;DR: 本研究评估了13种轨迹重建方法，发现速度感知方法优于仅基于位置的方法，其中VCHIP-ME方法在精度和计算效率方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 自动车辆定位(AVL)数据由于更新频率不一致，需要进行轨迹重建以提高数据有效性，但现有方法在复杂城市环境中的性能表现需要系统评估。

Method: 使用德克萨斯州奥斯汀的高分辨率AVL数据，评估13种轨迹重建方法（包括新方法），分析速度、位置、平滑和数据密度四个关键因素的影响，结合传统数学误差指标和物理现实性考量。

Result: 速度感知方法始终优于仅位置方法；平滑方法在复杂拥堵城市环境中可能降低性能；VCHIP-ME方法在精度和计算效率方面达到最优平衡。

Conclusion: 研究为轨迹重建系统的实施提供实用指导，强调投资更高频率AVL数据收集的重要性，VCHIP-ME方法适合历史分析和实时应用。

Abstract: Automatic vehicle location (AVL) data offers insights into transit dynamics,
but its effectiveness is often hampered by inconsistent update frequencies,
necessitating trajectory reconstruction. This research evaluates 13 trajectory
reconstruction methods, including several novel approaches, using
high-resolution AVL data from Austin, Texas. We examine the interplay of four
critical factors -- velocity, position, smoothing, and data density -- on
reconstruction performance. A key contribution of this study is evaluation of
these methods across sparse and dense datasets, providing insights into the
trade-off between accuracy and resource allocation. Our evaluation framework
combines traditional mathematical error metrics for positional and velocity
with practical considerations, such as physical realism (e.g., aligning
velocity and acceleration with stopped states, deceleration rates, and speed
variability). In addition, we provide insight into the relative value of each
method in calculating realistic metrics for infrastructure evaluations. Our
findings indicate that velocity-aware methods consistently outperform
position-only approaches. Interestingly, we discovered that smoothing-based
methods can degrade overall performance in complex, congested urban
environments, although enforcing monotonicity remains critical. The velocity
constrained Hermite interpolation with monotonicity enforcement (VCHIP-ME)
yields optimal results, offering a balance between high accuracy and
computational efficiency. Its minimal overhead makes it suitable for both
historical analysis and real-time applications, providing significant
predictive power when combined with dense datasets. These findings offer
practical guidance for researchers and practitioners implementing trajectory
reconstruction systems and emphasize the importance of investing in
higher-frequency AVL data collection for improved analysis.

</details>


### [9] [Needle Biopsy And Fiber-Optic Compatible Robotic Insertion Platform](https://arxiv.org/abs/2509.00530)
*Fanxin Wang,Yikun Cheng,Chuyuan Tao,Rohit Bhargava,Thenkurussi Kesavadas*

Main category: cs.RO

TL;DR: 这篇论文提出了一种经济、准确且机动性好的机器人插入平台，用于改善传统组织检查的限制，包括精确指导重复性好的细针插入和多模态诊断。


<details>
  <summary>Details</summary>
Motivation: 传统组织检查存在两个主要问题：1）手工采样容易出错；2）病理检查耗时较长。需要一种更准确、高效的方法来改善诊断过程。

Method: 设计了一种经济、准确且机动性好的机器人插入平台，能够控制各种不同尺寸的工具，包括组织提取针和光学纤维。系统包含机械设计和控制方案，支持多模态诊断。

Result: 通过一系列测试验证了系统的性能，包括定位精度、导纳性能和工具插入效果，证明了该平台的可靠性和有效性。

Conclusion: 该机器人插入平台成功充分解决了传统组织检查的两大限制，提供了一种更准确、高效的诊断方案，为多模态医学诊断开启了新可能。

Abstract: Tissue biopsy is the gold standard for diagnosing many diseases, involving
the extraction of diseased tissue for histopathology analysis by expert
pathologists. However, this procedure has two main limitations: 1) Manual
sampling through tissue biopsy is prone to inaccuracies; 2) The extraction
process is followed by a time-consuming pathology test. To address these
limitations, we present a compact, accurate, and maneuverable robotic insertion
platform to overcome the limitations in traditional histopathology. Our
platform is capable of steering a variety of tools with different sizes,
including needle for tissue extraction and optical fibers for vibrational
spectroscopy applications. This system facilitates the guidance of end-effector
to the tissue and assists surgeons in navigating to the biopsy target area for
multi-modal diagnosis. In this paper, we outline the general concept of our
device, followed by a detailed description of its mechanical design and control
scheme. We conclude with the validation of the system through a series of
tests, including positioning accuracy, admittance performance, and tool
insertion efficacy.

</details>


### [10] [Poke and Strike: Learning Task-Informed Exploration Policies](https://arxiv.org/abs/2509.00178)
*Marina Y. Aoyama,Joao Moura,Juan Del Aguila Ferrandis,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 提出基于强化学习的任务信息探索方法，通过特权任务策略对属性估计误差的敏感性自动生成奖励，训练探索策略来识别物体物理属性，在击球任务中达到90%成功率，平均探索时间低于1.2秒。


<details>
  <summary>Details</summary>
Motivation: 在动态机器人任务中，机器人需要识别物体的相关物理属性才能成功执行任务，但无法从失败中恢复或重试，需要人类干预。

Method: 基于强化学习的任务信息探索方法，使用特权任务策略对属性估计误差的敏感性自动生成奖励来训练探索策略，并引入基于不确定性的机制来确定何时从探索过渡到任务执行。

Result: 在击球任务中达到90%成功率，平均探索时间低于1.2秒，显著优于基线方法（最多40%成功率），并在KUKA iiwa机械臂上验证了识别物体属性和调整任务执行的能力。

Conclusion: 该方法能够有效捕获物理属性的相对重要性，实现高效的属性估计和任务执行，在真实物理设置中验证了其有效性。

Abstract: In many dynamic robotic tasks, such as striking pucks into a goal outside the
reachable workspace, the robot must first identify the relevant physical
properties of the object for successful task execution, as it is unable to
recover from failure or retry without human intervention. To address this
challenge, we propose a task-informed exploration approach, based on
reinforcement learning, that trains an exploration policy using rewards
automatically generated from the sensitivity of a privileged task policy to
errors in estimated properties. We also introduce an uncertainty-based
mechanism to determine when to transition from exploration to task execution,
ensuring sufficient property estimation accuracy with minimal exploration time.
Our method achieves a 90% success rate on the striking task with an average
exploration time under 1.2 seconds, significantly outperforming baselines that
achieve at most 40% success or require inefficient querying and retraining in a
simulator at test time. Additionally, we demonstrate that our task-informed
rewards capture the relative importance of physical properties in both the
striking task and the classical CartPole example. Finally, we validate our
approach by demonstrating its ability to identify object properties and adjust
task execution in a physical setup using the KUKA iiwa robot arm.

</details>


### [11] [Gray-Box Computed Torque Control for Differential-Drive Mobile Robot Tracking](https://arxiv.org/abs/2509.00571)
*Arman Javan Sekhavat Pishkhani*

Main category: cs.RO

TL;DR: 基于深度强化学习的计算转矩控制算法，提高差动轮移动机器人踪踪控制的样本效率和稳定性


<details>
  <summary>Details</summary>
Motivation: 解决计算转矩方法对系统参数准确性的依赖，以及深度强化学习算法样本效率低和稳定性保证弱的问题

Method: 将DRL策略网络替换为灰盒计算转矩控制器，使用TD3算法寻找最优控制器参数，并加入物理可行性约束和临界阻尼间响应要求

Result: 在MuJoCo模拟环境中评估控制器性能，与原始计算转矩控制器和传统运动学控制器进行对比

Conclusion: 提出的灰盒控制器结构在保持闭环系统稳定性的同时，显著提高了学习效率，只需少量短时间学习就能获得优称控制效果

Abstract: This study presents a learning-based nonlinear algorithm for tracking control
of differential-drive mobile robots. The Computed Torque Method (CTM) suffers
from inaccurate knowledge of system parameters, while Deep Reinforcement
Learning (DRL) algorithms are known for sample inefficiency and weak stability
guarantees. The proposed method replaces the black-box policy network of a DRL
agent with a gray-box Computed Torque Controller (CTC) to improve sample
efficiency and ensure closed-loop stability. This approach enables finding an
optimal set of controller parameters for an arbitrary reward function using
only a few short learning episodes. The Twin-Delayed Deep Deterministic Policy
Gradient (TD3) algorithm is used for this purpose. Additionally, some
controller parameters are constrained to lie within known value ranges,
ensuring the RL agent learns physically plausible values. A technique is also
applied to enforce a critically damped closed-loop time response. The
controller's performance is evaluated on a differential-drive mobile robot
simulated in the MuJoCo physics engine and compared against the raw CTC and a
conventional kinematic controller.

</details>


### [12] [First Order Model-Based RL through Decoupled Backpropagation](https://arxiv.org/abs/2509.00215)
*Joseph Amigo,Rooholla Khorrambakht,Elliot Chane-Sane,Nicolas Mansard,Ludovic Righetti*

Main category: cs.RO

TL;DR: 提出了一种结合模拟器轨迹生成和学习模型梯度计算的混合方法，实现高效的一阶策略优化，无需模拟器梯度，在样本效率和泛化性方面表现优异


<details>
  <summary>Details</summary>
Motivation: 传统基于梯度的RL方法需要模拟器导数，但实际中往往难以获取；基于模型的RL方法存在预测误差累积问题，影响策略性能

Method: 将轨迹生成与梯度计算解耦：使用模拟器展开轨迹，同时通过学习的可微分模型进行反向传播计算梯度

Result: 在基准控制任务和真实Go2四足机器人上验证有效，实现了SHAC等专用优化器的样本效率和速度，同时保持了PPO等标准方法的泛化性

Conclusion: 该方法解决了模拟器梯度不可用时的策略优化问题，避免了其他一阶MBRL方法的不良行为，在仿真和真实机器人任务中都表现出色

Abstract: There is growing interest in reinforcement learning (RL) methods that
leverage the simulator's derivatives to improve learning efficiency. While
early gradient-based approaches have demonstrated superior performance compared
to derivative-free methods, accessing simulator gradients is often impractical
due to their implementation cost or unavailability. Model-based RL (MBRL) can
approximate these gradients via learned dynamics models, but the solver
efficiency suffers from compounding prediction errors during training rollouts,
which can degrade policy performance. We propose an approach that decouples
trajectory generation from gradient computation: trajectories are unrolled
using a simulator, while gradients are computed via backpropagation through a
learned differentiable model of the simulator. This hybrid design enables
efficient and consistent first-order policy optimization, even when simulator
gradients are unavailable, as well as learning a critic from simulation
rollouts, which is more accurate. Our method achieves the sample efficiency and
speed of specialized optimizers such as SHAC, while maintaining the generality
of standard approaches like PPO and avoiding ill behaviors observed in other
first-order MBRL methods. We empirically validate our algorithm on benchmark
control tasks and demonstrate its effectiveness on a real Go2 quadruped robot,
across both quadrupedal and bipedal locomotion tasks.

</details>


### [13] [Safe and Efficient Lane-Changing for Autonomous Vehicles: An Improved Double Quintic Polynomial Approach with Time-to-Collision Evaluation](https://arxiv.org/abs/2509.00582)
*Rui Bai,Rui Xu,Teng Rui,Jiale Liu,Qi Wei Oung,Hoi Leong Lee,Zhen Tian,Fujiang Yuan*

Main category: cs.RO

TL;DR: 提出了一种改进的双五次多项式方法，通过在轨迹优化过程中直接集成基于碰撞时间(TTC)的评估机制，实现混合交通环境中安全高效的车道变换。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶技术虽然取得了显著进展，但在与人类驾驶车辆(HDVs)的安全舒适交互方面仍存在挑战，特别是在车道变换操作中需要确保安全。

Method: 采用双五次多项式进行轨迹生成，将解析TTC惩罚直接嵌入闭式双五次多项式求解器，包含状态估计、实时TTC计算和自适应轨迹评估。

Result: 在多种交通场景下的广泛仿真表明，相比传统的五次多项式、贝塞尔曲线和B样条方法，该方法在安全性、效率和舒适性方面表现更优，能够避免碰撞并确保平滑过渡。

Conclusion: 这项工作填补了基于模型和自适应轨迹规划方法之间的空白，为现实世界自动驾驶应用提供了稳定的解决方案，实现了实时安全感知的轨迹生成。

Abstract: Autonomous driving technology has made significant advancements in recent
years, yet challenges remain in ensuring safe and comfortable interactions with
human-driven vehicles (HDVs), particularly during lane-changing maneuvers. This
paper proposes an improved double quintic polynomial approach for safe and
efficient lane-changing in mixed traffic environments. The proposed method
integrates a time-to-collision (TTC) based evaluation mechanism directly into
the trajectory optimization process, ensuring that the ego vehicle proactively
maintains a safe gap from surrounding HDVs throughout the maneuver. The
framework comprises state estimation for both the autonomous vehicle (AV) and
HDVs, trajectory generation using double quintic polynomials, real-time TTC
computation, and adaptive trajectory evaluation. To the best of our knowledge,
this is the first work to embed an analytic TTC penalty directly into the
closed-form double-quintic polynomial solver, enabling real-time safety-aware
trajectory generation without post-hoc validation. Extensive simulations
conducted under diverse traffic scenarios demonstrate the safety, efficiency,
and comfort of the proposed approach compared to conventional methods such as
quintic polynomials, Bezier curves, and B-splines. The results highlight that
the improved method not only avoids collisions but also ensures smooth
transitions and adaptive decision-making in dynamic environments. This work
bridges the gap between model-based and adaptive trajectory planning
approaches, offering a stable solution for real-world autonomous driving
applications.

</details>


### [14] [Embodied AI in Social Spaces: Responsible and Adaptive Robots in Complex Setting - UKAIRS 2025 (Copy)](https://arxiv.org/abs/2509.00218)
*Aleksandra Landowska,Aislinn D Gomez Bergin,Ayodeji O. Abioye,Jayati Deshmukh,Andriana Bouadouki,Maria Wheadon,Athina Georgara,Dominic Price,Tuyen Nguyen,Shuang Ao,Lokesh Singh,Yi Long,Raffaele Miele,Joel E. Fischer,Sarvapali D. Ramchurn*

Main category: cs.RO

TL;DR: 开发负责任、自适应的多人类多机器人系统，整合协同设计、伦理框架和多模态感知，创建情感响应、情境感知的AI机器人


<details>
  <summary>Details</summary>
Motivation: 为复杂动态环境开发能够响应人类情感、符合伦理标准、满足多样化用户需求的多人类多机器人系统

Method: 采用多学科方法，整合协同设计、伦理框架和多模态感知技术，开发情感响应和情境感知的AI驱动机器人

Result: 项目展示了早期成果，证明具身AI可以支持可持续、符合伦理和以人为本的未来发展

Conclusion: 该项目为开发负责任、自适应且以人为中心的MHMR系统提供了有前景的框架，展示了具身AI在促进可持续和伦理未来方面的潜力

Abstract: This paper introduces and overviews a multidisciplinary project aimed at
developing responsible and adaptive multi-human multi-robot (MHMR) systems for
complex, dynamic settings. The project integrates co-design, ethical
frameworks, and multimodal sensing to create AI-driven robots that are
emotionally responsive, context-aware, and aligned with the needs of diverse
users. We outline the project's vision, methodology, and early outcomes,
demonstrating how embodied AI can support sustainable, ethical, and
human-centred futures.

</details>


### [15] [Vehicle-in-Virtual-Environment (VVE) Method for Developing and Evaluating VRU Safety of Connected and Autonomous Driving with Focus on Bicyclist Safety](https://arxiv.org/abs/2509.00624)
*Haochong Chen,Xincheng Cao,Bilin Aksun-Guvenc,Levent Guvenc*

Main category: cs.RO

TL;DR: 该研究应用VVE方法开发自动驾驶系统的安全功能，重点关注弱势道路使用者（特别是自行车骑行者）的安全，通过自动转向和制动技术来评估和演示安全性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶研究在弱势道路使用者安全方面存在多个空白，包括缺乏统一的规划避撞系统、延迟容忍控制策略研究不足，以及缺少高效标准化测试方法。VRU安全是自动驾驶领域最紧迫的挑战之一。

Method: 采用车辆在虚拟环境（VVE）方法，开发、评估和演示自动驾驶系统（ADS）的安全功能，重点使用自动转向和制动技术来保护弱势道路使用者。

Result: 项目第二年主要专注于增强第一年成果，并特别考虑了自行车骑行者的安全需求，但具体结果数据未在摘要中提供。

Conclusion: VVE方法为开发自动驾驶系统的VRU安全功能提供了有效的测试和评估框架，特别是在动态不可预测环境中保护自行车骑行者等弱势道路使用者方面具有重要意义。

Abstract: Extensive research has already been conducted in the autonomous driving field
to help vehicles navigate safely and efficiently. At the same time, plenty of
current research on vulnerable road user (VRU) safety is performed which
largely concentrates on perception, localization, or trajectory prediction of
VRUs. However, existing research still exhibits several gaps, including the
lack of a unified planning and collision avoidance system for autonomous
vehicles, limited investigation into delay tolerant control strategies, and the
absence of an efficient and standardized testing methodology. Ensuring VRU
safety remains one of the most pressing challenges in autonomous driving,
particularly in dynamic and unpredictable environments. In this two year
project, we focused on applying the Vehicle in Virtual Environment (VVE) method
to develop, evaluate, and demonstrate safety functions for Vulnerable Road
Users (VRUs) using automated steering and braking of ADS. In this current
second year project report, our primary focus was on enhancing the previous
year results while also considering bicyclist safety.

</details>


### [16] [Learn from What We HAVE: History-Aware VErifier that Reasons about Past Interactions Online](https://arxiv.org/abs/2509.00271)
*Yishu Li,Xinyi Mao,Ying Yuan,Kyutae Sim,Ben Eisner,David Held*

Main category: cs.RO

TL;DR: 提出HAVE方法，通过历史感知验证器解决机器人操作中的视觉模糊问题，将动作生成与验证分离，在模拟和真实环境中验证了有效性


<details>
  <summary>Details</summary>
Motivation: 机器人在操作视觉模糊物体时，生成模型在模糊情况下表现不佳，即使考虑动作历史也难以获得最优性能

Method: 使用无条件扩散生成器提出多个候选动作，通过历史感知验证器基于过去交互选择最有前景的动作

Result: 理论分析表明验证器显著提升动作质量预期，在多个模拟和真实环境（铰接物体、多模态门、不平整物体抓取）中验证了方法有效性

Conclusion: HAVE方法通过显式分离动作生成和验证，有效解决了机器人操作中的视觉模糊问题，优于基线方法

Abstract: We introduce a novel History-Aware VErifier (HAVE) to disambiguate uncertain
scenarios online by leveraging past interactions. Robots frequently encounter
visually ambiguous objects whose manipulation outcomes remain uncertain until
physically interacted with. While generative models alone could theoretically
adapt to such ambiguity, in practice they obtain suboptimal performance in
ambiguous cases, even when conditioned on action history. To address this, we
propose explicitly decoupling action generation from verification: we use an
unconditional diffusion-based generator to propose multiple candidate actions
and employ our history-aware verifier to select the most promising action by
reasoning about past interactions. Through theoretical analysis, we demonstrate
that employing a verifier significantly improves expected action quality.
Empirical evaluations and analysis across multiple simulated and real-world
environments including articulated objects, multi-modal doors, and uneven
object pick-up confirm the effectiveness of our method and improvements over
baselines. Our project website is available at:
https://liy1shu.github.io/HAVE_CoRL25/

</details>


### [17] [A Risk-aware Spatial-temporal Trajectory Planning Framework for Autonomous Vehicles Using QP-MPC and Dynamic Hazard Fields](https://arxiv.org/abs/2509.00643)
*Zhen Tian,Zhihao Lin,Dezong Zhao,Christos Anagnostopoulos,Qiyuan Wang,Wenjing Zhao,Xiaodan Wang,Chongfeng Wei*

Main category: cs.RO

TL;DR: 提出了一种基于QP-MPC的增强型轨迹规划框架，通过动态危险场(DHF)成本函数、时空安全规划和多目标优化，在自动驾驶车辆的各种复杂场景中实现了更好的效率、稳定性和舒适性。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹规划方法存在计算成本高、动态环境下性能不稳定、多样化场景验证有限等问题，需要一种能够同时平衡安全性、效率和舒适性的解决方案。

Method: 采用QP-MPC框架，创新性地引入动态危险场(DHF)进行风险评估，结合时空图进行时间安全规划，使用五次多项式采样和舒适度子奖励确保换道舒适性，通过效率子奖励维持驾驶效率，最终将多目标整合到DHF增强的目标函数中。

Result: 大量仿真实验表明，该框架在换道、超车、交叉口通行等多种场景下，在效率、稳定性和舒适性方面均优于基准优化方法。

Conclusion: 所提出的DHF增强QP-MPC框架为自动驾驶车辆提供了有效的轨迹规划解决方案，能够同时优化安全性、效率和舒适性，在复杂动态环境中表现出色。

Abstract: Trajectory planning is a critical component in ensuring the safety,
stability, and efficiency of autonomous vehicles. While existing trajectory
planning methods have achieved progress, they often suffer from high
computational costs, unstable performance in dynamic environments, and limited
validation across diverse scenarios. To overcome these challenges, we propose
an enhanced QP-MPC-based framework that incorporates three key innovations: (i)
a novel cost function designed with a dynamic hazard field, which explicitly
balances safety, efficiency, and comfort; (ii) seamless integration of this
cost function into the QP-MPC formulation, enabling direct optimization of
desired driving behaviors; and (iii) extensive validation of the proposed
framework across complex tasks. The spatial safe planning is guided by a
dynamic hazard field (DHF) for risk assessment, while temporal safe planning is
based on a space-time graph. Besides, the quintic polynomial sampling and
sub-reward of comforts are used to ensure comforts during lane-changing. The
sub-reward of efficiency is used to maintain driving efficiency. Finally, the
proposed DHF-enhanced objective function integrates multiple objectives,
providing a proper optimization tasks for QP-MPC. Extensive simulations
demonstrate that the proposed framework outperforms benchmark optimization
methods in terms of efficiency, stability, and comfort across a variety of
scenarios likes lane-changing, overtaking, and crossing intersections.

</details>


### [18] [TReF-6: Inferring Task-Relevant Frames from a Single Demonstration for One-Shot Skill Generalization](https://arxiv.org/abs/2509.00310)
*Yuxuan Ding,Shuangge Wang,Tesca Fitzgerald*

Main category: cs.RO

TL;DR: TReF-6是一种从单次演示中推断6自由度任务相关框架的方法，通过轨迹几何识别影响点来定义局部坐标系，结合视觉语言模型实现语义理解和跨场景泛化。


<details>
  <summary>Details</summary>
Motivation: 机器人通常难以从单次演示中泛化，因为缺乏可迁移和可解释的空间表示。需要一种能够从轨迹中提取抽象空间结构的方法来实现一次性模仿学习。

Method: 从轨迹几何中识别影响点来定义局部坐标系的原点，作为动态运动基元(DMP)的参数化参考。通过视觉语言模型进行语义接地，使用Grounded-SAM在新场景中定位框架。

Result: 在仿真中验证了TReF-6的有效性，展示了对轨迹噪声的鲁棒性。在真实世界操作任务中部署端到端管道，支持一次性模仿学习并在不同物体配置下保持任务意图。

Conclusion: TReF-6提供了一种可解释的空间表示方法，能够从单次演示中提取任务相关框架，实现功能一致的技能泛化，超越了传统的起点-终点模仿方法。

Abstract: Robots often struggle to generalize from a single demonstration due to the
lack of a transferable and interpretable spatial representation. In this work,
we introduce TReF-6, a method that infers a simplified, abstracted 6DoF
Task-Relevant Frame from a single trajectory. Our approach identifies an
influence point purely from the trajectory geometry to define the origin for a
local frame, which serves as a reference for parameterizing a Dynamic Movement
Primitive (DMP). This influence point captures the task's spatial structure,
extending the standard DMP formulation beyond start-goal imitation. The
inferred frame is semantically grounded via a vision-language model and
localized in novel scenes by Grounded-SAM, enabling functionally consistent
skill generalization. We validate TReF-6 in simulation and demonstrate
robustness to trajectory noise. We further deploy an end-to-end pipeline on
real-world manipulation tasks, showing that TReF-6 supports one-shot imitation
learning that preserves task intent across diverse object configurations.

</details>


### [19] [Hybrid Autonomy Framework for a Future Mars Science Helicopter](https://arxiv.org/abs/2509.01980)
*Luca Di Pierno,Robert Hewitt,Stephan Weiss,Roland Brockers*

Main category: cs.RO

TL;DR: NASA开发火星科学直升机自主控制框架，结合有限状态机和行为树，实现可扩展、鲁棒且计算高效的深空探索自主解决方案


<details>
  <summary>Details</summary>
Motivation: 解决地球-火星通信延迟问题，确保火星科学直升机在复杂任务中无需人工干预的安全高效运行

Method: 采用有限状态机(FSM)与行为树(BTs)混合的确定性高层控制框架，支持中间件无关集成

Result: 通过蒙特卡洛模拟和实地测试验证，框架对离散事件和实时系统反馈表现出鲁棒性和适应性

Conclusion: 该自主框架成功实现反应式和上下文感知响应，可扩展到航空机器人以外的应用领域

Abstract: Autonomous aerial vehicles, such as NASA's Ingenuity, enable rapid planetary
surface exploration beyond the reach of ground-based robots. Thus, NASA is
studying a Mars Science Helicopter (MSH), an advanced concept capable of
performing long-range science missions and autonomously navigating challenging
Martian terrain. Given significant Earth-Mars communication delays and mission
complexity, an advanced autonomy framework is required to ensure safe and
efficient operation by continuously adapting behavior based on mission
objectives and real-time conditions, without human intervention. This study
presents a deterministic high-level control framework for aerial exploration,
integrating a Finite State Machine (FSM) with Behavior Trees (BTs) to achieve a
scalable, robust, and computationally efficient autonomy solution for critical
scenarios like deep space exploration. In this paper we outline key
capabilities of a possible MSH and detail the FSM-BT hybrid autonomy framework
which orchestrates them to achieve the desired objectives. Monte Carlo
simulations and real field tests validate the framework, demonstrating its
robustness and adaptability to both discrete events and real-time system
feedback. These inputs trigger state transitions or dynamically adjust behavior
execution, enabling reactive and context-aware responses. The framework is
middleware-agnostic, supporting integration with systems like F-Prime and
extending beyond aerial robotics.

</details>


### [20] [A Framework for Task and Motion Planning based on Expanding AND/OR Graphs](https://arxiv.org/abs/2509.00317)
*Fulvio Mastrogiovanni,Antony Thomas*

Main category: cs.RO

TL;DR: 提出了基于扩展AND/OR图的TMP-EAOG框架，用于空间机器人任务与运动规划，具有鲁棒性、可控自主性和有限灵活性。


<details>
  <summary>Details</summary>
Motivation: 空间环境中的机器人自主性面临感知和运动不确定性、严格运动学约束以及人类干预机会有限等独特挑战，需要能够处理这些问题的任务与运动规划方法。

Method: TMP-EAOG框架在AND/OR图中编码任务级抽象，通过迭代扩展图结构并在循环中执行运动规划可行性评估。

Result: 在模拟移动机械臂上的评估表明，TMP-EAOG能够处理基准测试中的各种挑战，展现出良好的适应性。

Conclusion: TMP-EAOG框架为空间自主机器人提供了一种有效的任务与运动规划解决方案，具有应对不确定性和意外事件的能力。

Abstract: Robot autonomy in space environments presents unique challenges, including
high perception and motion uncertainty, strict kinematic constraints, and
limited opportunities for human intervention. Therefore, Task and Motion
Planning (TMP) may be critical for autonomous servicing, surface operations, or
even in-orbit missions, just to name a few, as it models tasks as discrete
action sequencing integrated with continuous motion feasibility assessments. In
this paper, we introduce a TMP framework based on expanding AND/OR graphs,
referred to as TMP-EAOG, and demonstrate its adaptability to different
scenarios. TMP-EAOG encodes task-level abstractions within an AND/OR graph,
which expands iteratively as the plan is executed, and performs in-the-loop
motion planning assessments to ascertain their feasibility. As a consequence,
TMP-EAOG is characterised by the desirable properties of (i) robustness to a
certain degree of uncertainty, because AND/OR graph expansion can accommodate
for unpredictable information about the robot environment, (ii) controlled
autonomy, since an AND/OR graph can be validated by human experts, and (iii)
bounded flexibility, in that unexpected events, including the assessment of
unfeasible motions, can lead to different courses of action as alternative
paths in the AND/OR graph. We evaluate TMP-EAOG on two benchmark domains. We
use a simulated mobile manipulator as a proxy for space-grade autonomous
robots. Our evaluation shows that TMP-EAOG can deal with a wide range of
challenges in the benchmarks.

</details>


### [21] [Adaptive Navigation Strategy for Low-Thrust Proximity Operations in Circular Relative Orbit](https://arxiv.org/abs/2509.02204)
*Dario Ruggiero,Mauro Mancini,Elisa Capello*

Main category: cs.RO

TL;DR: 提出了一种基于自适应观测器的航天器导航策略，用于圆形相对轨道场景，通过动态调整观测器增益实现快速收敛和低噪声敏感性。


<details>
  <summary>Details</summary>
Motivation: 解决航天器近距离操作（如编队飞行和非合作目标检测）中的状态估计挑战，传统固定增益观测器在收敛速度和噪声敏感性方面存在局限。

Method: 采用自适应观测器方法，根据估计状态动态调整观测器增益，结合Lyapunov稳定性分析确保系统稳定性和估计精度。

Result: 仿真验证表明，相比传统固定增益观测器，该方法提高了轨迹跟踪精度，减少了控制输入切换，在视觉传感器数据下表现良好。

Conclusion: 该方法为自主航天器定位和控制提供了一种有前景的解决方案，特别适用于圆形相对轨道场景的导航需求。

Abstract: This paper presents an adaptive observer-based navigation strategy for
spacecraft in Circular Relative Orbit (CRO) scenarios, addressing challenges in
proximity operations like formation flight and uncooperative target inspection.
The proposed method adjusts observer gains based on the estimated state to
achieve fast convergence and low noise sensitivity in state estimation. A
Lyapunov-based analysis ensures stability and accuracy, while simulations using
vision-based sensor data validate the approach under realistic conditions.
Compared to classical observers with time-invariant gains, the proposed method
enhances trajectory tracking precision and reduces control input switching,
making it a promising solution for autonomous spacecraft localization and
control.

</details>


### [22] [Mechanistic interpretability for steering vision-language-action models](https://arxiv.org/abs/2509.00328)
*Bear Häon,Kaylene Stocking,Ian Chuang,Claire Tomlin*

Main category: cs.RO

TL;DR: 视觉-语言-动作模型的机制解释性研究，通过激活值导向识别和调节模型行为，实现无需微调或环境交互的实时控制


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型在机器人实际部署中的稳健性和可解释性挑战，充分利用大语言模型机制解释性的进展

Method: 将transformer层内部激活值投影到令片嵌入基础，识别与动作选择因果相关的稀疏语义方向，并提出通用的激活值导向方法

Result: 在Pi0和OpenVLA两个开源VLA上验证，在模拟环境(LIBERO)和物理机器人(UR5)上实现了零样本行为控制

Conclusion: 体化VLA模型的可解释组件可以系统性地用于控制，为机器人领域的透明可控基础模型建立了新范式

Abstract: Vision-Language-Action (VLA) models are a promising path to realizing
generalist embodied agents that can quickly adapt to new tasks, modalities, and
environments. However, methods for interpreting and steering VLAs fall far
short of classical robotics pipelines, which are grounded in explicit models of
kinematics, dynamics, and control. This lack of mechanistic insight is a
central challenge for deploying learned policies in real-world robotics, where
robustness and explainability are critical. Motivated by advances in
mechanistic interpretability for large language models, we introduce the first
framework for interpreting and steering VLAs via their internal
representations, enabling direct intervention in model behavior at inference
time. We project feedforward activations within transformer layers onto the
token embedding basis, identifying sparse semantic directions - such as speed
and direction - that are causally linked to action selection. Leveraging these
findings, we introduce a general-purpose activation steering method that
modulates behavior in real time, without fine-tuning, reward signals, or
environment interaction. We evaluate this method on two recent open-source
VLAs, Pi0 and OpenVLA, and demonstrate zero-shot behavioral control in
simulation (LIBERO) and on a physical robot (UR5). This work demonstrates that
interpretable components of embodied VLAs can be systematically harnessed for
control - establishing a new paradigm for transparent and steerable foundation
models in robotics.

</details>


### [23] [Autonomous Aggregate Sorting in Construction and Mining via Computer Vision-Aided Robotic Arm Systems](https://arxiv.org/abs/2509.00339)
*Md. Taherul Islam Shawon,Yuan Li,Yincai Cai,Junjie Niu,Ting Peng*

Main category: cs.RO

TL;DR: 基于计算机视觉的机器人系统实现骨料自动分拣，平均成功率97.5%，解决了传统分拣方法精度低、灵活性差的问题


<details>
  <summary>Details</summary>
Motivation: 传统骨料分拣方法（人工或机械）存在精度低、灵活性有限、对不同材料特性适应性差的问题，需要更智能的自动化解决方案

Method: 集成六自由度机械臂、双目立体相机和ROS控制框架，采用注意力增强YOLOv8模型进行检测、立体匹配进行3D定位、DH运动学建模、最小外接矩形分析尺寸估计和手眼标定

Result: 在四种骨料类型上实现了平均97.5%的抓取分拣成功率，分类准确率相当

Conclusion: 该系统展示了提升生产效率、降低运营成本和改善安全性的巨大潜力，为建筑、采矿和回收行业的智能自动化提供了可扩展框架

Abstract: Traditional aggregate sorting methods, whether manual or mechanical, often
suffer from low precision, limited flexibility, and poor adaptability to
diverse material properties such as size, shape, and lithology. To address
these limitations, this study presents a computer vision-aided robotic arm
system designed for autonomous aggregate sorting in construction and mining
applications. The system integrates a six-degree-of-freedom robotic arm, a
binocular stereo camera for 3D perception, and a ROS-based control framework.
Core techniques include an attention-augmented YOLOv8 model for aggregate
detection, stereo matching for 3D localization, Denavit-Hartenberg kinematic
modeling for arm motion control, minimum enclosing rectangle analysis for size
estimation, and hand-eye calibration for precise coordinate alignment.
Experimental validation with four aggregate types achieved an average grasping
and sorting success rate of 97.5%, with comparable classification accuracy.
Remaining challenges include the reliable handling of small aggregates and
texture-based misclassification. Overall, the proposed system demonstrates
significant potential to enhance productivity, reduce operational costs, and
improve safety in aggregate handling, while providing a scalable framework for
advancing smart automation in construction, mining, and recycling industries.

</details>


### [24] [Generative Visual Foresight Meets Task-Agnostic Pose Estimation in Robotic Table-Top Manipulation](https://arxiv.org/abs/2509.00361)
*Chuye Zhang,Xiaoxiong Zhang,Wei Pan,Linfang Zheng,Wei Zhang*

Main category: cs.RO

TL;DR: GVF-TAPE是一个结合生成式视觉预测和任务无关位姿估计的闭环框架，用于实现可扩展的机器人操作，减少对任务特定数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境中的机器人操作需要能够跨多样化任务泛化同时保持鲁棒性的系统，现有方法往往依赖任务特定的动作数据，缺乏通用性。

Method: 使用生成式视频模型从单视角RGB图像和任务描述预测未来RGB-D帧，提供视觉规划；通过解耦的位姿估计模型从预测帧中提取末端执行器位姿，转换为可执行命令；通过闭环迭代整合视觉预测和位姿估计。

Result: 在仿真和真实环境的大量实验中，该方法实现了实时自适应操作，有效泛化到广泛任务范围，减少了对任务特定动作数据的依赖。

Conclusion: GVF-TAPE提供了一个实用且可扩展的智能机器人系统解决方案，通过生成式视觉预测和任务无关位姿估计的闭环整合，实现了强大的泛化能力和实时性能。

Abstract: Robotic manipulation in unstructured environments requires systems that can
generalize across diverse tasks while maintaining robust and reliable
performance. We introduce {GVF-TAPE}, a closed-loop framework that combines
generative visual foresight with task-agnostic pose estimation to enable
scalable robotic manipulation. GVF-TAPE employs a generative video model to
predict future RGB-D frames from a single side-view RGB image and a task
description, offering visual plans that guide robot actions. A decoupled pose
estimation model then extracts end-effector poses from the predicted frames,
translating them into executable commands via low-level controllers. By
iteratively integrating video foresight and pose estimation in a closed loop,
GVF-TAPE achieves real-time, adaptive manipulation across a broad range of
tasks. Extensive experiments in both simulation and real-world settings
demonstrate that our approach reduces reliance on task-specific action data and
generalizes effectively, providing a practical and scalable solution for
intelligent robotic systems.

</details>


### [25] [Embodied Spatial Intelligence: from Implicit Scene Modeling to Spatial Reasoning](https://arxiv.org/abs/2509.00465)
*Jiading Fang*

Main category: cs.RO

TL;DR: 本论文提出"体验式空间智能"概念，通过隐式神经场景表征和增强大语言模型空间推理能力，解决机器人根据自然语言指令在真实世界中感知和行动的挑战。


<details>
  <summary>Details</summary>
Motivation: 克服大语言模型(LLMs)与物理体验之间的差距，创造能够根据自然语言指令在真实世界中感知和行动的机器人。

Method: 在景观表征方面：使用隐式神经模型开发稳健、可扩展和准确的场景表征，包括自监督相机标定、高保真度深度场生成和大规模重建。在空间推理方面：通过引入新的导航标准、语言在3D环境中基础化方法和状态反馈机制来增强LLMs的空间能力。

Result: 为机器人能够稳健感知周围环境并智能地执行复杂语言命令奠定了基础。

Conclusion: 该研究成功构建了体验式空间智能的基础框架，有效缩小了语言模型与物理世界之间的差距，为未来智能机器人的发展提供了重要技术支撑。

Abstract: This thesis introduces "Embodied Spatial Intelligence" to address the
challenge of creating robots that can perceive and act in the real world based
on natural language instructions. To bridge the gap between Large Language
Models (LLMs) and physical embodiment, we present contributions on two fronts:
scene representation and spatial reasoning. For perception, we develop robust,
scalable, and accurate scene representations using implicit neural models, with
contributions in self-supervised camera calibration, high-fidelity depth field
generation, and large-scale reconstruction. For spatial reasoning, we enhance
the spatial capabilities of LLMs by introducing a novel navigation benchmark, a
method for grounding language in 3D, and a state-feedback mechanism to improve
long-horizon decision-making. This work lays a foundation for robots that can
robustly perceive their surroundings and intelligently act upon complex,
language-based commands.

</details>


### [26] [Extended Diffeomorphism for Real-Time Motion Replication in Workspaces with Different Spatial Arrangements](https://arxiv.org/abs/2509.00491)
*Masaki Saito,Shunki Itadera,Toshiyuki Murakami*

Main category: cs.RO

TL;DR: 提出两种扩展微分同胚设计来补偿机器人工作空间之间的空间位置差异，通过关键点映射实现多机器人遥操作中的平滑运动复制


<details>
  <summary>Details</summary>
Motivation: 多机器人遥操作需要实时复制机器人运动以提高相似任务的执行效率，但面临机器人工作空间空间布置误差补偿的挑战

Method: 基于预定义关键点的平滑映射方法，将主机器人姿态转换为从机器人姿态，使用扩展微分同胚设计

Result: 通过双UR5机械臂拾取任务实验证明，该方法能够在精确操作的较低映射误差和平滑复制的较低映射梯度之间取得平衡

Conclusion: 所提出的映射生成方法有效解决了多机器人运动复制中的空间布置补偿问题，实现了精确且平滑的运动传输

Abstract: This paper presents two types of extended diffeomorphism designs to
compensate for spatial placement differences between robot workspaces.
Teleoperation of multiple robots is attracting attention to expand the
utilization of the robot embodiment. Real-time reproduction of robot motion
would facilitate the efficient execution of similar tasks by multiple robots. A
challenge in the motion reproduction is compensating for the spatial
arrangement errors of target keypoints in robot workspaces. This paper proposes
a methodology for smooth mappings that transform primary robot poses into
follower robot poses based on the predefined key points in each workspace.
Through a picking task experiment using a dual-arm UR5 robot, this study
demonstrates that the proposed mapping generation method can balance lower
mapping errors for precise operation and lower mapping gradients for smooth
replicated movement.

</details>


### [27] [FLUID: A Fine-Grained Lightweight Urban Signalized-Intersection Dataset of Dense Conflict Trajectories](https://arxiv.org/abs/2509.00497)
*Yiyang Chen,Zhigang Wu,Guohong Zheng,Xuesong Wu,Liwen Xu,Haoyuan Tang,Zhaocheng He,Haipeng Zeng*

Main category: cs.RO

TL;DR: FLUID是一个基于无人机采集的精细交通轨迹数据集，包含三种典型城市信号交叉口的高密度冲突数据，提供超过2万个交通参与者的轨迹、信号灯、地图和原始视频数据，具有高时空精度。


<details>
  <summary>Details</summary>
Motivation: 现有无人机采集的交通数据集在场景代表性、信息丰富度和数据保真度方面存在局限，需要更全面的交叉口交通冲突数据来支持交通评估和政策优化。

Method: 使用无人机采集三个不同类型城市信号交叉口的交通数据，构建包含轨迹、交通信号、地图和原始视频的完整数据集，并通过与DataFromSky平台和地面真实测量对比验证准确性。

Result: 数据集包含约5小时记录时间，覆盖8类超过20,000个交通参与者，平均每分钟发生两次车辆冲突，涉及约25%的机动车辆，展示了多样化的交互行为。

Conclusion: FLUID数据集为人类偏好挖掘、交通行为建模和自动驾驶研究提供了宝贵资源，展示了城市交叉口复杂交通互动的多样性。

Abstract: The trajectory data of traffic participants (TPs) is a fundamental resource
for evaluating traffic conditions and optimizing policies, especially at urban
intersections. Although data acquisition using drones is efficient, existing
datasets still have limitations in scene representativeness, information
richness, and data fidelity. This study introduces FLUID, comprising a
fine-grained trajectory dataset that captures dense conflicts at typical urban
signalized intersections, and a lightweight, full-pipeline framework for
drone-based trajectory processing. FLUID covers three distinct intersection
types, with approximately 5 hours of recording time and featuring over 20,000
TPs across 8 categories. Notably, the dataset averages two vehicle conflicts
per minute, involving roughly 25% of all motor vehicles. FLUID provides
comprehensive data, including trajectories, traffic signals, maps, and raw
videos. Comparison with the DataFromSky platform and ground-truth measurements
validates its high spatio-temporal accuracy. Through a detailed classification
of motor vehicle conflicts and violations, FLUID reveals a diversity of
interactive behaviors, demonstrating its value for human preference mining,
traffic behavior modeling, and autonomous driving research.

</details>


### [28] [NeuralSVCD for Efficient Swept Volume Collision Detection](https://arxiv.org/abs/2509.00499)
*Dongwon Son,Hojin Jung,Beomjoon Kim*

Main category: cs.RO

TL;DR: NeuralSVCD是一种新颖的神经编码器-解码器架构，用于机器人操作中的扫描体积碰撞检测，通过分布式几何表示和时间优化来同时提高计算效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统离散碰撞检测方法可能在采样点之间遗漏碰撞，而现有扫描体积碰撞检测方法在效率和准确性之间存在权衡，限制了实际应用。

Method: 提出神经编码器-解码器架构，利用形状局部性和时间局部性，通过分布式几何表示和时间优化来提升计算效率。

Result: 综合实验表明，NeuralSVCD在碰撞检测准确性和计算效率方面均优于现有最先进方法，适用于各种机器人操作场景。

Conclusion: NeuralSVCD成功克服了效率与准确性之间的权衡，为无结构环境中的机器人操作提供了高效可靠的碰撞检测解决方案。

Abstract: Robot manipulation in unstructured environments requires efficient and
reliable Swept Volume Collision Detection (SVCD) for safe motion planning.
Traditional discrete methods potentially miss collisions between these points,
whereas SVCD continuously checks for collisions along the entire trajectory.
Existing SVCD methods typically face a trade-off between efficiency and
accuracy, limiting practical use. In this paper, we introduce NeuralSVCD, a
novel neural encoder-decoder architecture tailored to overcome this trade-off.
Our approach leverages shape locality and temporal locality through distributed
geometric representations and temporal optimization. This enhances
computational efficiency without sacrificing accuracy. Comprehensive
experiments show that NeuralSVCD consistently outperforms existing
state-of-the-art SVCD methods in terms of both collision detection accuracy and
computational efficiency, demonstrating its robust applicability across diverse
robotic manipulation scenarios. Code and videos are available at
https://neuralsvcd.github.io/.

</details>


### [29] [Reinforcement Learning of Dolly-In Filming Using a Ground-Based Robot](https://arxiv.org/abs/2509.00564)
*Philip Lorimer,Jack Saunders,Alan Hunter,Wenbin Li*

Main category: cs.RO

TL;DR: 使用强化学习自动化自由移动摄影机器人的推轨镜头拍摄，相比传统控制方法表现更优


<details>
  <summary>Details</summary>
Motivation: 解决自由移动摄影推车在自动化摄像机控制方面的挑战，推动技术与电影创作的融合

Method: 应用强化学习(RL)算法，在改进的ROSBot 2.0平台上结合摄像机云台进行联合控制

Result: RL管道在仿真中超越传统比例微分控制器性能，并在真实世界测试中验证了有效性

Conclusion: 该方法为复杂拍摄场景研究奠定了基础，显著促进了技术进步与电影创意的结合

Abstract: Free-roaming dollies enhance filmmaking with dynamic movement, but challenges
in automated camera control remain unresolved. Our study advances this field by
applying Reinforcement Learning (RL) to automate dolly-in shots using
free-roaming ground-based filming robots, overcoming traditional control
hurdles. We demonstrate the effectiveness of combined control for precise film
tasks by comparing it to independent control strategies. Our robust RL pipeline
surpasses traditional Proportional-Derivative controller performance in
simulation and proves its efficacy in real-world tests on a modified ROSBot 2.0
platform equipped with a camera turret. This validates our approach's
practicality and sets the stage for further research in complex filming
scenarios, contributing significantly to the fusion of technology with
cinematic creativity. This work presents a leap forward in the field and opens
new avenues for research and development, effectively bridging the gap between
technological advancement and creative filmmaking.

</details>


### [30] [ConceptBot: Enhancing Robot's Autonomy through Task Decomposition with Large Language Models and Knowledge Graph](https://arxiv.org/abs/2509.00570)
*Alessandro Leanza,Angelo Moroncelli,Giuseppe Vizzari,Francesco Braghin,Loris Roveda,Blerina Spahiu*

Main category: cs.RO

TL;DR: ConceptBot是一个结合大语言模型和知识图谱的模块化机器人规划框架，能够处理自然语言指令的模糊性并生成可行且风险感知的规划策略


<details>
  <summary>Details</summary>
Motivation: 解决机器人规划中因缺乏常识推理而导致的自然语言指令模糊性和环境对象分析困难的问题

Method: 集成三个模块：(i)对象属性提取模块，用ConceptNet丰富场景理解；(ii)用户请求处理模块，消歧和结构化指令；(iii)规划器，生成上下文感知的拾放策略

Result: 在比较评估中，ConceptBot在显式任务上达到100%成功率，隐式任务87%准确率（SayCan为31%），风险感知任务76%（SayCan为15%），在材料分类和毒性检测等应用场景中均优于SayCan，在SafeAgentBench上总体得分80%

Conclusion: ConceptBot能够无需领域特定训练即可泛化，并显著提高非结构化环境中机器人策略的可靠性

Abstract: ConceptBot is a modular robotic planning framework that combines Large
Language Models and Knowledge Graphs to generate feasible and risk-aware plans
despite ambiguities in natural language instructions and correctly analyzing
the objects present in the environment - challenges that typically arise from a
lack of commonsense reasoning. To do that, ConceptBot integrates (i) an Object
Property Extraction (OPE) module that enriches scene understanding with
semantic concepts from ConceptNet, (ii) a User Request Processing (URP) module
that disambiguates and structures instructions, and (iii) a Planner that
generates context-aware, feasible pick-and-place policies. In comparative
evaluations against Google SayCan, ConceptBot achieved 100% success on explicit
tasks, maintained 87% accuracy on implicit tasks (versus 31% for SayCan),
reached 76% on risk-aware tasks (versus 15%), and outperformed SayCan in
application-specific scenarios, including material classification (70% vs. 20%)
and toxicity detection (86% vs. 36%). On SafeAgentBench, ConceptBot achieved an
overall score of 80% (versus 46% for the next-best baseline). These results,
validated in both simulation and laboratory experiments, demonstrate
ConceptBot's ability to generalize without domain-specific training and to
significantly improve the reliability of robotic policies in unstructured
environments. Website: https://sites.google.com/view/conceptbot

</details>


### [31] [Learning Dolly-In Filming From Demonstration Using a Ground-Based Robot](https://arxiv.org/abs/2509.00574)
*Philip Lorimer,Alan Hunter,Wenbin Li*

Main category: cs.RO

TL;DR: 使用生成对抗模仿学习(GAIL)的从演示中学习方法，通过专家演示训练电影摄影机器人，无需手工设计奖励函数，实现了更好的拍摄效果和实时部署


<details>
  <summary>Details</summary>
Motivation: 电影摄影控制需要精确性和艺术性的平衡，传统强化学习方法依赖手工设计的奖励函数和大量调参，限制了创作可用性

Method: 采用从演示中学习(LfD)方法，使用生成对抗模仿学习(GAIL)。通过摇杆遥操作在模拟环境中收集专家轨迹，捕捉流畅、富有表现力的运动，无需显式目标设计

Result: GAIL策略在模拟环境中优于PPO基线，获得更高奖励、更快收敛和更低方差。无需微调即可直接迁移到真实机器人，比之前的TD3方法获得更一致的构图和主体对齐

Conclusion: LfD为电影领域提供了无需奖励函数的鲁棒替代方案，能够以最少的技术努力实现实时部署，使直观、风格化的相机控制触手可及，弥合艺术意图与机器人自主性之间的差距

Abstract: Cinematic camera control demands a balance of precision and artistry -
qualities that are difficult to encode through handcrafted reward functions.
While reinforcement learning (RL) has been applied to robotic filmmaking, its
reliance on bespoke rewards and extensive tuning limits creative usability. We
propose a Learning from Demonstration (LfD) approach using Generative
Adversarial Imitation Learning (GAIL) to automate dolly-in shots with a
free-roaming, ground-based filming robot. Expert trajectories are collected via
joystick teleoperation in simulation, capturing smooth, expressive motion
without explicit objective design.
  Trained exclusively on these demonstrations, our GAIL policy outperforms a
PPO baseline in simulation, achieving higher rewards, faster convergence, and
lower variance. Crucially, it transfers directly to a real-world robot without
fine-tuning, achieving more consistent framing and subject alignment than a
prior TD3-based method. These results show that LfD offers a robust,
reward-free alternative to RL in cinematic domains, enabling real-time
deployment with minimal technical effort. Our pipeline brings intuitive,
stylized camera control within reach of creative professionals, bridging the
gap between artistic intent and robotic autonomy.

</details>


### [32] [Galaxea Open-World Dataset and G0 Dual-System VLA Model](https://arxiv.org/abs/2509.00576)
*Tao Jiang,Tianyuan Yuan,Yicheng Liu,Chenhao Lu,Jianning Cui,Xiao Liu,Shuiqi Cheng,Jiyang Gao,Huazhe Xu,Hang Zhao*

Main category: cs.RO

TL;DR: 提出了Galaxea开放世界数据集和G0双系统框架，通过三阶段课程学习在机器人任务中实现强性能


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人在真实人类生活和工作环境中执行复杂任务的需求，需要大规模、多样化的数据集和有效的学习框架

Method: 构建Galaxea开放世界数据集，包含精确的子任务级语言标注；提出G0双系统框架，结合VLM进行多模态规划和VLA进行细粒度执行；采用三阶段课程学习：跨具身预训练、单具身预训练和任务特定后训练

Result: 在桌面操作、少样本学习和长时程移动操作等综合基准测试中表现出色，特别是单具身预训练阶段和Galaxea数据集对性能提升至关重要

Conclusion: Galaxea数据集和G0框架为机器人在开放世界环境中的学习和执行提供了有效的解决方案，单具身预训练是关键成功因素

Abstract: We present Galaxea Open-World Dataset, a large-scale, diverse collection of
robot behaviors recorded in authentic human living and working environments.
All demonstrations are gathered using a consistent robotic embodiment, paired
with precise subtask-level language annotations to facilitate both training and
evaluation. Building on this dataset, we introduce G0, a dual-system framework
that couples a Vision-Language Model (VLM) for multimodal planning with a
Vision-Language-Action (VLA) model for fine-grained execution. G0 is trained
using a three-stage curriculum: cross-embodiment pre-training,
single-embodiment pre-training, and task-specific post-training. A
comprehensive benchmark spanning tabletop manipulation, few-shot learning, and
long-horizon mobile manipulation, demonstrates the effectiveness of our
approach. In particular, we find that the single-embodiment pre-training stage,
together with the Galaxea Open-World Dataset, plays a critical role in
achieving strong performance.

</details>


### [33] [CARIS: A Context-Adaptable Robot Interface System for Personalized and Scalable Human-Robot Interaction](https://arxiv.org/abs/2509.00660)
*Felipe Arias-Russi,Yuanchen Bai,Angelique Taylor*

Main category: cs.RO

TL;DR: 开发了一个名为CARIS的情境自适应机器人界面系统，用于改进传统的Wizard-of-Oz控制方法，使其能够跨不同情境、用户和机器人平台使用。


<details>
  <summary>Details</summary>
Motivation: 传统Wizard-of-Oz工具通常局限于单一情境，难以适应不同设置、用户和机器人平台的需求，限制了人机交互研究的灵活性。

Method: 开发了CARIS系统，集成了远程操作、人类感知、人机对话和多模态数据记录等先进机器人功能，并通过在两个情境（心理健康伴侣和导游）中的试点研究进行验证。

Result: 试点研究表明CARIS具有在多情境下进行Wizard-of-Oz控制的潜力，同时识别了需要改进的领域，包括运动与通信的平滑集成、功能分离、推荐提示和一键通信选项。

Conclusion: CARIS为HRI研究社区提供了一个公开可用的情境自适应工具，能够帮助研究人员更高效地开发数据驱动的智能机器人行为方法。

Abstract: The human-robot interaction (HRI) field has traditionally used Wizard-of-Oz
(WoZ) controlled robots to explore navigation, conversational dynamics,
human-in-the-loop interactions, and more to explore appropriate robot behaviors
in everyday settings. However, existing WoZ tools are often limited to one
context, making them less adaptable across different settings, users, and
robotic platforms. To mitigate these issues, we introduce a Context-Adaptable
Robot Interface System (CARIS) that combines advanced robotic capabilities such
teleoperation, human perception, human-robot dialogue, and multimodal data
recording. Through pilot studies, we demonstrate the potential of CARIS to WoZ
control a robot in two contexts: 1) mental health companion and as a 2) tour
guide. Furthermore, we identified areas of improvement for CARIS, including
smoother integration between movement and communication, clearer functionality
separation, recommended prompts, and one-click communication options to enhance
the usability wizard control of CARIS. This project offers a publicly
available, context-adaptable tool for the HRI community, enabling researchers
to streamline data-driven approaches to intelligent robot behavior.

</details>


### [34] [DyPho-SLAM : Real-time Photorealistic SLAM in Dynamic Environments](https://arxiv.org/abs/2509.00741)
*Yi Liu,Keyu Fan,Bin Lan,Houde Liu*

Main category: cs.RO

TL;DR: DyPho-SLAM是一种实时视觉SLAM系统，针对动态环境中的移动物体干扰问题，通过集成先验图像信息生成精细化掩码，并采用自适应特征提取策略，在动态RGB-D数据集上实现了最先进的相机位姿估计和密集地图重建性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉SLAM算法在静态环境中表现可靠，但在处理动态物体干扰时经常遇到相机跟踪漂移和模糊映射问题，需要开发能够有效处理动态环境的实时SLAM系统。

Method: 系统集成了先验图像信息来生成精细化掩码，有效减少掩码误判带来的噪声；设计了自适应特征提取策略来增强移除动态障碍物后的优化约束，显著提高系统鲁棒性。

Result: 在公开动态RGB-D数据集上的实验表明，该系统在相机位姿估计和密集地图重建方面达到了最先进的性能，同时能够在动态场景中实时运行。

Conclusion: DyPho-SLAM成功解决了动态环境中视觉SLAM的挑战，通过创新的掩码生成和特征提取策略，实现了实时、高效的定位和逼真地图重建。

Abstract: Visual SLAM algorithms have been enhanced through the exploration of Gaussian
Splatting representations, particularly in generating high-fidelity dense maps.
While existing methods perform reliably in static environments, they often
encounter camera tracking drift and fuzzy mapping when dealing with the
disturbances caused by moving objects. This paper presents DyPho-SLAM, a
real-time, resource-efficient visual SLAM system designed to address the
challenges of localization and photorealistic mapping in environments with
dynamic objects. Specifically, the proposed system integrates prior image
information to generate refined masks, effectively minimizing noise from mask
misjudgment. Additionally, to enhance constraints for optimization after
removing dynamic obstacles, we devise adaptive feature extraction strategies
significantly improving the system's resilience. Experiments conducted on
publicly dynamic RGB-D datasets demonstrate that the proposed system achieves
state-of-the-art performance in camera pose estimation and dense map
reconstruction, while operating in real-time in dynamic scenes.

</details>


### [35] [Inverse Kinematics for a 6-Degree-of-Freedom Robot Manipulator Using Comprehensive Gröbner Systems](https://arxiv.org/abs/2509.00823)
*Takumu Okazaki,Akira Terui,Masahiko Mikawa*

Main category: cs.RO

TL;DR: 使用计算机代数和维纳基CGS方法解决6自由度机器人逆运动学问题，扩展了可解的机器人类型范围


<details>
  <summary>Details</summary>
Motivation: 解决更广泛类型的6-DOF机器人逆运动学问题，提高解题效率

Method: 扩展了三轴交点方法到两轴交点情况，使用CGS技术将关节参数作为系数参数避免重复计算

Result: 实验证明方法有效，能够解决更广泛类型的逆运动学问题

Conclusion: 该方法扩展了可解逆运动学问题的6-DOF机器人类型范围，有助于提高解题效率

Abstract: We propose an effective method for solving the inverse kinematic problem of a
specific model of 6-degree-of-freedom (6-DOF) robot manipulator using computer
algebra. It is known that when the rotation axes of three consecutive
rotational joints of a manipulator intersect at a single point, the inverse
kinematics problem can be divided into determining position and orientation. We
extend this method to more general manipulators in which the rotational axes of
two consecutive joints intersect. This extension broadens the class of 6-DOF
manipulators for which the inverse kinematics problem can be solved, and is
expected to enable more efficient solutions. The inverse kinematic problem is
solved using the Comprehensive Gr\"obner System (CGS) with joint parameters of
the robot appearing as parameters in the coefficients to prevent repetitive
calculations of the Gr\"obner bases. The effectiveness of the proposed method
is shown by experiments.

</details>


### [36] [An Effective Trajectory Planning and an Optimized Path Planning for a 6-Degree-of-Freedom Robot Manipulator](https://arxiv.org/abs/2509.00828)
*Takumu Okazaki,Akira Terui,Masahiko Mikawa*

Main category: cs.RO

TL;DR: 提出了一种基于计算机代数的6自由度机器人路径规划优化方法，通过逆运动学求解、可行区域计算和Dijkstra算法寻找最优关节配置序列


<details>
  <summary>Details</summary>
Motivation: 为了解决6自由度机器人末端执行器沿指定轨迹运动时，如何选择最优的逆运动学解序列以最小化关节运动量的问题

Method: 三步骤方法：1)计算末端执行器特定配置下的可行区域 2)在轨迹线段上寻找路径和关节配置序列 3)将问题转化为图的最短路径问题并应用Dijkstra算法

Result: 通过实验验证了所提方法的有效性

Conclusion: 该方法能够有效优化6自由度机器人的路径规划，通过代数计算和图搜索算法找到最优的关节配置序列

Abstract: An effective method for optimizing path planning for a specific model of a
6-degree-of-freedom (6-DOF) robot manipulator is presented as part of the
motion planning of the manipulator using computer algebra. We assume that we
are given a path in the form of a set of line segments that the end-effector
should follow. We also assume that we have a method to solve the inverse
kinematic problem of the manipulator at each via-point of the trajectory. The
proposed method consists of three steps. First, we calculate the feasible
region of the manipulator under a specific configuration of the end-effector.
Next, we aim to find a trajectory on the line segments and a sequence of joint
configurations the manipulator should follow to move the end-effector along the
specified trajectory. Finally, we find the optimal combination of solutions to
the inverse kinematic problem at each via-point along the trajectory by
reducing the problem to a shortest-path problem of the graph and applying
Dijkstra's algorithm. We show the effectiveness of the proposed method by
experiments.

</details>


### [37] [One-Step Model Predictive Path Integral for Manipulator Motion Planning Using Configuration Space Distance Fields](https://arxiv.org/abs/2509.00836)
*Yulin Li,Tetsuro Miyazaki,Kenji Kawashima*

Main category: cs.RO

TL;DR: 提出CDF-MPPI框架，将配置空间距离场与模型预测路径积分控制结合，实现高效高维运动规划


<details>
  <summary>Details</summary>
Motivation: 传统优化方法依赖SDF梯度但易陷入局部极小值，梯度自由方法如MPPI计算昂贵且成本函数设计困难

Method: 利用CDF梯度统一MPPI成本函数在关节空间，将规划时域缩减到单步，大幅降低计算量

Result: 在2D环境中达到近100%成功率，7自由度机械臂仿真中保持高成功率，控制频率超过750Hz

Conclusion: CDF-MPPI框架在保持避障性能的同时显著提升计算效率，适用于高维运动规划

Abstract: Motion planning for robotic manipulators is a fundamental problem in
robotics. Classical optimization-based methods typically rely on the gradients
of signed distance fields (SDFs) to impose collision-avoidance constraints.
However, these methods are susceptible to local minima and may fail when the
SDF gradients vanish. Recently, Configuration Space Distance Fields (CDFs) have
been introduced, which directly model distances in the robot's configuration
space. Unlike workspace SDFs, CDFs are differentiable almost everywhere and
thus provide reliable gradient information. On the other hand, gradient-free
approaches such as Model Predictive Path Integral (MPPI) control leverage
long-horizon rollouts to achieve collision avoidance. While effective, these
methods are computationally expensive due to the large number of trajectory
samples, repeated collision checks, and the difficulty of designing cost
functions with heterogeneous physical units. In this paper, we propose a
framework that integrates CDFs with MPPI to enable direct navigation in the
robot's configuration space. Leveraging CDF gradients, we unify the MPPI cost
in joint-space and reduce the horizon to one step, substantially cutting
computation while preserving collision avoidance in practice. We demonstrate
that our approach achieves nearly 100% success rates in 2D environments and
consistently high success rates in challenging 7-DOF Franka manipulator
simulations with complex obstacles. Furthermore, our method attains control
frequencies exceeding 750 Hz, substantially outperforming both
optimization-based and standard MPPI baselines. These results highlight the
effectiveness and efficiency of the proposed CDF-MPPI framework for
high-dimensional motion planning.

</details>


### [38] [Enhanced Mean Field Game for Interactive Decision-Making with Varied Stylish Multi-Vehicles](https://arxiv.org/abs/2509.00981)
*Liancheng Zheng,Zhen Tian,Yangfan He,Shuo Liu,Ke Gong,Huilin Chen,Zhihao Lin*

Main category: cs.RO

TL;DR: 基于MFG的自动驾驶决策框架，通过量化驾驶风格表征和空间影响场模型处理异构交通，结合安全关键换道算法实现零碰撞性能


<details>
  <summary>Details</summary>
Motivation: 解决异构交通中多样化人类行为的建模问题，为自动驾驶提供可扩展、可解释且行为感知的规划框架

Method: 提出定量驾驶风格表征方法，将抽象特征映射到速度、安全因子等参数；通过空间影响场模型嵌入MFG；引入基于动态安全边际和碰撞时间分析的安全关键换道算法

Result: 在六种风格组合、两个15辆车场景和NGSIM数据试验中实现零碰撞， consistently优于传统博弈论基线方法

Conclusion: 该框架为现实世界自动驾驶应用提供了可扩展、可解释且行为感知的规划解决方案

Abstract: This paper presents an MFG-based decision-making framework for autonomous
driving in heterogeneous traffic. To capture diverse human behaviors, we
propose a quantitative driving style representation that maps abstract traits
to parameters such as speed, safety factors, and reaction time. These
parameters are embedded into the MFG through a spatial influence field model.
To ensure safe operation in dense traffic, we introduce a safety-critical
lane-changing algorithm that leverages dynamic safety margins,
time-to-collision analysis, and multi-layered constraints. Real-world NGSIM
data is employed for style calibration and empirical validation. Experimental
results demonstrate zero collisions across six style combinations, two
15-vehicle scenarios, and NGSIM-based trials, consistently outperforming
conventional game-theoretic baselines. Overall, our approach provides a
scalable, interpretable, and behavior-aware planning framework for real-world
autonomous driving applications.

</details>


### [39] [A Robust Numerical Method for Solving Trigonometric Equations in Robotic Kinematics](https://arxiv.org/abs/2509.01010)
*Hai-Jun Su*

Main category: cs.RO

TL;DR: 提出了一种用于求解机器人运动学中三角方程组的鲁棒数值方法，通过多项式替换和特征值分解处理奇异矩阵和边缘情况，具有优越的数值稳定性。


<details>
  <summary>Details</summary>
Motivation: 机器人运动学中经常遇到三角方程组求解问题，传统方法在数值稳定性和奇异矩阵处理方面存在不足，需要开发更鲁棒的求解方法。

Method: 采用多项式替换技术结合特征值分解：对非奇异矩阵使用Weierstrass替换将系统转化为四次多项式；对奇异矩阵使用基于SVD分析的专门几何约束方法。

Result: 求解器在大量测试案例中表现出机器精度准确性（误差<10^{-15}），成功率达到100%，已实现为开源Python包。

Conclusion: 该方法在数值稳定性和准确性方面优于传统方法，特别适用于机器人逆运动学等应用场景，为解决复杂三角方程组提供了可靠工具。

Abstract: This paper presents a robust numerical method for solving systems of
trigonometric equations commonly encountered in robotic kinematics. Our
approach employs polynomial substitution techniques combined with eigenvalue
decomposition to handle singular matrices and edge cases effectively. The
method demonstrates superior numerical stability compared to traditional
approaches and has been implemented as an open-source Python package. For
non-singular matrices, we employ Weierstrass substitution to transform the
system into a quartic polynomial, ensuring all analytical solutions are found.
For singular matrices, we develop specialized geometric constraint methods
using SVD analysis. The solver demonstrates machine precision accuracy ($<
10^{-15}$ error) with 100\% success rate on extensive test cases, making it
particularly valuable for robotics applications such as inverse kinematics
problems.

</details>


### [40] [TARA: A Low-Cost 3D-Printed Robotic Arm for Accessible Robotics Education](https://arxiv.org/abs/2509.01043)
*Thays Leach Mitre*

Main category: cs.RO

TL;DR: TARA是一个低成本3D打印机械臂，用于机器人教育，成本约200美元，提供开源设计和代码，注重教育可复现性而非性能基准测试


<details>
  <summary>Details</summary>
Motivation: 解决机器人平台高成本限制学生获得实践技能的问题，使机器人教育更加普及和可及

Method: 开发低成本3D打印机械臂TARA，包含开源设计文件、组装说明和基础代码，平衡经济性和功能性

Result: 实验验证显示在基本操作任务中具有准确性能，成本显著低于数千美元的工业系统

Conclusion: TARA为教育提供了一个可可靠复现和扩展的平台，优先考虑教育可复现性而非性能基准测试

Abstract: The high cost of robotic platforms limits students' ability to gain practical
skills directly applicable in real-world scenarios. To address this challenge,
this paper presents TARA, a low-cost, 3D-printed robotic arm designed for
accessible robotics education. TARA includes an open-source repository with
design files, assembly instructions, and baseline code, enabling users to build
and customize the platform. The system balances affordability and
functionality, offering a highly capable robotic arm for approximately 200 USD,
significantly lower than industrial systems that often cost thousands of
dollars. Experimental validation confirmed accurate performance in basic
manipulation tasks. Rather than focusing on performance benchmarking, this work
prioritizes educational reproducibility, providing a platform that students and
educators can reliably replicate and extend.

</details>


### [41] [A Reactive Grasping Framework for Multi-DoF Grippers via Task Space Velocity Fields and Joint Space QP](https://arxiv.org/abs/2509.01044)
*Yonghyeon Lee,Tzu-Yuan Lin,Alexander Alexiev,Sangbae Kim*

Main category: cs.RO

TL;DR: 一种通过任务空间速度场和关节空间二次规划的层次结构，实现高自由度技器手系统的快速反应急抓的方法


<details>
  <summary>Details</summary>
Motivation: 高自由度系统的全局运动规划遇到状态维度和规划水平同时增加导致搜索空间组合爆烈的挑战，难以实现实时规划

Method: 在低维度任务空间（如指尖位置）进行全局规划，在完整关节空间进行局部跟踪，通过多个任务空间坐标的速度场构建和权重关节空间QP求解来计算关节速度

Result: 通过模拟实验和使用FoundationPose的实际测试，验证方法能够让高自由度手臂系统执行实时无碰撞到达运动，并适应动态环境和外部干扰

Conclusion: 层次结构结合任务空间规划和关节空间跟踪的方法有效解决了高自由度系统实时反应急抓的挑战

Abstract: We present a fast and reactive grasping framework for multi-DoF grippers that
combines task-space velocity fields with a joint-space Quadratic Program (QP)
in a hierarchical structure. Reactive, collision-free global motion planning is
particularly challenging for high-DoF systems, since simultaneous increases in
state dimensionality and planning horizon trigger a combinatorial explosion of
the search space, making real-time planning intractable. To address this, we
plan globally in a lower-dimensional task space, such as fingertip positions,
and track locally in the full joint space while enforcing all constraints. This
approach is realized by constructing velocity fields in multiple task-space
coordinates (or in some cases a subset of joint coordinates) and solving a
weighted joint-space QP to compute joint velocities that track these fields
with appropriately assigned priorities. Through simulation experiments with
privileged knowledge and real-world tests using the recent pose-tracking
algorithm FoundationPose, we verify that our method enables high-DoF arm-hand
systems to perform real-time, collision-free reaching motions while adapting to
dynamic environments and external disturbances.

</details>


### [42] [Model Predictive Control for a Soft Robotic Finger with Stochastic Behavior based on Fokker-Planck Equation](https://arxiv.org/abs/2509.01065)
*Sumitaka Honji,Takahiro Wada*

Main category: cs.RO

TL;DR: 提出基于Fokker-Planck方程的随机控制策略FPE-MPC，用于软体机器人手指的概率分布控制，有效处理柔性系统的不确定性


<details>
  <summary>Details</summary>
Motivation: 软体机器人的灵活性带来高度不确定性和非线性运动挑战，传统开环控制和确定性模型难以有效处理这些问题

Method: 使用Fokker-Planck方程（随机过程主方程）构建FPE-MPC模型预测控制方法，控制软体机器人的概率分布而非状态

Result: 通过两个数值模拟案例研究验证了该控制方法的性能和特性，证明其能有效管理软体机器人系统中的不确定性

Conclusion: FPE-MPC方法为软体机器人控制提供了一种有效的随机控制策略，能够处理柔性系统固有的不确定性挑战

Abstract: The inherent flexibility of soft robots offers numerous advantages, such as
enhanced adaptability and improved safety. However, this flexibility can also
introduce challenges regarding highly uncertain and nonlinear motion. These
challenges become particularly problematic when using open-loop control
methods, which lack a feedback mechanism and are commonly employed in soft
robot control. Though one potential solution is model-based control, typical
deterministic models struggle with uncertainty as mentioned above. The idea is
to use the Fokker-Planck Equation (FPE), a master equation of a stochastic
process, to control not the state of soft robots but the probabilistic
distribution. In this study, we propose and implement a stochastic-based
control strategy, termed FPE-based Model Predictive Control (FPE-MPC), for a
soft robotic finger. Two numerical simulation case studies examine the
performance and characteristics of this control method, revealing its efficacy
in managing the uncertainty inherent in soft robotic systems.

</details>


### [43] [SR-SLAM: Scene-reliability Based RGB-D SLAM in Diverse Environments](https://arxiv.org/abs/2509.01111)
*Haolan Zhang,Chenghao Li,Thanh Nguyen Canh,Lijun Wang,Nak Young Chong*

Main category: cs.RO

TL;DR: SRR-SLAM是一个基于场景可靠性的视觉SLAM框架，通过环境感知处理提升特征提取和位姿估计的适应性，在动态环境中实现高达90%的精度提升。


<details>
  <summary>Details</summary>
Motivation: 传统特征SLAM方法在动态环境中面临两个主要挑战：特征筛选和位姿估计的适应性不足，以及环境感知评估和优化策略不够充分。

Method: 提出统一的场景可靠性评估机制，包含自适应动态区域选择、深度辅助自调整聚类、可靠性感知位姿优化，以及基于可靠性的关键帧选择和加权优化方案。

Result: 在公开数据集和真实场景中的广泛实验表明，SRR-SLAM优于最先进的动态SLAM方法，在不同环境中实现了高达90%的精度和鲁棒性提升。

Conclusion: SRR-SLAM显著提高了自主机器人传感系统的测量精度和可靠性，为动态环境下的视觉SLAM提供了有效的解决方案。

Abstract: Visual simultaneous localization and mapping (SLAM) plays a critical role in
autonomous robotic systems, especially where accurate and reliable measurements
are essential for navigation and sensing. In feature-based SLAM, the
quantityand quality of extracted features significantly influence system
performance. Due to the variations in feature quantity and quality across
diverse environments, current approaches face two major challenges: (1) limited
adaptability in dynamic feature culling and pose estimation, and (2)
insufficient environmental awareness in assessment and optimization strategies.
To address these issues, we propose SRR-SLAM, a scene-reliability based
framework that enhances feature-based SLAM through environment-aware
processing. Our method introduces a unified scene reliability assessment
mechanism that incorporates multiple metrics and historical observations to
guide system behavior. Based on this assessment, we develop: (i) adaptive
dynamic region selection with flexible geometric constraints, (ii)
depth-assisted self-adjusting clustering for efficient dynamic feature removal
in high-dimensional settings, and (iii) reliability-aware pose refinement that
dynamically integrates direct methods when features are insufficient.
Furthermore, we propose (iv) reliability-based keyframe selection and a
weighted optimization scheme to reduce computational overhead while improving
estimation accuracy. Extensive experiments on public datasets and real world
scenarios show that SRR-SLAM outperforms state-of-the-art dynamic SLAM methods,
achieving up to 90% improvement in accuracy and robustness across diverse
environments. These improvements directly contribute to enhanced measurement
precision and reliability in autonomous robotic sensing systems.

</details>


### [44] [A novel parameter estimation method for pneumatic soft hand control applying logarithmic decrement for pseudo rigid body modeling](https://arxiv.org/abs/2509.01113)
*Haiyun Zhang,Kelvin HoLam Heung,Gabrielle J. Naquila,Ashwin Hingwe,Ashish D. Deshpande*

Main category: cs.RO

TL;DR: 这篇论文提出了一种结合伪刚体模型和对数减少方法的新方法PRBM+LDM，用于软体机器人手的高效控制，在位置和力控制方面都取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 软体机器人控制面临连续变形的挑战，现有模型存在计算效率低和参数识别复杂的问题，限制了实时应用。

Method: 提出PRBM+LDM方法，结合伪刚体模型和对数减少方法进行参数估计，并在软体机器人手平台上验证和实现闭环控制器。

Result: 位置控制器锐失从20.38度降到4.37度；力控制在脆弱物体摘取任务中表现优异：土豆片86对82.5，螺丝刀74.42对70，黄铜硬币64.75对35。

Conclusion: PRBM+LDM是一种计算高效、准确的软体驱动器建模技术，能够实现稳定灵活的摘取和精确的力调节。

Abstract: The rapid advancement in physical human-robot interaction (HRI) has
accelerated the development of soft robot designs and controllers. Controlling
soft robots, especially soft hand grasping, is challenging due to their
continuous deformation, motivating the use of reduced model-based controllers
for real-time dynamic performance. Most existing models, however, suffer from
computational inefficiency and complex parameter identification, limiting their
real-time applicability. To address this, we propose a paradigm coupling
Pseudo-Rigid Body Modeling with the Logarithmic Decrement Method for parameter
estimation (PRBM plus LDM). Using a soft robotic hand test bed, we validate
PRBM plus LDM for predicting position and force output from pressure input and
benchmark its performance. We then implement PRBM plus LDM as the basis for
closed-loop position and force controllers. Compared to a simple PID
controller, the PRBM plus LDM position controller achieves lower error (average
maximum error across all fingers: 4.37 degrees versus 20.38 degrees). For force
control, PRBM plus LDM outperforms constant pressure grasping in pinching tasks
on delicate objects: potato chip 86 versus 82.5, screwdriver 74.42 versus 70,
brass coin 64.75 versus 35. These results demonstrate PRBM plus LDM as a
computationally efficient and accurate modeling technique for soft actuators,
enabling stable and flexible grasping with precise force regulation.

</details>


### [45] [Novel bio-inspired soft actuators for upper-limb exoskeletons: design, fabrication and feasibility study](https://arxiv.org/abs/2509.01145)
*Haiyun Zhang,Gabrielle Naquila,Jung Hyun Bae,Zonghuan Wu,Ashwin Hingwe,Ashish Deshpande*

Main category: cs.RO

TL;DR: 这篇论文提出了一种新的上肢软体机器人扩展器设计范式，包括受龙虾启发的肚部扩展器和受户发启发的肩部扩展器，以解决现有软体机器人在康复治疗中的应用限制。


<details>
  <summary>Details</summary>
Motivation: 现有软体机器人在康复治疗中存在响应速度慢、运动范围受限、输出力小等问题，且缺乏对粗结构扩展器设计的定量分析。

Method: 设计了两种新型扩展器：LISPER（龙虾叒发的肚部氧动机器人）用于肚部，SCASPER（户发形肩部氧动机器人）用于肩部。提供了完整的分析模型来描述压力、弯曲角度和输出力之间的关系，并在模拟手臂上进行初步测试。

Result: LISPER具有更高的带宽、增强的输出力/扭矩和高线性度。SCASPER具有高输出力/扭矩和简化的制造过程。

Conclusion: 该研究提供了一种有前景的上肢软体机器人设计方案，通过精确的模型控制和优化设计，有望解决现有软体机器人在康复治疗中的技术限制。

Abstract: Soft robots have been increasingly utilized as sophisticated tools in
physical rehabilitation, particularly for assisting patients with neuromotor
impairments. However, many soft robotics for rehabilitation applications are
characterized by limitations such as slow response times, restricted range of
motion, and low output force. There are also limited studies on the precise
position and force control of wearable soft actuators. Furthermore, not many
studies articulate how bellow-structured actuator designs quantitatively
contribute to the robots' capability. This study introduces a paradigm of upper
limb soft actuator design. This paradigm comprises two actuators: the
Lobster-Inspired Silicone Pneumatic Robot (LISPER) for the elbow and the
Scallop-Shaped Pneumatic Robot (SCASPER) for the shoulder. LISPER is
characterized by higher bandwidth, increased output force/torque, and high
linearity. SCASPER is characterized by high output force/torque and simplified
fabrication processes. Comprehensive analytical models that describe the
relationship between pressure, bending angles, and output force for both
actuators were presented so the geometric configuration of the actuators can be
set to modify the range of motion and output forces. The preliminary test on a
dummy arm is conducted to test the capability of the actuators.

</details>


### [46] [OpenMulti: Open-Vocabulary Instance-Level Multi-Agent Distributed Implicit Mapping](https://arxiv.org/abs/2509.01228)
*Jianyu Dou,Yinan Deng,Jiahui Wang,Xingsi Tang,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: OpenMulti是一个开词汇实例级多智能体分布式隐式建图框架，通过跨智能体实例对齐和交叉渲染监督解决现有方法缺乏实例级感知和语义理解的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体分布式协作建图方法缺乏实例级感知和环境语义理解，限制了其在下游应用中的有效性。

Method: 提出Cross-Agent Instance Alignment模块构建实例协作图确保跨智能体实例理解一致性；利用Cross Rendering Supervision缓解盲区优化陷阱导致的建图精度下降。

Result: 实验结果表明OpenMulti在细粒度几何精度和零样本语义精度方面均优于相关算法，并支持实例级检索任务。

Conclusion: OpenMulti为下游应用提供语义标注，是一个有效的开词汇实例级多智能体分布式建图解决方案。

Abstract: Multi-agent distributed collaborative mapping provides comprehensive and
efficient representations for robots. However, existing approaches lack
instance-level awareness and semantic understanding of environments, limiting
their effectiveness for downstream applications. To address this issue, we
propose OpenMulti, an open-vocabulary instance-level multi-agent distributed
implicit mapping framework. Specifically, we introduce a Cross-Agent Instance
Alignment module, which constructs an Instance Collaborative Graph to ensure
consistent instance understanding across agents. To alleviate the degradation
of mapping accuracy due to the blind-zone optimization trap, we leverage Cross
Rendering Supervision to enhance distributed learning of the scene.
Experimental results show that OpenMulti outperforms related algorithms in both
fine-grained geometric accuracy and zero-shot semantic accuracy. In addition,
OpenMulti supports instance-level retrieval tasks, delivering semantic
annotations for downstream applications. The project website of OpenMulti is
publicly available at https://openmulti666.github.io/.

</details>


### [47] [Towards Data-Driven Metrics for Social Robot Navigation Benchmarking](https://arxiv.org/abs/2509.01251)
*Pilar Bachiller-Burgos,Ulysses Bernardet,Luis V. Calderita,Pranup Chhetri,Anthony Francis,Noriaki Hirose,Noé Pérez,Dhruv Shah,Phani T. Singamaneni,Xuesu Xiao,Luis J. Manso*

Main category: cs.RO

TL;DR: 开发数据驱动的社交机器人导航指标，用于基准测试和策略优化，包含4427条轨迹数据集和基于RNN的基线指标


<details>
  <summary>Details</summary>
Motivation: 需要建立标准化的社交机器人导航评估指标来促进算法比较和优化，缺乏公开可用的评分数据集

Method: 提出社交导航轨迹数据存储标准，收集4427条轨迹（182条真实+4245条模拟），人工评分后训练RNN基线模型

Result: 获得4402条评分轨迹数据集，训练出有效的RNN导航指标模型，所有数据和模型权重公开可用

Conclusion: 成功建立了社交机器人导航的标准化评估框架，为后续研究提供了基准数据集和评估工具

Abstract: This paper presents a joint effort towards the development of a data-driven
Social Robot Navigation metric to facilitate benchmarking and policy
optimization. We provide our motivations for our approach and describe our
proposal for storing rated social navigation trajectory datasets. Following
these guidelines, we compiled a dataset with 4427 trajectories -- 182 real and
4245 simulated -- and presented it to human raters, yielding a total of 4402
rated trajectories after data quality assurance. We also trained an RNN-based
baseline metric on the dataset and present quantitative and qualitative
results. All data, software, and model weights are publicly available.

</details>


### [48] [Toward a Holistic Multi-Criteria Trajectory Evaluation Framework for Autonomous Driving in Mixed Traffic Environment](https://arxiv.org/abs/2509.01291)
*Nouhed Naidja,Stéphane Font,Marc Revilloud,Guillaume Sandou*

Main category: cs.RO

TL;DR: 提出一个统一框架来评估和优化自动驾驶车辆轨迹，整合安全性、舒适性和效率标准，使用几何指标量化碰撞风险，并通过PSO算法进行优化。


<details>
  <summary>Details</summary>
Motivation: 需要一种综合的方法来同时评估和优化自动驾驶车辆的多个关键性能指标（安全性、舒适性、效率），以提升自动驾驶系统的整体性能。

Method: 使用基于自适应椭圆的安全区域分析来量化碰撞风险，应用鞋带公式计算不对齐和时间变化配置的交集面积；舒适性通过纵向和横向加加速度指标建模；效率通过总行驶时间评估；最后使用PSO算法优化综合目标函数。

Result: 该方法在真实交通条件下成功验证，包括城市交叉路口自动驾驶车辆与人工驾驶车辆的交互实验，以及基于真实交通中人类驾驶数据的仿真。

Conclusion: 提出的统一框架能够有效评估和优化自动驾驶车辆轨迹，在安全性、舒适性和效率方面表现出良好的综合性能，适用于真实交通场景。

Abstract: This paper presents a unified framework for the evaluation and optimization
of autonomous vehicle trajectories, integrating formal safety, comfort, and
efficiency criteria. An innovative geometric indicator, based on the analysis
of safety zones using adaptive ellipses, is used to accurately quantify
collision risks. Our method applies the Shoelace formula to compute the
intersection area in the case of misaligned and time-varying configurations.
Comfort is modeled using indicators centered on longitudinal and lateral jerk,
while efficiency is assessed by overall travel time. These criteria are
aggregated into a comprehensive objective function solved using a PSO based
algorithm. The approach was successfully validated under real traffic
conditions via experiments conducted in an urban intersection involving an
autonomous vehicle interacting with a human-operated vehicle, and in simulation
using data recorded from human driving in real traffic.

</details>


### [49] [Disentangled Multi-Context Meta-Learning: Unlocking robust and Generalized Task Learning](https://arxiv.org/abs/2509.01297)
*Seonsoo Kim,Jun-Gill Kang,Taehong Kim,Seongil Hong*

Main category: cs.RO

TL;DR: 提出了解耦多上下文元学习框架，通过为每个任务因素分配独立上下文向量来提升任务理解和泛化能力，在正弦回归和机器人运动任务中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有元学习方法通常将多个任务因素混合在单一纠缠表示中，这导致难以解释性能驱动因素并阻碍泛化能力。

Method: 引入解耦多上下文元学习框架，为每个任务因素分配独立的上下文向量，通过解耦变化实现更深层次的任务理解和跨任务上下文向量共享。

Result: 在正弦回归任务中优于基线方法，能够泛化到未见过的正弦函数；在四足机器人运动任务中，通过将解耦上下文向量从动力学模型转移到强化学习，提升了分布外条件下的鲁棒性，并实现了仅用20秒真实数据就能成功进行sim-to-real策略迁移。

Conclusion: 解耦多上下文元学习框架通过显式分离任务因素，显著提升了模型的解释性、泛化能力和鲁棒性，在多个领域验证了其有效性。

Abstract: In meta-learning and its downstream tasks, many methods rely on implicit
adaptation to task variations, where multiple factors are mixed together in a
single entangled representation. This makes it difficult to interpret which
factors drive performance and can hinder generalization. In this work, we
introduce a disentangled multi-context meta-learning framework that explicitly
assigns each task factor to a distinct context vector. By decoupling these
variations, our approach improves robustness through deeper task understanding
and enhances generalization by enabling context vector sharing across tasks
with shared factors. We evaluate our approach in two domains. First, on a
sinusoidal regression task, our model outperforms baselines on
out-of-distribution tasks and generalizes to unseen sine functions by sharing
context vectors associated with shared amplitudes or phase shifts. Second, in a
quadruped robot locomotion task, we disentangle the robot-specific properties
and the characteristics of the terrain in the robot dynamics model. By
transferring disentangled context vectors acquired from the dynamics model into
reinforcement learning, the resulting policy achieves improved robustness under
out-of-distribution conditions, surpassing the baselines that rely on a single
unified context. Furthermore, by effectively sharing context, our model enables
successful sim-to-real policy transfer to challenging terrains with
out-of-distribution robot-specific properties, using just 20 seconds of real
data from flat terrain, a result not achievable with single-task adaptation.

</details>


### [50] [TopoNav: Topological Graphs as a Key Enabler for Advanced Object Navigation](https://arxiv.org/abs/2509.01364)
*Peiran Liu,Qiang Zhang,Daojie Peng,Lingfeng Zhang,Yihao Qin,Hang Zhou,Jun Ma,Renjing Xu,Yiding Ji*

Main category: cs.RO

TL;DR: TopoNav是一个利用拓扑结构作为空间记忆的新框架，通过构建和更新捕捉场景连接、邻近性和语义意义的拓扑图，在物体导航任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 物体导航在大型语言模型推动下取得进展，但在长时程任务和动态场景中的记忆管理仍面临挑战，需要更好的空间记忆机制。

Method: 提出TopoNav框架，利用拓扑结构作为空间记忆，构建和更新包含场景连接、邻近关系和语义信息的拓扑图，帮助智能体积累空间知识、检索关键信息并进行有效推理。

Result: 在基准物体导航数据集上实现了最先进的性能，具有更高的成功率和更高效的路径规划，在多样复杂环境中表现尤为突出。

Conclusion: TopoNav通过将临时视觉输入与持久空间理解相连接，有效解决了物体导航中的记忆管理问题，为长时程导航任务提供了有力解决方案。

Abstract: Object Navigation (ObjectNav) has made great progress with large language
models (LLMs), but still faces challenges in memory management, especially in
long-horizon tasks and dynamic scenes. To address this, we propose TopoNav, a
new framework that leverages topological structures as spatial memory. By
building and updating a topological graph that captures scene connections,
adjacency, and semantic meaning, TopoNav helps agents accumulate spatial
knowledge over time, retrieve key information, and reason effectively toward
distant goals. Our experiments show that TopoNav achieves state-of-the-art
performance on benchmark ObjectNav datasets, with higher success rates and more
efficient paths. It particularly excels in diverse and complex environments, as
it connects temporary visual inputs with lasting spatial understanding.

</details>


### [51] [Analyzing Reluctance to Ask for Help When Cooperating With Robots: Insights to Integrate Artificial Agents in HRC](https://arxiv.org/abs/2509.01450)
*Ane San Martin,Michael Hagenow,Julie Shah,Johan Kildal,Elena Lazkano*

Main category: cs.RO

TL;DR: 这篇论文通过用户研究分析了人机协作任务中的远程帮助系统设计关键因素，包括帮助请求方式和帮助者类型对用户情感、生产力和偏好的影响


<details>
  <summary>Details</summary>
Motivation: 随着机器人技术的发展，人机协作在工业任务中将更加普遍。当人类遇到问题时，未来可能依赖人工智能组件或机器人获得帮助，因此需要研究设计未来用户帮助组件的关键方面

Method: 通过人机协作组装任务的用户研究，采集定量和定性数据，分析远程人类帮助的影响。研究包括帮助请求体验、帮助接收体验，以及用户对非人类帮助组件的看法和帮助方式偏好

Result: 研究分析了不同设计决策（人类或人工智能帮助者，需求帮助或主动帮助）对人机协作任务中用户情感响应、生产力和偏好的影响

Conclusion: 该研究为未来用户帮助组件的设计提供了重要参考，确定了帮助请求方式和帮助者类型等关键设计因素对人机协作效果的影响

Abstract: As robot technology advances, collaboration between humans and robots will
become more prevalent in industrial tasks. When humans run into issues in such
scenarios, a likely future involves relying on artificial agents or robots for
aid. This study identifies key aspects for the design of future user-assisting
agents. We analyze quantitative and qualitative data from a user study
examining the impact of on-demand assistance received from a remote human in a
human-robot collaboration (HRC) assembly task. We study scenarios in which
users require help and we assess their experiences in requesting and receiving
assistance. Additionally, we investigate participants' perceptions of future
non-human assisting agents and whether assistance should be on-demand or
unsolicited. Through a user study, we analyze the impact that such design
decisions (human or artificial assistant, on-demand or unsolicited help) can
have on elicited emotional responses, productivity, and preferences of humans
engaged in HRC tasks.

</details>


### [52] [FGO-SLAM: Enhancing Gaussian SLAM with Globally Consistent Opacity Radiance Field](https://arxiv.org/abs/2509.01547)
*Fan Zhu,Yifan Zhao,Ziyu Chen,Biao Yu,Hui Zhu*

Main category: cs.RO

TL;DR: FGO-SLAM是一个基于高斯SLAM的系统，通过引入不透明度辐射场和全局优化方法，解决了传统SLAM在高质量场景重建方面的不足，实现了卓越的跟踪精度和建图性能。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法难以满足高质量场景重建的需求，而现有的高斯SLAM系统缺乏有效的位姿优化方法，在几何重建方面面临挑战。

Method: 使用不透明度辐射场作为场景表示，采用全局调整优化相机位姿和稀疏点云，引入深度畸变和法线一致性项来精化场景表示，并通过四面体网格构建和水平集提取直接从3D高斯中提取表面。

Result: 在多个真实世界和大规模合成数据集上的实验表明，该方法在跟踪精度和建图性能方面达到了最先进的水平。

Conclusion: FGO-SLAM通过创新的场景表示和优化策略，成功解决了高斯SLAM系统中的关键问题，为高质量场景重建提供了有效的解决方案。

Abstract: Visual SLAM has regained attention due to its ability to provide perceptual
capabilities and simulation test data for Embodied AI. However, traditional
SLAM methods struggle to meet the demands of high-quality scene reconstruction,
and Gaussian SLAM systems, despite their rapid rendering and high-quality
mapping capabilities, lack effective pose optimization methods and face
challenges in geometric reconstruction. To address these issues, we introduce
FGO-SLAM, a Gaussian SLAM system that employs an opacity radiance field as the
scene representation to enhance geometric mapping performance. After initial
pose estimation, we apply global adjustment to optimize camera poses and sparse
point cloud, ensuring robust tracking of our approach. Additionally, we
maintain a globally consistent opacity radiance field based on 3D Gaussians and
introduce depth distortion and normal consistency terms to refine the scene
representation. Furthermore, after constructing tetrahedral grids, we identify
level sets to directly extract surfaces from 3D Gaussians. Results across
various real-world and large-scale synthetic datasets demonstrate that our
method achieves state-of-the-art tracking accuracy and mapping performance.

</details>


### [53] [Aleatoric Uncertainty from AI-based 6D Object Pose Predictors for Object-relative State Estimation](https://arxiv.org/abs/2509.01583)
*Thomas Jantos,Stephan Weiss,Jan Steinbrener*

Main category: cs.RO

TL;DR: 提出一种为深度学习6D位姿预测器添加认知不确定性的方法，通过附加两个多层感知器来动态推断测量不确定性，提升基于扩展卡尔曼滤波的状态估计性能


<details>
  <summary>Details</summary>
Motivation: 深度学习在机器人感知中广泛应用，但现有的6D物体位姿预测器缺乏不确定性量化，而概率状态估计器需要准确的测量不确定性信息才能有效工作

Method: 在现有预训练的位姿预测器基础上，附加两个独立的多层感知器（分别处理平移和旋转部分）来推断认知不确定性，冻结原有预测器参数仅训练新增部分

Result: 方法计算开销小，可在边缘设备部署，相比固定协方差方法显著提升了物体相对状态估计的性能，在合成数据和真实数据上都验证了有效性

Conclusion: 通过简单添加两个MLP来推断认知不确定性，能够有效提升基于深度学习的6D位姿预测在状态估计任务中的性能，且具有实际部署的可行性

Abstract: Deep Learning (DL) has become essential in various robotics applications due
to excelling at processing raw sensory data to extract task specific
information from semantic objects. For example, vision-based object-relative
navigation relies on a DL-based 6D object pose predictor to provide the
relative pose between the object and the robot as measurements to the robot's
state estimator. Accurately knowing the uncertainty inherent in such Deep
Neural Network (DNN) based measurements is essential for probabilistic state
estimators subsequently guiding the robot's tasks. Thus, in this letter, we
show that we can extend any existing DL-based object-relative pose predictor
for aleatoric uncertainty inference simply by including two multi-layer
perceptrons detached from the translational and rotational part of the DL
predictor. This allows for efficient training while freezing the existing
pre-trained predictor. We then use the inferred 6D pose and its uncertainty as
a measurement and corresponding noise covariance matrix in an extended Kalman
filter (EKF). Our approach induces minimal computational overhead such that the
state estimator can be deployed on edge devices while benefiting from the
dynamically inferred measurement uncertainty. This increases the performance of
the object-relative state estimation task compared to a fix-covariance
approach. We conduct evaluations on synthetic data and real-world data to
underline the benefits of aleatoric uncertainty inference for the
object-relative state estimation task.

</details>


### [54] [A Hybrid Input based Deep Reinforcement Learning for Lane Change Decision-Making of Autonomous Vehicle](https://arxiv.org/abs/2509.01611)
*Ziteng Gao,Jiaqi Qu,Chaoyu Chen*

Main category: cs.RO

TL;DR: 提出基于混合输入的深度强化学习算法，结合轨迹预测和多模态信息，实现自动驾驶车辆的安全换道决策与控制


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆换道决策复杂但回报高，需要综合考虑周围车辆未来行为和多种环境信息来提升决策安全性

Method: 混合输入深度强化学习：1) 周围车辆轨迹预测作为额外输入；2) 同时提取高维图像和低维传感器特征；3) 融合轨迹预测和多模态信息作为状态空间；4) 结合强化学习宏观决策与端到端车辆控制

Result: 在CARLA模拟器中实验表明，混合状态空间的使用显著提升了车辆换道决策的安全性

Conclusion: 所提出的混合输入深度强化学习方法通过整合轨迹预测和多模态信息，有效提高了自动驾驶车辆换道决策的安全性和合理性

Abstract: Lane change decision-making for autonomous vehicles is a complex but
high-reward behavior. In this paper, we propose a hybrid input based deep
reinforcement learning (DRL) algorithm, which realizes abstract lane change
decisions and lane change actions for autonomous vehicles within traffic flow.
Firstly, a surrounding vehicles trajectory prediction method is proposed to
reduce the risk of future behavior of surrounding vehicles to ego vehicle, and
the prediction results are input into the reinforcement learning model as
additional information. Secondly, to comprehensively leverage environmental
information, the model extracts feature from high-dimensional images and
low-dimensional sensor data simultaneously. The fusion of surrounding vehicle
trajectory prediction and multi-modal information are used as state space of
reinforcement learning to improve the rationality of lane change decision.
Finally, we integrate reinforcement learning macro decisions with end-to-end
vehicle control to achieve a holistic lane change process. Experiments were
conducted within the CARLA simulator, and the results demonstrated that the
utilization of a hybrid state space significantly enhances the safety of
vehicle lane change decisions.

</details>


### [55] [Speculative Design of Equitable Robotics: Queer Fictions and Futures](https://arxiv.org/abs/2509.01643)
*Minja Axelsson*

Main category: cs.RO

TL;DR: 本文通过探索性论文形式探讨LGBTQ+群体专属机器人的公平性话题，提出了三种酷儿机器人设计提案，并讨论相关伦理问题


<details>
  <summary>Details</summary>
Motivation: 旨在激发关于酷儿机器人未来愿景的思考和对话，探讨如何通过机器人技术为LGBTQ+群体创造更公平的未来

Method: 采用探索性论文格式，首先回顾科幻和科学中的酷儿机器人现状，然后提出三种推测性设计提案：反映用户酷儿身份的机器人、酷儿行动主义机器人和酷儿拥有网络机器人

Result: 提出了三种具体的酷儿机器人角色设计方案，并引发了关于机器人是否应该被酷儿化以及相关伦理影响的讨论

Conclusion: 为酷儿机器人未来提出了愿景建议，并指出了实现这些愿景所需的条件，推动了该领域的思考和对话

Abstract: This paper examines the speculative topic of equitable robots through an
exploratory essay format. It focuses specifically on robots by and for LGBTQ+
populations. It aims to provoke thought and conversations in the field about
what aspirational queer robotics futures may look like, both in the arts and
sciences. First, it briefly reviews the state-of-the-art of queer robotics in
fiction and science, drawing together threads from each. Then, it discusses
queering robots through three speculative design proposals for queer robot
roles: 1) reflecting the queerness of their ''in-group'' queer users, building
and celebrating ''in-group'' identity, 2) a new kind of queer activism by
implementing queer robot identity performance to interact with ''out-group''
users, with a goal of reducing bigotry through familiarisation, and 3) a
network of queer-owned robots, through which the community could reach each
other, and distribute and access important resources. The paper then questions
whether robots should be queered, and what ethical implications this raises.
Finally, the paper makes suggestions for what aspirational queer robotics
futures may look like, and what would be required to get there.

</details>


### [56] [Data Retrieval with Importance Weights for Few-Shot Imitation Learning](https://arxiv.org/abs/2509.01657)
*Amber Xie,Rahul Chand,Dorsa Sadigh,Joey Hejna*

Main category: cs.RO

TL;DR: 本文提出了重要性加权检索(IWR)方法，通过高斯核密度估计计算目标数据与先验数据分布的概率比来改进基于检索的模仿学习，解决了传统最近邻检索方法的高方差和忽略先验数据分布的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于检索的模仿学习方法使用最近邻距离作为检索标准，存在高方差估计和忽略先验数据分布的问题，限制了在小规模任务特定数据集上的学习效果。

Method: 提出重要性加权检索(IWR)方法，使用高斯核密度估计计算目标数据与先验数据分布的概率比作为重要性权重，通过考虑概率比来减少偏差，并利用所有数据点进行平滑估计。

Result: 在仿真环境和真实世界的Bridge数据集评估中，IWR方法持续提升了现有基于检索方法的性能，且只需要较小的修改。

Conclusion: IWR方法通过概率比估计有效解决了传统检索方法的问题，在少样本模仿学习中表现出显著的性能提升，为检索式学习提供了更稳健的数据选择策略。

Abstract: While large-scale robot datasets have propelled recent progress in imitation
learning, learning from smaller task specific datasets remains critical for
deployment in new environments and unseen tasks. One such approach to few-shot
imitation learning is retrieval-based imitation learning, which extracts
relevant samples from large, widely available prior datasets to augment a
limited demonstration dataset. To determine the relevant data from prior
datasets, retrieval-based approaches most commonly calculate a prior data
point's minimum distance to a point in the target dataset in latent space.
While retrieval-based methods have shown success using this metric for data
selection, we demonstrate its equivalence to the limit of a Gaussian kernel
density (KDE) estimate of the target data distribution. This reveals two
shortcomings of the retrieval rule used in prior work. First, it relies on
high-variance nearest neighbor estimates that are susceptible to noise. Second,
it does not account for the distribution of prior data when retrieving data. To
address these issues, we introduce Importance Weighted Retrieval (IWR), which
estimates importance weights, or the ratio between the target and prior data
distributions for retrieval, using Gaussian KDEs. By considering the
probability ratio, IWR seeks to mitigate the bias of previous selection rules,
and by using reasonable modeling parameters, IWR effectively smooths estimates
using all data points. Across both simulation environments and real-world
evaluations on the Bridge dataset we find that our method, IWR, consistently
improves performance of existing retrieval-based methods, despite only
requiring minor modifications.

</details>


### [57] [MoTo: A Zero-shot Plug-in Interaction-aware Navigation for General Mobile Manipulation](https://arxiv.org/abs/2509.01658)
*Zhenyu Wu,Angyuan Ma,Xiuwei Xu,Hang Yin,Yinan Liang,Ziwei Wang,Jiwen Lu,Haibin Yan*

Main category: cs.RO

TL;DR: MoTo是一个即插即用模块，可将任何现成的固定基座操作基础模型升级为移动操作能力，通过交互感知导航和视觉语言模型实现零样本移动操作


<details>
  <summary>Details</summary>
Motivation: 传统移动操作方法缺乏大规模训练数据而难以泛化，固定基座操作基础模型虽具有良好泛化能力但局限于固定设置，需要将其扩展到移动操作场景

Method: 提出交互感知导航策略生成机器人对接点，使用视觉语言模型在多视图一致性下生成交互关键点，结合运动规划目标最小化关键点距离并保持轨迹可行性

Result: 在OVMM和真实世界实验中，MoTo分别比最先进的移动操作方法成功率高出2.68%和16.67%，且无需额外训练数据

Conclusion: MoTo成功实现了零样本移动操作，证明了将固定基座操作模型扩展到移动场景的可行性，为机器人辅助人类日常任务提供了有效解决方案

Abstract: Mobile manipulation stands as a core challenge in robotics, enabling robots
to assist humans across varied tasks and dynamic daily environments.
Conventional mobile manipulation approaches often struggle to generalize across
different tasks and environments due to the lack of large-scale training.
However, recent advances in manipulation foundation models demonstrate
impressive generalization capability on a wide range of fixed-base manipulation
tasks, which are still limited to a fixed setting. Therefore, we devise a
plug-in module named MoTo, which can be combined with any off-the-shelf
manipulation foundation model to empower them with mobile manipulation ability.
Specifically, we propose an interaction-aware navigation policy to generate
robot docking points for generalized mobile manipulation. To enable zero-shot
ability, we propose an interaction keypoints framework via vision-language
models (VLM) under multi-view consistency for both target object and robotic
arm following instructions, where fixed-base manipulation foundation models can
be employed. We further propose motion planning objectives for the mobile base
and robot arm, which minimize the distance between the two keypoints and
maintain the physical feasibility of trajectories. In this way, MoTo guides the
robot to move to the docking points where fixed-base manipulation can be
successfully performed, and leverages VLM generation and trajectory
optimization to achieve mobile manipulation in a zero-shot manner, without any
requirement on mobile manipulation expert data. Extensive experimental results
on OVMM and real-world demonstrate that MoTo achieves success rates of 2.68%
and 16.67% higher than the state-of-the-art mobile manipulation methods,
respectively, without requiring additional training data.

</details>


### [58] [Articulated Object Estimation in the Wild](https://arxiv.org/abs/2509.01708)
*Abdelrhman Werby,Martin Büchner,Adrian Röfer,Chenguang Huang,Wolfram Burgard,Abhinav Valada*

Main category: cs.RO

TL;DR: ArtiPoint是一个新颖的3D关节物体运动估计框架，通过结合深度点跟踪和因子图优化，能够从原始RGB-D视频中鲁棒地估计关节部件轨迹和关节轴。


<details>
  <summary>Details</summary>
Motivation: 现有的关节估计方法主要关注受控环境，假设固定相机视角或直接观察不同物体状态，在无约束的真实环境中往往失效。受人类通过观察他人操作物体来推断关节的启发，需要开发能够在动态相机运动和部分可观测性下推断关节物体模型的方法。

Method: 结合深度点跟踪与因子图优化框架，直接从原始RGB-D视频中估计关节部件轨迹和关节轴。同时创建了首个以自我为中心的在野外场景级别捕获关节物体交互的数据集Arti4D。

Result: 在Arti4D数据集上对一系列经典和学习基线方法进行基准测试，证明了ArtiPoint的优越性能。

Conclusion: ArtiPoint框架能够有效解决动态相机运动和部分可观测性下的关节物体建模问题，为未来研究提供了新的数据集和方法基准。

Abstract: Understanding the 3D motion of articulated objects is essential in robotic
scene understanding, mobile manipulation, and motion planning. Prior methods
for articulation estimation have primarily focused on controlled settings,
assuming either fixed camera viewpoints or direct observations of various
object states, which tend to fail in more realistic unconstrained environments.
In contrast, humans effortlessly infer articulation by watching others
manipulate objects. Inspired by this, we introduce ArtiPoint, a novel
estimation framework that can infer articulated object models under dynamic
camera motion and partial observability. By combining deep point tracking with
a factor graph optimization framework, ArtiPoint robustly estimates articulated
part trajectories and articulation axes directly from raw RGB-D videos. To
foster future research in this domain, we introduce Arti4D, the first
ego-centric in-the-wild dataset that captures articulated object interactions
at a scene level, accompanied by articulation labels and ground-truth camera
poses. We benchmark ArtiPoint against a range of classical and learning-based
baselines, demonstrating its superior performance on Arti4D. We make code and
Arti4D publicly available at https://artipoint.cs.uni-freiburg.de.

</details>


### [59] [Constrained Decoding for Robotics Foundation Models](https://arxiv.org/abs/2509.01728)
*Parv Kapoor,Akila Ganlath,Changliu Liu,Sebastian Scherer,Eunsuk Kang*

Main category: cs.RO

TL;DR: 提出了一种用于机器人基础模型的约束解码框架，通过在运行时强制执行信号时序逻辑（STL）规范来确保生成的动作满足安全约束，无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人基础模型虽然具有端到端和通用能力，但缺乏对行为正确性和安全约束的显式考虑，存在安全隐患。

Method: 开发了约束解码框架，在解码时对动作轨迹施加逻辑约束，确保生成的动作满足STL规范，同时保持对底层基础模型的不可知性。

Result: 在多个最先进的导航基础模型上进行了全面评估，证明该方法不仅能过滤不安全动作，还能用于条件动作生成。

Conclusion: 该方法为机器人基础模型提供了运行时安全保障，无需重新训练即可确保动作满足安全约束，具有重要的实际应用价值。

Abstract: Recent advances in the development of robotic foundation models have led to
promising end-to-end and general-purpose capabilities in robotic systems. These
models are pretrained on vast datasets of robot trajectories to process multi-
modal inputs and directly output a sequence of action that the system then
executes in the real world. Although this approach is attractive from the
perspective of im- proved generalization across diverse tasks, these models are
still data-driven and, therefore, lack explicit notions of behavioral
correctness and safety constraints. We address these limitations by introducing
a constrained decoding framework for robotics foundation models that enforces
logical constraints on action trajec- tories in dynamical systems. Our method
ensures that generated actions provably satisfy signal temporal logic (STL)
specifications at runtime without retraining, while remaining agnostic of the
underlying foundation model. We perform com- prehensive evaluation of our
approach across state-of-the-art navigation founda- tion models and we show
that our decoding-time interventions are useful not only for filtering unsafe
actions but also for conditional action-generation. Videos available on our
website: https://constrained-robot-fms.github.io

</details>


### [60] [Fail2Progress: Learning from Real-World Robot Failures with Stein Variational Inference](https://arxiv.org/abs/2509.01746)
*Yixuan Huang,Novella Alvina,Mohanraj Devendran Shanthi,Tucker Hermans*

Main category: cs.RO

TL;DR: Fail2Progress利用Stein变分推理并行生成多个仿真环境，针对观察到的失败情况高效生成训练数据，从而提高技能效果模型在长时程操作任务中的失败恢复能力


<details>
  <summary>Details</summary>
Motivation: 长时程操作任务的技能效果模型在训练数据分布未覆盖的条件下容易失败，需要让机器人能够从失败中推理和学习

Method: 提出Fail2Progress方法，利用Stein变分推理并行生成多个仿真环境，针对观察到的失败高效生成数据集，然后对技能效果模型进行微调

Result: 方法能够处理多个具有挑战性的移动操作任务，包括运输多个物体、整理受限货架和桌面整理。通过大规模仿真和真实实验证明，该方法在不同物体数量下都能有效从失败中学习，且优于多个基线方法

Conclusion: Fail2Progress通过高效生成针对失败的数据集，显著提高了技能效果模型的失败恢复能力，减少了未来失败的发生

Abstract: Skill effect models for long-horizon manipulation tasks are prone to failures
in conditions not covered by training data distributions. Therefore, enabling
robots to reason about and learn from failures is necessary. We investigate the
problem of efficiently generating a dataset targeted to observed failures.
After fine-tuning a skill effect model on this dataset, we evaluate the extent
to which the model can recover from failures and minimize future failures. We
propose Fail2Progress, an approach that leverages Stein variational inference
to generate multiple simulation environments in parallel, enabling efficient
data sample generation similar to observed failures. Our method is capable of
handling several challenging mobile manipulation tasks, including transporting
multiple objects, organizing a constrained shelf, and tabletop organization.
Through large-scale simulation and real-world experiments, we demonstrate that
our approach excels at learning from failures across different numbers of
objects. Furthermore, we show that Fail2Progress outperforms several baselines.

</details>


### [61] [Non-conflicting Energy Minimization in Reinforcement Learning based Robot Control](https://arxiv.org/abs/2509.01765)
*Skand Peri,Akhil Perincherry,Bikram Pandit,Stefan Lee*

Main category: cs.RO

TL;DR: 提出了一种无需超参数调优的梯度优化方法，通过策略梯度投影在任务目标和能耗目标之间进行优化，在保持任务性能的同时显著降低能耗


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法通过奖励函数惩罚能耗需要仔细调优权重，容易导致能耗最小化与任务性能之间的不良权衡

Method: 基于多任务学习的策略梯度投影方法，在任务目标和能耗目标之间推导策略更新，以不影响任务性能的方式最小化能耗

Result: 在DM-Control和HumanoidBench标准运动基准测试中实现了64%的能耗降低，同时保持可比较的任务性能，并在Unitree GO2四足机器人上展示了Sim2Real迁移

Conclusion: 该方法易于在标准RL流程中实现，适用于任何策略梯度方法，为节能控制策略提供了基于原理的替代方案

Abstract: Efficient robot control often requires balancing task performance with energy
expenditure. A common approach in reinforcement learning (RL) is to penalize
energy use directly as part of the reward function. This requires carefully
tuning weight terms to avoid undesirable trade-offs where energy minimization
harms task success. In this work, we propose a hyperparameter-free gradient
optimization method to minimize energy expenditure without conflicting with
task performance. Inspired by recent works in multitask learning, our method
applies policy gradient projection between task and energy objectives to derive
policy updates that minimize energy expenditure in ways that do not impact task
performance. We evaluate this technique on standard locomotion benchmarks of
DM-Control and HumanoidBench and demonstrate a reduction of 64% energy usage
while maintaining comparable task performance. Further, we conduct experiments
on a Unitree GO2 quadruped showcasing Sim2Real transfer of energy efficient
policies. Our method is easy to implement in standard RL pipelines with minimal
code changes, is applicable to any policy gradient method, and offers a
principled alternative to reward shaping for energy efficient control policies.

</details>


### [62] [ManiFlow: A General Robot Manipulation Policy via Consistency Flow Training](https://arxiv.org/abs/2509.01819)
*Ge Yan,Jiyue Zhu,Yuquan Deng,Shiqi Yang,Ri-Zhao Qiu,Xuxin Cheng,Marius Memmel,Ranjay Krishna,Ankit Goyal,Xiaolong Wang,Dieter Fox*

Main category: cs.RO

TL;DR: ManiFlow是一个基于流匹配和一致性训练的视觉运动模仿学习策略，能够通过1-2次推理步骤生成高精度的机器人操作动作，支持多模态输入并显著提升各种机器人设置的成功率。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人操作中需要生成精确、高维动作的问题，同时处理多样化的视觉、语言和本体感觉输入，需要一个能够高效整合多模态信息并快速生成高质量动作的解决方案。

Method: 采用流匹配与一致性训练相结合的方法，提出DiT-X扩散变换器架构，具有自适应交叉注意力和AdaLN-Zero条件机制，实现动作令牌与多模态观察之间的细粒度特征交互。

Result: 在多样化仿真基准测试中表现一致提升，在真实世界任务中成功率几乎翻倍，涵盖单臂、双臂和人形机器人设置，展现出对新颖物体和背景变化的强鲁棒性和泛化能力。

Conclusion: ManiFlow通过创新的架构设计和训练方法，显著提升了机器人操作的性能和效率，展示了强大的扩展能力，为通用机器人操作提供了有效的解决方案。

Abstract: This paper introduces ManiFlow, a visuomotor imitation learning policy for
general robot manipulation that generates precise, high-dimensional actions
conditioned on diverse visual, language and proprioceptive inputs. We leverage
flow matching with consistency training to enable high-quality dexterous action
generation in just 1-2 inference steps. To handle diverse input modalities
efficiently, we propose DiT-X, a diffusion transformer architecture with
adaptive cross-attention and AdaLN-Zero conditioning that enables fine-grained
feature interactions between action tokens and multi-modal observations.
ManiFlow demonstrates consistent improvements across diverse simulation
benchmarks and nearly doubles success rates on real-world tasks across
single-arm, bimanual, and humanoid robot setups with increasing dexterity. The
extensive evaluation further demonstrates the strong robustness and
generalizability of ManiFlow to novel objects and background changes, and
highlights its strong scaling capability with larger-scale datasets. Our
website: maniflow-policy.github.io.

</details>


### [63] [Multi-vessel Interaction-Aware Trajectory Prediction and Collision Risk Assessment](https://arxiv.org/abs/2509.01836)
*Md Mahbub Alam,Jose F. Rodrigues-Jr,Gabriel Spadon*

Main category: cs.RO

TL;DR: 提出基于Transformer的多船舶轨迹预测框架，集成碰撞风险分析，通过并行流编码运动特征、因果卷积处理时序、空间变换进行位置编码，在真实AIS数据上表现优于传统单船预测方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动模型主要局限于单船预测，忽略了船舶交互、航行规则和显式碰撞风险评估，需要开发能够同时处理多船交互和碰撞风险分析的预测框架。

Method: 基于Transformer的框架，通过并行流编码运动学和物理特征，使用因果卷积处理时序局部性，空间变换进行位置编码，混合位置嵌入捕获局部运动模式和长程依赖关系。

Result: 在大规模真实AIS数据上评估，使用联合多船指标，模型展现出超越传统单船位移误差的优越预测能力，能够通过预测轨迹的交互模拟量化潜在碰撞风险。

Conclusion: 该框架为加强海上安全和决策支持提供了可行的见解，通过集成多船轨迹预测和碰撞风险分析，显著提升了海上态势感知和防碰撞能力。

Abstract: Accurate vessel trajectory prediction is essential for enhancing situational
awareness and preventing collisions. Still, existing data-driven models are
constrained mainly to single-vessel forecasting, overlooking vessel
interactions, navigation rules, and explicit collision risk assessment. We
present a transformer-based framework for multi-vessel trajectory prediction
with integrated collision risk analysis. For a given target vessel, the
framework identifies nearby vessels. It jointly predicts their future
trajectories through parallel streams encoding kinematic and derived physical
features, causal convolutions for temporal locality, spatial transformations
for positional encoding, and hybrid positional embeddings that capture both
local motion patterns and long-range dependencies. Evaluated on large-scale
real-world AIS data using joint multi-vessel metrics, the model demonstrates
superior forecasting capabilities beyond traditional single-vessel displacement
errors. By simulating interactions among predicted trajectories, the framework
further quantifies potential collision risks, offering actionable insights to
strengthen maritime safety and decision support.

</details>


### [64] [AI-Driven Marine Robotics: Emerging Trends in Underwater Perception and Ecosystem Monitoring](https://arxiv.org/abs/2509.01878)
*Scarlett Raine,Tobias Fischer*

Main category: cs.RO

TL;DR: 本文分析了水下AI作为新兴研究前沿的快速发展，探讨了海洋感知从利基应用转变为AI创新催化剂的三大驱动因素：环境监测需求、数据民主化和研究人员迁移，并展示了水下挑战如何推动弱监督学习、开放集识别等基础AI技术进步。


<details>
  <summary>Details</summary>
Motivation: 应对气候变化对海洋生态系统的压力，需要可扩展的AI监测解决方案。水下AI的快速发展为海洋感知提供了新的技术路径，从被动观测转向AI驱动的主动干预能力。

Method: 通过分析三大驱动因素（环境必要性、数据民主化、研究人员迁移）和独特的水下挑战（浑浊度、隐秘物种检测、专家标注瓶颈、跨生态系统泛化），系统研究水下AI如何推动弱监督学习、开放集识别和鲁棒感知等基础AI技术进步。

Result: 研究发现水下约束正在推动基础模型、自监督学习和感知技术的边界拓展，这些方法论创新不仅适用于海洋应用，还惠及通用计算机视觉、机器人和环境监测领域。

Conclusion: 水下AI已成为AI创新的重要催化剂，其独特挑战推动了基础AI技术的突破性发展，这些技术进步具有超越海洋应用的广泛影响和价值。

Abstract: Marine ecosystems face increasing pressure due to climate change, driving the
need for scalable, AI-powered monitoring solutions. This paper examines the
rapid emergence of underwater AI as a major research frontier and analyzes the
factors that have transformed marine perception from a niche application into a
catalyst for AI innovation. We identify three convergent drivers: environmental
necessity for ecosystem-scale monitoring, democratization of underwater
datasets through citizen science platforms, and researcher migration from
saturated terrestrial computer vision domains. Our analysis reveals how unique
underwater challenges - turbidity, cryptic species detection, expert annotation
bottlenecks, and cross-ecosystem generalization - are driving fundamental
advances in weakly supervised learning, open-set recognition, and robust
perception under degraded conditions. We survey emerging trends in datasets,
scene understanding and 3D reconstruction, highlighting the paradigm shift from
passive observation toward AI-driven, targeted intervention capabilities. The
paper demonstrates how underwater constraints are pushing the boundaries of
foundation models, self-supervised learning, and perception, with
methodological innovations that extend far beyond marine applications to
benefit general computer vision, robotics, and environmental monitoring.

</details>


### [65] [AutoDrive-R$^2$: Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving](https://arxiv.org/abs/2509.01944)
*Zhenlong Yuan,Jing Tang,Jinguo Luo,Rui Chen,Chengxuan Qian,Lei Sun,Xiangxiang Chu,Yujun Cai,Dapeng Zhang,Shuo Li*

Main category: cs.RO

TL;DR: AutoDrive-R²是一个新的视觉-语言-动作模型框架，通过思维链推理和强化学习提升自动驾驶系统的决策可解释性和动作合理性


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶VLA模型在决策过程可解释性和动作序列合理性方面存在不足，需要增强推理和自我反思能力

Method: 提出四步逻辑链的思维链数据集nuScenesR²-6K进行监督微调，并在强化学习阶段使用GRPO算法结合物理基础奖励框架

Result: 在nuScenes和Waymo数据集上实现了最先进的性能，展现出强大的泛化能力

Conclusion: AutoDrive-R²通过思维链推理和强化学习的结合，显著提升了自动驾驶系统的决策质量和可解释性

Abstract: Vision-Language-Action (VLA) models in autonomous driving systems have
recently demonstrated transformative potential by integrating multimodal
perception with decision-making capabilities. However, the interpretability and
coherence of the decision process and the plausibility of action sequences
remain largely underexplored. To address these issues, we propose
AutoDrive-R$^2$, a novel VLA framework that enhances both reasoning and
self-reflection capabilities of autonomous driving systems through
chain-of-thought (CoT) processing and reinforcement learning (RL).
Specifically, we first propose an innovative CoT dataset named nuScenesR$^2$-6K
for supervised fine-tuning, which effectively builds cognitive bridges between
input information and output trajectories through a four-step logical chain
with self-reflection for validation. Moreover, to maximize both reasoning and
self-reflection during the RL stage, we further employ the Group Relative
Policy Optimization (GRPO) algorithm within a physics-grounded reward framework
that incorporates spatial alignment, vehicle dynamic, and temporal smoothness
criteria to ensure reliable and realistic trajectory planning. Extensive
evaluation results across both nuScenes and Waymo datasets demonstrates the
state-of-the-art performance and robust generalization capacity of our proposed
method.

</details>


### [66] [Geometric Control of Mechanical Systems with Symmetries Based on Sliding Modes](https://arxiv.org/abs/2509.01985)
*Eduardo Espindola,Yu Tang*

Main category: cs.RO

TL;DR: 提出了一个基于主纤维丛的机械系统滑模控制框架，利用对称性简化设计，在基空间执行趋近阶段，在结构群执行滑动阶段，避免了复杂的坐标选择问题。


<details>
  <summary>Details</summary>
Motivation: 针对具有对称性的机械系统（包括无约束和约束系统），传统滑模控制在特定李群上选择坐标表示时存在困难，设计复杂度高，需要开发更简化的控制策略。

Method: 基于运动方程的降阶形式，在结构群上构建滑动子群，在基空间设计基于滑动向量场的趋近律，利用机械连接的局部形式驱动滑动变量到滑动子群，并通过协变导数给出时间演化。

Result: 通过Lyapunov分析证明了几乎全局渐近稳定性和局部指数稳定性，并将方法应用于刚性航天器（全驱动系统）和独轮车移动机器人（欠驱动非完整系统）的仿真验证。

Conclusion: 该框架成功降低了滑模控制的设计复杂度，避免了特定李群坐标表示的困难选择，为具有对称性的机械系统提供了一种有效的控制方法。

Abstract: In this paper, we propose a framework for designing sliding mode controllers
for a class of mechanical systems with symmetry, both unconstrained and
constrained, that evolve on principal fiber bundles. Control laws are developed
based on the reduced motion equations by exploring symmetries, leading to a
sliding mode control strategy where the reaching stage is executed on the base
space, and the sliding stage is performed on the structure group. Thus, design
complexity is reduced, and difficult choices for coordinate representations
when working with a particular Lie group are avoided. For this purpose, a
sliding subgroup is constructed on the structure group based on a kinematic
controller, and the sliding variable will converge to the identity of the state
manifold upon reaching the sliding subgroup. A reaching law based on a general
sliding vector field is then designed on the base space using the local form of
the mechanical connection to drive the sliding variable to the sliding
subgroup, and its time evolution is given according to the appropriate
covariant derivative. Almost global asymptotic stability and local exponential
stability are demonstrated using a Lyapunov analysis. We apply the results to a
fully actuated system (a rigid spacecraft actuated by reaction wheels) and a
subactuated nonholonomic system (unicycle mobile robot actuated by wheels),
which is also simulated for illustration.

</details>


### [67] [MIRAGE: Multimodal Intention Recognition and Admittance-Guided Enhancement in VR-based Multi-object Teleoperation](https://arxiv.org/abs/2509.01996)
*Chi Sun,Xian Wang,Abhishek Kumar,Chengbin Cui,Lik-Hang Lee*

Main category: cs.RO

TL;DR: 提出结合虚拟导纳模型和多模态CNN意图感知网络的共享控制框架，通过多模态输入和人工势场引导，显著提升VR遥操作中的抓取成功率和运动效率


<details>
  <summary>Details</summary>
Motivation: 解决VR环境中多目标遥操作任务的感知模糊性和单模态意图识别限制，提升人机交互效果和用户体验

Method: 虚拟导纳模型使用人工势场引导操作者向目标物体移动，优化运动轨迹；多模态CNN网络处理凝视、机器人运动和环境上下文等多模态输入来估计抓取意图

Result: 用户研究表明，多模态意图感知网络显著提高了抓取成功率，虚拟导纳模型通过缩短路径长度提升了运动效率，凝视数据是最重要的输入模态

Conclusion: 多模态线索与隐式引导相结合在VR遥操作中效果显著，为多目标抓取任务提供了强大解决方案，有望实现更自然的人机交互

Abstract: Effective human-robot interaction (HRI) in multi-object teleoperation tasks
faces significant challenges due to perceptual ambiguities in virtual reality
(VR) environments and the limitations of single-modality intention recognition.
This paper proposes a shared control framework that combines a virtual
admittance (VA) model with a Multimodal-CNN-based Human Intention Perception
Network (MMIPN) to enhance teleoperation performance and user experience. The
VA model employs artificial potential fields to guide operators toward target
objects by adjusting admittance force and optimizing motion trajectories. MMIPN
processes multimodal inputs, including gaze movement, robot motions, and
environmental context, to estimate human grasping intentions, helping to
overcome depth perception challenges in VR. Our user study evaluated four
conditions across two factors, and the results showed that MMIPN significantly
improved grasp success rates, while the VA model enhanced movement efficiency
by reducing path lengths. Gaze data emerged as the most crucial input modality.
These findings demonstrate the effectiveness of combining multimodal cues with
implicit guidance in VR-based teleoperation, providing a robust solution for
multi-object grasping tasks and enabling more natural interactions across
various applications in the future.

</details>


### [68] [Generalizing Unsupervised Lidar Odometry Model from Normal to Snowy Weather Conditions](https://arxiv.org/abs/2509.02011)
*Beibei Zhou,Zhiyuan Zhang,Zhenbo Song,Jianhui Guo,Hui Kong*

Main category: cs.RO

TL;DR: 提出了一种无监督激光雷达里程计模型，通过PSM模块和PPWP模块有效处理雪天噪声，在保持实时性能的同时提升在恶劣天气下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有激光雷达里程计模型对雪天噪声敏感，难以在不同天气条件下泛化，限制了实际应用。需要解决雪天噪声对位姿估计的影响。

Method: 使用Patch Spatial Measure模块检测离散噪声，Patch Point Weight Predictor分配自适应点权重，结合强度阈值掩码和多模态特征融合实现实时去噪。

Result: 模型在晴朗和雪天条件下都表现出鲁棒性能，经过各种场景的严格测试验证了有效性。

Conclusion: 该方法增强了模型在恶劣天气下的泛化能力，为更可靠的自动驾驶系统在更广泛环境条件下运行奠定了基础。

Abstract: Deep learning-based LiDAR odometry is crucial for autonomous driving and
robotic navigation, yet its performance under adverse weather, especially
snowfall, remains challenging. Existing models struggle to generalize across
conditions due to sensitivity to snow-induced noise, limiting real-world use.
In this work, we present an unsupervised LiDAR odometry model to close the gap
between clear and snowy weather conditions. Our approach focuses on effective
denoising to mitigate the impact of snowflake noise and outlier points on pose
estimation, while also maintaining computational efficiency for real-time
applications.
  To achieve this, we introduce a Patch Spatial Measure (PSM) module that
evaluates the dispersion of points within each patch, enabling effective
detection of sparse and discrete noise.
  We further propose a Patch Point Weight Predictor (PPWP) to assign adaptive
point-wise weights, enhancing their discriminative capacity within local
regions. To support real-time performance, we first apply an intensity
threshold mask to quickly suppress dense snowflake clusters near the LiDAR, and
then perform multi-modal feature fusion to refine the point-wise weight
prediction, improving overall robustness under adverse weather. Our model is
trained in clear weather conditions and rigorously tested across various
scenarios, including snowy and dynamic. Extensive experimental results confirm
the effectiveness of our method, demonstrating robust performance in both clear
and snowy weather. This advancement enhances the model's generalizability and
paves the way for more reliable autonomous systems capable of operating across
a wider range of environmental conditions.

</details>


### [69] [Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance](https://arxiv.org/abs/2509.02055)
*Yang Zhang,Chenwei Wang,Ouyang Lu,Yuan Zhao,Yunfei Ge,Zhenglong Sun,Xiu Li,Chi Zhang,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: 提出了ATE框架，通过动作空间对齐和引导机制，高效适应VLA模型到不同的机器人平台和任务，显著提升跨本体和跨任务的操作性能。


<details>
  <summary>Details</summary>
Motivation: VLA模型在预训练后适应下游任务时存在动作分布不匹配的问题，需要大量数据和计算资源进行微调，限制了实际部署的实用性。

Method: ATE框架包含两个步骤：首先使用变分自编码器构建统一潜在空间对齐动作分布，然后通过引导机制在微调过程中将模型输出推向目标域。

Result: 在仿真环境中平均多任务成功率提升9.8%，在真实世界跨本体设置中获得32%的成功率增益。

Conclusion: ATE提供了一个通用且轻量级的解决方案，大大增强了VLA模型在新机器人平台和任务上的部署实用性。

Abstract: Vision-Language-Action (VLA) models pre-trained on large, diverse datasets
show remarkable potential for general-purpose robotic manipulation. However, a
primary bottleneck remains in adapting these models to downstream tasks,
especially when the robot's embodiment or the task itself differs from the
pre-training data. This discrepancy leads to a significant mismatch in action
distributions, demanding extensive data and compute for effective fine-tuning.
To address this challenge, we introduce \textbf{Align-Then-stEer
(\texttt{ATE})}, a novel, data-efficient, and plug-and-play adaptation
framework. \texttt{ATE} first aligns disparate action spaces by constructing a
unified latent space, where a variational autoencoder constrained by reverse KL
divergence embeds adaptation actions into modes of the pre-training action
latent distribution. Subsequently, it steers the diffusion- or flow-based VLA's
generation process during fine-tuning via a guidance mechanism that pushes the
model's output distribution towards the target domain. We conduct extensive
experiments on cross-embodiment and cross-task manipulation in both simulation
and real world. Compared to direct fine-tuning of representative VLAs, our
method improves the average multi-task success rate by up to \textbf{9.8\%} in
simulation and achieves a striking \textbf{32\% success rate gain} in a
real-world cross-embodiment setting. Our work presents a general and
lightweight solution that greatly enhances the practicality of deploying VLA
models to new robotic platforms and tasks.

</details>


### [70] [A Geometric Method for Base Parameter Analysis in Robot Inertia Identification Based on Projective Geometric Algebra](https://arxiv.org/abs/2509.02071)
*Guangzhen Sun,Ye Ding,Xiangyang Zhu*

Main category: cs.RO

TL;DR: 提出了一种基于投影几何代数的新型几何方法，用于分析确定机器人系统的基础惯性参数，开发了具有几何解释的封闭形式识别模型和高效算法。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统基础惯性参数识别方法缺乏几何直观性且计算效率有限，特别是在并联机构(PKM)中表现不佳，需要一种具有清晰几何解释和高计算效率的新方法。

Method: 使用投影几何代数重构刚体动力学，提出"四面体点(TP)"识别模型，基于三个基本原理(共享点、固定点、平面旋转)开发算法，核心算法DRNG在O(N)预处理后达到O(1)复杂度。

Result: 在Puma560、Unitree Go2、2RRU-1RRS和2PRS-1PSR四种机器人上成功验证，算法能完整识别所有基础参数，特别是在PKM中表现出高鲁棒性和计算效率。

Conclusion: 该方法具有通用性、鲁棒性和高效性，为机器人系统基础参数识别提供了几何直观且计算高效的解决方案，特别适用于复杂并联机构。

Abstract: This paper proposes a novel geometric method for analytically determining the
base inertial parameters of robotic systems. The rigid body dynamics is
reformulated using projective geometric algebra, leading to a new
identification model named ``tetrahedral-point (TP)" model. Based on the rigid
body TP model, coefficients in the regresoor matrix of the identification model
are derived in closed-form, exhibiting clear geometric interpretations.
Building directly from the dynamic model, three foundational principles for
base parameter analysis are proposed: the shared points principle, fixed points
principle, and planar rotations principle. With these principles, algorithms
are developed to automatically determine all the base parameters. The core
algorithm, referred to as Dynamics Regressor Nullspace Generator (DRNG),
achieves $O(1)$-complexity theoretically following an $O(N)$-complexity
preprocessing stage, where $N$ is the number of rigid bodies. The proposed
method and algorithms are validated across four robots: Puma560, Unitree Go2, a
2RRU-1RRS parallel kinematics mechanism (PKM), and a 2PRS-1PSR PKM. In all
cases, the algorithms successfully identify the complete set of base
parameters. Notably, the approach demonstrates high robustness and
computational efficiency, particularly in the cases of PKMs. Through the
comprehensive demonstrations, the method is shown to be general, robust, and
efficient.

</details>


### [71] [Learning Social Heuristics for Human-Aware Path Planning](https://arxiv.org/abs/2509.02134)
*Andrea Eirale,Matteo Leonetti,Marcello Chiaberge*

Main category: cs.RO

TL;DR: 提出HPLSV方法，通过学习的社交价值函数作为启发式搜索路径规划的额外启发项，解决机器人社交导航中的队列加入问题


<details>
  <summary>Details</summary>
Motivation: 传统导航方法无法满足真正的社交接受度，机器人需要学习特定的社交规范，而不仅仅是避障和保持社交距离

Method: Heuristic Planning with Learned Social Value (HPLSV) - 学习封装社交导航成本的价值函数，并将其作为启发式搜索路径规划的额外启发项

Result: 初步应用于加入人群队列的常见社交场景，并计划推广到更多人类活动

Conclusion: 该方法为机器人实现真正的社交接受度提供了一种新的学习框架，通过专门的社交价值学习过程来获得社交规范

Abstract: Social robotic navigation has been at the center of numerous studies in
recent years. Most of the research has focused on driving the robotic agent
along obstacle-free trajectories, respecting social distances from humans, and
predicting their movements to optimize navigation. However, in order to really
be socially accepted, the robots must be able to attain certain social norms
that cannot arise from conventional navigation, but require a dedicated
learning process. We propose Heuristic Planning with Learned Social Value
(HPLSV), a method to learn a value function encapsulating the cost of social
navigation, and use it as an additional heuristic in heuristic-search path
planning. In this preliminary work, we apply the methodology to the common
social scenario of joining a queue of people, with the intention of
generalizing to further human activities.

</details>


### [72] [Systematic Evaluation of Trade-Offs in Motion Planning Algorithms for Optimal Industrial Robotic Work Cell Design](https://arxiv.org/abs/2509.02146)
*G. de Mathelin,C. Hartl-Nesic,A. Kugi*

Main category: cs.RO

TL;DR: 本文提出了评估工业机器人工作单元双层优化中运动规划权衡的指标，通过仿真研究分析运动级简化对高层优化的影响，并在模块化机器人码垛场景中应用


<details>
  <summary>Details</summary>
Motivation: 工业机器人工作单元性能优化需要双层优化方法，但底层运动规划的计算复杂性引入了各种权衡，这些权衡对整体性能的影响尚未被系统评估

Method: 引入评估运动规划权衡的指标（最优性、时间增益、鲁棒性、一致性），通过广泛的仿真研究分析运动级优化简化对高层优化结果的影响

Result: 提出了系统的评估框架，在模块化机器人的两个码垛场景中成功应用所提算法找到了时间最优的运动学设计

Conclusion: 运动级优化的简化策略显著影响双层优化的整体性能，需要仔细平衡计算复杂度和解的质量，提出的评估指标为这种权衡提供了系统分析工具

Abstract: The performance of industrial robotic work cells depends on optimizing
various hyperparameters referring to the cell layout, such as robot base
placement, tool placement, and kinematic design. Achieving this requires a
bilevel optimization approach, where the high-level optimization adjusts these
hyperparameters, and the low-level optimization computes robot motions.
However, computing the optimal robot motion is computationally infeasible,
introducing trade-offs in motion planning to make the problem tractable. These
trade-offs significantly impact the overall performance of the bilevel
optimization, but their effects still need to be systematically evaluated. In
this paper, we introduce metrics to assess these trade-offs regarding
optimality, time gain, robustness, and consistency. Through extensive
simulation studies, we investigate how simplifications in motion-level
optimization affect the high-level optimization outcomes, balancing
computational complexity with solution quality. The proposed algorithms are
applied to find the time-optimal kinematic design for a modular robot in two
palletization scenarios.

</details>


### [73] [Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety](https://arxiv.org/abs/2509.02163)
*Wenxiao Zhang,Xiangrui Kong,Conan Dewitt,Thomas Bräunl,Jin B. Hong*

Main category: cs.RO

TL;DR: 提出了一个统一框架来提升LLM机器人系统的可靠性和安全性，通过提示组装、状态管理和安全验证机制，在对抗攻击和复杂环境下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在机器人系统中实现了先进的决策和适应性，但确保系统可靠性（包括对抗攻击的安全性和复杂环境下的安全性）仍是一个关键挑战。

Method: 提出了一个统一框架，结合提示组装、状态管理和安全验证机制，通过鲁棒的验证机制来缓解提示注入攻击并强制执行操作安全性。

Result: 实验显示在注入攻击下性能提升30.8%，在复杂环境对抗条件下相比基线场景提升高达325%。

Conclusion: 这项工作弥合了基于LLM的机器人系统中安全性和安全性之间的差距，为在现实世界环境中部署可靠的LLM集成移动机器人提供了可行的见解，框架已开源。

Abstract: Integrating large language models (LLMs) into robotic systems has
revolutionised embodied artificial intelligence, enabling advanced
decision-making and adaptability. However, ensuring reliability, encompassing
both security against adversarial attacks and safety in complex environments,
remains a critical challenge. To address this, we propose a unified framework
that mitigates prompt injection attacks while enforcing operational safety
through robust validation mechanisms. Our approach combines prompt assembling,
state management, and safety validation, evaluated using both performance and
security metrics. Experiments show a 30.8% improvement under injection attacks
and up to a 325% improvement in complex environment settings under adversarial
conditions compared to baseline scenarios. This work bridges the gap between
safety and security in LLM-based robotic systems, offering actionable insights
for deploying reliable LLM-integrated mobile robots in real-world settings. The
framework is open-sourced with simulation and physical deployment demos at
https://llmeyesim.vercel.app/

</details>


### [74] [Human-Inspired Soft Anthropomorphic Hand System for Neuromorphic Object and Pose Recognition Using Multimodal Signals](https://arxiv.org/abs/2509.02275)
*Fengyi Wang,Xiangyu Fu,Nitish Thakor,Gordon Cheng*

Main category: cs.RO

TL;DR: 本文提出了一种仿生多模态传感器化软体人手，采用脉冲神经网络处理多模态感官数据，在物体识别和材料分类方面取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 受人类体感系统整合触觉、本体感觉和温度信号的多模态感知机制启发，旨在为机器人系统实现高效、鲁棒且类人的感知能力。

Method: 开发了配备多种传感器的仿生软体人手，采用生物启发编码方案将多模态感官数据转换为脉冲序列，通过脉冲神经网络进行处理，并引入了新型微分神经元模型来捕捉动态热响应。

Result: 系统在不同姿态下的物体识别准确率达到97.14%，显著优于以往软体手研究，同时在材料分类方面也表现出色。

Conclusion: 多模态感官融合和神经形态方法在实现机器人系统高效、鲁棒和类人感知方面具有巨大潜力。

Abstract: The human somatosensory system integrates multimodal sensory feedback,
including tactile, proprioceptive, and thermal signals, to enable comprehensive
perception and effective interaction with the environment. Inspired by the
biological mechanism, we present a sensorized soft anthropomorphic hand
equipped with diverse sensors designed to emulate the sensory modalities of the
human hand. This system incorporates biologically inspired encoding schemes
that convert multimodal sensory data into spike trains, enabling
highly-efficient processing through Spiking Neural Networks (SNNs). By
utilizing these neuromorphic signals, the proposed framework achieves 97.14%
accuracy in object recognition across varying poses, significantly
outperforming previous studies on soft hands. Additionally, we introduce a
novel differentiator neuron model to enhance material classification by
capturing dynamic thermal responses. Our results demonstrate the benefits of
multimodal sensory fusion and highlight the potential of neuromorphic
approaches for achieving efficient, robust, and human-like perception in
robotic systems.

</details>


### [75] [Sem-RaDiff: Diffusion-Based 3D Radar Semantic Perception in Cluttered Agricultural Environments](https://arxiv.org/abs/2509.02283)
*Ruibin Zhang,Fei Gao*

Main category: cs.RO

TL;DR: 提出基于雷达的3D环境感知框架，用于农业场景中机器人导航，通过扩散模型和并行帧积累技术解决光学传感器易受遮挡污染的问题，在精度和效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前机器人导航主要依赖光学传感器（相机、LiDAR），但在农业场景中易受传感器污染和视觉遮挡影响导致性能下降或系统失效。雷达具有较强的穿透能力，可作为替代方案。

Method: 1) 并行帧积累增强雷达信噪比；2) 基于扩散模型的分层学习框架，先滤除雷达旁瓣伪影，再生成细粒度3D语义点云；3) 专门设计的稀疏3D网络处理大规模雷达原始数据。

Result: 在真实农业场景数据集上测试，结构性和语义预测性能优于现有方法，计算和内存成本分别降低51.3%和27.5%，能够完整重建和准确分类电线杆等细薄结构。

Conclusion: 该方法展示了密集准确3D雷达感知的潜力，特别适用于存在传感器污染风险的农业环境，为机器人自主导航提供了可靠的感知替代方案。

Abstract: Accurate and robust environmental perception is crucial for robot autonomous
navigation. While current methods typically adopt optical sensors (e.g.,
camera, LiDAR) as primary sensing modalities, their susceptibility to visual
occlusion often leads to degraded performance or complete system failure. In
this paper, we focus on agricultural scenarios where robots are exposed to the
risk of onboard sensor contamination. Leveraging radar's strong penetration
capability, we introduce a radar-based 3D environmental perception framework as
a viable alternative. It comprises three core modules designed for dense and
accurate semantic perception: 1) Parallel frame accumulation to enhance
signal-to-noise ratio of radar raw data. 2) A diffusion model-based
hierarchical learning framework that first filters radar sidelobe artifacts
then generates fine-grained 3D semantic point clouds. 3) A specifically
designed sparse 3D network optimized for processing large-scale radar raw data.
We conducted extensive benchmark comparisons and experimental evaluations on a
self-built dataset collected in real-world agricultural field scenes. Results
demonstrate that our method achieves superior structural and semantic
prediction performance compared to existing methods, while simultaneously
reducing computational and memory costs by 51.3% and 27.5%, respectively.
Furthermore, our approach achieves complete reconstruction and accurate
classification of thin structures such as poles and wires-which existing
methods struggle to perceive-highlighting its potential for dense and accurate
3D radar perception.

</details>


### [76] [Language-Guided Long Horizon Manipulation with LLM-based Planning and Visual Perception](https://arxiv.org/abs/2509.02324)
*Changshi Zhou,Haichuan Xu,Ningquan Gu,Zhipeng Wang,Bin Cheng,Pengpeng Zhang,Yanchao Dong,Mitsuhiro Hayashibe,Yanmin Zhou,Bin He*

Main category: cs.RO

TL;DR: 这是一个使用大语言模型和视觉-语言模型的统一框架，用于语言指导的长时序变形物体操纵任务，特别是多步衣物折叠任务。


<details>
  <summary>Details</summary>
Motivation: 解决语言指导的长时序变形物体操纵面临的挑战，包括高约束度、复杂动力学和准确的视觉-语言基础。多步衣物折叠作为代表性任务，需要结构化的长时序规划和细粒度视觉感知。

Method: 提出了一个统一框架，集成了LLM基于的规划器、VLM基于的感知系统和任务执行模块。LLM规划器将高级语言指令分解为低级动作原语；VLM感知模块采用SigLIP2驱动的架构，包含双向交叉注意力融合机制和DoRA精调。

Result: 在模拟环境中，方法在见过的指令、未见的指令和未见的任务上分别超过最先进基线2.23、1.87和33.3。在真实机器人上，能够稳健执行来自语言指令的多步折叠序列，适应不同衣物材料和配置，展现了强大的实际场景演绎能力。

Conclusion: 该统一框架通过集成LLM和VLM技术，有效解决了语言指导长时序变形物体操纵的挑战，在模拟和真实环境中都展现了良好的性能和演绎能力。

Abstract: Language-guided long-horizon manipulation of deformable objects presents
significant challenges due to high degrees of freedom, complex dynamics, and
the need for accurate vision-language grounding. In this work, we focus on
multi-step cloth folding, a representative deformable-object manipulation task
that requires both structured long-horizon planning and fine-grained visual
perception. To this end, we propose a unified framework that integrates a Large
Language Model (LLM)-based planner, a Vision-Language Model (VLM)-based
perception system, and a task execution module. Specifically, the LLM-based
planner decomposes high-level language instructions into low-level action
primitives, bridging the semantic-execution gap, aligning perception with
action, and enhancing generalization. The VLM-based perception module employs a
SigLIP2-driven architecture with a bidirectional cross-attention fusion
mechanism and weight-decomposed low-rank adaptation (DoRA) fine-tuning to
achieve language-conditioned fine-grained visual grounding. Experiments in both
simulation and real-world settings demonstrate the method's effectiveness. In
simulation, it outperforms state-of-the-art baselines by 2.23, 1.87, and 33.3
on seen instructions, unseen instructions, and unseen tasks, respectively. On a
real robot, it robustly executes multi-step folding sequences from language
instructions across diverse cloth materials and configurations, demonstrating
strong generalization in practical scenarios. Project page:
https://language-guided.netlify.app/

</details>


### [77] [Physics-Informed Machine Learning with Adaptive Grids for Optical Microrobot Depth Estimation](https://arxiv.org/abs/2509.02343)
*Lan Wei,Lou Genoud,Dandan Zhang*

Main category: cs.RO

TL;DR: 基于物理信息的深度估计框架，通过物理重点指标与卷积神经网络结合，实现了光学微结构器人的高精度三维感知，在数据有限条件下显著提升性能


<details>
  <summary>Details</summary>
Motivation: 光学微结构器人在生物医学应用中需要准确的三维感知，但透明性质和低对比度显微镜成像给传统深度学习方法带来挑战，同时大规模标注数据成本较高

Method: 提出物理信息驱动的深度估计框架，将卷积特征提取与基于物理的重点指标（如熵、拉普拉斯和梯度销利度）相结合，采用适应性网格策略在微结构器人区域分配更细细的网格以提高深度敏感性

Result: 在多种微结构器人类型上评估，平均方差锐减60%以上，决定系数R^2在所有测试案例中都有提升。仅使用20%数据训练的模型依然超过了使用全部数据训练的ResNet50模型

Conclusion: 该方法为光学微结构器人的三维感知提供了一种数据高效、计算效率高的解决方案，在数据有限条件下保持了漂亮的性能，对于复杂生物环境中的精确控制具有重要意义

Abstract: Optical microrobots actuated by optical tweezers (OT) offer great potential
for biomedical applications such as cell manipulation and microscale assembly.
These tasks demand accurate three-dimensional perception to ensure precise
control in complex and dynamic biological environments. However, the
transparent nature of microrobots and low-contrast microscopic imaging
challenge conventional deep learning methods, which also require large
annotated datasets that are costly to obtain. To address these challenges, we
propose a physics-informed, data-efficient framework for depth estimation of
optical microrobots. Our method augments convolutional feature extraction with
physics-based focus metrics, such as entropy, Laplacian of Gaussian, and
gradient sharpness, calculated using an adaptive grid strategy. This approach
allocates finer grids over microrobot regions and coarser grids over background
areas, enhancing depth sensitivity while reducing computational complexity. We
evaluate our framework on multiple microrobot types and demonstrate significant
improvements over baseline models. Specifically, our approach reduces mean
squared error (MSE) by over 60% and improves the coefficient of determination
(R^2) across all test cases. Notably, even when trained on only 20% of the
available data, our model outperforms ResNet50 trained on the full dataset,
highlighting its robustness under limited data conditions. Our code is
available at: https://github.com/LannWei/CBS2025.

</details>


### [78] [OpenGuide: Assistive Object Retrieval in Indoor Spaces for Individuals with Visual Impairments](https://arxiv.org/abs/2509.02425)
*Yifan Xu,Qianwei Wang,Vineet Kamat,Carol Menassa*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Indoor built environments like homes and offices often present complex and
cluttered layouts that pose significant challenges for individuals who are
blind or visually impaired, especially when performing tasks that involve
locating and gathering multiple objects. While many existing assistive
technologies focus on basic navigation or obstacle avoidance, few systems
provide scalable and efficient multi-object search capabilities in real-world,
partially observable settings. To address this gap, we introduce OpenGuide, an
assistive mobile robot system that combines natural language understanding with
vision-language foundation models (VLM), frontier-based exploration, and a
Partially Observable Markov Decision Process (POMDP) planner. OpenGuide
interprets open-vocabulary requests, reasons about object-scene relationships,
and adaptively navigates and localizes multiple target items in novel
environments. Our approach enables robust recovery from missed detections
through value decay and belief-space reasoning, resulting in more effective
exploration and object localization. We validate OpenGuide in simulated and
real-world experiments, demonstrating substantial improvements in task success
rate and search efficiency over prior methods. This work establishes a
foundation for scalable, human-centered robotic assistance in assisted living
environments.

</details>


### [79] [U-ARM : Ultra low-cost general teleoperation interface for robot manipulation](https://arxiv.org/abs/2509.02437)
*Yanwen Zou,Zhaoye Zhou,Chenyang Shi,Zewei Ye,Junda Huang,Yan Ding,Bo Zhao*

Main category: cs.RO

TL;DR: U-Arm是一个低成本、快速适配的领导者-跟随者遥操作框架，可与大多数商用机械臂兼容，通过3D打印的领导者臂实现，成本仅50-57美元，数据收集效率比Joycon高39%


<details>
  <summary>Details</summary>
Motivation: 为了解决现有开源遥操作接口成本高、兼容性差的问题，开发一个低成本、快速适配的领导者-跟随者遥操作框架，使其能够与大多数商用机械臂兼容

Method: 设计三种结构不同的3D打印领导者臂，共享一致的控制逻辑；优化机械设计和伺服选择；通过机械和控制优化解决冗余自由度控制难题

Result: 6自由度版本成本50.5美元，7自由度版本56.8美元；数据收集效率比Joycon高39%；在多种操作场景中达到相当的任务成功率

Conclusion: U-Arm是一个成功的低成本遥操作解决方案，具有优秀的兼容性和实用性，已开源所有CAD模型和仿真支持，并提供真实世界操作数据集

Abstract: We propose U-Arm, a low-cost and rapidly adaptable leader-follower
teleoperation framework designed to interface with most of commercially
available robotic arms. Our system supports teleoperation through three
structurally distinct 3D-printed leader arms that share consistent control
logic, enabling seamless compatibility with diverse commercial robot
configurations. Compared with previous open-source leader-follower interfaces,
we further optimized both the mechanical design and servo selection, achieving
a bill of materials (BOM) cost of only \$50.5 for the 6-DoF leader arm and
\$56.8 for the 7-DoF version. To enhance usability, we mitigate the common
challenge in controlling redundant degrees of freedom by %engineering methods
mechanical and control optimizations. Experimental results demonstrate that
U-Arm achieves 39\% higher data collection efficiency and comparable task
success rates across multiple manipulation scenarios compared with Joycon,
another low-cost teleoperation interface. We have open-sourced all CAD models
of three configs and also provided simulation support for validating
teleoperation workflows. We also open-sourced real-world manipulation data
collected with U-Arm. The project website is
https://github.com/MINT-SJTU/LeRobot-Anything-U-Arm.

</details>


### [80] [Coral: A Unifying Abstraction Layer for Composable Robotics Software](https://arxiv.org/abs/2509.02453)
*Steven Swanbeck,Mitch Pryor*

Main category: cs.RO

TL;DR: Coral是一个机器人软件抽象层，通过最大化组件可组合性来解决系统集成难题，无需修改底层代码即可快速集成独立软件组件。


<details>
  <summary>Details</summary>
Motivation: 机器人软件集成耗时且困难，现有系统通常紧密耦合，即使是小的改动也需要大量工程投入，阻碍了性能改进、任务调整和新硬件部署。

Method: Coral作为抽象层，通过引入高层语义约束来补充现有工具，限制集成过程到有意义的语义选择，减少配置负担同时保持对不同领域、系统和任务的适应性。

Result: 在LiDAR SLAM和多机器人腐蚀缓解等复杂场景中验证了Coral的实用性，展示了其在提高组件可重用性、系统可重构性和用户可访问性方面的效果。

Conclusion: Coral通过实现机器人软件的实际可组合性，为广泛的系统集成挑战提供了可扩展解决方案，并已开源发布。

Abstract: Despite the multitude of excellent software components and tools available in
the robotics and broader software engineering communities, successful
integration of software for robotic systems remains a time-consuming and
challenging task for users of all knowledge and skill levels. And with robotics
software often being built into tightly coupled, monolithic systems, even minor
alterations to improve performance, adjust to changing task requirements, or
deploy to new hardware can require significant engineering investment. To help
solve this problem, this paper presents Coral, an abstraction layer for
building, deploying, and coordinating independent software components that
maximizes composability to allow for rapid system integration without modifying
low-level code. Rather than replacing existing tools, Coral complements them by
introducing a higher-level abstraction that constrains the integration process
to semantically meaningful choices, reducing the configuration burden without
limiting adaptability to diverse domains, systems, and tasks. We describe Coral
in detail and demonstrate its utility in integrating software for scenarios of
increasing complexity, including LiDAR-based SLAM and multi-robot corrosion
mitigation tasks. By enabling practical composability in robotics software,
Coral offers a scalable solution to a broad range of robotics system
integration challenges, improving component reusability, system
reconfigurability, and accessibility to both expert and non-expert users. We
release Coral open source.

</details>


### [81] [Classification of Vision-Based Tactile Sensors: A Review](https://arxiv.org/abs/2509.02478)
*Haoran Li,Yijiong Lin,Chenghua Lu,Max Yang,Efi Psomopoulou,Nathan F Lepora*

Main category: cs.RO

TL;DR: 本文提出了一种新的视觉触觉传感器分类方法，将其分为基于标记的转换原理和基于强度的转换原理两大类，并进一步细分为四种机制，提供了硬件特性的比较研究和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 视觉触觉传感器在机器人领域应用广泛，但现有技术存在多种不同的传感原理、材料组成和多模态方法，缺乏统一的分类框架来系统比较和分析这些技术。

Method: 提出基于接触转换为触觉图像的转换原理进行分类：标记基转换（检测标记位移和密度变化）和强度基转换（像素值变化映射外部干扰）。标记基进一步分为简单标记基和形态标记基，强度基分为反射层基和透明层基。

Result: 建立了系统的视觉触觉传感器分类框架，对四种传感器类型的硬件特性进行了比较研究，包括各种组合类型和常用的触觉信息解释方法。

Conclusion: 该分类方法揭示了视觉触觉传感器技术当前面临的挑战，并为未来研究提供了方向指导，有助于推动该领域的标准化和发展。

Abstract: Vision-based tactile sensors (VBTS) have gained widespread application in
robotic hands, grippers and prosthetics due to their high spatial resolution,
low manufacturing costs, and ease of customization. While VBTSs have common
design features, such as a camera module, they can differ in a rich diversity
of sensing principles, material compositions, multimodal approaches, and data
interpretation methods. Here, we propose a novel classification of VBTS that
categorizes the technology into two primary sensing principles based on the
underlying transduction of contact into a tactile image: the Marker-Based
Transduction Principle and the Intensity-Based Transduction Principle.
Marker-Based Transduction interprets tactile information by detecting marker
displacement and changes in marker density. In contrast, Intensity-Based
Transduction maps external disturbances with variations in pixel values.
Depending on the design of the contact module, Marker-Based Transduction can be
further divided into two subtypes: Simple Marker-Based (SMB) and Morphological
Marker-Based (MMB) mechanisms. Similarly, the Intensity-Based Transduction
Principle encompasses the Reflective Layer-based (RLB) and Transparent
Layer-Based (TLB) mechanisms. This paper provides a comparative study of the
hardware characteristics of these four types of sensors including various
combination types, and discusses the commonly used methods for interpreting
tactile information. This~comparison reveals some current challenges faced by
VBTS technology and directions for future research.

</details>


### [82] [Fault-tolerant Model Predictive Control for Spacecraft](https://arxiv.org/abs/2509.02527)
*Raphael Stöckner,Pedro Roque,Maria Charitidou,Dimos V. Dimarogonas*

Main category: cs.RO

TL;DR: 提出基于模型预测控制的航天器轨迹控制方法，可在多执行器故障情况下实现稳定控制和安全导航


<details>
  <summary>Details</summary>
Motivation: 卫星星座成本高昂且功能关键，需要确保任务寿命和安全退役，这对空间可持续性至关重要

Method: 采用模型预测控制(MPC)方法处理航天器轨迹和设定点稳定问题，支持多执行器故障情况下的控制

Result: 该方法能够高效控制故障航天器，实现安全导航至服务或避碰轨迹，确保闭环渐近稳定性和递归可行性

Conclusion: 通过开源数值结果和ATMOS平台的真实实验验证了该方案的有效性，为航天器故障控制提供了可靠解决方案

Abstract: Given the cost and critical functions of satellite constellations, ensuring
mission longevity and safe decommissioning is essential for space
sustainability. This article presents a Model Predictive Control for spacecraft
trajectory and setpoint stabilization under multiple actuation failures. The
proposed solution allows us to efficiently control the faulty spacecraft
enabling safe navigation towards servicing or collision-free trajectories. The
proposed scheme ensures closed-loop asymptotic stability and is shown to be
recursively feasible. We demonstrate its efficacy through open-source numerical
results and realistic experiments using the ATMOS platform.

</details>


### [83] [Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots](https://arxiv.org/abs/2509.02530)
*Minghuan Liu,Zhengbang Zhu,Xiaoshen Han,Peng Hu,Haotong Lin,Xinyao Li,Jingxiao Chen,Jiafeng Xu,Yichu Yang,Yunfeng Lin,Xinghang Li,Yong Yu,Weinan Zhang,Tao Kong,Bingyi Kang*

Main category: cs.RO

TL;DR: 这篇论文提出了相机深度模型(CDMs)，通过模拟深度摄像头的噪声模式生成高质量数据，实现了从模拟到现实的无缝转换，使得仅使用模拟深度训练的策略能够在现实任务中实现良好的性能。


<details>
  <summary>Details</summary>
Motivation: 现代机器人操作主要依赖于2D视觉观测，但普遍存在性能不佳和缺乏演绎性的问题。人类在3D世界中更依赖于物理属性而非纹理，因此希望通过深度摄像头为机器人提供类似的3D感知能力。

Method: 提出相机深度模型(CDMs)，作为普通深度摄像头的插件，输入RGB图像和原始深度信号，输出去噪后的准确深度值。开发了神经网络数据引擎，通过模拟深度摄像头的噪声模式来生成高质量的配对数据。

Result: CDMs实现了接近模拟级别的深度预测精度，有效缩小了模拟与现实之间的差距。在两个具有挑战性的长期限任务中，仅使用模拟深度训练的策略能够无缝演绎到现实机器人，并处理关节、反射性和细长物体，性能减退微小或无减退。

Conclusion: 该研究为利用模拟数据和3D信息来开发更具演绎性的机器人策略提供了新的思路，通过准确模拟深度摄像头的噪声特性，实现了模拟到现实的高效转换。

Abstract: Modern robotic manipulation primarily relies on visual observations in a 2D
color space for skill learning but suffers from poor generalization. In
contrast, humans, living in a 3D world, depend more on physical properties-such
as distance, size, and shape-than on texture when interacting with objects.
Since such 3D geometric information can be acquired from widely available depth
cameras, it appears feasible to endow robots with similar perceptual
capabilities. Our pilot study found that using depth cameras for manipulation
is challenging, primarily due to their limited accuracy and susceptibility to
various types of noise. In this work, we propose Camera Depth Models (CDMs) as
a simple plugin on daily-use depth cameras, which take RGB images and raw depth
signals as input and output denoised, accurate metric depth. To achieve this,
we develop a neural data engine that generates high-quality paired data from
simulation by modeling a depth camera's noise pattern. Our results show that
CDMs achieve nearly simulation-level accuracy in depth prediction, effectively
bridging the sim-to-real gap for manipulation tasks. Notably, our experiments
demonstrate, for the first time, that a policy trained on raw simulated depth,
without the need for adding noise or real-world fine-tuning, generalizes
seamlessly to real-world robots on two challenging long-horizon tasks involving
articulated, reflective, and slender objects, with little to no performance
degradation. We hope our findings will inspire future research in utilizing
simulation data and 3D information in general robot policies.

</details>
