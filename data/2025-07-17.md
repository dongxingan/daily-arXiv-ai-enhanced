<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [HCOMC: A Hierarchical Cooperative On-Ramp Merging Control Framework in Mixed Traffic Environment on Two-Lane Highways](https://arxiv.org/abs/2507.11621)
*Tianyi Wang,Yangyang Wang,Jie Pan,Junfeng Jiao,Christian Claudel*

Main category: cs.RO

TL;DR: 论文提出了一种分层协作式匝道合流控制（HCOMC）框架，用于解决混合交通流中的匝道合流问题，结合纵向跟车和横向换道模型，并通过仿真验证其性能。


<details>
  <summary>Details</summary>
Motivation: 高速公路匝道合流区域是交通拥堵和事故的常见瓶颈，而基于联网自动驾驶车辆（CAVs）的协作控制策略是根本解决方案。在CAV未完全普及的情况下，需提出适用于混合交通流的控制框架。

Method: 扩展了基于智能驾驶员模型的纵向跟车模型和基于五次多项式曲线的横向换道模型，提出了HCOMC框架，包括分层协作规划模型、基于博弈论的可选换道模型和多目标优化模型。

Result: 仿真结果表明，HCOMC在提升车辆群安全性、稳定和加速合流过程、优化交通效率和节省燃油消耗方面具有显著优势。

Conclusion: HCOMC框架为混合交通流中的匝道合流问题提供了有效的解决方案，具有实际应用潜力。

Abstract: Highway on-ramp merging areas are common bottlenecks to traffic congestion
and accidents. Currently, a cooperative control strategy based on connected and
automated vehicles (CAVs) is a fundamental solution to this problem. While CAVs
are not fully widespread, it is necessary to propose a hierarchical cooperative
on-ramp merging control (HCOMC) framework for heterogeneous traffic flow on
two-lane highways to address this gap. This paper extends longitudinal
car-following models based on the intelligent driver model and lateral
lane-changing models using the quintic polynomial curve to account for
human-driven vehicles (HDVs) and CAVs, comprehensively considering human
factors and cooperative adaptive cruise control. Besides, this paper proposes a
HCOMC framework, consisting of a hierarchical cooperative planning model based
on the modified virtual vehicle model, a discretionary lane-changing model
based on game theory, and a multi-objective optimization model using the
elitist non-dominated sorting genetic algorithm to ensure the safe, smooth, and
efficient merging process. Then, the performance of our HCOMC is analyzed under
different traffic densities and CAV penetration rates through simulation. The
findings underscore our HCOMC's pronounced comprehensive advantages in
enhancing the safety of group vehicles, stabilizing and expediting merging
process, optimizing traffic efficiency, and economizing fuel consumption
compared with benchmarks.

</details>


### [2] [A Roadmap for Climate-Relevant Robotics Research](https://arxiv.org/abs/2507.11623)
*Alan Papalia,Charles Dawson,Laurentiu L. Anton,Norhan Magdy Bayomi,Bianca Champenois,Jung-Hoon Cho,Levi Cai,Joseph DelPreto,Kristen Edwards,Bilha-Catherine Githinji,Cameron Hickert,Vindula Jayawardana,Matthew Kramer,Shreyaa Raghavan,David Russell,Shide Salimi,Jingnan Shi,Soumya Sudhakar,Yanwei Wang,Shouyi Wang,Luca Carlone,Vijay Kumar,Daniela Rus,John E. Fernandez,Cathy Wu,George Kantor,Derek Young,Hanumant Singh*

Main category: cs.RO

TL;DR: 本文提出了一个气候相关机器人研究的路线图，旨在通过机器人技术与气候领域的合作解决高影响力问题。


<details>
  <summary>Details</summary>
Motivation: 气候变化是21世纪的重要挑战，机器人社区希望通过技术贡献应对这一问题。

Method: 通过识别机器人技术与气候领域（如能源、建筑环境、交通等）的合作机会，提出具体应用方向，包括能源优化、精准农业等。

Result: 路线图展示了机器人技术（包括算法和物理机器人）在气候问题中的潜在应用，并提出了具体研究方向。

Conclusion: 本文旨在激发机器人社区的新研究方向，推动跨领域合作以应对气候挑战。

Abstract: Climate change is one of the defining challenges of the 21st century, and
many in the robotics community are looking for ways to contribute. This paper
presents a roadmap for climate-relevant robotics research, identifying
high-impact opportunities for collaboration between roboticists and experts
across climate domains such as energy, the built environment, transportation,
industry, land use, and Earth sciences. These applications include problems
such as energy systems optimization, construction, precision agriculture,
building envelope retrofits, autonomous trucking, and large-scale environmental
monitoring. Critically, we include opportunities to apply not only physical
robots but also the broader robotics toolkit - including planning, perception,
control, and estimation algorithms - to climate-relevant problems. A central
goal of this roadmap is to inspire new research directions and collaboration by
highlighting specific, actionable problems at the intersection of robotics and
climate. This work represents a collaboration between robotics researchers and
domain experts in various climate disciplines, and it serves as an invitation
to the robotics community to bring their expertise to bear on urgent climate
priorities.

</details>


### [3] [CoNav Chair: Development and Evaluation of a Shared Control based Wheelchair for the Built Environment](https://arxiv.org/abs/2507.11716)
*Yifan Xu,Qianwei Wang,Jordan Lillie,Vineet Kamat,Carol Menassa,Clive D'Souza*

Main category: cs.RO

TL;DR: 论文介绍了CoNav Chair，一种基于ROS的智能轮椅，结合共享控制导航和避障功能，旨在提高导航效率、安全性和易用性。初步评估显示共享控制模式在碰撞次数、任务完成时间和用户主观评价上优于完全自主和手动模式。


<details>
  <summary>Details</summary>
Motivation: 随着残疾人口增长，现有电动轮椅在灵活性和导航能力上存在不足，完全自主或手动控制模式效率低且影响用户信任。

Method: 设计CoNav Chair，基于ROS，支持共享控制导航和避障功能，并通过21名健康参与者对比手动、共享和完全自主三种导航模式。

Result: 共享控制模式碰撞更少，任务完成时间、轨迹长度和平滑度表现优异，用户主观评价认为其更安全高效。

Conclusion: CoNav系统表现出良好的安全性和性能，为后续残疾用户测试奠定了基础。

Abstract: As the global population of people with disabilities (PWD) continues to grow,
so will the need for mobility solutions that promote independent living and
social integration. Wheelchairs are vital for the mobility of PWD in both
indoor and outdoor environments. The current SOTA in powered wheelchairs is
based on either manually controlled or fully autonomous modes of operation,
offering limited flexibility and often proving difficult to navigate in
spatially constrained environments. Moreover, research on robotic wheelchairs
has focused predominantly on complete autonomy or improved manual control;
approaches that can compromise efficiency and user trust. To overcome these
challenges, this paper introduces the CoNav Chair, a smart wheelchair based on
the Robot Operating System (ROS) and featuring shared control navigation and
obstacle avoidance capabilities that are intended to enhance navigational
efficiency, safety, and ease of use for the user. The paper outlines the CoNav
Chair's design and presents a preliminary usability evaluation comparing three
distinct navigation modes, namely, manual, shared, and fully autonomous,
conducted with 21 healthy, unimpaired participants traversing an indoor
building environment. Study findings indicated that the shared control
navigation framework had significantly fewer collisions and performed
comparably, if not superior to the autonomous and manual modes, on task
completion time, trajectory length, and smoothness; and was perceived as being
safer and more efficient based on user reported subjective assessments of
usability. Overall, the CoNav system demonstrated acceptable safety and
performance, laying the foundation for subsequent usability testing with end
users, namely, PWDs who rely on a powered wheelchair for mobility.

</details>


### [4] [Generating Actionable Robot Knowledge Bases by Combining 3D Scene Graphs with Robot Ontologies](https://arxiv.org/abs/2507.11770)
*Giang Nguyen,Mihai Pomarlan,Sascha Jongebloed,Nils Leusmann,Minh Nhat Vu,Michael Beetz*

Main category: cs.RO

TL;DR: 论文提出了一种统一场景图模型，将多种格式（如MJCF、URDF、SDF）标准化为USD格式，并通过语义标注与机器人本体集成，提升机器人认知控制能力。


<details>
  <summary>Details</summary>
Motivation: 解决机器人领域中环境数据格式多样且不兼容的问题，以支持认知机器人控制。

Method: 开发统一场景图模型，将不同格式转换为USD格式，并通过语义标注与知识图谱集成。

Result: 成功将3D环境转换为USD格式，并通过知识图谱回答能力问题，验证了实时机器人决策的实用性。

Conclusion: 提出的方法有效解决了数据格式不兼容问题，并通过可视化工具提升了语义映射的易用性。

Abstract: In robotics, the effective integration of environmental data into actionable
knowledge remains a significant challenge due to the variety and
incompatibility of data formats commonly used in scene descriptions, such as
MJCF, URDF, and SDF. This paper presents a novel approach that addresses these
challenges by developing a unified scene graph model that standardizes these
varied formats into the Universal Scene Description (USD) format. This
standardization facilitates the integration of these scene graphs with robot
ontologies through semantic reporting, enabling the translation of complex
environmental data into actionable knowledge essential for cognitive robotic
control. We evaluated our approach by converting procedural 3D environments
into USD format, which is then annotated semantically and translated into a
knowledge graph to effectively answer competency questions, demonstrating its
utility for real-time robotic decision-making. Additionally, we developed a
web-based visualization tool to support the semantic mapping process, providing
users with an intuitive interface to manage the 3D environment.

</details>


### [5] [The Developments and Challenges towards Dexterous and Embodied Robotic Manipulation: A Survey](https://arxiv.org/abs/2507.11840)
*Gaofeng Li,Ruize Wang,Peisen Xu,Qi Ye,Jiming Chen*

Main category: cs.RO

TL;DR: 论文概述了机器人操作从机械编程到具身智能的演变，重点关注当前阶段的灵巧操作，总结了数据收集和技能学习框架的进展，并讨论了三大挑战。


<details>
  <summary>Details</summary>
Motivation: 实现类人灵巧机器人操作是机器人领域的核心目标和关键挑战，AI的发展推动了这一领域的快速进步。

Method: 通过仿真、人类演示和远程操作收集灵巧操作数据，并利用模仿学习和强化学习框架进行技能学习。

Result: 总结了灵巧机器人操作的关键特征和主要挑战，并概述了当前的研究进展。

Conclusion: 论文指出了限制灵巧机器人操作发展的三大关键挑战，为未来研究提供了方向。

Abstract: Achieving human-like dexterous robotic manipulation remains a central goal
and a pivotal challenge in robotics. The development of Artificial Intelligence
(AI) has allowed rapid progress in robotic manipulation. This survey summarizes
the evolution of robotic manipulation from mechanical programming to embodied
intelligence, alongside the transition from simple grippers to multi-fingered
dexterous hands, outlining key characteristics and main challenges. Focusing on
the current stage of embodied dexterous manipulation, we highlight recent
advances in two critical areas: dexterous manipulation data collection (via
simulation, human demonstrations, and teleoperation) and skill-learning
frameworks (imitation and reinforcement learning). Then, based on the overview
of the existing data collection paradigm and learning framework, three key
challenges restricting the development of dexterous robotic manipulation are
summarized and discussed.

</details>


### [6] [Towards Autonomous Riding: A Review of Perception, Planning, and Control in Intelligent Two-Wheelers](https://arxiv.org/abs/2507.11852)
*Mohammed Hassanin,Mohammad Abu Alsheikh,Carlos C. N. Kuhn,Damith Herath,Dinh Thai Hoang,Ibrahim Radwan*

Main category: cs.RO

TL;DR: 本文综述了自动驾驶骑行（AR）技术的现状与挑战，通过借鉴自动驾驶（AD）技术，分析了AR在感知、规划和控制方面的核心组件，并指出了当前研究的不足与未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着微型交通工具（如电动滑板车和电动自行车）的迅速普及，开发可靠的AR技术变得迫切，但其独特的不稳定性和环境复杂性带来了安全挑战。

Method: 通过系统分析AR的核心组件（感知、规划和控制），并借鉴AD技术，识别当前AR研究的不足。

Result: 研究发现AR在感知系统、行业与政府支持及研究关注度方面存在显著不足，提出了多模态传感器技术和边缘深度学习架构等未来方向。

Conclusion: 通过结合AD技术与AR的特定需求，本文旨在推动安全、高效且可扩展的AR系统的发展，以支持未来城市交通。

Abstract: The rapid adoption of micromobility solutions, particularly two-wheeled
vehicles like e-scooters and e-bikes, has created an urgent need for reliable
autonomous riding (AR) technologies. While autonomous driving (AD) systems have
matured significantly, AR presents unique challenges due to the inherent
instability of two-wheeled platforms, limited size, limited power, and
unpredictable environments, which pose very serious concerns about road users'
safety. This review provides a comprehensive analysis of AR systems by
systematically examining their core components, perception, planning, and
control, through the lens of AD technologies. We identify critical gaps in
current AR research, including a lack of comprehensive perception systems for
various AR tasks, limited industry and government support for such
developments, and insufficient attention from the research community. The
review analyses the gaps of AR from the perspective of AD to highlight
promising research directions, such as multimodal sensor techniques for
lightweight platforms and edge deep learning architectures. By synthesising
insights from AD research with the specific requirements of AR, this review
aims to accelerate the development of safe, efficient, and scalable autonomous
riding systems for future urban mobility.

</details>


### [7] [A Fast Method for Planning All Optimal Homotopic Configurations for Tethered Robots and Its Extended Applications](https://arxiv.org/abs/2507.11880)
*Jinyuan Liu,Minglei Fu,Ling Shi,Chenguang Yang,Wenan Zhang*

Main category: cs.RO

TL;DR: 论文提出了一种名为CDT-TCS的新算法，用于解决系留机器人在运动规划中的拓扑约束问题，并衍生出三种应用算法，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 系留机器人在特殊环境中具有优势，但其运动规划受限于系绳长度和缠绕风险，需要高效解决方案。

Method: 利用CDT编码作为同伦不变量表示路径拓扑状态，结合代数拓扑和几何优化，提出CDT-TCS算法及三种衍生算法。

Result: 仿真和实验表明，所提算法在各自问题领域显著优于现有方法，具有实际工程价值。

Conclusion: CDT-TCS及其衍生算法为系留机器人运动规划提供了高效解决方案，具有广泛的应用潜力。

Abstract: Tethered robots play a pivotal role in specialized environments such as
disaster response and underground exploration, where their stable power supply
and reliable communication offer unparalleled advantages. However, their motion
planning is severely constrained by tether length limitations and entanglement
risks, posing significant challenges to achieving optimal path planning. To
address these challenges, this study introduces CDT-TCS (Convex Dissection
Topology-based Tethered Configuration Search), a novel algorithm that leverages
CDT Encoding as a homotopy invariant to represent topological states of paths.
By integrating algebraic topology with geometric optimization, CDT-TCS
efficiently computes the complete set of optimal feasible configurations for
tethered robots at all positions in 2D environments through a single
computation. Building on this foundation, we further propose three
application-specific algorithms: i) CDT-TPP for optimal tethered path planning,
ii) CDT-TMV for multi-goal visiting with tether constraints, iii) CDT-UTPP for
distance-optimal path planning of untethered robots. All theoretical results
and propositions underlying these algorithms are rigorously proven and
thoroughly discussed in this paper. Extensive simulations demonstrate that the
proposed algorithms significantly outperform state-of-the-art methods in their
respective problem domains. Furthermore, real-world experiments on robotic
platforms validate the practicality and engineering value of the proposed
framework.

</details>


### [8] [NemeSys: An Online Underwater Explorer with Goal-Driven Adaptive Autonomy](https://arxiv.org/abs/2507.11889)
*Adnan Abdullah,Alankrit Gupta,Vaishnav Ramesh,Shivali Patel,Md Jahidul Islam*

Main category: cs.RO

TL;DR: NemeSys是一种新型AUV系统，支持通过浮标的光学和磁电信号进行实时任务重配置，适用于GPS缺失和通信受限的水下环境。


<details>
  <summary>Details</summary>
Motivation: 当前AUV平台多依赖静态预编程任务或高延迟通信，限制了其适应性和响应能力。

Method: 设计了NemeSys系统，包括控制架构和语义任务编码框架，支持低带宽通信的交互式探索和任务适应。

Result: 通过建模、实验和开放水域测试验证了系统的可行性，实现了在线任务适应和语义任务更新。

Conclusion: NemeSys为动态和不确定水下环境中的目标驱动自适应自主性提供了有效解决方案。

Abstract: Adaptive mission control and dynamic parameter reconfiguration are essential
for autonomous underwater vehicles (AUVs) operating in GPS-denied,
communication-limited marine environments. However, most current AUV platforms
execute static, pre-programmed missions or rely on tethered connections and
high-latency acoustic channels for mid-mission updates, significantly limiting
their adaptability and responsiveness. In this paper, we introduce NemeSys, a
novel AUV system designed to support real-time mission reconfiguration through
compact optical and magnetoelectric (OME) signaling facilitated by floating
buoys. We present the full system design, control architecture, and a semantic
mission encoding framework that enables interactive exploration and task
adaptation via low-bandwidth communication. The proposed system is validated
through analytical modeling, controlled experimental evaluations, and
open-water trials. Results confirm the feasibility of online mission adaptation
and semantic task updates, highlighting NemeSys as an online AUV platform for
goal-driven adaptive autonomy in dynamic and uncertain underwater environments.

</details>


### [9] [Hybrid Conformal Prediction-based Risk-Aware Model Predictive Planning in Dense, Uncertain Environments](https://arxiv.org/abs/2507.11920)
*Jeongyong Yang,KwangBin Lee,SooJean Han*

Main category: cs.RO

TL;DR: HyPRAP是一种基于预测的风险感知路径规划框架，通过混合模型预测障碍物运动，并利用P-CRI评估风险，平衡安全性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决密集动态环境中实时路径规划的挑战，特别是预测大量动态障碍物未来运动的计算负担和不现实性。

Method: HyPRAP结合多种模型预测障碍物运动，使用P-CRI评估风险，并选择性分配计算资源。同时通过混合共形预测量化不确定性。

Result: 理论分析和仿真表明，HyPRAP在安全性和计算效率上优于单一预测方法，P-CRI优于基于邻近性的风险评估。

Conclusion: HyPRAP通过混合预测模型和风险感知机制，有效解决了密集动态环境中的路径规划问题。

Abstract: Real-time path planning in dense, uncertain environments remains a
challenging problem, as predicting the future motions of numerous dynamic
obstacles is computationally burdensome and unrealistic. To address this, we
introduce Hybrid Prediction-based Risk-Aware Planning (HyPRAP), a
prediction-based risk-aware path-planning framework which uses a hybrid
combination of models to predict local obstacle movement. HyPRAP uses a novel
Prediction-based Collision Risk Index (P-CRI) to evaluate the risk posed by
each obstacle, enabling the selective use of predictors based on whether the
agent prioritizes high predictive accuracy or low computational prediction
overhead. This selective routing enables the agent to focus on high-risk
obstacles while ignoring or simplifying low-risk ones, making it suitable for
environments with a large number of obstacles. Moreover, HyPRAP incorporates
uncertainty quantification through hybrid conformal prediction by deriving
confidence bounds simultaneously achieved by multiple predictions across
different models. Theoretical analysis demonstrates that HyPRAP effectively
balances safety and computational efficiency by leveraging the diversity of
prediction models. Extensive simulations validate these insights for more
general settings, confirming that HyPRAP performs better compared to single
predictor methods, and P-CRI performs better over naive proximity-based risk
assessment.

</details>


### [10] [IANN-MPPI: Interaction-Aware Neural Network-Enhanced Model Predictive Path Integral Approach for Autonomous Driving](https://arxiv.org/abs/2507.11940)
*Kanghyun Ryu,Minjun Sung,Piyush Gupta,Jovin D'sa,Faizan M. Tariq,David Isele,Sangjae Bae*

Main category: cs.RO

TL;DR: 提出了一种基于交互感知的神经网络增强模型预测路径积分（IANN-MPPI）控制方法，用于自动驾驶车辆在密集交通中的轨迹规划，解决了传统方法忽视周围车辆交互行为的局限性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在密集交通中的运动规划常因无法预测周围车辆的交互行为而过于保守或无法满足规划目标。

Method: 结合交互感知神经网络和MPPI控制，预测周围车辆对每个控制序列的反应，并引入基于样条的采样分布先验以优化车道变更行为。

Result: 在密集交通合并场景中验证了方法的有效性，能够实现高效的合并操作。

Conclusion: IANN-MPPI通过交互感知和优化采样分布，显著提升了自动驾驶车辆在复杂交通环境中的规划能力。

Abstract: Motion planning for autonomous vehicles (AVs) in dense traffic is
challenging, often leading to overly conservative behavior and unmet planning
objectives. This challenge stems from the AVs' limited ability to anticipate
and respond to the interactive behavior of surrounding agents. Traditional
decoupled prediction and planning pipelines rely on non-interactive predictions
that overlook the fact that agents often adapt their behavior in response to
the AV's actions. To address this, we propose Interaction-Aware Neural
Network-Enhanced Model Predictive Path Integral (IANN-MPPI) control, which
enables interactive trajectory planning by predicting how surrounding agents
may react to each control sequence sampled by MPPI. To improve performance in
structured lane environments, we introduce a spline-based prior for the MPPI
sampling distribution, enabling efficient lane-changing behavior. We evaluate
IANN-MPPI in a dense traffic merging scenario, demonstrating its ability to
perform efficient merging maneuvers. Our project website is available at
https://sites.google.com/berkeley.edu/iann-mppi

</details>


### [11] [A Multi-Level Similarity Approach for Single-View Object Grasping: Matching, Planning, and Fine-Tuning](https://arxiv.org/abs/2507.11938)
*Hao Chen,Takuya Kiyokawa,Zhengtao Hu,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 论文提出了一种基于相似性匹配的新方法，通过利用已知物体的相似性来指导未知物体的抓取，解决了单视角下抓取不确定性的问题。


<details>
  <summary>Details</summary>
Motivation: 传统学习框架对感知噪声和环境变化敏感，性能鲁棒性不足，因此需要一种更通用的抓取方法。

Method: 通过视觉特征相似性匹配、候选模型抓取规划和局部优化三个步骤，结合多级相似性匹配框架和新提出的C-FPFH描述符，提升抓取性能。

Result: 新方法在单视角下实现了对未知物体的鲁棒抓取，并通过实验验证了其有效性。

Conclusion: 相似性匹配方法为未知物体抓取提供了新视角，显著提升了性能鲁棒性和通用性。

Abstract: Grasping unknown objects from a single view has remained a challenging topic
in robotics due to the uncertainty of partial observation. Recent advances in
large-scale models have led to benchmark solutions such as GraspNet-1Billion.
However, such learning-based approaches still face a critical limitation in
performance robustness for their sensitivity to sensing noise and environmental
changes. To address this bottleneck in achieving highly generalized grasping,
we abandon the traditional learning framework and introduce a new perspective:
similarity matching, where similar known objects are utilized to guide the
grasping of unknown target objects. We newly propose a method that robustly
achieves unknown-object grasping from a single viewpoint through three key
steps: 1) Leverage the visual features of the observed object to perform
similarity matching with an existing database containing various object models,
identifying potential candidates with high similarity; 2) Use the candidate
models with pre-existing grasping knowledge to plan imitative grasps for the
unknown target object; 3) Optimize the grasp quality through a local
fine-tuning process. To address the uncertainty caused by partial and noisy
observation, we propose a multi-level similarity matching framework that
integrates semantic, geometric, and dimensional features for comprehensive
evaluation. Especially, we introduce a novel point cloud geometric descriptor,
the C-FPFH descriptor, which facilitates accurate similarity assessment between
partial point clouds of observed objects and complete point clouds of database
models. In addition, we incorporate the use of large language models, introduce
the semi-oriented bounding box, and develop a novel point cloud registration
approach based on plane detection to enhance matching accuracy under
single-view conditions. Videos are available at https://youtu.be/qQDIELMhQmk.

</details>


### [12] [A Review of Generative AI in Aquaculture: Foundations, Applications, and Future Directions for Smart and Sustainable Farming](https://arxiv.org/abs/2507.11974)
*Waseem Akram,Muhayy Ud Din,Lyes Saad Soud,Irfan Hussain*

Main category: cs.RO

TL;DR: 本文综述了生成式人工智能（GAI）在水产养殖中的应用，涵盖技术架构、实验系统、实际案例及其在环境监测、机器人、疾病诊断等领域的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着水产养殖向数据驱动和自动化转型（Aquaculture 4.0），GAI为行业提供了智能决策支持的新机遇。

Method: 通过分析GAI的基础架构（如扩散模型、Transformer）、实验系统和实际部署案例，总结了其在水下感知、数字孪生建模等领域的应用。

Result: GAI在水产养殖中展现出广泛潜力，但也面临数据不足、实时性能限制、可解释性等挑战。

Conclusion: GAI是推动智能、可持续水产养殖系统的关键工具。

Abstract: Generative Artificial Intelligence (GAI) has rapidly emerged as a
transformative force in aquaculture, enabling intelligent synthesis of
multimodal data, including text, images, audio, and simulation outputs for
smarter, more adaptive decision-making. As the aquaculture industry shifts
toward data-driven, automation and digital integration operations under the
Aquaculture 4.0 paradigm, GAI models offer novel opportunities across
environmental monitoring, robotics, disease diagnostics, infrastructure
planning, reporting, and market analysis. This review presents the first
comprehensive synthesis of GAI applications in aquaculture, encompassing
foundational architectures (e.g., diffusion models, transformers, and retrieval
augmented generation), experimental systems, pilot deployments, and real-world
use cases. We highlight GAI's growing role in enabling underwater perception,
digital twin modeling, and autonomous planning for remotely operated vehicle
(ROV) missions. We also provide an updated application taxonomy that spans
sensing, control, optimization, communication, and regulatory compliance.
Beyond technical capabilities, we analyze key limitations, including limited
data availability, real-time performance constraints, trust and explainability,
environmental costs, and regulatory uncertainty. This review positions GAI not
merely as a tool but as a critical enabler of smart, resilient, and
environmentally aligned aquaculture systems.

</details>


### [13] [Robust Planning for Autonomous Vehicles with Diffusion-Based Failure Samplers](https://arxiv.org/abs/2507.11991)
*Juanran Wang,Marc R. Schlichting,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 利用深度生成模型提升自动驾驶车辆在交叉路口的安全性，通过生成碰撞噪声序列训练单步去噪扩散模型，并应用于规划器，显著降低故障率和延迟率。


<details>
  <summary>Details</summary>
Motivation: 高风险交通区域（如交叉路口）是碰撞的主要原因，研究旨在通过生成模型提升自动驾驶车辆的安全性。

Method: 训练1000步去噪扩散概率模型生成碰撞噪声序列，并通过生成对抗架构将其蒸馏为单步模型，应用于规划器。

Result: 单步模型在保持采样质量的同时实现快速推理，规划器在仿真实验中显著降低故障率和延迟率。

Conclusion: 单步去噪扩散模型结合规划器可有效提升自动驾驶车辆在交叉路口的安全性。

Abstract: High-risk traffic zones such as intersections are a major cause of
collisions. This study leverages deep generative models to enhance the safety
of autonomous vehicles in an intersection context. We train a 1000-step
denoising diffusion probabilistic model to generate collision-causing sensor
noise sequences for an autonomous vehicle navigating a four-way intersection
based on the current relative position and velocity of an intruder. Using the
generative adversarial architecture, the 1000-step model is distilled into a
single-step denoising diffusion model which demonstrates fast inference speed
while maintaining similar sampling quality. We demonstrate one possible
application of the single-step model in building a robust planner for the
autonomous vehicle. The planner uses the single-step model to efficiently
sample potential failure cases based on the currently measured traffic state to
inform its decision-making. Through simulation experiments, the robust planner
demonstrates significantly lower failure rate and delay rate compared with the
baseline Intelligent Driver Model controller.

</details>


### [14] [Robust Route Planning for Sidewalk Delivery Robots](https://arxiv.org/abs/2507.12067)
*Xing Tong,Michele D. Simoni*

Main category: cs.RO

TL;DR: 研究针对人行道送货机器人的鲁棒路径规划问题，通过优化与仿真结合，解决因行人密度和障碍物导致的旅行时间不确定性。


<details>
  <summary>Details</summary>
Motivation: 人行道送货机器人是城市货运的潜在解决方案，但旅行时间的不确定性影响其效率。

Method: 集成优化与仿真，采用预算、椭球和支持向量聚类（SVC）方法及分布鲁棒方法解决最短路径问题。

Result: 鲁棒路径规划显著提升操作可靠性，椭球和DRSP方法表现最佳。

Conclusion: 鲁棒方法在恶劣天气和高行人密度下表现更优，尤其适合较宽、较慢的机器人。

Abstract: Sidewalk delivery robots are a promising solution for urban freight
distribution, reducing congestion compared to trucks and providing a safer,
higher-capacity alternative to drones. However, unreliable travel times on
sidewalks due to pedestrian density, obstacles, and varying infrastructure
conditions can significantly affect their efficiency. This study addresses the
robust route planning problem for sidewalk robots, explicitly accounting for
travel time uncertainty due to varying sidewalk conditions. Optimization is
integrated with simulation to reproduce the effect of obstacles and pedestrian
flows and generate realistic travel times. The study investigates three
different approaches to derive uncertainty sets, including budgeted,
ellipsoidal, and support vector clustering (SVC)-based methods, along with a
distributionally robust method to solve the shortest path (SP) problem. A
realistic case study reproducing pedestrian patterns in Stockholm's city center
is used to evaluate the efficiency of robust routing across various robot
designs and environmental conditions. The results show that, when compared to a
conventional SP, robust routing significantly enhances operational reliability
under variable sidewalk conditions. The Ellipsoidal and DRSP approaches
outperform the other methods, yielding the most efficient paths in terms of
average and worst-case delay. Sensitivity analyses reveal that robust
approaches consistently outperform the conventional SP, particularly for
sidewalk delivery robots that are wider, slower, and have more conservative
navigation behaviors. These benefits are even more pronounced in adverse
weather conditions and high pedestrian congestion scenarios.

</details>


### [15] [Tree-SLAM: semantic object SLAM for efficient mapping of individual trees in orchards](https://arxiv.org/abs/2507.12093)
*David Rapado-Rincon,Gert Kootstra*

Main category: cs.RO

TL;DR: Tree-SLAM是一种针对果园中单棵树定位的语义SLAM方法，结合RGB-D图像和实例分割模型，通过级联图数据关联算法实现树干识别与定位，最终生成高精度地图。


<details>
  <summary>Details</summary>
Motivation: 果园中单棵树的精准定位对农业机器人执行任务至关重要，但GPS信号在密集树冠下不可靠，且传统SLAM方法因树木外观重复易出错。

Method: 使用RGB-D图像和实例分割模型检测树干，通过级联图数据关联算法重识别树干，结合GPS、里程计和树干观测构建因子图框架。

Result: 系统生成的单棵树地图定位误差低至18厘米，小于种植距离的20%，并在不同季节的苹果和梨园数据集中验证了高精度和鲁棒性。

Conclusion: Tree-SLAM在GPS信号不可靠的果园环境中表现出高精度和鲁棒性，为精准农业提供了有效解决方案。

Abstract: Accurate mapping of individual trees is an important component for precision
agriculture in orchards, as it allows autonomous robots to perform tasks like
targeted operations or individual tree monitoring. However, creating these maps
is challenging because GPS signals are often unreliable under dense tree
canopies. Furthermore, standard Simultaneous Localization and Mapping (SLAM)
approaches struggle in orchards because the repetitive appearance of trees can
confuse the system, leading to mapping errors. To address this, we introduce
Tree-SLAM, a semantic SLAM approach tailored for creating maps of individual
trees in orchards. Utilizing RGB-D images, our method detects tree trunks with
an instance segmentation model, estimates their location and re-identifies them
using a cascade-graph-based data association algorithm. These re-identified
trunks serve as landmarks in a factor graph framework that integrates noisy GPS
signals, odometry, and trunk observations. The system produces maps of
individual trees with a geo-localization error as low as 18 cm, which is less
than 20\% of the planting distance. The proposed method was validated on
diverse datasets from apple and pear orchards across different seasons,
demonstrating high mapping accuracy and robustness in scenarios with unreliable
GPS signals.

</details>


### [16] [Leveraging Sidewalk Robots for Walkability-Related Analyses](https://arxiv.org/abs/2507.12148)
*Xing Tong,Michele D. Simoni,Kaj Munhoz Arfvidsson,Jonas Mårtensson*

Main category: cs.RO

TL;DR: 利用人行道配送机器人作为移动数据收集平台，自动、实时地捕捉与步行性相关的特征，为可持续城市发展提供支持。


<details>
  <summary>Details</summary>
Motivation: 传统方法收集步行性相关数据成本高且扩展性差，而配送机器人提供了一种低成本、可扩展的解决方案。

Method: 在斯德哥尔摩KTH校园部署传感器机器人，完成101次行程，收集包括人行道条件、行人密度等数据。

Result: 行人运动模式受人行道特征显著影响，机器人速度可作为行人行为的代理指标。

Conclusion: 该框架支持持续监测人行道条件和行人行为，促进更宜居、包容的城市环境。

Abstract: Walkability is a key component of sustainable urban development, while
collecting detailed data on its related features remains challenging due to the
high costs and limited scalability of traditional methods. Sidewalk delivery
robots, increasingly deployed in urban environments, offer a promising solution
to these limitations. This paper explores how these robots can serve as mobile
data collection platforms, capturing sidewalk-level features related to
walkability in a scalable, automated, and real-time manner. A sensor-equipped
robot was deployed on a sidewalk network at KTH in Stockholm, completing 101
trips covering 900 segments. From the collected data, different typologies of
features are derived, including robot trip characteristics (e.g., speed,
duration), sidewalk conditions (e.g., width, surface unevenness), and sidewalk
utilization (e.g., pedestrian density). Their walkability-related implications
were investigated with a series of analyses. The results demonstrate that
pedestrian movement patterns are strongly influenced by sidewalk
characteristics, with higher density, reduced width, and surface irregularity
associated with slower and more variable trajectories. Notably, robot speed
closely mirrors pedestrian behavior, highlighting its potential as a proxy for
assessing pedestrian dynamics. The proposed framework enables continuous
monitoring of sidewalk conditions and pedestrian behavior, contributing to the
development of more walkable, inclusive, and responsive urban environments.

</details>


### [17] [Probabilistic Safety Verification for an Autonomous Ground Vehicle: A Situation Coverage Grid Approach](https://arxiv.org/abs/2507.12158)
*Nawshin Mannan Proma,Gricel Vázquez,Sepeedeh Shahbeigi,Arjun Badyal,Victoria Hodge*

Main category: cs.RO

TL;DR: 提出了一种基于系统情境提取、概率建模和验证的工业自动驾驶车辆安全验证方法，通过概率模型检查识别高风险情境并提供定量安全保证。


<details>
  <summary>Details</summary>
Motivation: 随着工业自动驾驶车辆在安全关键环境中的部署增加，确保其在多样化条件下的安全操作至关重要。

Method: 利用情境覆盖网格枚举相关环境配置，结合概率数据生成模型，通过概率模型检查验证安全性。

Result: 方法有效识别高风险情境，提供定量安全保证，并支持符合监管标准。

Conclusion: 该方法为自动驾驶系统的稳健部署提供了有力支持。

Abstract: As industrial autonomous ground vehicles are increasingly deployed in
safety-critical environments, ensuring their safe operation under diverse
conditions is paramount. This paper presents a novel approach for their safety
verification based on systematic situation extraction, probabilistic modelling
and verification. We build upon the concept of a situation coverage grid, which
exhaustively enumerates environmental configurations relevant to the vehicle's
operation. This grid is augmented with quantitative probabilistic data
collected from situation-based system testing, capturing probabilistic
transitions between situations. We then generate a probabilistic model that
encodes the dynamics of both normal and unsafe system behaviour. Safety
properties extracted from hazard analysis and formalised in temporal logic are
verified through probabilistic model checking against this model. The results
demonstrate that our approach effectively identifies high-risk situations,
provides quantitative safety guarantees, and supports compliance with
regulatory standards, thereby contributing to the robust deployment of
autonomous systems.

</details>


### [18] [Fast and Scalable Game-Theoretic Trajectory Planning with Intentional Uncertainties](https://arxiv.org/abs/2507.12174)
*Zhenmin Huang,Yusen Xie,Benshan Ma,Shaojie Shen,Jun Ma*

Main category: cs.RO

TL;DR: 提出一种基于博弈论的多智能体轨迹规划方法，有效处理意图不确定性，提高效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 多智能体交互中的意图不确定性导致现有博弈论方法计算负担重、效率低、可扩展性差。

Method: 将意图不确定性下的交互建模为贝叶斯博弈，并转化为潜在博弈；提出基于ADMM的分布式算法。

Result: 方法在多种意图不确定性场景下有效，可扩展性优于现有基线，支持实时规划。

Conclusion: 新方法高效且可扩展，适用于不确定博弈环境中的实时轨迹规划。

Abstract: Trajectory planning involving multi-agent interactions has been a
long-standing challenge in the field of robotics, primarily burdened by the
inherent yet intricate interactions among agents. While game-theoretic methods
are widely acknowledged for their effectiveness in managing multi-agent
interactions, significant impediments persist when it comes to accommodating
the intentional uncertainties of agents. In the context of intentional
uncertainties, the heavy computational burdens associated with existing
game-theoretic methods are induced, leading to inefficiencies and poor
scalability. In this paper, we propose a novel game-theoretic interactive
trajectory planning method to effectively address the intentional uncertainties
of agents, and it demonstrates both high efficiency and enhanced scalability.
As the underpinning basis, we model the interactions between agents under
intentional uncertainties as a general Bayesian game, and we show that its
agent-form equivalence can be represented as a potential game under certain
minor assumptions. The existence and attainability of the optimal interactive
trajectories are illustrated, as the corresponding Bayesian Nash equilibrium
can be attained by optimizing a unified optimization problem. Additionally, we
present a distributed algorithm based on the dual consensus alternating
direction method of multipliers (ADMM) tailored to the parallel solving of the
problem, thereby significantly improving the scalability. The attendant
outcomes from simulations and experiments demonstrate that the proposed method
is effective across a range of scenarios characterized by general forms of
intentional uncertainties. Its scalability surpasses that of existing
centralized and decentralized baselines, allowing for real-time interactive
trajectory planning in uncertain game settings.

</details>


### [19] [UniLGL: Learning Uniform Place Recognition for FOV-limited/Panoramic LiDAR Global Localization](https://arxiv.org/abs/2507.12194)
*Hongming Shen,Xun Chen,Yulin Hui,Zhenyu Wu,Wei Wang,Qiyang Lyu,Tianchen Deng,Danwei Wang*

Main category: cs.RO

TL;DR: 提出了一种统一的LGL方法UniLGL，通过编码完整点云信息并设计多BEV融合网络，实现空间、材料和传感器类型的统一性。


<details>
  <summary>Details</summary>
Motivation: 现有LGL方法通常仅考虑部分信息或针对单一传感器，忽略了统一性。

Method: 将点云编码为空间和强度BEV图像，设计多BEV融合网络，引入视角不变性假设。

Result: 实验表明UniLGL优于现有方法，适用于多种平台和场景。

Conclusion: UniLGL在工业与野外场景中展现出高精度定位与协作探索的潜力。

Abstract: Existing LGL methods typically consider only partial information (e.g.,
geometric features) from LiDAR observations or are designed for homogeneous
LiDAR sensors, overlooking the uniformity in LGL. In this work, a uniform LGL
method is proposed, termed UniLGL, which simultaneously achieves spatial and
material uniformity, as well as sensor-type uniformity. The key idea of the
proposed method is to encode the complete point cloud, which contains both
geometric and material information, into a pair of BEV images (i.e., a spatial
BEV image and an intensity BEV image). An end-to-end multi-BEV fusion network
is designed to extract uniform features, equipping UniLGL with spatial and
material uniformity. To ensure robust LGL across heterogeneous LiDAR sensors, a
viewpoint invariance hypothesis is introduced, which replaces the conventional
translation equivariance assumption commonly used in existing LPR networks and
supervises UniLGL to achieve sensor-type uniformity in both global descriptors
and local feature representations. Finally, based on the mapping between local
features on the 2D BEV image and the point cloud, a robust global pose
estimator is derived that determines the global minimum of the global pose on
SE(3) without requiring additional registration. To validate the effectiveness
of the proposed uniform LGL, extensive benchmarks are conducted in real-world
environments, and the results show that the proposed UniLGL is demonstratively
competitive compared to other State-of-the-Art LGL methods. Furthermore, UniLGL
has been deployed on diverse platforms, including full-size trucks and agile
Micro Aerial Vehicles (MAVs), to enable high-precision localization and mapping
as well as multi-MAV collaborative exploration in port and forest environments,
demonstrating the applicability of UniLGL in industrial and field scenarios.

</details>


### [20] [Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction with an Agentic Robot](https://arxiv.org/abs/2507.12273)
*Luca Garello,Francesca Cocchella,Alessandra Sciutti,Manuel Catalano,Francesco Rea*

Main category: cs.RO

TL;DR: 论文介绍了博物馆自主导览机器人Alter-Ego的设计与评估，结合先进导航和交互能力，利用LLM实现实时问答，并通过SLAM技术优化导航。实验显示机器人提升了参观体验，但也存在理解与响应限制。


<details>
  <summary>Details</summary>
Motivation: 探索AI驱动的机器人在文化空间中的应用潜力，以提升用户体验和知识获取。

Method: 设计并实现Alter-Ego机器人，结合LLM和SLAM技术，进行博物馆环境下的实验评估。

Result: 机器人受到普遍欢迎，提升了参观体验，但在理解和响应方面存在不足。

Conclusion: 研究揭示了AI机器人在文化空间中的潜力与挑战，为未来技术部署提供了参考。

Abstract: Autonomous robots are increasingly being tested into public spaces to enhance
user experiences, particularly in cultural and educational settings. This paper
presents the design, implementation, and evaluation of the autonomous museum
guide robot Alter-Ego equipped with advanced navigation and interactive
capabilities. The robot leverages state-of-the-art Large Language Models (LLMs)
to provide real-time, context aware question-and-answer (Q&A) interactions,
allowing visitors to engage in conversations about exhibits. It also employs
robust simultaneous localization and mapping (SLAM) techniques, enabling
seamless navigation through museum spaces and route adaptation based on user
requests. The system was tested in a real museum environment with 34
participants, combining qualitative analysis of visitor-robot conversations and
quantitative analysis of pre and post interaction surveys. Results showed that
the robot was generally well-received and contributed to an engaging museum
experience, despite some limitations in comprehension and responsiveness. This
study sheds light on HRI in cultural spaces, highlighting not only the
potential of AI-driven robotics to support accessibility and knowledge
acquisition, but also the current limitations and challenges of deploying such
technologies in complex, real-world environments.

</details>


### [21] [Assessing the Value of Visual Input: A Benchmark of Multimodal Large Language Models for Robotic Path Planning](https://arxiv.org/abs/2507.12391)
*Jacinto Colan,Ana Davila,Yasuhisa Hasegawa*

Main category: cs.RO

TL;DR: 评估多模态大语言模型在机器人路径规划中的视觉输入效用，发现视觉输入在简单任务中有一定帮助，但在复杂任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 探索视觉输入对多模态大语言模型在机器人路径规划任务中的潜在提升作用。

Method: 通过基准测试评估15种多模态大语言模型在2D网格环境中的路径规划能力，比较纯文本与文本加视觉输入的差异。

Result: 在简单任务中视觉输入或少量文本提示有一定优势，但在复杂任务中表现显著下降；大模型表现更好，但视觉输入并非总是优于结构化文本。

Conclusion: 当前模型在空间推理、约束遵循和多模态扩展性方面存在局限，需进一步改进。

Abstract: Large Language Models (LLMs) show potential for enhancing robotic path
planning. This paper assesses visual input's utility for multimodal LLMs in
such tasks via a comprehensive benchmark. We evaluated 15 multimodal LLMs on
generating valid and optimal paths in 2D grid environments, simulating
simplified robotic planning, comparing text-only versus text-plus-visual inputs
across varying model sizes and grid complexities. Our results indicate moderate
success rates on simpler small grids, where visual input or few-shot text
prompting offered some benefits. However, performance significantly degraded on
larger grids, highlighting a scalability challenge. While larger models
generally achieved higher average success, the visual modality was not
universally dominant over well-structured text for these multimodal systems,
and successful paths on simpler grids were generally of high quality. These
results indicate current limitations in robust spatial reasoning, constraint
adherence, and scalable multimodal integration, identifying areas for future
LLM development in robotic path planning.

</details>


### [22] [Regrasp Maps for Sequential Manipulation Planning](https://arxiv.org/abs/2507.12407)
*Svetlana Levit,Marc Toussaint*

Main category: cs.RO

TL;DR: 提出了一种基于优化的任务与运动规划（TAMP）求解器，通过状态空间抽象（regrasp map）加速搜索，解决受限和杂乱环境中的多次抓取问题。


<details>
  <summary>Details</summary>
Motivation: 在受限和杂乱环境中，多次抓取操作需要高效规划，传统方法难以快速找到可行解。

Method: 使用regrasp map抽象状态空间，提供抓取序列和区域信息，结合优化求解器迭代改进。

Result: 通过迭代生成和调整regrasp map，实现了对复杂抓取问题的鲁棒搜索。

Conclusion: 该方法显著提高了TAMP求解器在复杂抓取问题中的效率和鲁棒性。

Abstract: We consider manipulation problems in constrained and cluttered settings,
which require several regrasps at unknown locations. We propose to inform an
optimization-based task and motion planning (TAMP) solver with possible regrasp
areas and grasp sequences to speed up the search. Our main idea is to use a
state space abstraction, a regrasp map, capturing the combinations of available
grasps in different parts of the configuration space, and allowing us to
provide the solver with guesses for the mode switches and additional
constraints for the object placements. By interleaving the creation of regrasp
maps, their adaptation based on failed refinements, and solving TAMP
(sub)problems, we are able to provide a robust search method for challenging
regrasp manipulation problems.

</details>


### [23] [Design and Development of an Automated Contact Angle Tester (ACAT) for Surface Wettability Measurement](https://arxiv.org/abs/2507.12431)
*Connor Burgess,Kyle Douin,Amir Kordijazi*

Main category: cs.RO

TL;DR: ACAT是一个自动化机器人工作单元，用于测量3D打印材料的表面润湿性，解决了手动测试的局限性。


<details>
  <summary>Details</summary>
Motivation: 手动接触角测试存在精度和重复性问题，ACAT旨在通过自动化提高效率和安全性。

Method: 系统由电气、软件控制和机械三个子系统组成，符合工业标准，采用Raspberry Pi和Python控制。

Result: ACAT实现了高通量、自动化的表面表征，为智能制造和材料发现提供了平台。

Conclusion: ACAT的设计和实现为自动化表面测试提供了高效、安全的解决方案。

Abstract: The Automated Contact Angle Tester (ACAT) is a fully integrated robotic work
cell developed to automate the measurement of surface wettability on 3D-printed
materials. Designed for precision, repeatability, and safety, ACAT addresses
the limitations of manual contact angle testing by combining programmable
robotics, precise liquid dispensing, and a modular software-hardware
architecture. The system is composed of three core subsystems: (1) an
electrical system including power, control, and safety circuits compliant with
industrial standards such as NEC 70, NFPA 79, and UL 508A; (2) a software
control system based on a Raspberry Pi and Python, featuring fault detection,
GPIO logic, and operator interfaces; and (3) a mechanical system that includes
a 3-axis Cartesian robot, pneumatic actuation, and a precision liquid dispenser
enclosed within a safety-certified frame. The ACAT enables high-throughput,
automated surface characterization and provides a robust platform for future
integration into smart manufacturing and materials discovery workflows. This
paper details the design methodology, implementation strategies, and system
integration required to develop the ACAT platform.

</details>


### [24] [EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos](https://arxiv.org/abs/2507.12440)
*Ruihan Yang,Qinxi Yu,Yecheng Wu,Rui Yan,Borui Li,An-Chieh Cheng,Xueyan Zou,Yunhao Fang,Hongxu Yin,Sifei Liu,Song Han,Yao Lu,Xiaolong Wang*

Main category: cs.RO

TL;DR: 论文提出了一种利用人类视频训练视觉-语言-动作（VLA）模型的方法，通过逆运动学和重定向将人类动作转换为机器人动作，显著提升了机器人模仿学习的性能。


<details>
  <summary>Details</summary>
Motivation: 传统机器人模仿学习依赖真实机器人数据，但硬件限制导致数据规模受限。人类视频数据规模大且场景丰富，为解决这一问题提供了可能。

Method: 使用人类视频训练VLA模型预测人类手腕和手部动作，通过逆运动学和重定向转换为机器人动作，并用少量机器人演示微调模型（EgoVLA）。

Result: 在Isaac Humanoid Manipulation Benchmark上评估，EgoVLA显著优于基线模型，并验证了人类数据的重要性。

Conclusion: 人类视频数据可以高效训练机器人策略，为模仿学习提供了新的数据来源。

Abstract: Real robot data collection for imitation learning has led to significant
advancements in robotic manipulation. However, the requirement for robot
hardware in the process fundamentally constrains the scale of the data. In this
paper, we explore training Vision-Language-Action (VLA) models using egocentric
human videos. The benefit of using human videos is not only for their scale but
more importantly for the richness of scenes and tasks. With a VLA trained on
human video that predicts human wrist and hand actions, we can perform Inverse
Kinematics and retargeting to convert the human actions to robot actions. We
fine-tune the model using a few robot manipulation demonstrations to obtain the
robot policy, namely EgoVLA. We propose a simulation benchmark called Isaac
Humanoid Manipulation Benchmark, where we design diverse bimanual manipulation
tasks with demonstrations. We fine-tune and evaluate EgoVLA with Isaac Humanoid
Manipulation Benchmark and show significant improvements over baselines and
ablate the importance of human data. Videos can be found on our website:
https://rchalyang.github.io/EgoVLA

</details>
