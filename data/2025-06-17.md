<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 51]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Design and Development of a Robotic Transcatheter Delivery System for Aortic Valve Replacement](https://arxiv.org/abs/2506.12082)
*Harith S. Gallage,Bailey F. De Sousa,Benjamin I. Chesnik,Chaikel G. Brownstein,Anson Paul,Ronghuai Qi*

Main category: cs.RO

TL;DR: 提出了一种新型机器人导管输送系统，用于提高TAVR手术中的位置精度。


<details>
  <summary>Details</summary>
Motivation: 尽管现代机器人TAVR设备已广泛应用，但实现精确的瓣膜对齐仍依赖手动操作，存在临床挑战。

Method: 开发了一种具有全向弯曲关节和驱动系统的机器人导管输送系统。

Result: 初步实验结果验证了该系统的功能。

Conclusion: 该系统有望提升TAVR手术的精确性和准确性。

Abstract: Minimally invasive transcatheter approaches are increasingly adopted for
aortic stenosis treatment, where optimal commissural and coronary alignment is
important. Achieving precise alignment remains clinically challenging, even
with contemporary robotic transcatheter aortic valve replacement (TAVR)
devices, as this task is still performed manually. This paper proposes the
development of a robotic transcatheter delivery system featuring an
omnidirectional bending joint and an actuation system designed to enhance
positional accuracy and precision in TAVR procedures. The preliminary
experimental results validate the functionality of this novel robotic system.

</details>


### [2] [Using Behavior Trees in Risk Assessment](https://arxiv.org/abs/2506.12089)
*Razan Ghzouli,Atieh Hanna,Endre Erös,Rebekka Wohlrab*

Main category: cs.RO

TL;DR: 本文提出了一种基于行为树模型的早期风险评估方法，旨在解决工业中安全专家在设计阶段难以完全理解机器人任务的问题。


<details>
  <summary>Details</summary>
Motivation: 工业中早期风险评估的实践与理论脱节，安全专家难以在设计阶段充分理解机器人任务并确保风险评估结果在实施中被考虑。

Method: 采用设计科学研究方法，提出基于行为树模型的早期风险评估方法，并与四家公司的五位从业者共同评估。

Result: 行为树模型支持早期风险识别、可视化，并弥合了代码实施与风险评估输出之间的差距。

Conclusion: 该方法是首次尝试使用行为树模型支持风险评估，结果表明其潜力，但需进一步开发。

Abstract: Cyber-physical production systems increasingly involve collaborative robotic
missions, requiring more demand for robust and safe missions. Industries rely
on risk assessments to identify potential failures and implement measures to
mitigate their risks. Although it is recommended to conduct risk assessments
early in the design of robotic missions, the state of practice in the industry
is different. Safety experts often struggle to completely understand robotics
missions at the early design stages of projects and to ensure that the output
of risk assessments is adequately considered during implementation.
  This paper presents a design science study that conceived a model-based
approach for early risk assessment in a development-centric way. Our approach
supports risk assessment activities by using the behavior-tree model. We
evaluated the approach together with five practitioners from four companies.
Our findings highlight the potential of the behavior-tree model in supporting
early identification, visualisation, and bridging the gap between code
implementation and risk assessments' outputs. This approach is the first
attempt to use the behavior-tree model to support risk assessment; thus, the
findings highlight the need for further development.

</details>


### [3] [DoublyAware: Dual Planning and Policy Awareness for Temporal Difference Learning in Humanoid Locomotion](https://arxiv.org/abs/2506.12095)
*Khang Nguyen,An T. Le,Jan Peters,Minh Nhat Vu*

Main category: cs.RO

TL;DR: 论文提出DoublyAware方法，通过分解不确定性和结合规划与策略优化，提升人形机器人运动的鲁棒性和学习效率。


<details>
  <summary>Details</summary>
Motivation: 解决模型强化学习中环境随机性和高维动作空间带来的不确定性挑战，提升学习稳定性和探索效率。

Method: 提出DoublyAware方法，分解不确定性为规划和策略两部分，使用conformal prediction和GRPC优化器分别处理。

Result: 在HumanoidBench测试中，DoublyAware表现出更高的样本效率、收敛速度和运动可行性。

Conclusion: 结构化不确定性建模对TD-MPC框架下人形机器人运动学习的数据效率和可靠性至关重要。

Abstract: Achieving robust robot learning for humanoid locomotion is a fundamental
challenge in model-based reinforcement learning (MBRL), where environmental
stochasticity and randomness can hinder efficient exploration and learning
stability. The environmental, so-called aleatoric, uncertainty can be amplified
in high-dimensional action spaces with complex contact dynamics, and further
entangled with epistemic uncertainty in the models during learning phases. In
this work, we propose DoublyAware, an uncertainty-aware extension of Temporal
Difference Model Predictive Control (TD-MPC) that explicitly decomposes
uncertainty into two disjoint interpretable components, i.e., planning and
policy uncertainties. To handle the planning uncertainty, DoublyAware employs
conformal prediction to filter candidate trajectories using quantile-calibrated
risk bounds, ensuring statistical consistency and robustness against stochastic
dynamics. Meanwhile, policy rollouts are leveraged as structured informative
priors to support the learning phase with Group-Relative Policy Constraint
(GRPC) optimizers that impose a group-based adaptive trust-region in the latent
action space. This principled combination enables the robot agent to prioritize
high-confidence, high-reward behavior while maintaining effective, targeted
exploration under uncertainty. Evaluated on the HumanoidBench locomotion suite
with the Unitree 26-DoF H1-2 humanoid, DoublyAware demonstrates improved sample
efficiency, accelerated convergence, and enhanced motion feasibility compared
to RL baselines. Our simulation results emphasize the significance of
structured uncertainty modeling for data-efficient and reliable decision-making
in TD-MPC-based humanoid locomotion learning.

</details>


### [4] [SPLATART: Articulated Gaussian Splatting with Estimated Object Structure](https://arxiv.org/abs/2506.12184)
*Stanley Lewis,Vishal Chandra,Tom Gao,Odest Chadwicke Jenkins*

Main category: cs.RO

TL;DR: SPLATART是一种从姿态图像中学习铰接对象高斯样条表示的管道，能够分离部件分割与关节估计任务，适用于更深的运动树结构。


<details>
  <summary>Details</summary>
Motivation: 铰接对象的表示在机器人领域仍然是一个难题，尤其是对于具有多自由度和复杂运动树的对象。

Method: SPLATART管道通过从姿态图像中学习高斯样条表示，分离部件分割和关节估计任务。

Result: 在合成Paris数据集和真实世界对象上展示了SPLATART的效果，并验证了其在更深运动树结构上的适用性。

Conclusion: SPLATART为解决复杂铰接对象的表示问题提供了一种有效方法，尤其适用于多自由度和深层运动树结构。

Abstract: Representing articulated objects remains a difficult problem within the field
of robotics. Objects such as pliers, clamps, or cabinets require
representations that capture not only geometry and color information, but also
part seperation, connectivity, and joint parametrization. Furthermore, learning
these representations becomes even more difficult with each additional degree
of freedom. Complex articulated objects such as robot arms may have seven or
more degrees of freedom, and the depth of their kinematic tree may be notably
greater than the tools, drawers, and cabinets that are the typical subjects of
articulated object research. To address these concerns, we introduce SPLATART -
a pipeline for learning Gaussian splat representations of articulated objects
from posed images, of which a subset contains image space part segmentations.
SPLATART disentangles the part separation task from the articulation estimation
task, allowing for post-facto determination of joint estimation and
representation of articulated objects with deeper kinematic trees than
previously exhibited. In this work, we present data on the SPLATART pipeline as
applied to the syntheic Paris dataset objects, and qualitative results on a
real-world object under spare segmentation supervision. We additionally present
on articulated serial chain manipulators to demonstrate usage on deeper
kinematic tree structures.

</details>


### [5] [Role of Uncertainty in Model Development and Control Design for a Manufacturing Process](https://arxiv.org/abs/2506.12273)
*Rongfei Li,Francis Assadian*

Main category: cs.RO

TL;DR: 论文探讨了多机器人控制系统在减少制造环境中不确定性方面的有效性，尤其是在高精度微尺度制造中。


<details>
  <summary>Details</summary>
Motivation: 人类在微尺度制造中仍优于机器人，主要依赖感官线索补偿环境不确定性。机器人虽配备先进传感器和微处理器，但控制算法仍是一种经济高效的替代方案。

Method: 提出了一种多机器人控制系统，旨在减少制造任务中的不确定性。

Result: 研究表明，多机器人控制系统能显著减少多种不确定性。

Conclusion: 多机器人控制系统是减少制造环境中不确定性的有效且经济的方法。

Abstract: The use of robotic technology has drastically increased in manufacturing in
the 21st century. But by utilizing their sensory cues, humans still outperform
machines, especially in the micro scale manufacturing, which requires
high-precision robot manipulators. These sensory cues naturally compensate for
high level of uncertainties that exist in the manufacturing environment.
Uncertainties in performing manufacturing tasks may come from measurement
noise, model inaccuracy, joint compliance (e.g., elasticity) etc. Although
advanced metrology sensors and high-precision microprocessors, which are
utilized in nowadays robots, have compensated for many structural and dynamic
errors in robot positioning, but a well-designed control algorithm still works
as a comparable and cheaper alternative to reduce uncertainties in automated
manufacturing. Our work illustrates that a multi-robot control system can
reduce various uncertainties to a great amount.

</details>


### [6] [ViTaSCOPE: Visuo-tactile Implicit Representation for In-hand Pose and Extrinsic Contact Estimation](https://arxiv.org/abs/2506.12239)
*Jayjun Lee,Nima Fazeli*

Main category: cs.RO

TL;DR: ViTaSCOPE结合视觉与高分辨率触觉反馈，通过神经隐式表示实现物体姿态与外部接触位置的精确估计。


<details>
  <summary>Details</summary>
Motivation: 在部分和噪声观测下，精确估计物体姿态和接触位置是灵巧操作的挑战。

Method: 采用神经隐式表示，将物体建模为有符号距离场，触觉反馈建模为神经剪切场，融合视觉与触觉数据。

Result: 在仿真和真实实验中验证了方法的有效性，支持灵巧操作。

Conclusion: ViTaSCOPE通过融合视觉与触觉反馈，解决了物体姿态与接触位置估计的难题。

Abstract: Mastering dexterous, contact-rich object manipulation demands precise
estimation of both in-hand object poses and external contact
locations$\unicode{x2013}$tasks particularly challenging due to partial and
noisy observations. We present ViTaSCOPE: Visuo-Tactile Simultaneous Contact
and Object Pose Estimation, an object-centric neural implicit representation
that fuses vision and high-resolution tactile feedback. By representing objects
as signed distance fields and distributed tactile feedback as neural shear
fields, ViTaSCOPE accurately localizes objects and registers extrinsic contacts
onto their 3D geometry as contact fields. Our method enables seamless reasoning
over complementary visuo-tactile cues by leveraging simulation for scalable
training and zero-shot transfers to the real-world by bridging the sim-to-real
gap. We evaluate our method through comprehensive simulated and real-world
experiments, demonstrating its capabilities in dexterous manipulation
scenarios.

</details>


### [7] [Explosive Output to Enhance Jumping Ability: A Variable Reduction Ratio Design Paradigm for Humanoid Robots Knee Joint](https://arxiv.org/abs/2506.12314)
*Xiaoshuai Ma,Haoxiang Qi,Qingqing Li,Haochen Xu,Xuechao Chen,Junyao Gao,Zhangguo Yu,Qiang Huang*

Main category: cs.RO

TL;DR: 论文提出了一种新型膝关节设计，通过动态减小减速比来提升跳跃时的爆发力输出，显著提高了人形机器人的跳跃性能。


<details>
  <summary>Details</summary>
Motivation: 提升膝关节的爆发力输出对人形机器人的敏捷性和越障能力至关重要，但传统设计因减速比与跳跃需求不匹配以及电机高速性能下降而受限。

Method: 采用动态减小减速比的策略，通过线性执行器驱动的导杆机构实现，并结合参数优化和跳跃控制策略。

Result: 实验验证显示单关节平台垂直跳跃高度达63厘米（比固定减速比设计提升28.1%），集成到人形机器人后实现了1.1米远跳、0.5米高跳和0.5米箱跳。

Conclusion: 动态减速比设计有效解决了传统膝关节在跳跃中的性能限制，显著提升了人形机器人的爆发力和跳跃能力。

Abstract: Enhancing the explosive power output of the knee joints is critical for
improving the agility and obstacle-crossing capabilities of humanoid robots.
However, a mismatch between the knee-to-center-of-mass (CoM) transmission ratio
and jumping demands, coupled with motor performance degradation at high speeds,
restricts the duration of high-power output and limits jump performance. To
address these problems, this paper introduces a novel knee joint design
paradigm employing a dynamically decreasing reduction ratio for explosive
output during jump. Analysis of motor output characteristics and knee
kinematics during jumping inspired a coupling strategy in which the reduction
ratio gradually decreases as the joint extends. A high initial ratio rapidly
increases torque at jump initiation, while its gradual reduction minimizes
motor speed increments and power losses, thereby maintaining sustained
high-power output. A compact and efficient linear actuator-driven guide-rod
mechanism realizes this coupling strategy, supported by parameter optimization
guided by explosive jump control strategies. Experimental validation
demonstrated a 63 cm vertical jump on a single-joint platform (a theoretical
improvement of 28.1\% over the optimal fixed-ratio joints). Integrated into a
humanoid robot, the proposed design enabled a 1.1 m long jump, a 0.5 m vertical
jump, and a 0.5 m box jump.

</details>


### [8] [ProVox: Personalization and Proactive Planning for Situated Human-Robot Collaboration](https://arxiv.org/abs/2506.12248)
*Jennifer Grannen,Siddharth Karamcheti,Blake Wulfe,Dorsa Sadigh*

Main category: cs.RO

TL;DR: ProVox框架通过个性化提示和主动语言模型任务规划，使机器人能快速推断用户意图并提前规划行为，减少用户负担，提升协作效率。


<details>
  <summary>Details</summary>
Motivation: 协作机器人需快速适应用户意图和偏好，尤其是在动态环境中，通过主动推断目标减少用户显式指令的需求。

Method: 提出ProVox框架，结合元提示协议和主动语言模型任务规划，从交互上下文中推断用户意图并建议行为。

Result: 用户研究表明，ProVox显著提升任务完成速度（38.7%）并减少用户负担（31.9%）。

Conclusion: 元提示和主动性是提升人机协作效率的关键，ProVox为动态环境中的个性化协作提供了有效解决方案。

Abstract: Collaborative robots must quickly adapt to their partner's intent and
preferences to proactively identify helpful actions. This is especially true in
situated settings where human partners can continually teach robots new
high-level behaviors, visual concepts, and physical skills (e.g., through
demonstration), growing the robot's capabilities as the human-robot pair work
together to accomplish diverse tasks. In this work, we argue that robots should
be able to infer their partner's goals from early interactions and use this
information to proactively plan behaviors ahead of explicit instructions from
the user. Building from the strong commonsense priors and steerability of large
language models, we introduce ProVox ("Proactive Voice"), a novel framework
that enables robots to efficiently personalize and adapt to individual
collaborators. We design a meta-prompting protocol that empowers users to
communicate their distinct preferences, intent, and expected robot behaviors
ahead of starting a physical interaction. ProVox then uses the personalized
prompt to condition a proactive language model task planner that anticipates a
user's intent from the current interaction context and robot capabilities to
suggest helpful actions; in doing so, we alleviate user burden, minimizing the
amount of time partners spend explicitly instructing and supervising the robot.
We evaluate ProVox through user studies grounded in household manipulation
tasks (e.g., assembling lunch bags) that measure the efficiency of the
collaboration, as well as features such as perceived helpfulness, ease of use,
and reliability. Our analysis suggests that both meta-prompting and proactivity
are critical, resulting in 38.7% faster task completion times and 31.9% less
user burden relative to non-active baselines. Supplementary material, code, and
videos can be found at https://provox-2025.github.io.

</details>


### [9] [Constrained Optimal Planning to Minimize Battery Degradation of Autonomous Mobile Robots](https://arxiv.org/abs/2506.13019)
*Jiachen Li,Jian Chu,Feiyang Zhao,Shihao Li,Wei Li,Dongmei Chen*

Main category: cs.RO

TL;DR: 提出了一种优化框架，用于减少自主移动机器人（AMR）电池的循环退化和日历老化，同时确保任务完成。


<details>
  <summary>Details</summary>
Motivation: 解决AMR电池的循环退化和日历老化问题，以延长电池寿命并确保任务完成。

Method: 采用分段线性近似的矩形方法，将双线性优化问题线性化。

Result: 通过案例研究验证了框架在实现AMR最优路径规划并减少电池老化方面的效率。

Conclusion: 该框架能有效优化AMR路径规划，减少电池老化。

Abstract: This paper proposes an optimization framework that addresses both cycling
degradation and calendar aging of batteries for autonomous mobile robot (AMR)
to minimize battery degradation while ensuring task completion. A rectangle
method of piecewise linear approximation is employed to linearize the bilinear
optimization problem. We conduct a case study to validate the efficiency of the
proposed framework in achieving an optimal path planning for AMRs while
reducing battery aging.

</details>


### [10] [Strategic Vantage Selection for Learning Viewpoint-Agnostic Manipulation Policies](https://arxiv.org/abs/2506.12261)
*Sreevishakh Vasudevan,Som Sagar,Ransalu Senanayake*

Main category: cs.RO

TL;DR: 论文提出Vantage框架，通过优化视角选择训练鲁棒的视角无关操作策略，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决视觉操作策略因视角变化导致的泛化能力不足问题，避免数据收集的资源浪费。

Method: 利用贝叶斯优化选择最优视角，迭代微调策略，平衡探索与利用。

Result: 在多种任务中，Vantage框架平均性能提升46.19%，优于固定或随机策略。

Conclusion: Vantage框架通过系统化视角选择，显著提升视角无关操作策略的性能和鲁棒性。

Abstract: Vision-based manipulation has shown remarkable success, achieving promising
performance across a range of tasks. However, these manipulation policies often
fail to generalize beyond their training viewpoints, which is a persistent
challenge in achieving perspective-agnostic manipulation, especially in
settings where the camera is expected to move at runtime. Although collecting
data from many angles seems a natural solution, such a naive approach is both
resource-intensive and degrades manipulation policy performance due to
excessive and unstructured visual diversity. This paper proposes Vantage, a
framework that systematically identifies and integrates data from optimal
perspectives to train robust, viewpoint-agnostic policies. By formulating
viewpoint selection as a continuous optimization problem, we iteratively
fine-tune policies on a few vantage points. Since we leverage Bayesian
optimization to efficiently navigate the infinite space of potential camera
configurations, we are able to balance exploration of novel views and
exploitation of high-performing ones, thereby ensuring data collection from a
minimal number of effective viewpoints. We empirically evaluate this framework
on diverse standard manipulation tasks using multiple policy learning methods,
demonstrating that fine-tuning with data from strategic camera placements
yields substantial performance gains, achieving average improvements of up to
46.19% when compared to fixed, random, or heuristic-based strategies.

</details>


### [11] [Cognitive Synergy Architecture: SEGO for Human-Centric Collaborative Robots](https://arxiv.org/abs/2506.13149)
*Jaehong Oh*

Main category: cs.RO

TL;DR: SEGO是一种认知映射架构，结合几何感知、语义推理和解释生成，用于人机协作机器人。


<details>
  <summary>Details</summary>
Motivation: 旨在为协作机器人提供一个统一的框架，整合环境的空间配置和语义关系。

Method: 结合SLAM定位、深度学习目标检测与跟踪，以及本体驱动推理，构建动态认知场景图。

Result: 实现了实时、语义一致的映射。

Conclusion: SEGO为协作机器人提供了高效的语义理解和场景建模能力。

Abstract: This paper presents SEGO (Semantic Graph Ontology), a cognitive mapping
architecture designed to integrate geometric perception, semantic reasoning,
and explanation generation into a unified framework for human-centric
collaborative robotics. SEGO constructs dynamic cognitive scene graphs that
represent not only the spatial configuration of the environment but also the
semantic relations and ontological consistency among detected objects. The
architecture seamlessly combines SLAM-based localization, deep-learning-based
object detection and tracking, and ontology-driven reasoning to enable
real-time, semantically coherent mapping.

</details>


### [12] [Delayed Expansion AGT: Kinodynamic Planning with Application to Tractor-Trailer Parking](https://arxiv.org/abs/2506.13421)
*Dongliang Zheng,Yebin Wang,Stefano Di Cairano,Panagiotis Tsiotras*

Main category: cs.RO

TL;DR: DE-AGT算法通过预计算运动基元和A*启发式方法，解决了高维状态空间和复杂系统动力学下的运动规划问题，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 针对高维状态空间和复杂动力学的运动规划问题，传统方法计算效率低，DE-AGT旨在通过优化运动基元扩展和启发式学习提升效率。

Method: DE-AGT采用延迟扩展运动基元模式，结合监督学习训练神经网络预测启发式成本，并改进目标到达机制。

Result: 仿真结果显示，DE-AGT比之前方法平均加速10倍。

Conclusion: DE-AGT通过优化运动基元扩展和启发式学习，显著提升了运动规划效率，适用于复杂环境中的车辆运动规划。

Abstract: Kinodynamic planning of articulated vehicles in cluttered environments faces
additional challenges arising from high-dimensional state space and complex
system dynamics. Built upon [1],[2], this work proposes the DE-AGT algorithm
that grows a tree using pre-computed motion primitives (MPs) and A* heuristics.
The first feature of DE-AGT is a delayed expansion of MPs. In particular, the
MPs are divided into different modes, which are ranked online. With the MP
classification and prioritization, DE-AGT expands the most promising mode of
MPs first, which eliminates unnecessary computation and finds solutions faster.
To obtain the cost-to-go heuristic for nonholonomic articulated vehicles, we
rely on supervised learning and train neural networks for fast and accurate
cost-to-go prediction. The learned heuristic is used for online mode ranking
and node selection. Another feature of DE-AGT is the improved goal-reaching.
Exactly reaching a goal state usually requires a constant connection checking
with the goal by solving steering problems -- non-trivial and time-consuming
for articulated vehicles. The proposed termination scheme overcomes this
challenge by tightly integrating a light-weight trajectory tracking controller
with the search process. DE-AGT is implemented for autonomous parking of a
general car-like tractor with 3-trailer. Simulation results show an average of
10x acceleration compared to a previous method.

</details>


### [13] [Perspective on Utilizing Foundation Models for Laboratory Automation in Materials Research](https://arxiv.org/abs/2506.12312)
*Kan Hatakeyama-Sato,Toshihiko Nishida,Kenta Kitamura,Yoshitaka Ushiku,Koichi Takahashi,Yuta Nabae,Teruaki Hayakawa*

Main category: cs.RO

TL;DR: 综述探讨了基础模型在材料和化学科学实验室自动化中的潜力，强调其认知和物理功能，并提出未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 传统实验室自动化依赖专用系统，缺乏灵活性；基础模型通过通用智能和多模态能力提供适应性。

Method: 利用大型语言模型（LLMs）和多模态机器人系统处理复杂动态任务。

Result: 展示了基础模型在实验室自动化中的可行性，但仍面临硬件操作精度、多模态数据整合和安全等挑战。

Conclusion: 提出未来路线图，强调跨学科合作、基准建立和人机协同，以实现完全自主的实验室。

Abstract: This review explores the potential of foundation models to advance laboratory
automation in the materials and chemical sciences. It emphasizes the dual roles
of these models: cognitive functions for experimental planning and data
analysis, and physical functions for hardware operations. While traditional
laboratory automation has relied heavily on specialized, rigid systems,
foundation models offer adaptability through their general-purpose intelligence
and multimodal capabilities. Recent advancements have demonstrated the
feasibility of using large language models (LLMs) and multimodal robotic
systems to handle complex and dynamic laboratory tasks. However, significant
challenges remain, including precision manipulation of hardware, integration of
multimodal data, and ensuring operational safety. This paper outlines a roadmap
highlighting future directions, advocating for close interdisciplinary
collaboration, benchmark establishment, and strategic human-AI integration to
realize fully autonomous experimental laboratories.

</details>


### [14] [A Survey on Imitation Learning for Contact-Rich Tasks in Robotics](https://arxiv.org/abs/2506.13498)
*Toshiaki Tsuji,Yasuhiro Kato,Gokhan Solak,Heng Zhang,Tadej Petrič,Francesco Nori,Arash Ajoudani*

Main category: cs.RO

TL;DR: 本文综述了模仿学习在接触密集型机器人任务中的研究趋势，分析了演示收集方法和学习方法的进展，并探讨了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 接触密集型任务因其非线性动态和对微小位置偏差的敏感性，是机器人领域的核心挑战，需要深入研究模仿学习在此类任务中的应用。

Method: 通过系统整理演示收集方法（如教学方法和感官模态）和模仿学习方法（如多模态学习和基础模型），分析其在接触密集型任务中的应用。

Result: 多模态学习和基础模型的进步显著提升了工业、家庭和医疗领域中复杂接触任务的性能。

Conclusion: 本文为未来接触密集型机器人操作的研究提供了系统性基础和挑战分析。

Abstract: This paper comprehensively surveys research trends in imitation learning for
contact-rich robotic tasks. Contact-rich tasks, which require complex physical
interactions with the environment, represent a central challenge in robotics
due to their nonlinear dynamics and sensitivity to small positional deviations.
The paper examines demonstration collection methodologies, including teaching
methods and sensory modalities crucial for capturing subtle interaction
dynamics. We then analyze imitation learning approaches, highlighting their
applications to contact-rich manipulation. Recent advances in multimodal
learning and foundation models have significantly enhanced performance in
complex contact tasks across industrial, household, and healthcare domains.
Through systematic organization of current research and identification of
challenges, this survey provides a foundation for future advancements in
contact-rich robotic manipulation.

</details>


### [15] [AntiGrounding: Lifting Robotic Actions into VLM Representation Space for Decision Making](https://arxiv.org/abs/2506.12374)
*Wenbo Li,Shiyi Wang,Yiteng Chen,Huiping Zhuang,Qingyao Wu*

Main category: cs.RO

TL;DR: 提出AntiGrounding框架，通过逆向指令接地过程，直接在VLM表示空间中生成候选动作，并利用多视角渲染和结构化视觉问答实现零样本任务合成。


<details>
  <summary>Details</summary>
Motivation: 当前方法将视觉语言模型（VLM）的高维表示压缩为中间表示，丢失了任务关键信息（如细粒度空间或语义细节）。

Method: 提出AntiGrounding框架，逆向指令接地过程，在VLM表示空间中生成动作，多视角渲染轨迹，结构化视觉问答辅助决策，并引入离线策略优化模块。

Result: 在仿真和真实环境中，该方法在多样化机器人操作任务中优于基线。

Conclusion: AntiGrounding框架通过保留高维表示中的关键信息，实现了零样本任务合成和性能提升。

Abstract: Vision-Language Models (VLMs) encode knowledge and reasoning capabilities for
robotic manipulation within high-dimensional representation spaces. However,
current approaches often project them into compressed intermediate
representations, discarding important task-specific information such as
fine-grained spatial or semantic details. To address this, we propose
AntiGrounding, a new framework that reverses the instruction grounding process.
It lifts candidate actions directly into the VLM representation space, renders
trajectories from multiple views, and uses structured visual question answering
for instruction-based decision making. This enables zero-shot synthesis of
optimal closed-loop robot trajectories for new tasks. We also propose an
offline policy refinement module that leverages past experience to enhance
long-term performance. Experiments in both simulation and real-world
environments show that our method outperforms baselines across diverse robotic
manipulation tasks.

</details>


### [16] [Sense and Sensibility: What makes a social robot convincing to high-school students?](https://arxiv.org/abs/2506.12507)
*Pablo Gonzalez-Oliveras,Olov Engwall,Ali Reza Majlesi*

Main category: cs.RO

TL;DR: 研究表明，社交教育机器人对学生决策有显著影响，尤其是熟悉AI的学生更容易被误导。机器人表现出的确定性程度直接影响学生的接受度。


<details>
  <summary>Details</summary>
Motivation: 探讨社交教育机器人对学生决策的影响，以及机器人表现出的确定性如何改变学生的接受度和感知可信度。

Method: 40名高中生参与实验，机器人针对8道判断题提供答案（6对2错），并展示三种确定性水平（确定、中立、不确定）。

Result: 75%学生受机器人影响，94.4%在机器人确定时接受答案，71.4%在不确定时接受。熟悉AI的学生更容易被误导。

Conclusion: 教育机器人应根据信息可靠性调整确定性表现，以促进学生批判性思维并减少不当影响。

Abstract: This study with 40 high-school students demonstrates the high influence of a
social educational robot on students' decision-making for a set of eight
true-false questions on electric circuits, for which the theory had been
covered in the students' courses. The robot argued for the correct answer on
six questions and the wrong on two, and 75% of the students were persuaded by
the robot to perform beyond their expected capacity, positively when the robot
was correct and negatively when it was wrong. Students with more experience of
using large language models were even more likely to be influenced by the
robot's stance -- in particular for the two easiest questions on which the
robot was wrong -- suggesting that familiarity with AI can increase
susceptibility to misinformation by AI.
  We further examined how three different levels of portrayed robot certainty,
displayed using semantics, prosody and facial signals, affected how the
students aligned with the robot's answer on specific questions and how
convincing they perceived the robot to be on these questions. The students
aligned with the robot's answers in 94.4% of the cases when the robot was
portrayed as Certain, 82.6% when it was Neutral and 71.4% when it was
Uncertain. The alignment was thus high for all conditions, highlighting
students' general susceptibility to accept the robot's stance, but alignment in
the Uncertain condition was significantly lower than in the Certain. Post-test
questionnaire answers further show that students found the robot most
convincing when it was portrayed as Certain. These findings highlight the need
for educational robots to adjust their display of certainty based on the
reliability of the information they convey, to promote students' critical
thinking and reduce undue influence.

</details>


### [17] [A Spatial Relationship Aware Dataset for Robotics](https://arxiv.org/abs/2506.12525)
*Peng Wang,Minh Huy Pham,Zhihao Guo,Wei Zhou*

Main category: cs.RO

TL;DR: 论文提出了一种空间关系感知的数据集，用于机器人任务规划，并测试了六种先进场景图生成模型的性能，结果表明显式空间关系能显著提升模型生成空间感知计划的能力。


<details>
  <summary>Details</summary>
Motivation: 机器人任务规划需要理解物体间的空间关系，但现有数据集缺乏对复杂空间关系的详细标注。

Method: 使用Boston Dynamics Spot机器人采集近1000张室内图像，并通过自定义标注工具标注物体属性、位置和空间关系。

Result: 测试了六种场景图生成模型，发现显式空间关系能显著提升模型性能，尤其是生成可执行的空间感知计划。

Conclusion: 数据集和标注工具公开可用，支持机器人空间推理的进一步研究。

Abstract: Robotic task planning in real-world environments requires not only object
recognition but also a nuanced understanding of spatial relationships between
objects. We present a spatial-relationship-aware dataset of nearly 1,000
robot-acquired indoor images, annotated with object attributes, positions, and
detailed spatial relationships. Captured using a Boston Dynamics Spot robot and
labelled with a custom annotation tool, the dataset reflects complex scenarios
with similar or identical objects and intricate spatial arrangements. We
benchmark six state-of-the-art scene-graph generation models on this dataset,
analysing their inference speed and relational accuracy. Our results highlight
significant differences in model performance and demonstrate that integrating
explicit spatial relationships into foundation models, such as ChatGPT 4o,
substantially improves their ability to generate executable, spatially-aware
plans for robotics. The dataset and annotation tool are publicly available at
https://github.com/PengPaulWang/SpatialAwareRobotDataset, supporting further
research in spatial reasoning for robotics.

</details>


### [18] [Deep Fusion of Ultra-Low-Resolution Thermal Camera and Gyroscope Data for Lighting-Robust and Compute-Efficient Rotational Odometry](https://arxiv.org/abs/2506.12536)
*Farida Mohsen,Ali Safa*

Main category: cs.RO

TL;DR: 提出了一种新型的热成像与陀螺仪融合方法，用于旋转里程计，适用于资源受限的机器人系统。


<details>
  <summary>Details</summary>
Motivation: 精确的旋转里程计对小型、功率受限的机器人平台至关重要，而传统方法在光照变化和惯性传感器漂移方面存在局限。

Method: 开发了多模态数据采集系统，结合热成像和陀螺仪数据，并设计轻量级CNN进行融合估计旋转速度。

Result: 热成像-陀螺仪融合显著降低了热成像分辨率需求，同时保持精度，提高了计算效率和内存利用率。

Conclusion: 该方法适用于实时部署，并公开了数据集以促进进一步研究。

Abstract: Accurate rotational odometry is crucial for autonomous robotic systems,
particularly for small, power-constrained platforms such as drones and mobile
robots. This study introduces thermal-gyro fusion, a novel sensor fusion
approach that integrates ultra-low-resolution thermal imaging with gyroscope
readings for rotational odometry. Unlike RGB cameras, thermal imaging is
invariant to lighting conditions and, when fused with gyroscopic data,
mitigates drift which is a common limitation of inertial sensors. We first
develop a multimodal data acquisition system to collect synchronized thermal
and gyroscope data, along with rotational speed labels, across diverse
environments. Subsequently, we design and train a lightweight Convolutional
Neural Network (CNN) that fuses both modalities for rotational speed
estimation. Our analysis demonstrates that thermal-gyro fusion enables a
significant reduction in thermal camera resolution without significantly
compromising accuracy, thereby improving computational efficiency and memory
utilization. These advantages make our approach well-suited for real-time
deployment in resource-constrained robotic systems. Finally, to facilitate
further research, we publicly release our dataset as supplementary material.

</details>


### [19] [Goal-based Self-Adaptive Generative Adversarial Imitation Learning (Goal-SAGAIL) for Multi-goal Robotic Manipulation Tasks](https://arxiv.org/abs/2506.12676)
*Yingyi Kuang,Luis J. Manso,George Vogiatzis*

Main category: cs.RO

TL;DR: 提出了一种名为Goal-SAGAIL的新框架，结合自适应性学习和目标条件GAIL，提升多目标机器人操作任务的模仿学习效率。


<details>
  <summary>Details</summary>
Motivation: 多目标机器人操作任务的目标空间复杂多样，现有方法如HER和GAIL在演示数据不足时效果有限，尤其是人类远程操作提供的演示数据覆盖不足。

Method: 结合自适应性学习与目标条件GAIL，提出Goal-SAGAIL框架，优化模仿学习效率。

Result: 实验表明，该方法在多种多目标操作任务中显著提升学习效率，包括复杂的手内操作任务。

Conclusion: Goal-SAGAIL框架有效解决了演示数据不足的问题，提升了多目标机器人操作任务的模仿学习效率。

Abstract: Reinforcement learning for multi-goal robot manipulation tasks poses
significant challenges due to the diversity and complexity of the goal space.
Techniques such as Hindsight Experience Replay (HER) have been introduced to
improve learning efficiency for such tasks. More recently, researchers have
combined HER with advanced imitation learning methods such as Generative
Adversarial Imitation Learning (GAIL) to integrate demonstration data and
accelerate training speed. However, demonstration data often fails to provide
enough coverage for the goal space, especially when acquired from human
teleoperation. This biases the learning-from-demonstration process toward
mastering easier sub-tasks instead of tackling the more challenging ones. In
this work, we present Goal-based Self-Adaptive Generative Adversarial Imitation
Learning (Goal-SAGAIL), a novel framework specifically designed for multi-goal
robot manipulation tasks. By integrating self-adaptive learning principles with
goal-conditioned GAIL, our approach enhances imitation learning efficiency,
even when limited, suboptimal demonstrations are available. Experimental
results validate that our method significantly improves learning efficiency
across various multi-goal manipulation scenarios -- including complex in-hand
manipulation tasks -- using suboptimal demonstrations provided by both
simulation and human experts.

</details>


### [20] [Adapting by Analogy: OOD Generalization of Visuomotor Policies via Functional Correspondence](https://arxiv.org/abs/2506.12678)
*Pranay Gupta,Henny Admoni,Andrea Bajcsy*

Main category: cs.RO

TL;DR: 论文提出了一种通过专家反馈实现端到端视觉运动策略在分布外（OOD）条件下泛化的方法，避免了昂贵的重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有行为克隆训练的端到端策略在OOD条件下表现不佳，而传统的交互式模仿学习需要大量专家纠正演示，成本高且低效。

Method: 方法包括检测OOD观察、获取专家功能对应反馈，并用对应ID观察干预OOD观察以实现泛化。

Result: 实验证明，该方法能显著提升视觉扩散策略在OOD条件下的泛化能力，且反馈成本低。

Conclusion: 通过功能对应反馈，无需重新训练即可实现OOD条件下的高效泛化。

Abstract: End-to-end visuomotor policies trained using behavior cloning have shown a
remarkable ability to generate complex, multi-modal low-level robot behaviors.
However, at deployment time, these policies still struggle to act reliably when
faced with out-of-distribution (OOD) visuals induced by objects, backgrounds,
or environment changes. Prior works in interactive imitation learning solicit
corrective expert demonstrations under the OOD conditions -- but this can be
costly and inefficient. We observe that task success under OOD conditions does
not always warrant novel robot behaviors. In-distribution (ID) behaviors can
directly be transferred to OOD conditions that share functional similarities
with ID conditions. For example, behaviors trained to interact with
in-distribution (ID) pens can apply to interacting with a visually-OOD pencil.
The key challenge lies in disambiguating which ID observations functionally
correspond to the OOD observation for the task at hand. We propose that an
expert can provide this OOD-to-ID functional correspondence. Thus, instead of
collecting new demonstrations and re-training at every OOD encounter, our
method: (1) detects the need for feedback by first checking if current
observations are OOD and then identifying whether the most similar training
observations show divergent behaviors, (2) solicits functional correspondence
feedback to disambiguate between those behaviors, and (3) intervenes on the OOD
observations with the functionally corresponding ID observations to perform
deployment-time generalization. We validate our method across diverse
real-world robotic manipulation tasks with a Franka Panda robotic manipulator.
Our results show that test-time functional correspondences can improve the
generalization of a vision-based diffusion policy to OOD objects and
environment conditions with low feedback.

</details>


### [21] [Multimodal Large Language Models-Enabled UAV Swarm: Towards Efficient and Intelligent Autonomous Aerial Systems](https://arxiv.org/abs/2506.12710)
*Yuqi Ping,Tianhao Liang,Huahao Ding,Guangyu Lei,Junwei Wu,Xuan Zou,Kuan Shi,Rui Shao,Chiya Zhang,Weizheng Zhang,Weijie Yuan,Tingting Zhang*

Main category: cs.RO

TL;DR: 论文探讨了将多模态大语言模型（MLLMs）与无人机群（UAV）结合，以提升其在动态任务中的智能和适应性，并以森林灭火为例展示了其潜力。


<details>
  <summary>Details</summary>
Motivation: 无人机群在动态、安全关键任务中需要快速的情境理解和自主适应能力，而MLLMs的突破为AI系统提供了跨模态的感知、推理和交互能力。

Method: 论文首先概述了无人机和MLLMs的基础架构与功能，分析了MLLMs如何提升无人机系统的目标检测、自主导航和多智能体协调能力，并提出了集成方案。

Result: 通过森林灭火的案例研究，展示了该框架在人机交互、群体任务规划、火情评估和任务执行方面的能力。

Conclusion: 论文讨论了MLLMs赋能无人机群的挑战和未来研究方向，并提供了实验视频链接。

Abstract: Recent breakthroughs in multimodal large language models (MLLMs) have endowed
AI systems with unified perception, reasoning and natural-language interaction
across text, image and video streams. Meanwhile, Unmanned Aerial Vehicle (UAV)
swarms are increasingly deployed in dynamic, safety-critical missions that
demand rapid situational understanding and autonomous adaptation. This paper
explores potential solutions for integrating MLLMs with UAV swarms to enhance
the intelligence and adaptability across diverse tasks. Specifically, we first
outline the fundamental architectures and functions of UAVs and MLLMs. Then, we
analyze how MLLMs can enhance the UAV system performance in terms of target
detection, autonomous navigation, and multi-agent coordination, while exploring
solutions for integrating MLLMs into UAV systems. Next, we propose a practical
case study focused on the forest fire fighting. To fully reveal the
capabilities of the proposed framework, human-machine interaction, swarm task
planning, fire assessment, and task execution are investigated. Finally, we
discuss the challenges and future research directions for the MLLMs-enabled UAV
swarm. An experiment illustration video could be found online at
https://youtu.be/zwnB9ZSa5A4.

</details>


### [22] [Physics-informed Neural Motion Planning via Domain Decomposition in Large Environments](https://arxiv.org/abs/2506.12742)
*Yuchen Liu,Alexiy Buynitsky,Ruiqi Ni,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: FB-NTFields提出了一种新的神经场表示方法，通过构建潜在空间表示来解决PiNMPs在运动规划中的可扩展性问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: PiNMPs在解决Eikonal PDE和运动规划中的成本函数表示时存在可扩展性问题，主要受限于频谱偏差和PDE驱动的复杂损失地形。

Method: FB-NTFields通过构建潜在空间表示，将成本函数计算为起点和终点坐标的潜在嵌入之间的距离，同时结合域分解，确保全局空间一致性。

Result: 在复杂合成和真实场景中验证了FB-NTFields的优越性，显著优于现有PiNMPs，并在四足机器人上成功部署。

Conclusion: FB-NTFields为大规模运动规划提供了一种高效且可扩展的解决方案，解决了PiNMPs的关键限制。

Abstract: Physics-informed Neural Motion Planners (PiNMPs) provide a data-efficient
framework for solving the Eikonal Partial Differential Equation (PDE) and
representing the cost-to-go function for motion planning. However, their
scalability remains limited by spectral bias and the complex loss landscape of
PDE-driven training. Domain decomposition mitigates these issues by dividing
the environment into smaller subdomains, but existing methods enforce
continuity only at individual spatial points. While effective for function
approximation, these methods fail to capture the spatial connectivity required
for motion planning, where the cost-to-go function depends on both the start
and goal coordinates rather than a single query point. We propose Finite Basis
Neural Time Fields (FB-NTFields), a novel neural field representation for
scalable cost-to-go estimation. Instead of enforcing continuity in output
space, FB-NTFields construct a latent space representation, computing the
cost-to-go as a distance between the latent embeddings of start and goal
coordinates. This enables global spatial coherence while integrating domain
decomposition, ensuring efficient large-scale motion planning. We validate
FB-NTFields in complex synthetic and real-world scenarios, demonstrating
substantial improvements over existing PiNMPs. Finally, we deploy our method on
a Unitree B1 quadruped robot, successfully navigating indoor environments. The
supplementary videos can be found at https://youtu.be/OpRuCbLNOwM.

</details>


### [23] [On-board Sonar Data Classification for Path Following in Underwater Vehicles using Fast Interval Type-2 Fuzzy Extreme Learning Machine](https://arxiv.org/abs/2506.12762)
*Adrian Rubio-Solis,Luciano Nava-Balanzar,Tomas Salgado-Jimenez*

Main category: cs.RO

TL;DR: 论文提出了一种基于FIT2-FELM的TSK IT2-FIS方法，用于水下自主导航，通过HNS实现实时路径规划和避障。


<details>
  <summary>Details</summary>
Motivation: 水下自主任务的成功依赖于对环境的准确识别，传统导航架构在不确定性和噪声下表现不佳。

Method: 应用FIT2-FELM训练TSK IT2-FIS，集成到HNS中作为导航引擎，实现实时路径规划和避障。

Result: 在2.5m x 2.5m x 3.5m的水箱中，BlueROV2表现出鲁棒的路径跟踪能力，且能同时执行多任务。

Conclusion: 该方法为水下自主导航提供了更完整的环境感知和实时规划能力。

Abstract: In autonomous underwater missions, the successful completion of predefined
paths mainly depends on the ability of underwater vehicles to recognise their
surroundings. In this study, we apply the concept of Fast Interval Type-2 Fuzzy
Extreme Learning Machine (FIT2-FELM) to train a Takagi-Sugeno-Kang IT2 Fuzzy
Inference System (TSK IT2-FIS) for on-board sonar data classification using an
underwater vehicle called BlueROV2. The TSK IT2-FIS is integrated into a
Hierarchical Navigation Strategy (HNS) as the main navigation engine to infer
local motions and provide the BlueROV2 with full autonomy to follow an
obstacle-free trajectory in a water container of 2.5m x 2.5m x 3.5m. Compared
to traditional navigation architectures, using the proposed method, we observe
a robust path following behaviour in the presence of uncertainty and noise. We
found that the proposed approach provides the BlueROV with a more complete
sensory picture about its surroundings while real-time navigation planning is
performed by the concurrent execution of two or more tasks.

</details>


### [24] [RL from Physical Feedback: Aligning Large Motion Models with Humanoid Control](https://arxiv.org/abs/2506.12769)
*Junpeng Yue,Zepeng Wang,Yuxuan Wang,Weishuai Zeng,Jiangxing Wang,Xinrun Xu,Yu Zhang,Sipeng Zheng,Ziluo Ding,Zongqing Lu*

Main category: cs.RO

TL;DR: 论文提出RLPF框架，通过物理反馈强化学习解决文本驱动动作生成的物理可行性问题，实现语义与物理的双重优化。


<details>
  <summary>Details</summary>
Motivation: 现有文本到动作生成方法虽能实现语义对齐，但常产生物理不可行的动作，无法实际部署。

Method: RLPF结合物理感知动作评估与文本条件动作生成，通过运动跟踪策略评估可行性并生成奖励，同时引入对齐验证模块保持语义忠实度。

Result: 实验表明RLPF在生成物理可行动作并保持语义对齐方面显著优于基线方法，成功应用于真实人形机器人。

Conclusion: RLPF有效解决了文本驱动动作生成的物理可行性问题，为机器人行为学习提供了高效且低成本的方法。

Abstract: This paper focuses on a critical challenge in robotics: translating
text-driven human motions into executable actions for humanoid robots, enabling
efficient and cost-effective learning of new behaviors. While existing
text-to-motion generation methods achieve semantic alignment between language
and motion, they often produce kinematically or physically infeasible motions
unsuitable for real-world deployment. To bridge this sim-to-real gap, we
propose Reinforcement Learning from Physical Feedback (RLPF), a novel framework
that integrates physics-aware motion evaluation with text-conditioned motion
generation. RLPF employs a motion tracking policy to assess feasibility in a
physics simulator, generating rewards for fine-tuning the motion generator.
Furthermore, RLPF introduces an alignment verification module to preserve
semantic fidelity to text instructions. This joint optimization ensures both
physical plausibility and instruction alignment. Extensive experiments show
that RLPF greatly outperforms baseline methods in generating physically
feasible motions while maintaining semantic correspondence with text
instruction, enabling successful deployment on real humanoid robots.

</details>


### [25] [From Experts to a Generalist: Toward General Whole-Body Control for Humanoid Robots](https://arxiv.org/abs/2506.12779)
*Yuxuan Wang,Ming Yang,Weishuai Zeng,Yu Zhang,Xinrun Xu,Haobin Jiang,Ziluo Ding,Zongqing Lu*

Main category: cs.RO

TL;DR: BumbleBee (BB) 是一种专家-通才学习框架，通过运动聚类和仿真到现实的适应，实现人形机器人的通用敏捷全身控制。


<details>
  <summary>Details</summary>
Motivation: 现有框架在训练单一运动策略时表现优异，但在处理多样化行为时因控制需求冲突和数据分布不匹配而难以泛化。

Method: BB 使用基于自动编码器的聚类方法分组行为相似的运动，训练专家策略并通过迭代增量动作建模适应现实数据，最终将这些专家蒸馏为统一控制器。

Result: 实验表明，BB 在仿真和真实人形机器人上实现了最先进的通用全身控制，为现实世界中的敏捷、鲁棒和可泛化性能设定了新标准。

Conclusion: BB 框架成功解决了多样化运动需求和数据冲突的挑战，为通用敏捷全身控制提供了有效解决方案。

Abstract: Achieving general agile whole-body control on humanoid robots remains a major
challenge due to diverse motion demands and data conflicts. While existing
frameworks excel in training single motion-specific policies, they struggle to
generalize across highly varied behaviors due to conflicting control
requirements and mismatched data distributions. In this work, we propose
BumbleBee (BB), an expert-generalist learning framework that combines motion
clustering and sim-to-real adaptation to overcome these challenges. BB first
leverages an autoencoder-based clustering method to group behaviorally similar
motions using motion features and motion descriptions. Expert policies are then
trained within each cluster and refined with real-world data through iterative
delta action modeling to bridge the sim-to-real gap. Finally, these experts are
distilled into a unified generalist controller that preserves agility and
robustness across all motion types. Experiments on two simulations and a real
humanoid robot demonstrate that BB achieves state-of-the-art general whole-body
control, setting a new benchmark for agile, robust, and generalizable humanoid
performance in the real world.

</details>


### [26] [KungfuBot: Physics-Based Humanoid Whole-Body Control for Learning Highly-Dynamic Skills](https://arxiv.org/abs/2506.12851)
*Weiji Xie,Jinrui Han,Jiakun Zheng,Huanyu Li,Xinzhe Liu,Jiyuan Shi,Weinan Zhang,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: 本文提出了一种基于物理的人形机器人控制框架，通过多步骤运动处理和自适应运动跟踪，实现了对高动态人类行为（如功夫和舞蹈）的模仿。


<details>
  <summary>Details</summary>
Motivation: 现有算法仅能跟踪平滑、低速的人类动作，而本文旨在解决高动态行为的模仿问题。

Method: 设计了运动处理流程（提取、过滤、校正、重定向）和自适应运动跟踪的双层优化问题，并采用非对称actor-critic框架进行策略训练。

Result: 实验表明，该方法跟踪误差显著低于现有方法，并在Unitree G1机器人上实现了稳定且富有表现力的行为。

Conclusion: 该框架成功实现了高动态行为的模仿，为机器人技能学习提供了新思路。

Abstract: Humanoid robots are promising to acquire various skills by imitating human
behaviors. However, existing algorithms are only capable of tracking smooth,
low-speed human motions, even with delicate reward and curriculum design. This
paper presents a physics-based humanoid control framework, aiming to master
highly-dynamic human behaviors such as Kungfu and dancing through multi-steps
motion processing and adaptive motion tracking. For motion processing, we
design a pipeline to extract, filter out, correct, and retarget motions, while
ensuring compliance with physical constraints to the maximum extent. For motion
imitation, we formulate a bi-level optimization problem to dynamically adjust
the tracking accuracy tolerance based on the current tracking error, creating
an adaptive curriculum mechanism. We further construct an asymmetric
actor-critic framework for policy training. In experiments, we train whole-body
control policies to imitate a set of highly-dynamic motions. Our method
achieves significantly lower tracking errors than existing approaches and is
successfully deployed on the Unitree G1 robot, demonstrating stable and
expressive behaviors. The project page is https://kungfu-bot.github.io.

</details>


### [27] [CHARM: Considering Human Attributes for Reinforcement Modeling](https://arxiv.org/abs/2506.13079)
*Qidi Fang,Hang Yu,Shijie Fang,Jindan Huang,Qiuyu Chen,Reuben M. Aronson,Elaine S. Short*

Main category: cs.RO

TL;DR: 研究了人类反馈模式与个体特征的关系，发现机器人经验和教育背景显著影响反馈质量，且结合个体特征能更准确预测反馈价值。


<details>
  <summary>Details</summary>
Motivation: 探索人类教师的个体特征如何影响反馈模式，填补了相关研究的空白。

Method: 设计了公开空间实验，包含两个长期任务和46名参与者，收集反馈和个体特征数据。

Result: 反馈模式与任务统计（如奖励）和个体特征（如机器人经验、教育背景）相关，结合个体特征能更准确预测反馈价值。

Conclusion: 人类个体特征对反馈质量有显著影响，未来研究应考虑这些因素以提高反馈效果。

Abstract: Reinforcement Learning from Human Feedback has recently achieved significant
success in various fields, and its performance is highly related to feedback
quality. While much prior work acknowledged that human teachers'
characteristics would affect human feedback patterns, there is little work that
has closely investigated the actual effects. In this work, we designed an
exploratory study investigating how human feedback patterns are associated with
human characteristics. We conducted a public space study with two long horizon
tasks and 46 participants. We found that feedback patterns are not only
correlated with task statistics, such as rewards, but also correlated with
participants' characteristics, especially robot experience and educational
background. Additionally, we demonstrated that human feedback value can be more
accurately predicted with human characteristics compared to only using task
statistics. All human feedback and characteristics we collected, and codes for
our data collection and predicting more accurate human feedback are available
at https://github.com/AABL-Lab/CHARM

</details>


### [28] [IKDiffuser: Fast and Diverse Inverse Kinematics Solution Generation for Multi-arm Robotic Systems](https://arxiv.org/abs/2506.13087)
*Zeyu Zhang,Ziyuan Jiao*

Main category: cs.RO

TL;DR: IKDiffuser是一种基于扩散的模型，用于快速生成多臂机器人系统的多样逆运动学解。


<details>
  <summary>Details</summary>
Motivation: 多臂机器人系统的逆运动学问题因复杂性（如自碰撞、耦合关节和高维冗余）而难以解决，传统方法效率低且缺乏多样性。

Method: IKDiffuser通过学习配置空间的联合分布，捕捉复杂依赖关系，并支持在推理时加入额外目标而无需重新训练。

Result: 在6种多臂系统上的实验表明，IKDiffuser在准确性、精度、多样性和计算效率上优于现有方法。

Conclusion: IKDiffuser为多臂机器人系统提供了一种可扩展的统一解决方案，支持实时操作任务。

Abstract: Solving Inverse Kinematics (IK) problems is fundamental to robotics, but has
primarily been successful with single serial manipulators. For multi-arm
robotic systems, IK remains challenging due to complex self-collisions, coupled
joints, and high-dimensional redundancy. These complexities make traditional IK
solvers slow, prone to failure, and lacking in solution diversity. In this
paper, we present IKDiffuser, a diffusion-based model designed for fast and
diverse IK solution generation for multi-arm robotic systems. IKDiffuser learns
the joint distribution over the configuration space, capturing complex
dependencies and enabling seamless generalization to multi-arm robotic systems
of different structures. In addition, IKDiffuser can incorporate additional
objectives during inference without retraining, offering versatility and
adaptability for task-specific requirements. In experiments on 6 different
multi-arm systems, the proposed IKDiffuser achieves superior solution accuracy,
precision, diversity, and computational efficiency compared to existing
solvers. The proposed IKDiffuser framework offers a scalable, unified approach
to solving multi-arm IK problems, facilitating the potential of multi-arm
robotic systems in real-time manipulation tasks.

</details>


### [29] [A Novel ViDAR Device With Visual Inertial Encoder Odometry and Reinforcement Learning-Based Active SLAM Method](https://arxiv.org/abs/2506.13100)
*Zhanhua Xin,Zhihao Wang,Shenghao Zhang,Wanchao Chi,Yan Meng,Shihan Kong,Yan Xiong,Chong Zhang,Yuzhen Liu,Junzhi Yu*

Main category: cs.RO

TL;DR: 论文提出了一种基于ViDAR设备的视觉-惯性-编码器紧耦合里程计（VIEO），并通过深度强化学习（DRL）提出了一种平台运动解耦的主动SLAM方法，显著提升了状态估计精度和特征点多样性。


<details>
  <summary>Details</summary>
Motivation: 现有SLAM系统中，单目相机和IMU被广泛使用，但电机编码器设备的集成研究较少。通过引入电机编码器，可以低成本、低复杂度地提升主动能力和视野范围。

Method: 提出VIEO算法，结合ViDAR设备进行校准；提出基于DRL的平台运动解耦主动SLAM方法。

Result: 实验表明，VIEO算法显著提升了跨帧共视关系，状态估计精度优于传统VIO算法；DRL方法进一步增强了特征点多样性。

Conclusion: 该方法为复杂环境下的平台设计和主动SLAM系统提供了新思路。

Abstract: In the field of multi-sensor fusion for simultaneous localization and mapping
(SLAM), monocular cameras and IMUs are widely used to build simple and
effective visual-inertial systems. However, limited research has explored the
integration of motor-encoder devices to enhance SLAM performance. By
incorporating such devices, it is possible to significantly improve active
capability and field of view (FOV) with minimal additional cost and structural
complexity. This paper proposes a novel visual-inertial-encoder tightly coupled
odometry (VIEO) based on a ViDAR (Video Detection and Ranging) device. A ViDAR
calibration method is introduced to ensure accurate initialization for VIEO. In
addition, a platform motion decoupled active SLAM method based on deep
reinforcement learning (DRL) is proposed. Experimental data demonstrate that
the proposed ViDAR and the VIEO algorithm significantly increase cross-frame
co-visibility relationships compared to its corresponding visual-inertial
odometry (VIO) algorithm, improving state estimation accuracy. Additionally,
the DRL-based active SLAM algorithm, with the ability to decouple from platform
motion, can increase the diversity weight of the feature points and further
enhance the VIEO algorithm's performance. The proposed methodology sheds fresh
insights into both the updated platform design and decoupled approach of active
SLAM systems in complex environments.

</details>


### [30] [Underwater target 6D State Estimation via UUV Attitude Enhance Observability](https://arxiv.org/abs/2506.13105)
*Fen Liu,Chengfeng Jia,Na Zhang,Shenghai Yuan,Rong Su*

Main category: cs.RO

TL;DR: 提出了一种新型的6D状态估计框架，使单个UUV仅通过两个单静态声纳传感器的连续噪声测距测量，估计其与非合作目标的相对运动。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏GPS、复杂的水下动力学和传感器限制，UUV对非合作目标的相对状态观测仍具挑战性。现有方法依赖全局定位基础设施或多UUV协作，不适用于单个UUV在大型或未知环境中操作。

Method: 提出了一种可观测性增强的姿态控制策略，通过卡尔曼滤波器优化UUV方向以提高相对状态估计的可观测性，并引入基于Lyapunov的跟踪控制策略保证长期稳定性。

Result: 理论分析和仿真表明，该方法显著提高了6D相对状态估计的准确性和鲁棒性。

Conclusion: 该研究为UUV在水下跟踪非合作目标提供了一种可扩展、无需基础设施的解决方案。

Abstract: Accurate relative state observation of Unmanned Underwater Vehicles (UUVs)
for tracking uncooperative targets remains a significant challenge due to the
absence of GPS, complex underwater dynamics, and sensor limitations. Existing
localization approaches rely on either global positioning infrastructure or
multi-UUV collaboration, both of which are impractical for a single UUV
operating in large or unknown environments. To address this, we propose a novel
persistent relative 6D state estimation framework that enables a single UUV to
estimate its relative motion to a non-cooperative target using only successive
noisy range measurements from two monostatic sonar sensors. Our key
contribution is an observability-enhanced attitude control strategy, which
optimally adjusts the UUV's orientation to improve the observability of
relative state estimation using a Kalman filter, effectively mitigating the
impact of sensor noise and drift accumulation. Additionally, we introduce a
rigorously proven Lyapunov-based tracking control strategy that guarantees
long-term stability by ensuring that the UUV maintains an optimal measurement
range, preventing localization errors from diverging over time. Through
theoretical analysis and simulations, we demonstrate that our method
significantly improves 6D relative state estimation accuracy and robustness
compared to conventional approaches. This work provides a scalable,
infrastructure-free solution for UUVs tracking uncooperative targets
underwater.

</details>


### [31] [Autonomous 3D Moving Target Encirclement and Interception with Range measurement](https://arxiv.org/abs/2506.13106)
*Fen Liu,Shenghai Yuan,Thien-Minh Nguyen,Rong Su*

Main category: cs.RO

TL;DR: 提出了一种自主3D目标包围与拦截策略，用于对抗商用无人机（UAV）的安全威胁，适用于非视距、GPS拒止和雷达干扰环境。


<details>
  <summary>Details</summary>
Motivation: 商用无人机可能携带危险载荷或干扰空中交通，传统地面引导系统在复杂环境下失效，需自主解决方案。

Method: 利用无人机实时测量的噪声距离，通过观测和速度补偿方法估计目标相对位置，结合反同步（AS）和X-Y圆周运动加垂直抖动实现包围控制。

Result: 实验和仿真验证了该策略在检测、包围和拦截敌对无人机方面的有效性。

Conclusion: 该策略为复杂环境下的无人机对抗提供了高效自主解决方案。

Abstract: Commercial UAVs are an emerging security threat as they are capable of
carrying hazardous payloads or disrupting air traffic. To counter UAVs, we
introduce an autonomous 3D target encirclement and interception strategy.
Unlike traditional ground-guided systems, this strategy employs autonomous
drones to track and engage non-cooperative hostile UAVs, which is effective in
non-line-of-sight conditions, GPS denial, and radar jamming, where conventional
detection and neutralization from ground guidance fail. Using two noisy
real-time distances measured by drones, guardian drones estimate the relative
position from their own to the target using observation and velocity
compensation methods, based on anti-synchronization (AS) and an X$-$Y circular
motion combined with vertical jitter. An encirclement control mechanism is
proposed to enable UAVs to adaptively transition from encircling and protecting
a target to encircling and monitoring a hostile target. Upon breaching a
warning threshold, the UAVs may even employ a suicide attack to neutralize the
hostile target. We validate this strategy through real-world UAV experiments
and simulated analysis in MATLAB, demonstrating its effectiveness in detecting,
encircling, and intercepting hostile drones. More details:
https://youtu.be/5eHW56lPVto.

</details>


### [32] [Equilibrium-Driven Smooth Separation and Navigation of Marsupial Robotic Systems](https://arxiv.org/abs/2506.13198)
*Bin-Bin Hu,Bayu Jayawardhana,Ming Cao*

Main category: cs.RO

TL;DR: 提出一种基于平衡驱动的控制器，实现载体-乘客机器人系统的平滑分离及乘客机器人导航至目标点。


<details>
  <summary>Details</summary>
Motivation: 解决载体-乘客机器人系统在分离和导航过程中的平滑性与适应性挑战。

Method: 设计基于立方多项式的势梯度控制器，利用载体-乘客和目标距离动态调整平衡点。

Result: 仿真验证控制器在含障碍环境中的有效性和适应性。

Conclusion: 该方法能实现平滑分离和导航，适用于复杂环境。

Abstract: In this paper, we propose an equilibrium-driven controller that enables a
marsupial carrier-passenger robotic system to achieve smooth carrier-passenger
separation and then to navigate the passenger robot toward a predetermined
target point. Particularly, we design a potential gradient in the form of a
cubic polynomial for the passenger's controller as a function of the
carrier-passenger and carrier-target distances in the moving carrier's frame.
This introduces multiple equilibrium points corresponding to the zero state of
the error dynamic system during carrier-passenger separation. The change of
equilibrium points is associated with the change in their attraction regions,
enabling smooth carrier-passenger separation and afterwards seamless navigation
toward the target. Finally, simulations demonstrate the effectiveness and
adaptability of the proposed controller in environments containing obstacles.

</details>


### [33] [C2TE: Coordinated Constrained Task Execution Design for Ordering-Flexible Multi-Vehicle Platoon Merging](https://arxiv.org/abs/2506.13202)
*Bin-Bin Hu,Yanxin Zhou,Henglai Wei,Shuo Cheng,Chen Lv*

Main category: cs.RO

TL;DR: 提出一种分布式协调约束任务执行（C2TE）算法，实现多车道车辆协作合并为顺序灵活的编队。


<details>
  <summary>Details</summary>
Motivation: 解决多车辆编队合并时顺序灵活性的问题，避免预设固定空间顺序的限制。

Method: 将任务分为两个阶段：预合并调节和顺序灵活编队合并，分别用分布式约束优化问题建模，并利用控制屏障函数（CBF）约束实现安全与效率。

Result: 实验和仿真验证了算法的有效性、灵活性、鲁棒性和可扩展性。

Conclusion: 该算法在多场景下表现优异，适用于动态和复杂环境。

Abstract: In this paper, we propose a distributed coordinated constrained task
execution (C2TE) algorithm that enables a team of vehicles from different lanes
to cooperatively merge into an {\it ordering-flexible platoon} maneuvering on
the desired lane. Therein, the platoon is flexible in the sense that no
specific spatial ordering sequences of vehicles are predetermined. To attain
such a flexible platoon, we first separate the multi-vehicle platoon (MVP)
merging mission into two stages, namely, pre-merging regulation and {\it
ordering-flexible platoon} merging, and then formulate them into distributed
constraint-based optimization problems. Particularly, by encoding
longitudinal-distance regulation and same-lane collision avoidance subtasks
into the corresponding control barrier function (CBF) constraints, the proposed
algorithm in Stage 1 can safely enlarge sufficient longitudinal distances among
adjacent vehicles. Then, by encoding lateral convergence, longitudinal-target
attraction, and neighboring collision avoidance subtasks into CBF constraints,
the proposed algorithm in Stage~2 can efficiently achieve the {\it
ordering-flexible platoon}. Note that the {\it ordering-flexible platoon} is
realized through the interaction of the longitudinal-target attraction and
time-varying neighboring collision avoidance constraints simultaneously.
Feasibility guarantee and rigorous convergence analysis are both provided under
strong nonlinear couplings induced by flexible orderings. Finally, experiments
using three autonomous mobile vehicles (AMVs) are conducted to verify the
effectiveness and flexibility of the proposed algorithm, and extensive
simulations are performed to demonstrate its robustness, adaptability, and
scalability when tackling vehicles' sudden breakdown, new appearing, different
number of lanes, mixed autonomy, and large-scale scenarios, respectively.

</details>


### [34] [Uncertainty-Informed Active Perception for Open Vocabulary Object Goal Navigation](https://arxiv.org/abs/2506.13367)
*Utkarsh Bajpai,Julius Rückin,Cyrill Stachniss,Marija Popović*

Main category: cs.RO

TL;DR: 提出了一种基于语义不确定性的主动感知管道，用于室内环境中的目标导航任务，通过量化视觉语言模型的语义不确定性并融入概率几何语义地图，提升导航效率。


<details>
  <summary>Details</summary>
Motivation: 当前目标导航方法依赖提示工程且忽略语义不确定性，导致探索效率低下，限制了性能。

Method: 提出了一种概率传感器模型量化语义不确定性，结合概率几何语义地图，并开发了基于不确定性信息的多臂老虎机目标的前沿探索规划器。

Result: 实验结果表明，该方法在不依赖大量提示工程的情况下，达到了与最先进方法相当的目标导航成功率。

Conclusion: 该方法通过量化语义不确定性并融入导航策略，显著提升了目标导航的效率和性能。

Abstract: Mobile robots exploring indoor environments increasingly rely on
vision-language models to perceive high-level semantic cues in camera images,
such as object categories. Such models offer the potential to substantially
advance robot behaviour for tasks such as object-goal navigation (ObjectNav),
where the robot must locate objects specified in natural language by exploring
the environment. Current ObjectNav methods heavily depend on prompt engineering
for perception and do not address the semantic uncertainty induced by
variations in prompt phrasing. Ignoring semantic uncertainty can lead to
suboptimal exploration, which in turn limits performance. Hence, we propose a
semantic uncertainty-informed active perception pipeline for ObjectNav in
indoor environments. We introduce a novel probabilistic sensor model for
quantifying semantic uncertainty in vision-language models and incorporate it
into a probabilistic geometric-semantic map to enhance spatial understanding.
Based on this map, we develop a frontier exploration planner with an
uncertainty-informed multi-armed bandit objective to guide efficient object
search. Experimental results demonstrate that our method achieves ObjectNav
success rates comparable to those of state-of-the-art approaches, without
requiring extensive prompt engineering.

</details>


### [35] [Observability-Aware Active Calibration of Multi-Sensor Extrinsics for Ground Robots via Online Trajectory Optimization](https://arxiv.org/abs/2506.13420)
*Jiang Wang,Yaozhong Kang,Linya Fu,Kazuhiro Nakadai,He Kong*

Main category: cs.RO

TL;DR: 提出了一种基于可观测性感知的主动校准方法，用于地面机器人的多模态传感器外参校准，通过轨迹优化提升校准效率。


<details>
  <summary>Details</summary>
Motivation: 现有校准方法复杂且依赖人工操作，且常忽略声学传感器，限制了系统的听觉感知能力。

Method: 利用Fisher信息矩阵量化参数可观测性，通过B样条曲线优化轨迹生成，实现在线数据收集与校准。

Result: 通过数值模拟和实际实验验证了方法的有效性和优势，并开源了代码和数据。

Conclusion: 该方法为多传感器外参校准提供了更智能的解决方案，推动了机器人系统的发展。

Abstract: Accurate calibration of sensor extrinsic parameters for ground robotic
systems (i.e., relative poses) is crucial for ensuring spatial alignment and
achieving high-performance perception. However, existing calibration methods
typically require complex and often human-operated processes to collect data.
Moreover, most frameworks neglect acoustic sensors, thereby limiting the
associated systems' auditory perception capabilities. To alleviate these
issues, we propose an observability-aware active calibration method for ground
robots with multimodal sensors, including a microphone array, a LiDAR
(exteroceptive sensors), and wheel encoders (proprioceptive sensors). Unlike
traditional approaches, our method enables active trajectory optimization for
online data collection and calibration, contributing to the development of more
intelligent robotic systems. Specifically, we leverage the Fisher information
matrix (FIM) to quantify parameter observability and adopt its minimum
eigenvalue as an optimization metric for trajectory generation via B-spline
curves. Through planning and replanning of robot trajectory online, the method
enhances the observability of multi-sensor extrinsic parameters. The
effectiveness and advantages of our method have been demonstrated through
numerical simulations and real-world experiments. For the benefit of the
community, we have also open-sourced our code and data at
https://github.com/AISLAB-sustech/Multisensor-Calibration.

</details>


### [36] [JENGA: Object selection and pose estimation for robotic grasping from a stack](https://arxiv.org/abs/2506.13425)
*Sai Srinivas Jeevanandam,Sandeep Inuganti,Shreedhar Govil,Didier Stricker,Jason Rambach*

Main category: cs.RO

TL;DR: 论文提出了一种基于相机-IMU的方法，用于在结构化物体堆叠场景中选择适合抓取的物体并估计其6DoF位姿，同时引入了数据集和评估指标。


<details>
  <summary>Details</summary>
Motivation: 在建筑或仓库自动化等场景中，机器人需要与结构化物体堆叠（如砖块堆）交互，而现有研究多关注孤立物体或无结构物体。

Method: 采用相机-IMU结合的方法，优先选择堆叠高层未被遮挡的物体，并开发了数据集和评估指标。

Result: 实验表明方法表现良好，但完全无误差的解决方案仍具挑战性。

Conclusion: 方法在建筑场景的砖块抓取应用中展示了实用性。

Abstract: Vision-based robotic object grasping is typically investigated in the context
of isolated objects or unstructured object sets in bin picking scenarios.
However, there are several settings, such as construction or warehouse
automation, where a robot needs to interact with a structured object formation
such as a stack. In this context, we define the problem of selecting suitable
objects for grasping along with estimating an accurate 6DoF pose of these
objects. To address this problem, we propose a camera-IMU based approach that
prioritizes unobstructed objects on the higher layers of stacks and introduce a
dataset for benchmarking and evaluation, along with a suitable evaluation
metric that combines object selection with pose accuracy. Experimental results
show that although our method can perform quite well, this is a challenging
problem if a completely error-free solution is needed. Finally, we show results
from the deployment of our method for a brick-picking application in a
construction scenario.

</details>


### [37] [VLM-SFD: VLM-Assisted Siamese Flow Diffusion Framework for Dual-Arm Cooperative Manipulation](https://arxiv.org/abs/2506.13428)
*Jiaming Chen,Yiyu Jiang,Aoshen Huang,Yang Li,Wei Pan*

Main category: cs.RO

TL;DR: 论文提出了一种名为VLM-SFD的新框架，用于双臂协作操作的模仿学习，通过结合视觉语言模型和扩散模型，显著提高了任务适应性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 双臂协作操作在复杂任务中具有潜力，但现有方法难以适应动态环境和多样化任务，尤其是在涉及两个物体交互的场景中。

Method: 提出了VLM-SFD框架，包括Siamese Flow Diffusion Network（SFDNet）和动态任务分配策略，结合扩散模型和视觉语言模型生成双流运动流。

Result: 实验验证了该方法的有效性，能够从少量人类演示中快速适应和泛化到多样化任务。

Conclusion: VLM-SFD框架在双臂协作操作中表现出色，具有高效性和适应性，代码和演示视频已公开。

Abstract: Dual-arm cooperative manipulation holds great promise for tackling complex
real-world tasks that demand seamless coordination and adaptive dynamics.
Despite substantial progress in learning-based motion planning, most approaches
struggle to generalize across diverse manipulation tasks and adapt to dynamic,
unstructured environments, particularly in scenarios involving interactions
between two objects such as assembly, tool use, and bimanual grasping. To
address these challenges, we introduce a novel VLM-Assisted Siamese Flow
Diffusion (VLM-SFD) framework for efficient imitation learning in dual-arm
cooperative manipulation. The proposed VLM-SFD framework exhibits outstanding
adaptability, significantly enhancing the ability to rapidly adapt and
generalize to diverse real-world tasks from only a minimal number of human
demonstrations. Specifically, we propose a Siamese Flow Diffusion Network
(SFDNet) employs a dual-encoder-decoder Siamese architecture to embed two
target objects into a shared latent space, while a diffusion-based conditioning
process-conditioned by task instructions-generates two-stream object-centric
motion flows that guide dual-arm coordination. We further design a dynamic task
assignment strategy that seamlessly maps the predicted 2D motion flows into 3D
space and incorporates a pre-trained vision-language model (VLM) to adaptively
assign the optimal motion to each robotic arm over time. Experiments validate
the effectiveness of the proposed method, demonstrating its ability to
generalize to diverse manipulation tasks while maintaining high efficiency and
adaptability. The code and demo videos are publicly available on our project
website https://sites.google.com/view/vlm-sfd/.

</details>


### [38] [Adaptive Model-Base Control of Quadrupeds via Online System Identification using Kalman Filter](https://arxiv.org/abs/2506.13432)
*Jonas Haack,Franek Stark,Shubham Vyas,Frank Kirchner,Shivesh Kumar*

Main category: cs.RO

TL;DR: 本文提出了一种基于卡尔曼滤波的在线质量与质心识别方法，用于四足机器人，提高了模型控制器的鲁棒性和跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，四足机器人需要适应不同负载，而传统基于固定模型的控制器限制了其适用性。

Method: 采用卡尔曼滤波器在线识别机器人的质量和质心，并与经典递归最小二乘法进行比较。

Result: 该方法在强测量噪声下比递归最小二乘法更鲁棒，并能提升模型控制器在变负载下的跟踪性能。

Conclusion: 卡尔曼滤波器在线识别方法有效提升了四足机器人在变负载场景下的控制性能。

Abstract: Many real-world applications require legged robots to be able to carry
variable payloads. Model-based controllers such as model predictive control
(MPC) have become the de facto standard in research for controlling these
systems. However, most model-based control architectures use fixed plant
models, which limits their applicability to different tasks. In this paper, we
present a Kalman filter (KF) formulation for online identification of the mass
and center of mass (COM) of a four-legged robot. We evaluate our method on a
quadrupedal robot carrying various payloads and find that it is more robust to
strong measurement noise than classical recursive least squares (RLS) methods.
Moreover, it improves the tracking performance of the model-based controller
with varying payloads when the model parameters are adjusted at runtime.

</details>


### [39] [Towards a Formal Specification for Self-organized Shape Formation in Swarm Robotics](https://arxiv.org/abs/2506.13453)
*YR Darr,MA Niazi*

Main category: cs.RO

TL;DR: 本文提出了一种使用形式化规范方法（Z语言）建模群机器人自组织形状形成任务的方法，填补了该领域的研究空白。


<details>
  <summary>Details</summary>
Motivation: 群机器人自组织形成复杂结构是一个复杂系统，但形式化规范方法尚未用于建模这一过程。本文旨在填补这一空白。

Method: 使用基于状态的Z语言对系统实体的状态进行建模，并验证其在自组织形状形成中的有效性。

Result: 提出的形式化规范模型为设计和实现群机器人系统提供了框架，并为多智能体系统仿真奠定了基础。

Conclusion: 形式化规范方法（Z语言）适用于群机器人自组织形状形成的建模，为复杂系统研究提供了新思路。

Abstract: The self-organization of robots for the formation of structures and shapes is
a stimulating application of the swarm robotic system. It involves a large
number of autonomous robots of heterogeneous behavior, coordination among them,
and their interaction with the dynamic environment. This process of complex
structure formation is considered a complex system, which needs to be modeled
by using any modeling approach. Although the formal specification approach
along with other formal methods has been used to model the behavior of robots
in a swarm. However, to the best of our knowledge, the formal specification
approach has not been used to model the self-organization process in swarm
robotic systems for shape formation. In this paper, we use a formal
specification approach to model the shape formation task of swarm robots. We
use Z (Zed) language of formal specification, which is a state-based language,
to model the states of the entities of the systems. We demonstrate the
effectiveness of Z for the self-organized shape formation. The presented formal
specification model gives the outlines for designing and implementing the swarm
robotic system for the formation of complex shapes and structures. It also
provides the foundation for modeling the complex shape formation process for
swarm robotics using a multi-agent system in a simulation-based environment.
Keywords: Swarm robotics, Self-organization, Formal specification, Complex
systems

</details>


### [40] [Learning Swing-up Maneuvers for a Suspended Aerial Manipulation Platform in a Hierarchical Control Framework](https://arxiv.org/abs/2506.13478)
*Hemjyoti Das,Minh Nhat Vu,Christian Ott*

Main category: cs.RO

TL;DR: 提出了一种结合模型控制与强化学习的层次化控制框架，用于实现悬挂式空中平台的摆动动作。


<details>
  <summary>Details</summary>
Motivation: 悬挂式空中平台在建筑工地等场景有广泛应用，但仅靠推力难以完成特定位置的摆动动作。

Method: 采用层次化控制框架，优先级任务（如保持末端执行器位置）由模型控制完成，低优先级任务（摆动动作）由强化学习代理调整参考点。

Result: 通过数值模拟验证了方法的有效性。

Conclusion: 该方法为复杂任务提供了灵活且高效的解决方案。

Abstract: In this work, we present a novel approach to augment a model-based control
method with a reinforcement learning (RL) agent and demonstrate a swing-up
maneuver with a suspended aerial manipulation platform. These platforms are
targeted towards a wide range of applications on construction sites involving
cranes, with swing-up maneuvers allowing it to perch at a given location,
inaccessible with purely the thrust force of the platform. Our proposed
approach is based on a hierarchical control framework, which allows different
tasks to be executed according to their assigned priorities. An RL agent is
then subsequently utilized to adjust the reference set-point of the
lower-priority tasks to perform the swing-up maneuver, which is confined in the
nullspace of the higher-priority tasks, such as maintaining a specific
orientation and position of the end-effector. Our approach is validated using
extensive numerical simulation studies.

</details>


### [41] [What Matters in Learning from Large-Scale Datasets for Robot Manipulation](https://arxiv.org/abs/2506.13536)
*Vaibhav Saxena,Matthew Bronars,Nadun Ranawaka Arachchige,Kuancheng Wang,Woo Chul Shin,Soroush Nasiriany,Ajay Mandlekar,Danfei Xu*

Main category: cs.RO

TL;DR: 该论文研究了如何通过控制数据集组成来优化机器人模仿学习的效果，提出了数据生成框架，并得出相机位姿和空间布局是关键因素的结论。


<details>
  <summary>Details</summary>
Motivation: 尽管大规模多任务演示数据集在机器人模仿学习中具有潜力，但目前缺乏对如何优化数据集组成的系统性理解。

Method: 开发了一个数据生成框架，模拟现有数据集的多样性来源，并生成受控组成的大规模数据集，用于研究数据集组成的影响。

Result: 研究发现相机位姿和空间布局是关键因素，且在真实机器人学习中，模拟中的结论依然适用，检索策略能提升性能达70%。

Conclusion: 论文为未来数据集收集和现有数据集检索提供了实用指导，强调了多样性和对齐的重要性。

Abstract: Imitation learning from large multi-task demonstration datasets has emerged
as a promising path for building generally-capable robots. As a result, 1000s
of hours have been spent on building such large-scale datasets around the
globe. Despite the continuous growth of such efforts, we still lack a
systematic understanding of what data should be collected to improve the
utility of a robotics dataset and facilitate downstream policy learning. In
this work, we conduct a large-scale dataset composition study to answer this
question. We develop a data generation framework to procedurally emulate common
sources of diversity in existing datasets (such as sensor placements and object
types and arrangements), and use it to generate large-scale robot datasets with
controlled compositions, enabling a suite of dataset composition studies that
would be prohibitively expensive in the real world. We focus on two practical
settings: (1) what types of diversity should be emphasized when future
researchers collect large-scale datasets for robotics, and (2) how should
current practitioners retrieve relevant demonstrations from existing datasets
to maximize downstream policy performance on tasks of interest. Our study
yields several critical insights -- for example, we find that camera poses and
spatial arrangements are crucial dimensions for both diversity in collection
and alignment in retrieval. In real-world robot learning settings, we find that
not only do our insights from simulation carry over, but our retrieval
strategies on existing datasets such as DROID allow us to consistently
outperform existing training strategies by up to 70%. More results at
https://robo-mimiclabs.github.io/

</details>


### [42] [Disturbance-aware minimum-time planning strategies for motorsport vehicles with probabilistic safety certificates](https://arxiv.org/abs/2506.13622)
*Martino Gulisano,Matteo Masoni,Marco Gabiccini,Massimo Guiggiani*

Main category: cs.RO

TL;DR: 本文提出了一种扰动感知框架，将鲁棒性嵌入到赛车运动的最小圈速轨迹优化中，分为开环和闭环两种方法，均能生成安全且性能优化的轨迹。


<details>
  <summary>Details</summary>
Motivation: 赛车运动中的轨迹优化需要在高性能要求下同时保证安全性，传统方法在不确定性下可能失效，因此需要一种鲁棒性强的优化框架。

Method: （i）开环方法基于有限窗口的最坏情况不确定性增长收紧约束；（ii）闭环方法结合时变LQR反馈律，提供更精确的约束收紧。

Result: 两种方法均满足安全概率要求，闭环方法在圈速损失上优于开环方法，且非鲁棒轨迹在相同不确定性下不可行。

Conclusion: 该框架通过考虑不确定性和反馈作用，生成了性能最优且概率安全的轨迹，推动了最小时间优化在赛车运动中的实际应用。

Abstract: This paper presents a disturbance-aware framework that embeds robustness into
minimum-lap-time trajectory optimization for motorsport. Two formulations are
introduced. (i) Open-loop, horizon-based covariance propagation uses worst-case
uncertainty growth over a finite window to tighten tire-friction and
track-limit constraints. (ii) Closed-loop, covariance-aware planning
incorporates a time-varying LQR feedback law in the optimizer, providing a
feedback-consistent estimate of disturbance attenuation and enabling sharper
yet reliable constraint tightening. Both methods yield reference trajectories
for human or artificial drivers: in autonomous applications the modelled
controller can replicate the on-board implementation, while for human driving
accuracy increases with the extent to which the driver can be approximated by
the assumed time-varying LQR policy. Computational tests on a representative
Barcelona-Catalunya sector show that both schemes meet the prescribed safety
probability, yet the closed-loop variant incurs smaller lap-time penalties than
the more conservative open-loop solution, while the nominal (non-robust)
trajectory remains infeasible under the same uncertainties. By accounting for
uncertainty growth and feedback action during planning, the proposed framework
delivers trajectories that are both performance-optimal and probabilistically
safe, advancing minimum-time optimization toward real-world deployment in
high-performance motorsport and autonomous racing.

</details>


### [43] [Towards Efficient Occupancy Mapping via Gaussian Process Latent Field Shaping](https://arxiv.org/abs/2506.13640)
*Cedric Le Gentil,Cedric Pradalier,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 该论文提出了一种基于高斯过程的占用映射方法，通过直接操作潜在函数来高效整合自由空间信息，并区分自由与未知空间，提高了重建精度。


<details>
  <summary>Details</summary>
Motivation: 占用映射是移动机器人的关键技术，传统离散网格表示已发展为连续表示。现有高斯过程方法将任务视为二分类问题，但未直接操作潜在函数。本文旨在通过直接操作潜在函数，更高效地整合自由空间信息。

Method: 提出直接操作高斯过程潜在函数的方法，将自由空间信息作为先验，并区分自由与未知空间。占用区域定义为自由到未知的过渡点。

Result: 在模拟环境中验证了方法的有效性，重建精度具有竞争力。

Conclusion: 该方法通过直接操作潜在函数和区分自由与未知空间，实现了高效的占用映射，为移动机器人提供了更精确的环境表示。

Abstract: Occupancy mapping has been a key enabler of mobile robotics. Originally based
on a discrete grid representation, occupancy mapping has evolved towards
continuous representations that can predict the occupancy status at any
location and account for occupancy correlations between neighbouring areas.
Gaussian Process (GP) approaches treat this task as a binary classification
problem using both observations of occupied and free space. Conceptually, a GP
latent field is passed through a logistic function to obtain the output class
without actually manipulating the GP latent field. In this work, we propose to
act directly on the latent function to efficiently integrate free space
information as a prior based on the shape of the sensor's field-of-view. A
major difference with existing methods is the change in the classification
problem, as we distinguish between free and unknown space. The `occupied' area
is the infinitesimally thin location where the class transitions from free to
unknown. We demonstrate in simulated environments that our approach is sound
and leads to competitive reconstruction accuracy.

</details>


### [44] [ROSA: Harnessing Robot States for Vision-Language and Action Alignment](https://arxiv.org/abs/2506.13679)
*Yuqing Wen,Kefan Gu,Haoxuan Liu,Yucheng Zhao,Tiancai Wang,Haoqiang Fan,Xiaoyan Sun*

Main category: cs.RO

TL;DR: ROSA是一种新的训练范式，通过机器人状态估计提升视觉-语言-动作（VLA）模型的空间对齐能力，解决了现有方法的数据效率低和依赖人工的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过直接微调视觉语言模型（VLMs）存在时空差距，导致数据效率低下且依赖人工。

Method: 提出ROSA训练范式，利用机器人状态估计数据自动对齐视觉-语言与动作空间。

Result: 在模拟和真实环境中验证了ROSA的有效性，尤其在低数据情况下表现优异。

Conclusion: ROSA通过增强空间理解和自感知能力，显著提升了VLA模型的性能和泛化能力。

Abstract: Vision-Language-Action (VLA) models have recently made significant advance in
multi-task, end-to-end robotic control, due to the strong generalization
capabilities of Vision-Language Models (VLMs). A fundamental challenge in
developing such models is effectively aligning the vision-language space with
the robotic action space. Existing approaches typically rely on directly
fine-tuning VLMs using expert demonstrations. However, this strategy suffers
from a spatio-temporal gap, resulting in considerable data inefficiency and
heavy reliance on human labor. Spatially, VLMs operate within a high-level
semantic space, whereas robotic actions are grounded in low-level 3D physical
space; temporally, VLMs primarily interpret the present, while VLA models
anticipate future actions. To overcome these challenges, we propose a novel
training paradigm, ROSA, which leverages robot state estimation to improve
alignment between vision-language and action spaces. By integrating robot state
estimation data obtained via an automated process, ROSA enables the VLA model
to gain enhanced spatial understanding and self-awareness, thereby boosting
performance and generalization. Extensive experiments in both simulated and
real-world environments demonstrate the effectiveness of ROSA, particularly in
low-data regimes.

</details>


### [45] [HARMONI: Haptic-Guided Assistance for Unified Robotic Tele-Manipulation and Tele-Navigation](https://arxiv.org/abs/2506.13704)
*V. Sripada,A. Khan,J. Föcker,S. Parsa,Susmitha P,H Maior,A. Ghalamzan-E*

Main category: cs.RO

TL;DR: 提出了一种基于触觉引导共享控制的统一远程移动操作框架，显著提高了任务准确性和效率，同时未增加认知负担。


<details>
  <summary>Details</summary>
Motivation: 现有触觉引导远程操作多限于简化任务，且导航与操作策略分离，增加了认知和操作负担。

Method: 整合9-DoF移动机械臂和7-DoF机械臂，通过实时触觉反馈实现导航与操作的无缝切换。

Result: 20名参与者的实验表明，框架显著提升了任务准确性和效率。

Conclusion: 触觉引导共享控制有望在复杂远程操作中提升操作者表现。

Abstract: Shared control, which combines human expertise with autonomous assistance, is
critical for effective teleoperation in complex environments. While recent
advances in haptic-guided teleoperation have shown promise, they are often
limited to simplified tasks involving 6- or 7-DoF manipulators and rely on
separate control strategies for navigation and manipulation. This increases
both cognitive load and operational overhead. In this paper, we present a
unified tele-mobile manipulation framework that leverages haptic-guided shared
control. The system integrates a 9-DoF follower mobile manipulator and a 7-DoF
leader robotic arm, enabling seamless transitions between tele-navigation and
tele-manipulation through real-time haptic feedback. A user study with 20
participants under real-world conditions demonstrates that our framework
significantly improves task accuracy and efficiency without increasing
cognitive load. These findings highlight the potential of haptic-guided shared
control for enhancing operator performance in demanding teleoperation
scenarios.

</details>


### [46] [CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding](https://arxiv.org/abs/2506.13725)
*Wenxuan Song,Jiayi Chen,Pengxiang Ding,Yuxin Huang,Han Zhao,Donglin Wang,Haoang Li*

Main category: cs.RO

TL;DR: 本文提出了一种通过一致性蒸馏训练和早期退出解码策略加速视觉-语言-动作（VLA）模型推理的方法，实现了4倍以上的加速，同时保持高任务成功率。


<details>
  <summary>Details</summary>
Motivation: VLA模型在机器人领域具有重要应用，但其推理速度瓶颈限制了实际部署。传统方法如雅可比解码效率有限，需要改进。

Method: 采用一致性蒸馏训练预测多个动作标记，结合混合标签监督减少误差积累，并提出早期退出解码策略放松收敛条件。

Result: 实验表明，该方法在不同基准上实现了4倍以上的推理加速，同时在模拟和真实机器人任务中保持高成功率。

Conclusion: 该方法为加速机器人多模态决策提供了高效且通用的解决方案。

Abstract: In recent years, Vision-Language-Action (VLA) models have become a vital
research direction in robotics due to their impressive multimodal understanding
and generalization capabilities. Despite the progress, their practical
deployment is severely constrained by inference speed bottlenecks, particularly
in high-frequency and dexterous manipulation tasks. While recent studies have
explored Jacobi decoding as a more efficient alternative to traditional
autoregressive decoding, its practical benefits are marginal due to the lengthy
iterations. To address it, we introduce consistency distillation training to
predict multiple correct action tokens in each iteration, thereby achieving
acceleration. Besides, we design mixed-label supervision to mitigate the error
accumulation during distillation. Although distillation brings acceptable
speedup, we identify that certain inefficient iterations remain a critical
bottleneck. To tackle this, we propose an early-exit decoding strategy that
moderately relaxes convergence conditions, which further improves average
inference efficiency. Experimental results show that the proposed method
achieves more than 4 times inference acceleration across different baselines
while maintaining high task success rates in both simulated and real-world
robot tasks. These experiments validate that our approach provides an efficient
and general paradigm for accelerating multimodal decision-making in robotics.
Our project page is available at https://irpn-eai.github.io/CEED-VLA/.

</details>


### [47] [Critical Insights about Robots for Mental Wellbeing](https://arxiv.org/abs/2506.13739)
*Guy Laban,Micol Spitale,Minja Axelsson,Nida Itrat Abbasi,Hatice Gunes*

Main category: cs.RO

TL;DR: 本文总结了社交机器人在促进心理健康方面的六个关键见解，包括测量方法的多样性、机器人角色的灵活性、虚拟互动的潜力、临床设计的必要性、互动时长的差异以及个性化需求的非必要性。


<details>
  <summary>Details</summary>
Motivation: 探讨社交机器人作为非临床环境中支持情感健康的工具，明确其机会与挑战。

Method: 基于实证研究和实际部署，提炼出六个关键见解。

Result: 机器人应被视为辅助工具，而非人类治疗师的替代品，需基于证据和伦理设计。

Conclusion: 为未来研究和机器人心理健康应用的负责任使用提供指导。

Abstract: Social robots are increasingly being explored as tools to support emotional
wellbeing, particularly in non-clinical settings. Drawing on a range of
empirical studies and practical deployments, this paper outlines six key
insights that highlight both the opportunities and challenges in using robots
to promote mental wellbeing. These include (1) the lack of a single, objective
measure of wellbeing, (2) the fact that robots don't need to act as companions
to be effective, (3) the growing potential of virtual interactions, (4) the
importance of involving clinicians in the design process, (5) the difference
between one-off and long-term interactions, and (6) the idea that adaptation
and personalization are not always necessary for positive outcomes. Rather than
positioning robots as replacements for human therapists, we argue that they are
best understood as supportive tools that must be designed with care, grounded
in evidence, and shaped by ethical and psychological considerations. Our aim is
to inform future research and guide responsible, effective use of robots in
mental health and wellbeing contexts.

</details>


### [48] [LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction](https://arxiv.org/abs/2506.13751)
*Haoru Xue,Xiaoyu Huang,Dantong Niu,Qiayuan Liao,Thomas Kragerud,Jan Tommy Gravdahl,Xue Bin Peng,Guanya Shi,Trevor Darrell,Koushil Screenath,Shankar Sastry*

Main category: cs.RO

TL;DR: 论文提出LeVERB框架，解决人形机器人视觉语言动作（VLA）模型在全身控制（WBC）任务中的不足，并通过新基准测试验证其性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型依赖低层控制器和手工动作词汇，限制了其在动态任务中的应用，尤其是人形机器人全身控制任务。

Method: 提出LeVERB框架，分层次设计：高层视觉语言策略学习潜在动作词汇，低层强化学习策略生成动态命令。

Result: LeVERB在基准测试中，简单视觉导航任务成功率达80%，整体成功率58.5%，优于基线方法7.8倍。

Conclusion: LeVERB填补了VLA模型在人形机器人全身控制任务中的空白，展示了零样本泛化能力。

Abstract: Vision-language-action (VLA) models have demonstrated strong semantic
understanding and zero-shot generalization, yet most existing systems assume an
accurate low-level controller with hand-crafted action "vocabulary" such as
end-effector pose or root velocity. This assumption confines prior work to
quasi-static tasks and precludes the agile, whole-body behaviors required by
humanoid whole-body control (WBC) tasks. To capture this gap in the literature,
we start by introducing the first sim-to-real-ready, vision-language,
closed-loop benchmark for humanoid WBC, comprising over 150 tasks from 10
categories. We then propose LeVERB: Latent Vision-Language-Encoded Robot
Behavior, a hierarchical latent instruction-following framework for humanoid
vision-language WBC, the first of its kind. At the top level, a vision-language
policy learns a latent action vocabulary from synthetically rendered kinematic
demonstrations; at the low level, a reinforcement-learned WBC policy consumes
these latent verbs to generate dynamics-level commands. In our benchmark,
LeVERB can zero-shot attain a 80% success rate on simple visual navigation
tasks, and 58.5% success rate overall, outperforming naive hierarchical
whole-body VLA implementation by 7.8 times.

</details>


### [49] [Edge Nearest Neighbor in Sampling-Based Motion Planning](https://arxiv.org/abs/2506.13753)
*Stav Ashur,Nancy M. Amato,Sariel Har-Peled*

Main category: cs.RO

TL;DR: 本文实现了一种基于层次数据结构的邻域查找器，用于RRT算法，并通过理论和实验证明其效率更高，同时提出了一种改进的RRG算法变体。


<details>
  <summary>Details</summary>
Motivation: 邻域查找和最近邻查询是基于采样的运动规划算法的核心部分，不同的距离度量或邻域定义会产生不同特性的算法。

Method: 实现了一种基于层次数据结构的邻域查找器，用于在RRT算法中查找采样点的最近邻。

Result: 理论和实验证明该方法提高了算法效率。

Conclusion: 提出了一种改进的RRG算法变体，更好地利用了新描述的邻域查找子程序来探索狭窄通道。

Abstract: Neighborhood finders and nearest neighbor queries are fundamental parts of
sampling based motion planning algorithms. Using different distance metrics or
otherwise changing the definition of a neighborhood produces different
algorithms with unique empiric and theoretical properties. In \cite{l-pa-06}
LaValle suggests a neighborhood finder for the Rapidly-exploring Random Tree
RRT
  algorithm \cite{l-rrtnt-98} which finds the nearest neighbor of the sampled
point on the swath of the tree, that is on the set of all of the points on the
tree edges, using a hierarchical data structure. In this paper we implement
such a neighborhood finder and show, theoretically and experimentally, that
this results in more efficient algorithms, and suggest a variant of the
Rapidly-exploring Random Graph RRG algorithm \cite{f-isaom-10} that better
exploits the exploration properties of the newly described subroutine for
finding narrow passages.

</details>


### [50] [Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins](https://arxiv.org/abs/2506.13761)
*Chuanruo Ning,Kuan Fang,Wei-Chiu Ma*

Main category: cs.RO

TL;DR: 提出了一种结合视觉语言模型（VLM）和数字孪生的模型预测控制框架，用于开放世界机器人操作，通过模拟生成可行运动轨迹并优化任务执行。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在高层次规划中表现优异，但在低层次机器人控制预测方面因物理世界理解不足而受限。

Method: 结合VLM的语义推理能力和数字孪生的物理模拟，生成运动轨迹并通过未来观察提示VLM评估任务执行。

Result: 在多样复杂操作任务中验证，性能优于基于VLM的语言条件机器人控制基线方法。

Conclusion: 该方法通过数字孪生增强VLM的物理世界理解能力，显著提升了开放世界机器人操作的性能。

Abstract: Recent advancements in open-world robot manipulation have been largely driven
by vision-language models (VLMs). While these models exhibit strong
generalization ability in high-level planning, they struggle to predict
low-level robot controls due to limited physical-world understanding. To
address this issue, we propose a model predictive control framework for
open-world manipulation that combines the semantic reasoning capabilities of
VLMs with physically-grounded, interactive digital twins of the real-world
environments. By constructing and simulating the digital twins, our approach
generates feasible motion trajectories, simulates corresponding outcomes, and
prompts the VLM with future observations to evaluate and select the most
suitable outcome based on language instructions of the task. To further enhance
the capability of pre-trained VLMs in understanding complex scenes for robotic
control, we leverage the flexible rendering capabilities of the digital twin to
synthesize the scene at various novel, unoccluded viewpoints. We validate our
approach on a diverse set of complex manipulation tasks, demonstrating superior
performance compared to baseline methods for language-conditioned robotic
control using VLMs.

</details>


### [51] [Touch begins where vision ends: Generalizable policies for contact-rich manipulation](https://arxiv.org/abs/2506.13762)
*Zifan Zhao,Siddhant Haldar,Jinda Cui,Lerrel Pinto,Raunaq Bhirangi*

Main category: cs.RO

TL;DR: ViTaL框架通过分阶段策略（定位与局部交互）解决精细操作任务，结合视觉语言模型和触觉传感，实现高成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方法在精细操作上表现不佳，模仿学习需要大量演示，强化学习策略脆弱且难以泛化。

Method: ViTaL将任务分解为定位阶段（使用视觉语言模型）和局部交互阶段（使用可复用的ViTaL策略，结合视觉和触觉传感）。

Result: 在未见环境中，ViTaL在接触密集型任务中达到约90%的成功率，且对干扰物具有鲁棒性。

Conclusion: ViTaL通过结合基础模型、残差强化学习和触觉传感，实现了高效、可泛化的精细操作策略。

Abstract: Data-driven approaches struggle with precise manipulation; imitation learning
requires many hard-to-obtain demonstrations, while reinforcement learning
yields brittle, non-generalizable policies. We introduce VisuoTactile Local
(ViTaL) policy learning, a framework that solves fine-grained manipulation
tasks by decomposing them into two phases: a reaching phase, where a
vision-language model (VLM) enables scene-level reasoning to localize the
object of interest, and a local interaction phase, where a reusable,
scene-agnostic ViTaL policy performs contact-rich manipulation using egocentric
vision and tactile sensing. This approach is motivated by the observation that
while scene context varies, the low-level interaction remains consistent across
task instances. By training local policies once in a canonical setting, they
can generalize via a localize-then-execute strategy. ViTaL achieves around 90%
success on contact-rich tasks in unseen environments and is robust to
distractors. ViTaL's effectiveness stems from three key insights: (1)
foundation models for segmentation enable training robust visual encoders via
behavior cloning; (2) these encoders improve the generalizability of policies
learned using residual RL; and (3) tactile sensing significantly boosts
performance in contact-rich tasks. Ablation studies validate each of these
insights, and we demonstrate that ViTaL integrates well with high-level VLMs,
enabling robust, reusable low-level skills. Results and videos are available at
https://vitalprecise.github.io.

</details>
