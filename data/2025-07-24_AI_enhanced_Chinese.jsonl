{"id": "2507.16839", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16839", "abs": "https://arxiv.org/abs/2507.16839", "authors": ["Gregory Beale", "Gibran Ali"], "title": "Summarizing Normative Driving Behavior From Large-Scale NDS Datasets for Vehicle System Development", "comment": "Accepted to the 2025 IEEE International Conference on Intelligent\n  Transportation Systems (ITSC 2025)", "summary": "This paper presents a methodology to process large-scale naturalistic driving\nstudies (NDS) to describe the driving behavior for five vehicle metrics,\nincluding speed, speeding, lane keeping, following distance, and headway,\ncontextualized by roadway characteristics, vehicle classes, and driver\ndemographics. Such descriptions of normative driving behaviors can aid in the\ndevelopment of vehicle safety and intelligent transportation systems. The\nmethodology is demonstrated using data from the Second Strategic Highway\nResearch Program (SHRP 2) NDS, which includes over 34 million miles of driving\nacross more than 3,400 drivers. Summaries of each driving metric were generated\nusing vehicle, GPS, and forward radar data. Additionally, interactive online\nanalytics tools were developed to visualize and compare driving behavior across\ngroups through dynamic data selection and grouping. For example, among drivers\non 65-mph roads for the SHRP 2 NDS, females aged 16-19 exceeded the speed limit\nby 7.5 to 15 mph slightly more often than their male counterparts, and younger\ndrivers maintained headways under 1.5 seconds more frequently than older\ndrivers. This work supports better vehicle systems and safer infrastructure by\nquantifying normative driving behaviors and offers a methodology for analyzing\nNDS datasets for cross group comparisons.", "AI": {"tldr": "本研究开发了一套方法论来处理大规模自然驾驶研究数据，分析了超过3400名驾驶员的3400万英里驾驶数据，从速度、车道保持、跟车距离等五个维度描述驾驶行为，并开发了交互式在线分析工具来可视化不同群体间的驾驶行为差异。", "motivation": "为了支持车辆安全系统和智能交通系统的开发，需要建立一套系统的方法论来处理大规模自然驾驶研究数据，并描述不同路况、车型和驾驶员人口统计学特征下的规范化驾驶行为模式。", "method": "使用SHRP 2自然驾驶研究数据，结合车辆GPS和前向雷达数据，开发了一套处理大规模NDS数据的方法论。从速度、超速、车道保持、跟车距离和车头时距五个车辆指标维度分析驾驶行为，并根据道路特征、车辆类别和驾驶员人口统计学特征进行情境化分析。同时开发了交互式在线分析工具用于可视化和比较不同群体的驾驶行为。", "result": "基于超过3400名驾驶员的3400万英里驾驶数据，成功生成了各项驾驶指标的汇总分析。研究发现，在65英里限速道路上，16-19岁女性驾驶员超速7.5-15英里的频率略高于同龄男性；年轻驾驶员保持1.5秒以下车头时距的频率高于年长驾驶员。开发的交互式分析工具能够实现动态数据选择和分组比较。", "conclusion": "该研究通过量化规范化驾驶行为，为开发更好的车辆系统和更安全的基础设施提供支持，并提供了一套可用于NDS数据集跨群体比较分析的方法论，有助于车辆安全和智能交通系统的发展。"}}
{"id": "2507.16841", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16841", "abs": "https://arxiv.org/abs/2507.16841", "authors": ["Waseem Akram", "Muhayy Ud Din", "Abdelhaleem Saad", "Irfan Hussain"], "title": "AquaChat: An LLM-Guided ROV Framework for Adaptive Inspection of Aquaculture Net Pens", "comment": null, "summary": "Inspection of aquaculture net pens is essential for maintaining the\nstructural integrity, biosecurity, and operational efficiency of fish farming\nsystems. Traditional inspection approaches rely on pre-programmed missions or\nmanual control, offering limited adaptability to dynamic underwater conditions\nand user-specific demands. In this study, we propose AquaChat, a novel Remotely\nOperated Vehicle (ROV) framework that integrates Large Language Models (LLMs)\nfor intelligent and adaptive net pen inspection. The system features a\nmulti-layered architecture: (1) a high-level planning layer that interprets\nnatural language user commands using an LLM to generate symbolic task plans;\n(2) a mid-level task manager that translates plans into ROV control sequences;\nand (3) a low-level motion control layer that executes navigation and\ninspection tasks with precision. Real-time feedback and event-triggered\nreplanning enhance robustness in challenging aquaculture environments. The\nframework is validated through experiments in both simulated and controlled\naquatic environments representative of aquaculture net pens. Results\ndemonstrate improved task flexibility, inspection accuracy, and operational\nefficiency. AquaChat illustrates the potential of integrating language-based AI\nwith marine robotics to enable intelligent, user-interactive inspection systems\nfor sustainable aquaculture operations.", "AI": {"tldr": "本研究提出了AquaChat框架，通过集成大语言模型(LLM)实现智能化水产养殖网箱检查，采用多层架构设计，能够理解自然语言指令并自适应执行检查任务", "motivation": "传统的水产养殖网箱检查方法依赖预编程任务或人工控制，对动态水下环境和用户特定需求的适应性有限，缺乏智能化和灵活性", "method": "设计了AquaChat远程操作载具(ROV)框架，采用三层架构：(1)高级规划层使用LLM解释自然语言用户指令生成符号化任务计划；(2)中级任务管理层将计划转换为ROV控制序列；(3)低级运动控制层精确执行导航和检查任务。系统还具备实时反馈和事件触发重规划功能", "result": "通过仿真和受控水生环境实验验证，结果显示任务灵活性、检查精度和操作效率均有显著提升", "conclusion": "AquaChat展示了将基于语言的人工智能与海洋机器人技术相结合的潜力，能够实现智能化、用户交互式的检查系统，为可持续水产养殖作业提供支持"}}
{"id": "2507.16842", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16842", "abs": "https://arxiv.org/abs/2507.16842", "authors": ["Yinan Meng", "Kun Qian", "Jiong Yang", "Renbo Su", "Zhenhong Li", "Charlie C. L. Wang"], "title": "Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning", "comment": null, "summary": "The intrinsic compliance and high degree of freedom (DoF) of redundant soft\nmanipulators facilitate safe interaction and flexible task execution. However,\neffective kinematic control remains highly challenging, as it must handle\ndeformations caused by unknown external loads and avoid actuator saturation due\nto improper null-space regulation - particularly in confined environments. In\nthis paper, we propose a Sensor-Space Imitation Learning Kinematic Control\n(SS-ILKC) framework to enable robust kinematic control under actuator\nsaturation and restrictive environmental constraints. We employ a dual-learning\nstrategy: a multi-goal sensor-space control framework based on reinforcement\nlearning principle is trained in simulation to develop robust control policies\nfor open spaces, while a generative adversarial imitation learning approach\nenables effective policy learning from sparse expert demonstrations for\nconfined spaces. To enable zero-shot real-world deployment, a pre-processed\nsim-to-real transfer mechanism is proposed to mitigate the\nsimulation-to-reality gap and accurately characterize actuator saturation\nlimits. Experimental results demonstrate that our method can effectively\ncontrol a pneumatically actuated soft manipulator, achieving precise\npath-following and object manipulation in confined environments under unknown\nloading conditions.", "AI": {"tldr": "本文提出了一种传感器空间模仿学习运动学控制(SS-ILKC)框架，通过双重学习策略和仿真到现实转移机制，解决软体机械臂在执行器饱和和环境约束下的鲁棒运动控制问题。", "motivation": "冗余软体机械臂虽然具有内在柔顺性和高自由度优势，但在面对未知外部载荷变形和执行器饱和问题时，有效的运动学控制仍然极具挑战性，特别是在受限环境中的零空间调节不当会导致执行器饱和。", "method": "提出SS-ILKC框架，采用双重学习策略：(1)基于强化学习原理的多目标传感器空间控制框架在仿真中训练开放空间的鲁棒控制策略；(2)生成对抗模仿学习方法从稀疏专家演示中学习受限空间的有效策略；(3)设计预处理的仿真到现实转移机制来缓解仿真现实差距并准确表征执行器饱和限制。", "result": "实验结果表明该方法能够有效控制气动软体机械臂，在未知载荷条件下的受限环境中实现精确的路径跟踪和物体操作任务。", "conclusion": "SS-ILKC框架成功解决了软体机械臂在执行器饱和和环境约束条件下的鲁棒运动控制问题，实现了从仿真到现实的零样本部署，为软体机械臂在复杂环境中的实际应用提供了有效的控制解决方案。"}}
{"id": "2507.16846", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16846", "abs": "https://arxiv.org/abs/2507.16846", "authors": ["Qing Tang", "Xianbiao Hu"], "title": "Analytical Formulation of Autonomous Vehicle Freeway Merging Control with State-Dependent Discharge Rates", "comment": "Accepted for publication in IEEE Transactions on Intelligent\n  Transportation Systems (2025) as a regular paper (minor revision approved)", "summary": "The core of the freeway merging control problem lies in dynamic queue\npropagation and dissipation linked to merging vehicle behavior. Traditionally,\nqueuing is modeled through demand-supply interactions with time varying demand\nand fixed capacity. However, field observations show flow rates decrease during\ncongestion at freeway merges due to the impact of intersecting traffic, a\nfactor overlooked in fundamental diagrams. This manuscript introduces an\nanalytical approach to characterize and control the dynamic multi-stage merging\nof autonomous vehicles, prioritizing traffic efficiency and safety. For the\nfirst time, the effective discharge rate at the merging point, reduced by the\nmulti-stage dynamic merging process, is analytically derived using a closed\nform formulation. Leveraging this expression, performance metrics such as queue\nlength and traffic delay are derived as the first objective. Additionally, a\ncrash risk function is established to quantitatively assess potential\ncollisions during the merging process, serving as the second objective.\nFinally, the problem is formulated as a dynamic programming model to jointly\nminimize delay and crash risk, with the merging location and speed as decision\nvariables. Given the terminal state, the ramp vehicle merging task is\nformulated as a recursive optimization problem, employing backward induction to\nfind the minimum cost solution. Numerical experiments using the NGSIM dataset\nvalidate the derived effective discharge rate. The results indicate that the\nproposed model outperforms two benchmark algorithms, leading to a more\nefficient and safer merging process.", "AI": {"tldr": "本文针对高速公路匝道汇入控制问题，提出了一种考虑多阶段动态汇入过程的分析方法，通过动态规划模型同时优化交通效率和安全性，在NGSIM数据集上验证了所提方法的有效性。", "motivation": "传统的高速公路汇入控制模型忽略了交叉交通对流量的影响，未能准确反映拥堵时汇入点流量下降的实际情况。现有方法缺乏对多阶段动态汇入过程的精确建模，难以同时优化交通效率和安全性。", "method": "首次通过闭式公式解析推导了受多阶段动态汇入过程影响的有效排放率；建立了队列长度和交通延误的性能指标；构建了碰撞风险函数来定量评估汇入过程中的潜在碰撞；将问题表述为动态规划模型，以汇入位置和速度为决策变量，采用反向归纳法求解最小成本方案。", "result": "使用NGSIM数据集验证了推导的有效排放率的准确性；提出的模型在性能上优于两种基准算法；实现了更高效和更安全的汇入过程，同时减少了延误和碰撞风险。", "conclusion": "本文成功建立了考虑多阶段动态汇入的分析框架，能够准确建模汇入点的有效排放率，并通过动态规划方法实现了交通效率和安全性的联合优化，为自动驾驶车辆的高速公路汇入控制提供了有效解决方案。"}}
{"id": "2507.16853", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.16853", "abs": "https://arxiv.org/abs/2507.16853", "authors": ["Ning Li", "Xiangmou Qu", "Jiamu Zhou", "Jun Wang", "Muning Wen", "Kounianhua Du", "Xingyu Lou", "Qiuying Peng", "Jun Wang", "Weinan Zhang"], "title": "MobileUse: A GUI Agent with Hierarchical Reflection for Autonomous Mobile Operation", "comment": "A technical report on a GUI agent based on multi-agent systems", "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled the\ndevelopment of mobile agents that can understand visual inputs and follow user\ninstructions, unlocking new possibilities for automating complex tasks on\nmobile devices. However, applying these models to real-world mobile scenarios\nremains a significant challenge due to the long-horizon task execution,\ndifficulty in error recovery, and the cold-start problem in unfamiliar\nenvironments. To address these challenges, we propose MobileUse, a GUI agent\ndesigned for robust and adaptive mobile task execution. To improve resilience\nin long-horizon tasks and dynamic environments, we introduce a hierarchical\nreflection architecture that enables the agent to self-monitor, detect, and\nrecover from errors across multiple temporal scales-ranging from individual\nactions to overall task completion-while maintaining efficiency through a\nreflection-on-demand strategy. To tackle cold-start issues, we further\nintroduce a proactive exploration module, which enriches the agent's\nunderstanding of the environment through self-planned exploration. Evaluations\non AndroidWorld and AndroidLab benchmarks demonstrate that MobileUse\nestablishes new state-of-the-art performance, achieving success rates of 62.9%\nand 44.2%, respectively. To facilitate real-world applications, we release an\nout-of-the-box toolkit for automated task execution on physical mobile devices,\nwhich is available at https://github.com/MadeAgents/mobile-use.", "AI": {"tldr": "本文提出了MobileUse，一个用于移动设备任务自动化执行的GUI智能体，通过分层反思架构和主动探索模块解决长期任务执行、错误恢复和冷启动问题，在AndroidWorld和AndroidLab基准测试中达到了新的最先进性能。", "motivation": "多模态大语言模型在移动设备应用中面临长期任务执行困难、错误恢复能力差以及在陌生环境中的冷启动问题，需要开发更加鲁棒和自适应的移动任务执行智能体。", "method": "提出MobileUse GUI智能体，包含两个核心模块：1）分层反思架构，能够在多个时间尺度上进行自我监控、错误检测和恢复，采用按需反思策略保持效率；2）主动探索模块，通过自主规划的探索来丰富智能体对环境的理解，解决冷启动问题。", "result": "在AndroidWorld和AndroidLab基准测试中取得了最先进的性能，成功率分别达到62.9%和44.2%。发布了用于物理移动设备自动化任务执行的开箱即用工具包。", "conclusion": "MobileUse通过分层反思架构和主动探索模块有效解决了移动智能体面临的关键挑战，在基准测试中达到了新的最先进性能，为移动设备任务自动化提供了实用的解决方案。"}}
{"id": "2507.16859", "categories": ["cs.RO", "cs.AI", "62H30", "I.2"], "pdf": "https://arxiv.org/pdf/2507.16859", "abs": "https://arxiv.org/abs/2507.16859", "authors": ["Luobin Cui", "Yanlai Wu", "Tang Ying", "Weikai Li"], "title": "Leveraging multi-source and heterogeneous signals for fatigue detection", "comment": "1figures,32pages", "summary": "Fatigue detection plays a critical role in safety-critical applications such\nas aviation, mining, and long-haul transport. However, most existing methods\nrely on high-end sensors and controlled environments, limiting their\napplicability in real world settings. This paper formally defines a practical\nyet underexplored problem setting for real world fatigue detection, where\nsystems operating with context-appropriate sensors aim to leverage knowledge\nfrom differently instrumented sources including those using impractical sensors\ndeployed in controlled environments. To tackle this challenge, we propose a\nheterogeneous and multi-source fatigue detection framework that adaptively\nutilizes the available modalities in the target domain while benefiting from\nthe diverse configurations present in source domains. Our experiments,\nconducted using a realistic field-deployed sensor setup and two publicly\navailable datasets, demonstrate the practicality, robustness, and improved\ngeneralization of our approach, paving the practical way for effective fatigue\nmonitoring in sensor-constrained scenarios.", "AI": {"tldr": "提出了一个异构多源疲劳检测框架，能够在传感器受限的真实环境中有效监测疲劳状态，通过利用不同配置源域的知识来提升目标域的检测性能", "motivation": "现有疲劳检测方法依赖高端传感器和受控环境，在真实世界应用中存在局限性。需要开发能够在传感器受限场景下工作的实用疲劳检测系统，特别是在航空、采矿、长途运输等安全关键应用中", "method": "提出异构多源疲劳检测框架，该框架能够自适应地利用目标域中可用的模态，同时从源域的多样化传感器配置中获益。通过知识迁移的方式，将高端传感器在受控环境下获得的知识应用到实际部署的低成本传感器系统中", "result": "在真实部署的传感器设置和两个公开数据集上进行实验验证，结果表明该方法具有实用性、鲁棒性和更好的泛化能力，能够在传感器受限场景下实现有效的疲劳监测", "conclusion": "该框架为在传感器受限的真实世界场景中进行有效疲劳监测铺平了实用道路，解决了现有方法在实际应用中的局限性问题，提升了疲劳检测系统的实用性和可部署性"}}
{"id": "2507.16865", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16865", "abs": "https://arxiv.org/abs/2507.16865", "authors": ["Shanshan Zhang", "Tianshui Wen", "Siyue Wang", "Qi Zhang", "Ziheng Zhou", "Huiru Zheng", "Lingxiang Zheng", "Yu Yang"], "title": "ResKACNNet: A Residual ChebyKAN Network for Inertial Odometry", "comment": null, "summary": "Inertial Measurement Unit (IMU) has become a key technology for achieving\nlow-cost and precise positioning. However, traditional CNN-based inertial\npositioning methods struggle to capture the nonlinear motion characteristics\nand long-term dependencies in IMU data. To address this limitation, we propose\na novel inertial positioning network with a generic backbone called\nResChebyKAN, which leverages the nonlinear approximation capabilities of\nChebyshev polynomials to model complex motion patterns. Additionally, we\nintroduce an Efficient Kernel-based Self-Attention (EKSA) module to effectively\ncapture contextual information and enhance long-term dependency modeling.\nExperimental results on public datasets (e.g., RIDI, RoNIN, RNIN-VIO, OxIOD,\nIMUNet, and TLIO) demonstrate that our method reduces the absolute trajectory\nerror by 3.79% to 42.32% compared to existing benchmark methods. Furthermore,\nwe release a preprocessed dataset and empirically show that removing the\ngravity component from acceleration data significantly improves inertial\npositioning performance.", "AI": {"tldr": "提出了一种基于ResChebyKAN骨干网络和EKSA模块的惯性定位方法，通过切比雪夫多项式建模复杂运动模式，并有效捕获长期依赖关系，在多个公开数据集上显著降低了轨迹误差。", "motivation": "传统基于CNN的惯性定位方法难以捕获IMU数据中的非线性运动特征和长期依赖关系，需要开发新的方法来提高低成本精确定位的性能。", "method": "提出ResChebyKAN惯性定位网络，利用切比雪夫多项式的非线性逼近能力建模复杂运动模式，并引入高效核自注意力（EKSA）模块来捕获上下文信息和增强长期依赖建模。", "result": "在RIDI、RoNIN、RNIN-VIO、OxIOD、IMUNet和TLIO等公开数据集上，相比现有基准方法，绝对轨迹误差降低了3.79%到42.32%。实验还表明去除加速度数据中的重力分量可显著提升定位性能。", "conclusion": "基于ResChebyKAN的惯性定位网络能够有效处理IMU数据的非线性特征和长期依赖关系，在多个数据集上取得了显著的性能提升，为低成本精确惯性定位提供了新的解决方案。"}}
{"id": "2507.16941", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16941", "abs": "https://arxiv.org/abs/2507.16941", "authors": ["Daniel Correa", "Tero Kaarlela", "Jose Fuentes", "Paulo Padrao", "Alain Duran", "Leonardo Bobadilla"], "title": "Multi-agent Reinforcement Learning for Robotized Coral Reef Sample Collection", "comment": null, "summary": "This paper presents a reinforcement learning (RL) environment for developing\nan autonomous underwater robotic coral sampling agent, a crucial coral reef\nconservation and research task. Using software-in-the-loop (SIL) and\nhardware-in-the-loop (HIL), an RL-trained artificial intelligence (AI)\ncontroller is developed using a digital twin (DT) in simulation and\nsubsequently verified in physical experiments. An underwater motion capture\n(MOCAP) system provides real-time 3D position and orientation feedback during\nverification testing for precise synchronization between the digital and\nphysical domains. A key novelty of this approach is the combined use of a\ngeneral-purpose game engine for simulation, deep RL, and real-time underwater\nmotion capture for an effective zero-shot sim-to-real strategy.", "AI": {"tldr": "本文提出了一种用于开发水下机器人珊瑚采样智能体的强化学习环境，通过软件在环和硬件在环的方式，结合数字孪生技术在仿真中训练AI控制器，并在物理实验中验证。该方法的创新点在于将通用游戏引擎、深度强化学习和实时水下动作捕捉系统相结合，实现了有效的零样本仿真到现实转移策略。", "motivation": "珊瑚礁保护和研究需要自主水下机器人进行珊瑚采样任务，这是一项对海洋生态保护至关重要的工作。传统方法可能存在效率低、精度不够等问题，因此需要开发智能化的水下机器人系统来执行精确的珊瑚采样任务。", "method": "采用强化学习环境开发自主水下机器人珊瑚采样智能体。使用软件在环(SIL)和硬件在环(HIL)方法，在数字孪生仿真环境中训练强化学习AI控制器。结合通用游戏引擎进行仿真、深度强化学习算法，以及实时水下动作捕捉(MOCAP)系统提供3D位置和姿态反馈，实现数字域和物理域之间的精确同步。", "result": "成功开发了基于强化学习的水下机器人AI控制器，并通过物理实验验证了其有效性。水下动作捕捉系统能够提供实时的3D位置和姿态反馈，确保了数字孪生和物理实验之间的精确同步，实现了有效的零样本仿真到现实转移。", "conclusion": "该研究成功展示了将通用游戏引擎、深度强化学习和实时水下动作捕捉技术相结合的可行性，为水下机器人珊瑚采样任务提供了一种有效的智能化解决方案。这种零样本仿真到现实的策略为海洋机器人技术的发展和珊瑚礁保护研究提供了新的技术途径。"}}
{"id": "2507.16988", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16988", "abs": "https://arxiv.org/abs/2507.16988", "authors": ["Maaz Qureshi", "Mohammad Omid Bagheri", "Abdelrahman Elbadrawy", "William Melek", "George Shaker"], "title": "RAPTAR: Radar Radiation Pattern Acquisition through Automated Collaborative Robotics", "comment": "8 Pages, IEEE Journal", "summary": "Accurate characterization of modern on-chip antennas remains challenging, as\ncurrent probe-station techniques offer limited angular coverage, rely on\nbespoke hardware, and require frequent manual alignment. This research\nintroduces RAPTAR (Radiation Pattern Acquisition through Robotic Automation), a\nportable, state-of-the-art, and autonomous system based on collaborative\nrobotics. RAPTAR enables 3D radiation-pattern measurement of integrated radar\nmodules without dedicated anechoic facilities. The system is designed to\naddress the challenges of testing radar modules mounted in diverse real-world\nconfigurations, including vehicles, UAVs, AR/VR headsets, and biomedical\ndevices, where traditional measurement setups are impractical. A\n7-degree-of-freedom Franka cobot holds the receiver probe and performs\ncollision-free manipulation across a hemispherical spatial domain, guided by\nreal-time motion planning and calibration accuracy with RMS error below 0.9 mm.\nThe system achieves an angular resolution upto 2.5 degree and integrates\nseamlessly with RF instrumentation for near- and far-field power measurements.\nExperimental scans of a 60 GHz radar module show a mean absolute error of less\nthan 2 dB compared to full-wave electromagnetic simulations ground truth.\nBenchmarking against baseline method demonstrates 36.5% lower mean absolute\nerror, highlighting RAPTAR accuracy and repeatability.", "AI": {"tldr": "该研究提出了RAPTAR系统，一个基于协作机器人的便携式自主系统，用于集成雷达模块的3D辐射方向图测量，无需专用消声室设施。", "motivation": "现有的探针台技术在片上天线表征方面存在角度覆盖有限、依赖定制硬件、需要频繁手动对准等挑战，且传统测量设置在车辆、无人机、AR/VR头戴设备和生物医学设备等真实世界配置中不实用。", "method": "使用7自由度Franka协作机器人持有接收探头，在半球形空间域内执行无碰撞操作，通过实时运动规划和校准实现精确控制，RMS误差低于0.9毫米，角度分辨率可达2.5度，并与RF仪器无缝集成进行近场和远场功率测量。", "result": "对60 GHz雷达模块的实验扫描显示，与全波电磁仿真基准相比，平均绝对误差小于2 dB。与基线方法相比，RAPTAR系统的平均绝对误差降低了36.5%。", "conclusion": "RAPTAR系统成功实现了集成雷达模块的高精度、可重复的3D辐射方向图测量，为现代片上天线表征提供了一种便携式、自主化的解决方案，特别适用于传统测量设置不可行的复杂实际应用场景。"}}
{"id": "2507.17055", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17055", "abs": "https://arxiv.org/abs/2507.17055", "authors": ["Jannis Bähler", "Diego Paez-Granados", "Jorge Peña-Queralta"], "title": "Shared Control of Holonomic Wheelchairs through Reinforcement Learning", "comment": null, "summary": "Smart electric wheelchairs can improve user experience by supporting the\ndriver with shared control. State-of-the-art work showed the potential of\nshared control in improving safety in navigation for non-holonomic robots.\nHowever, for holonomic systems, current approaches often lead to unintuitive\nbehavior for the user and fail to utilize the full potential of omnidirectional\ndriving. Therefore, we propose a reinforcement learning-based method, which\ntakes a 2D user input and outputs a 3D motion while ensuring user comfort and\nreducing cognitive load on the driver. Our approach is trained in Isaac Gym and\ntested in simulation in Gazebo. We compare different RL agent architectures and\nreward functions based on metrics considering cognitive load and user comfort.\nWe show that our method ensures collision-free navigation while smartly\norienting the wheelchair and showing better or competitive smoothness compared\nto a previous non-learning-based method. We further perform a sim-to-real\ntransfer and demonstrate, to the best of our knowledge, the first real-world\nimplementation of RL-based shared control for an omnidirectional mobility\nplatform.", "AI": {"tldr": "提出了一种基于强化学习的智能电动轮椅共享控制方法，能够将用户的2D输入转换为3D运动，在确保安全导航的同时提升用户舒适度并降低认知负荷", "motivation": "现有的全向系统共享控制方法往往导致用户体验不直观，未能充分利用全向驾驶的潜力，因此需要开发更好的智能轮椅共享控制系统来改善用户体验", "method": "采用强化学习方法，接收2D用户输入并输出3D运动控制；在Isaac Gym中训练，在Gazebo中仿真测试；比较不同的强化学习智能体架构和奖励函数；最终进行仿真到真实环境的迁移", "result": "实现了无碰撞导航，智能控制轮椅方向，在平滑性方面表现优于或与非学习方法相当；成功完成仿真到真实环境的迁移，实现了首个基于强化学习的全向移动平台共享控制真实世界应用", "conclusion": "该方法成功地为全向智能轮椅开发了基于强化学习的共享控制系统，在保证安全性的同时提升了用户舒适度和操作直观性，并首次在真实环境中验证了该技术的可行性"}}
{"id": "2507.17085", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17085", "abs": "https://arxiv.org/abs/2507.17085", "authors": ["Jayadeep Jacob", "Wenzheng Zhang", "Houston Warren", "Paulo Borges", "Tirthankar Bandyopadhyay", "Fabio Ramos"], "title": "Deformable Cluster Manipulation via Whole-Arm Policy Learning", "comment": null, "summary": "Manipulating clusters of deformable objects presents a substantial challenge\nwith widespread applicability, but requires contact-rich whole-arm\ninteractions. A potential solution must address the limited capacity for\nrealistic model synthesis, high uncertainty in perception, and the lack of\nefficient spatial abstractions, among others. We propose a novel framework for\nlearning model-free policies integrating two modalities: 3D point clouds and\nproprioceptive touch indicators, emphasising manipulation with full body\ncontact awareness, going beyond traditional end-effector modes. Our\nreinforcement learning framework leverages a distributional state\nrepresentation, aided by kernel mean embeddings, to achieve improved training\nefficiency and real-time inference. Furthermore, we propose a novel\ncontext-agnostic occlusion heuristic to clear deformables from a target region\nfor exposure tasks. We deploy the framework in a power line clearance scenario\nand observe that the agent generates creative strategies leveraging multiple\narm links for de-occlusion. Finally, we perform zero-shot sim-to-real policy\ntransfer, allowing the arm to clear real branches with unknown occlusion\npatterns, unseen topology, and uncertain dynamics.", "AI": {"tldr": "本文提出了一个新颖的无模型强化学习框架，结合3D点云和本体感觉触觉指示器，用于操作可变形物体集群，特别是在电力线路清理场景中实现了创新的全臂接触策略和零样本仿真到现实的策略迁移。", "motivation": "操作可变形物体集群面临重大挑战，需要接触丰富的全臂交互。现有方法在真实模型合成能力有限、感知不确定性高、缺乏高效空间抽象等方面存在不足，传统的末端执行器操作模式无法满足复杂的接触感知需求。", "method": "提出了一个结合3D点云和本体感觉触觉指示器的无模型强化学习框架，强调具有全身接触感知的操作。采用分布式状态表示和核均值嵌入来提高训练效率和实时推理能力。同时提出了一种新颖的上下文无关遮挡启发式算法，用于清理目标区域的可变形物体。", "result": "在电力线路清理场景中部署该框架，智能体生成了利用多个手臂连接进行去遮挡的创新策略。实现了零样本仿真到现实的策略迁移，使机械臂能够清理具有未知遮挡模式、未见拓扑结构和不确定动力学的真实树枝。", "conclusion": "该框架成功解决了可变形物体集群操作的关键挑战，通过多模态感知和全臂接触策略，在复杂的现实场景中展现了良好的适应性和泛化能力，为接触丰富的机器人操作任务提供了有效解决方案。"}}
{"id": "2507.17130", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17130", "abs": "https://arxiv.org/abs/2507.17130", "authors": ["Seokhwan Jeong", "Hogyun Kim", "Younggun Cho"], "title": "MARSCalib: Multi-robot, Automatic, Robust, Spherical Target-based Extrinsic Calibration in Field and Extraterrestrial Environments", "comment": "8 pages, 9 figures", "summary": "This paper presents a novel spherical target-based LiDAR-camera extrinsic\ncalibration method designed for outdoor environments with multi-robot systems,\nconsidering both target and sensor corruption. The method extracts the 2D\nellipse center from the image and the 3D sphere center from the pointcloud,\nwhich are then paired to compute the transformation matrix. Specifically, the\nimage is first decomposed using the Segment Anything Model (SAM). Then, a novel\nalgorithm extracts an ellipse from a potentially corrupted sphere, and the\nextracted center of ellipse is corrected for errors caused by the perspective\nprojection model. For the LiDAR pointcloud, points on the sphere tend to be\nhighly noisy due to the absence of flat regions. To accurately extract the\nsphere from these noisy measurements, we apply a hierarchical weighted sum to\nthe accumulated pointcloud. Through experiments, we demonstrated that the\nsphere can be robustly detected even under both types of corruption,\noutperforming other targets. We evaluated our method using three different\ntypes of LiDARs (spinning, solid-state, and non-repetitive) with cameras\npositioned in three different locations. Furthermore, we validated the\nrobustness of our method to target corruption by experimenting with spheres\nsubjected to various types of degradation. These experiments were conducted in\nboth a planetary test and a field environment. Our code is available at\nhttps://github.com/sparolab/MARSCalib.", "AI": {"tldr": "本文提出了一种基于球形目标的LiDAR-相机外参标定方法，适用于多机器人系统的户外环境，能够处理目标和传感器的损坏情况。", "motivation": "在户外多机器人系统中，需要一种鲁棒的LiDAR-相机外参标定方法，能够应对目标物体和传感器损坏的情况，现有方法在这些挑战性环境下表现不佳。", "method": "使用球形目标进行标定：1）通过SAM模型分解图像并提取椭圆中心，对透视投影误差进行校正；2）对LiDAR点云使用分层加权求和方法提取球心，以应对球面缺乏平坦区域导致的噪声问题；3）将2D椭圆中心与3D球心配对计算变换矩阵。", "result": "在三种不同类型的LiDAR（旋转式、固态式、非重复式）和三个不同位置的相机上进行测试，球形目标在两种损坏情况下都能被鲁棒检测，性能优于其他目标。在行星测试和野外环境中验证了方法对目标损坏的鲁棒性。", "conclusion": "所提出的球形目标标定方法在处理目标和传感器损坏方面表现出色，为户外多机器人系统提供了一种可靠的LiDAR-相机外参标定解决方案，具有良好的鲁棒性和适用性。"}}
{"id": "2507.17132", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17132", "abs": "https://arxiv.org/abs/2507.17132", "authors": ["Xiao Liu", "Xianlong Yang", "Weijun Wang", "Wei Feng"], "title": "Dynamic Modeling and Dimensional Optimization of Legged Mechanisms for Construction Robot", "comment": null, "summary": "With the rapid development of the construction industry, issues such as harsh\nworking environments, high-intensity and high-risk tasks, and labor shortages\nhave become increasingly prominent. This drives higher demands for construction\nrobots in terms of low energy consumption, high mobility, and high load\ncapacity. This paper focuses on the design and optimization of leg structures\nfor construction robots, aiming to improve their dynamic performance, reduce\nenergy consumption, and enhance load-bearing capabilities. Firstly, based on\nthe leg configuration of ants in nature, we design a structure for the robot's\nleg. Secondly, we propose a novel structural optimization method. Using the\nLagrangian approach, a dynamic model of the leg was established. Combining the\ndynamic model with the leg's motion trajectory, we formulated multiple dynamic\nevaluation metrics and conducted a comprehensive optimization study on the\ngeometric parameters of each leg segment. The results show that the optimized\nleg structure reduces peak joint torques and energy consumption by over 20%.\nFinally, dynamic simulation experiments were conducted using ADAMS. The results\ndemonstrate a significant reduction in the driving power of each joint after\noptimization, validating the effectiveness and rationality of the proposed\nstrategy. This study provides a theoretical foundation and technical support\nfor the design of heavy-load, high-performance construction robots.", "AI": {"tldr": "本文提出了一种基于蚂蚁腿部结构的建筑机器人腿部设计和优化方法，通过拉格朗日动力学建模和几何参数优化，实现了关节扭矩和能耗降低20%以上，为重载高性能建筑机器人提供了理论基础。", "motivation": "建筑行业快速发展中面临恶劣工作环境、高强度高风险任务和劳动力短缺等问题，迫切需要低能耗、高机动性和高负载能力的建筑机器人，因此需要对机器人腿部结构进行设计优化以提升动态性能、降低能耗并增强承载能力。", "method": "基于自然界蚂蚁的腿部构型设计机器人腿部结构，提出新颖的结构优化方法，采用拉格朗日方法建立腿部动力学模型，结合腿部运动轨迹制定多个动态评估指标，对各腿段几何参数进行综合优化研究。", "result": "优化后的腿部结构使峰值关节扭矩和能耗降低超过20%，ADAMS动力学仿真实验显示优化后各关节驱动功率显著降低，验证了所提策略的有效性和合理性。", "conclusion": "该研究为重载、高性能建筑机器人的设计提供了理论基础和技术支撑，证明了基于仿生学的腿部结构优化方法在提升建筑机器人性能方面的有效性。"}}
{"id": "2507.17136", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17136", "abs": "https://arxiv.org/abs/2507.17136", "authors": ["Xiao Liu", "Yunxiao Cheng", "Weijun Wang", "Tianlun Huang", "Wei Feng"], "title": "Dynamic Parameter Identification of a Curtain Wall Installation Robotic Arm", "comment": null, "summary": "In the construction industry, traditional methods fail to meet the modern\ndemands for efficiency and quality. The curtain wall installation is a critical\ncomponent of construction projects. We design a hydraulically driven robotic\narm for curtain wall installation and a dynamic parameter identification\nmethod. We establish a Denavit-Hartenberg (D-H) model based on measured robotic\narm structural parameters and integrate hydraulic cylinder dynamics to\nconstruct a composite parametric system driven by a Stribeck friction model. By\ndesigning high-signal-to-noise ratio displacement excitation signals for\nhydraulic cylinders and combining Fourier series to construct optimal\nexcitation trajectories that satisfy joint constraints, this method effectively\nexcites the characteristics of each parameter in the minimal parameter set of\nthe dynamic model of the robotic arm. On this basis, a hierarchical progressive\nparameter identification strategy is proposed: least squares estimation is\nemployed to separately identify and jointly calibrate the dynamic parameters of\nboth the hydraulic cylinder and the robotic arm, yielding Stribeck model curves\nfor each joint. Experimental validation on a robotic arm platform demonstrates\nresidual standard deviations below 0.4 Nm between theoretical and measured\njoint torques, confirming high-precision dynamic parameter identification for\nthe hydraulic-driven curtain wall installation robotic arm. This significantly\ncontributes to enhancing the intelligence level of curtain wall installation\noperations.", "AI": {"tldr": "本文设计了一种液压驱动的幕墙安装机械臂，并提出了动态参数识别方法，通过建立D-H模型和液压缸动力学集成的复合参数系统，使用分层递进参数识别策略，实现了高精度的动态参数识别，提升了幕墙安装作业的智能化水平。", "motivation": "传统建筑施工方法无法满足现代对效率和质量的需求，幕墙安装是建筑项目的关键组成部分，需要提高幕墙安装作业的智能化水平和精度。", "method": "设计液压驱动的幕墙安装机械臂；建立基于D-H模型的复合参数系统，集成液压缸动力学和Stribeck摩擦模型；设计高信噪比位移激励信号和最优激励轨迹；提出分层递进参数识别策略，采用最小二乘估计分别识别和联合标定液压缸和机械臂的动态参数。", "result": "在机械臂平台上的实验验证显示，理论与测量关节力矩之间的残余标准偏差低于0.4 Nm，确认了液压驱动幕墙安装机械臂的高精度动态参数识别效果。", "conclusion": "该方法有效实现了液压驱动幕墙安装机械臂的高精度动态参数识别，显著提升了幕墙安装作业的智能化水平，为建筑行业的自动化发展做出了重要贡献。"}}
{"id": "2507.17140", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17140", "abs": "https://arxiv.org/abs/2507.17140", "authors": ["Xiao Liu", "Yunxiao Cheng", "Weijun Wang", "Tianlun Huang", "Zhiyong Wang", "Wei Feng"], "title": "Multi-Objective Trajectory Planning for a Robotic Arm in Curtain Wall Installation", "comment": null, "summary": "In the context of labor shortages and rising costs, construction robots are\nregarded as the key to revolutionizing traditional construction methods and\nimproving efficiency and quality in the construction industry. In order to\nensure that construction robots can perform tasks efficiently and accurately in\ncomplex construction environments, traditional single-objective trajectory\noptimization methods are difficult to meet the complex requirements of the\nchanging construction environment. Therefore, we propose a multi-objective\ntrajectory optimization for the robotic arm used in the curtain wall\ninstallation. First, we design a robotic arm for curtain wall installation,\nintegrating serial, parallel, and folding arm elements, while considering its\nphysical properties and motion characteristics. In addition, this paper\nproposes an NSGA-III-FO algorithm (NSGA-III with Focused Operator, NSGA-III-FO)\nthat incorporates a focus operator screening mechanism to accelerate the\nconvergence of the algorithm towards the Pareto front, thereby effectively\nbalancing the multi-objective constraints of construction robots. The proposed\nalgorithm is tested against NSGA-III, MOEA/D, and MSOPS-II in ten consecutive\ntrials on the DTLZ3 and WFG3 test functions, showing significantly better\nconvergence efficiency than the other algorithms. Finally, we conduct two sets\nof experiments on the designed robotic arm platform, which confirm the\nefficiency and practicality of the NSGA-III-FO algorithm in solving\nmulti-objective trajectory planning problems for curtain wall installation\ntasks.", "AI": {"tldr": "本文针对幕墙安装任务提出了一种改进的多目标轨迹优化算法NSGA-III-FO，设计了集成串联、并联和折叠臂元素的机械臂，通过引入聚焦算子筛选机制提高算法收敛效率，实验验证了该方法在建筑机器人轨迹规划中的有效性和实用性。", "motivation": "在劳动力短缺和成本上升的背景下，建筑机器人被视为革新传统建筑方法、提高建筑行业效率和质量的关键。传统单目标轨迹优化方法难以满足复杂多变建筑环境的复杂需求，因此需要开发适用于幕墙安装的多目标轨迹优化方法。", "method": "设计了集成串联、并联和折叠臂元素的幕墙安装机械臂，考虑其物理特性和运动特征。提出了NSGA-III-FO算法（带聚焦算子的NSGA-III），通过引入聚焦算子筛选机制加速算法向帕累托前沿收敛，有效平衡建筑机器人的多目标约束。", "result": "在DTLZ3和WFG3测试函数上进行的十次连续试验中，NSGA-III-FO算法相比NSGA-III、MOEA/D和MSOPS-II表现出显著更好的收敛效率。在设计的机械臂平台上进行的两组实验验证了算法在幕墙安装任务多目标轨迹规划问题中的效率和实用性。", "conclusion": "NSGA-III-FO算法通过聚焦算子筛选机制有效提高了多目标轨迹优化的收敛效率，能够有效解决建筑机器人在复杂环境中的多目标轨迹规划问题，为幕墙安装机器人的实际应用提供了可行的技术方案。"}}
{"id": "2507.17141", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17141", "abs": "https://arxiv.org/abs/2507.17141", "authors": ["Guang Gao", "Jianan Wang", "Jinbo Zuo", "Junnan Jiang", "Jingfan Zhang", "Xianwen Zeng", "Yuejiang Zhu", "Lianyang Ma", "Ke Chen", "Minhua Sheng", "Ruirui Zhang", "Zhaohui An"], "title": "Towards Human-level Intelligence via Human-like Whole-Body Manipulation", "comment": null, "summary": "Building general-purpose intelligent robots has long been a fundamental goal\nof robotics. A promising approach is to mirror the evolutionary trajectory of\nhumans: learning through continuous interaction with the environment, with\nearly progress driven by the imitation of human behaviors. Achieving this goal\npresents three core challenges: (1) designing safe robotic hardware with\nhuman-level physical capabilities; (2) developing an intuitive and scalable\nwhole-body teleoperation interface for data collection; and (3) creating\nalgorithms capable of learning whole-body visuomotor policies from human\ndemonstrations. To address these challenges in a unified framework, we propose\nAstribot Suite, a robot learning suite for whole-body manipulation aimed at\ngeneral daily tasks across diverse environments. We demonstrate the\neffectiveness of our system on a wide range of activities that require\nwhole-body coordination, extensive reachability, human-level dexterity, and\nagility. Our results show that Astribot's cohesive integration of embodiment,\nteleoperation interface, and learning pipeline marks a significant step towards\nreal-world, general-purpose whole-body robotic manipulation, laying the\ngroundwork for the next generation of intelligent robots.", "AI": {"tldr": "Astribot Suite是一个机器人学习套件，通过模仿人类行为和全身操控来实现通用智能机器人，整合了安全硬件、直观遥操作界面和全身视觉运动策略学习算法。", "motivation": "构建通用智能机器人是机器人学的基本目标。研究者希望模仿人类进化轨迹，通过与环境的持续交互学习，并通过模仿人类行为来驱动早期进展。这需要解决安全硬件设计、可扩展遥操作界面开发和全身视觉运动策略学习三大核心挑战。", "method": "提出Astribot Suite统一框架，包含三个核心组件：(1) 设计具有人类级别物理能力的安全机器人硬件；(2) 开发直观且可扩展的全身遥操作界面用于数据收集；(3) 创建能够从人类演示中学习全身视觉运动策略的算法。通过这三个组件的整合来实现全身操控学习。", "result": "系统在需要全身协调、广泛可达性、人类级别灵巧性和敏捷性的各种活动中展现了有效性。Astribot实现了embodiment（具身化）、遥操作界面和学习管道的cohesive integration（紧密整合），能够处理不同环境中的通用日常任务。", "conclusion": "Astribot Suite在实现真实世界通用全身机器人操控方面迈出了重要一步，为下一代智能机器人奠定了基础。该系统成功整合了硬件、接口和算法三个关键组件，为通用机器人操控提供了可行的解决方案。"}}
{"id": "2507.17144", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17144", "abs": "https://arxiv.org/abs/2507.17144", "authors": ["Kazuki Numazato", "Keiichiro Kan", "Masaki Kitagawa", "Yunong Li", "Johannes Kubel", "Moju Zhao"], "title": "Falconry-like palm landing by a flapping-wing drone based on the human gesture interaction and distance-aware flight planning", "comment": "8 pages, 14 figures", "summary": "Flapping-wing drones have attracted significant attention due to their\nbiomimetic flight. They are considered more human-friendly due to their\ncharacteristics such as low noise and flexible wings, making them suitable for\nhuman-drone interactions. However, few studies have explored the practical\ninteraction between humans and flapping-wing drones. On establishing a physical\ninteraction system with flapping-wing drones, we can acquire inspirations from\nfalconers who guide birds of prey to land on their arms. This interaction\ninterprets the human body as a dynamic landing platform, which can be utilized\nin various scenarios such as crowded or spatially constrained environments.\nThus, in this study, we propose a falconry-like interaction system in which a\nflapping-wing drone performs a palm landing motion on a human hand. To achieve\na safe approach toward humans, we design a trajectory planning method that\nconsiders both physical and psychological factors of the human safety such as\nthe drone's velocity and distance from the user. We use a commercial flapping\nplatform with our implemented motion planning and conduct experiments to\nevaluate the palm landing performance and safety. The results demonstrate that\nour approach enables safe and smooth hand landing interactions. To the best of\nour knowledge, it is the first time to achieve a contact-based interaction\nbetween flapping-wing drones and humans.", "AI": {"tldr": "本研究首次实现了扑翼无人机与人类的接触式交互，开发了一个仿鹰猎人的交互系统，使扑翼无人机能够安全地降落在人类手掌上。", "motivation": "扑翼无人机因其低噪音和柔性翅膀等特性被认为更适合人机交互，但缺乏实际的人机交互研究。研究者从鹰猎人引导猛禽降落在手臂上的行为中获得启发，希望将人体作为动态降落平台，在拥挤或空间受限的环境中实现应用。", "method": "设计了一个仿鹰猎人的交互系统，开发了考虑人类安全物理和心理因素（如无人机速度和与用户距离）的轨迹规划方法，使扑翼无人机能够在人类手掌上执行降落动作。使用商业扑翼平台实现运动规划并进行实验评估。", "result": "实验结果表明该方法能够实现安全、平稳的手部降落交互。成功验证了扑翼无人机手掌降落的性能和安全性。", "conclusion": "这是首次实现扑翼无人机与人类之间基于接触的交互，为人机交互领域开辟了新的可能性，特别是在需要近距离接触的应用场景中具有重要意义。"}}
{"id": "2507.17152", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17152", "abs": "https://arxiv.org/abs/2507.17152", "authors": ["Fangze Lin", "Ying He", "Fei Yu", "Hong Zhang"], "title": "JAM: Keypoint-Guided Joint Prediction after Classification-Aware Marginal Proposal for Multi-Agent Interaction", "comment": "IROS 2025 Accepted", "summary": "Predicting the future motion of road participants is a critical task in\nautonomous driving. In this work, we address the challenge of low-quality\ngeneration of low-probability modes in multi-agent joint prediction. To tackle\nthis issue, we propose a two-stage multi-agent interactive prediction framework\nnamed \\textit{keypoint-guided joint prediction after classification-aware\nmarginal proposal} (JAM). The first stage is modeled as a marginal prediction\nprocess, which classifies queries by trajectory type to encourage the model to\nlearn all categories of trajectories, providing comprehensive mode information\nfor the joint prediction module. The second stage is modeled as a joint\nprediction process, which takes the scene context and the marginal proposals\nfrom the first stage as inputs to learn the final joint distribution. We\nexplicitly introduce key waypoints to guide the joint prediction module in\nbetter capturing and leveraging the critical information from the initial\npredicted trajectories. We conduct extensive experiments on the real-world\nWaymo Open Motion Dataset interactive prediction benchmark. The results show\nthat our approach achieves competitive performance. In particular, in the\nframework comparison experiments, the proposed JAM outperforms other prediction\nframeworks and achieves state-of-the-art performance in interactive trajectory\nprediction. The code is available at https://github.com/LinFunster/JAM to\nfacilitate future research.", "AI": {"tldr": "提出了一个名为JAM的两阶段多智能体交互预测框架，通过分类感知的边际提议和关键点引导的联合预测来解决自动驾驶中低概率模式生成质量差的问题，在Waymo数据集上达到了最先进的性能。", "motivation": "自动驾驶中预测道路参与者的未来运动是关键任务，但现有方法在多智能体联合预测中存在低概率模式生成质量差的问题，需要改进预测框架以更好地捕获和利用关键轨迹信息。", "method": "提出JAM框架，包含两个阶段：第一阶段是边际预测过程，通过轨迹类型对查询进行分类以学习所有类别的轨迹；第二阶段是联合预测过程，以场景上下文和第一阶段的边际提议为输入学习最终联合分布。明确引入关键路径点来引导联合预测模块更好地捕获关键信息。", "result": "在Waymo Open Motion Dataset交互预测基准上进行了广泛实验，方法取得了竞争性能表现。在框架比较实验中，JAM超越了其他预测框架，在交互轨迹预测任务上达到了最先进的性能。", "conclusion": "JAM框架通过两阶段设计和关键点引导机制有效解决了多智能体联合预测中低概率模式生成质量差的问题，在真实世界数据集上验证了方法的有效性，为交互轨迹预测提供了新的解决方案。"}}
{"id": "2507.17163", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17163", "abs": "https://arxiv.org/abs/2507.17163", "authors": ["Botao Lin", "Shuang Song", "Jiaole Wang"], "title": "Reconfigurable Tendon-Driven Robots: Eliminating Inter-segmental Coupling via Independently Lockable Joints", "comment": null, "summary": "With a slender redundant body, the tendon-driven robot (TDR) has a large\nworkspace and great maneuverability while working in complex environments. TDR\ncomprises multiple independently controlled robot segments, each with a set of\ndriving tendons. While increasing the number of robot segments enhances\ndexterity and expands the workspace, this structural expansion also introduces\nintensified inter-segmental coupling. Therefore, achieving precise TDR control\nrequires more complex models and additional motors. This paper presents a\nreconfigurable tendon-driven robot (RTR) equipped with innovative lockable\njoints. Each joint's state (locked/free) can be individually controlled through\na pair of antagonistic tendons, and its structure eliminates the need for a\ncontinuous power supply to maintain the state. Operators can selectively\nactuate the targeted robot segments, and this scheme fundamentally eliminates\nthe inter-segmental coupling, thereby avoiding the requirement for complex\ncoordinated control between segments. The workspace of RTR has been simulated\nand compared with traditional TDRs' workspace, and RTR's advantages are further\nrevealed. The kinematics and statics models of the RTR have been derived and\nvalidation experiments have been conducted. Demonstrations have been performed\nusing a seven-joint RTR prototype to show its reconfigurability and moving\nability in complex environments with an actuator pack comprising only six\nmotors.", "AI": {"tldr": "本文提出了一种配备创新可锁定关节的可重构腱驱动机器人(RTR)，通过选择性锁定关节来消除段间耦合，从而简化控制并提高在复杂环境中的机动性。", "motivation": "传统腱驱动机器人虽然具有大工作空间和良好的机动性，但随着机器人段数增加会引入严重的段间耦合问题，需要复杂的模型和更多电机来实现精确控制。", "method": "设计了配备可锁定关节的可重构腱驱动机器人，每个关节的状态（锁定/自由）可通过一对拮抗腱独立控制，且无需持续供电维持状态。操作员可选择性激活目标机器人段，从根本上消除段间耦合。", "result": "仿真比较显示RTR相比传统TDR具有优势，建立了运动学和静力学模型并进行了验证实验。使用七关节RTR原型进行演示，仅用六个电机的执行器包就展现了其可重构性和在复杂环境中的运动能力。", "conclusion": "RTR通过创新的可锁定关节设计成功解决了传统腱驱动机器人的段间耦合问题，避免了复杂的协调控制需求，在保持灵活性的同时简化了控制系统。"}}
{"id": "2507.17210", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17210", "abs": "https://arxiv.org/abs/2507.17210", "authors": ["Chunran Zheng", "Fu Zhang"], "title": "FAST-Calib: LiDAR-Camera Extrinsic Calibration in One Second", "comment": null, "summary": "This paper proposes FAST-Calib, a fast and user-friendly LiDAR-camera\nextrinsic calibration tool based on a custom-made 3D target. FAST-Calib\nsupports both mechanical and solid-state LiDARs by leveraging an efficient and\nreliable edge extraction algorithm that is agnostic to LiDAR scan patterns. It\nalso compensates for edge dilation artifacts caused by LiDAR spot spread\nthrough ellipse fitting, and supports joint optimization across multiple\nscenes. We validate FAST-Calib on three LiDAR models (Ouster, Avia, and\nMid360), each paired with a wide-angle camera. Experimental results demonstrate\nsuperior accuracy and robustness compared to existing methods. With\npoint-to-point registration errors consistently below 6.5mm and total\nprocessing time under 0.7s, FAST-Calib provides an efficient, accurate, and\ntarget-based automatic calibration pipeline. We have open-sourced our code and\ndataset on GitHub to benefit the robotics community.", "AI": {"tldr": "本文提出了FAST-Calib，一种基于定制3D标靶的快速用户友好型LiDAR-相机外参标定工具，支持机械式和固态LiDAR，具有高精度和鲁棒性。", "motivation": "现有LiDAR-相机外参标定方法存在精度不足、处理速度慢、对不同LiDAR扫描模式适应性差等问题，需要开发一种快速、准确且用户友好的标定工具。", "method": "设计定制3D标靶，开发与LiDAR扫描模式无关的高效可靠边缘提取算法，通过椭圆拟合补偿LiDAR光斑扩散导致的边缘扩张伪影，支持多场景联合优化。", "result": "在三种LiDAR模型（Ouster、Avia和Mid360）与广角相机的组合上验证，点对点配准误差始终低于6.5mm，总处理时间不到0.7秒，相比现有方法具有更优的精度和鲁棒性。", "conclusion": "FAST-Calib提供了一个高效、准确且基于标靶的自动标定流水线，已在GitHub开源代码和数据集以造福机器人社区。"}}
{"id": "2507.17253", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17253", "abs": "https://arxiv.org/abs/2507.17253", "authors": ["Maharshi Shastri", "Ujjval Shrivastav"], "title": "Optimizing Delivery Logistics: Enhancing Speed and Safety with Drone Technology", "comment": null, "summary": "The increasing demand for fast and cost effective last mile delivery\nsolutions has catalyzed significant advancements in drone based logistics. This\nresearch describes the development of an AI integrated drone delivery system,\nfocusing on route optimization, object detection, secure package handling, and\nreal time tracking. The proposed system leverages YOLOv4 Tiny for object\ndetection, the NEO 6M GPS module for navigation, and the A7670 SIM module for\nreal time communication. A comparative analysis of lightweight AI models and\nhardware components is conducted to determine the optimal configuration for\nreal time UAV based delivery. Key challenges including battery efficiency,\nregulatory compliance, and security considerations are addressed through the\nintegration of machine learning techniques, IoT devices, and encryption\nprotocols. Preliminary studies demonstrate improvement in delivery time\ncompared to conventional ground based logistics, along with high accuracy\nrecipient authentication through facial recognition. The study also discusses\nethical implications and societal acceptance of drone deliveries, ensuring\ncompliance with FAA, EASA and DGCA regulatory standards. Note: This paper\npresents the architecture, design, and preliminary simulation results of the\nproposed system. Experimental results, simulation benchmarks, and deployment\nstatistics are currently being acquired. A comprehensive analysis will be\nincluded in the extended version of this work.", "AI": {"tldr": "本研究开发了一个AI集成的无人机配送系统，采用YOLOv4 Tiny进行目标检测，NEO 6M GPS模块导航，A7670 SIM模块实时通信，通过机器学习、物联网设备和加密协议解决电池效率、监管合规和安全问题，初步研究显示相比传统地面物流在配送时间上有所改善。", "motivation": "随着对快速且经济高效的最后一公里配送解决方案需求的增长，催化了基于无人机物流的重大进步。研究旨在解决传统地面物流在配送效率方面的局限性，开发更快速、更智能的无人机配送系统。", "method": "系统采用YOLOv4 Tiny进行目标检测，NEO 6M GPS模块进行导航定位，A7670 SIM模块实现实时通信。通过对轻量级AI模型和硬件组件进行比较分析，确定实时无人机配送的最优配置。集成机器学习技术、物联网设备和加密协议来解决关键挑战。使用面部识别技术进行高精度收件人身份验证。", "result": "初步研究表明，与传统地面物流相比，配送时间有所改善。通过面部识别实现了高精度的收件人身份验证。系统架构、设计和初步仿真结果已完成，但实验结果、仿真基准和部署统计数据仍在获取中。", "conclusion": "研究成功开发了AI集成无人机配送系统的架构和设计，解决了电池效率、监管合规（符合FAA、EASA和DGCA标准）和安全考虑等关键挑战。同时讨论了无人机配送的伦理影响和社会接受度。该系统在提高配送效率和安全性方面显示出潜力，但需要进一步的实验验证和全面分析。"}}
{"id": "2507.17275", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17275", "abs": "https://arxiv.org/abs/2507.17275", "authors": ["Po-Yen Wu", "Cheng-Yu Kuo", "Yuki Kadokawa", "Takamitsu Matsubara"], "title": "Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning", "comment": "Under review", "summary": "In inaccessible environments with uncertain task demands, robots often rely\non general-purpose tools that lack predefined usage strategies. These tools are\nnot tailored for particular operations, making their longevity highly sensitive\nto how they are used. This creates a fundamental challenge: how can a robot\nlearn a tool-use policy that both completes the task and prolongs the tool's\nlifespan? In this work, we address this challenge by introducing a\nreinforcement learning (RL) framework that incorporates tool lifespan as a\nfactor during policy optimization. Our framework leverages Finite Element\nAnalysis (FEA) and Miner's Rule to estimate Remaining Useful Life (RUL) based\non accumulated stress, and integrates the RUL into the RL reward to guide\npolicy learning toward lifespan-guided behavior. To handle the fact that RUL\ncan only be estimated after task execution, we introduce an Adaptive Reward\nNormalization (ARN) mechanism that dynamically adjusts reward scaling based on\nestimated RULs, ensuring stable learning signals. We validate our method across\nsimulated and real-world tool use tasks, including Object-Moving and\nDoor-Opening with multiple general-purpose tools. The learned policies\nconsistently prolong tool lifespan (up to 8.01x in simulation) and transfer\neffectively to real-world settings, demonstrating the practical value of\nlearning lifespan-guided tool use strategies.", "AI": {"tldr": "本文提出了一个强化学习框架，通过将工具寿命作为优化因子，训练机器人学习既能完成任务又能延长工具使用寿命的策略，在仿真和真实环境中验证了该方法的有效性。", "motivation": "在不可达环境中，机器人经常依赖缺乏预定义使用策略的通用工具，这些工具的寿命对使用方式高度敏感。如何让机器人学习既能完成任务又能延长工具寿命的使用策略是一个根本性挑战。", "method": "提出一个强化学习框架，将工具寿命纳入策略优化过程。利用有限元分析(FEA)和Miner规则基于累积应力估算剩余使用寿命(RUL)，并将RUL集成到RL奖励中指导策略学习。引入自适应奖励归一化(ARN)机制，根据估计的RUL动态调整奖励缩放，确保稳定的学习信号。", "result": "在仿真和真实世界的工具使用任务中验证了方法的有效性，包括物体移动和开门任务。学习到的策略能够持续延长工具寿命(仿真中最高达8.01倍)，并能有效迁移到真实世界环境中。", "conclusion": "该研究成功解决了机器人在使用通用工具时平衡任务完成和工具寿命延长的难题，证明了学习寿命导向型工具使用策略的实用价值，为机器人在复杂环境中的可持续工具使用提供了新的解决方案。"}}
{"id": "2507.17294", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17294", "abs": "https://arxiv.org/abs/2507.17294", "authors": ["Jianxin Bi", "Kevin Yuchen Ma", "Ce Hao", "Mike Zheng Shou", "Harold Soh"], "title": "VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback", "comment": "19 pages, 5 figures", "summary": "Tactile feedback is generally recognized to be crucial for effective\ninteraction with the physical world. However, state-of-the-art\nVision-Language-Action (VLA) models lack the ability to interpret and use\ntactile signals, limiting their effectiveness in contact-rich tasks.\nIncorporating tactile feedback into these systems is challenging due to the\nabsence of large multi-modal datasets. We present VLA-Touch, an approach that\nenhances generalist robot policies with tactile sensing \\emph{without\nfine-tuning} the base VLA. Our method introduces two key innovations: (1) a\npipeline that leverages a pretrained tactile-language model that provides\nsemantic tactile feedback for high-level task planning, and (2) a\ndiffusion-based controller that refines VLA-generated actions with tactile\nsignals for contact-rich manipulation. Through real-world experiments, we\ndemonstrate that our dual-level integration of tactile feedback improves task\nplanning efficiency while enhancing execution precision. Code is open-sourced\nat \\href{https://github.com/jxbi1010/VLA-Touch}{this URL}.", "AI": {"tldr": "VLA-Touch是一种无需微调基础VLA模型就能为通用机器人策略增加触觉感知能力的方法，通过双层触觉反馈集成提升了任务规划效率和执行精度。", "motivation": "现有的视觉-语言-动作(VLA)模型缺乏解释和使用触觉信号的能力，这限制了它们在接触密集型任务中的有效性。由于缺乏大型多模态数据集，将触觉反馈整合到这些系统中具有挑战性。", "method": "提出VLA-Touch方法，包含两个关键创新：(1)利用预训练触觉-语言模型为高层任务规划提供语义触觉反馈的管道；(2)基于扩散的控制器，使用触觉信号优化VLA生成的动作以实现接触密集型操作。", "result": "通过真实世界实验验证，双层触觉反馈集成提升了任务规划效率，同时增强了执行精度。代码已开源。", "conclusion": "VLA-Touch成功实现了在不微调基础VLA模型的情况下，通过双层触觉反馈集成有效提升通用机器人策略在接触密集型任务中的性能。"}}
{"id": "2507.17317", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17317", "abs": "https://arxiv.org/abs/2507.17317", "authors": ["Miguel Escudero-Jiménez", "Noé Pérez-Higueras", "Andrés Martínez-Silva", "Fernando Caballero", "Luis Merino"], "title": "HuNavSim 2.0", "comment": "Preprint submitted to the 8th Iberian Robotics Conference (ROBOT\n  2025)", "summary": "This work presents a new iteration of the Human Navigation Simulator\n(HuNavSim), a novel open-source tool for the simulation of different\nhuman-agent navigation behaviors in scenarios with mobile robots. The tool,\nprogrammed under the ROS 2 framework, can be used together with different\nwell-known robotics simulators such as Gazebo or NVidia Isaac Sim. The main\ngoal is to facilitate the development and evaluation of human-aware robot\nnavigation systems in simulation. In this new version, several features have\nbeen improved and new ones added, such as the extended set of actions and\nconditions that can be combined in Behavior Trees to compound complex and\nrealistic human behaviors.", "AI": {"tldr": "本文介绍了Human Navigation Simulator (HuNavSim)的新版本，这是一个开源的人机导航行为仿真工具，基于ROS 2框架开发，可与Gazebo和NVidia Isaac Sim等机器人仿真器集成使用。", "motivation": "为了促进人机感知机器人导航系统的开发和评估，需要一个能够仿真不同人类-智能体导航行为的工具，特别是在移动机器人场景中模拟复杂且真实的人类行为。", "method": "开发了基于ROS 2框架的Human Navigation Simulator (HuNavSim)工具，该工具可以与多种知名机器人仿真器（如Gazebo或NVidia Isaac Sim）配合使用。新版本扩展了行为树中可组合的动作和条件集合，以构建复杂和真实的人类行为。", "result": "成功推出了HuNavSim的新版本，改进了多个功能并添加了新特性，特别是扩展了行为树系统中的动作和条件集合，使得能够模拟更加复杂和真实的人类导航行为。", "conclusion": "新版本的HuNavSim为人机感知机器人导航系统的仿真开发和评估提供了更强大的工具支持，通过扩展的行为树功能能够更好地模拟复杂的人类导航行为，有助于推进该领域的研究发展。"}}
{"id": "2507.17338", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17338", "abs": "https://arxiv.org/abs/2507.17338", "authors": ["Corrado Pezzato", "Ozan Çatal", "Toon Van de Maele", "Riddhi J. Pitliya", "Tim Verbelen"], "title": "Mobile Manipulation with Active Inference for Long-Horizon Rearrangement Tasks", "comment": null, "summary": "Despite growing interest in active inference for robotic control, its\napplication to complex, long-horizon tasks remains untested. We address this\ngap by introducing a fully hierarchical active inference architecture for\ngoal-directed behavior in realistic robotic settings. Our model combines a\nhigh-level active inference model that selects among discrete skills realized\nvia a whole-body active inference controller. This unified approach enables\nflexible skill composition, online adaptability, and recovery from task\nfailures without requiring offline training. Evaluated on the Habitat Benchmark\nfor mobile manipulation, our method outperforms state-of-the-art baselines\nacross the three long-horizon tasks, demonstrating for the first time that\nactive inference can scale to the complexity of modern robotics benchmarks.", "AI": {"tldr": "研究提出了一种分层主动推理架构，用于机器人复杂长期任务控制，在Habitat基准测试中超越了现有方法，首次证明主动推理可以扩展到现代机器人复杂任务", "motivation": "尽管主动推理在机器人控制中受到关注，但其在复杂长期任务中的应用尚未得到验证，存在将主动推理扩展到现实机器人复杂任务的需求", "method": "引入了完全分层的主动推理架构，结合高层主动推理模型选择离散技能和全身主动推理控制器，实现统一的目标导向行为控制方法", "result": "在Habitat移动操作基准测试的三个长期任务中，该方法在所有任务上都超越了最先进的基线方法，展现出灵活的技能组合、在线适应性和任务失败恢复能力", "conclusion": "首次证明了主动推理可以成功扩展到现代机器人基准测试的复杂性水平，为机器人复杂任务控制提供了新的有效解决方案"}}
{"id": "2507.17376", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17376", "abs": "https://arxiv.org/abs/2507.17376", "authors": ["Tianshu Ruan", "Aniketh Ramesh", "Rustam Stolkin", "Manolis Chiou"], "title": "An Exploratory Study on Human-Robot Interaction using Semantics-based Situational Awareness", "comment": null, "summary": "In this paper, we investigate the impact of high-level semantics (evaluation\nof the environment) on Human-Robot Teams (HRT) and Human-Robot Interaction\n(HRI) in the context of mobile robot deployments. Although semantics has been\nwidely researched in AI, how high-level semantics can benefit the HRT paradigm\nis underexplored, often fuzzy, and intractable. We applied a semantics-based\nframework that could reveal different indicators of the environment (i.e. how\nmuch semantic information exists) in a mock-up disaster response mission. In\nsuch missions, semantics are crucial as the HRT should handle complex\nsituations and respond quickly with correct decisions, where humans might have\na high workload and stress. Especially when human operators need to shift their\nattention between robots and other tasks, they will struggle to build\nSituational Awareness (SA) quickly. The experiment suggests that the presented\nsemantics: 1) alleviate the perceived workload of human operators; 2) increase\nthe operator's trust in the SA; and 3) help to reduce the reaction time in\nswitching the level of autonomy when needed. Additionally, we find that\nparticipants with higher trust in the system are encouraged by high-level\nsemantics to use teleoperation mode more.", "AI": {"tldr": "本文研究了高级语义对人机团队和人机交互的影响，提出了一个基于语义的框架，在模拟灾难响应任务中验证了高级语义能够减轻操作员工作负担、提高情境感知信任度并缩短反应时间。", "motivation": "在移动机器人部署的人机团队中，高级语义对人机交互的益处尚未得到充分探索，且往往模糊难解。特别是在灾难响应等复杂任务中，人类操作员面临高工作负荷和压力，需要在机器人和其他任务间切换注意力，难以快速建立情境感知。", "method": "应用基于语义的框架，该框架能够揭示环境的不同指标（即存在多少语义信息）。在模拟灾难响应任务中进行实验，评估高级语义对人机团队表现的影响。", "result": "实验结果表明，所提出的语义方法能够：1）减轻人类操作员的感知工作负荷；2）增加操作员对情境感知的信任；3）帮助减少在需要时切换自主水平的反应时间。此外，发现对系统信任度较高的参与者更倾向于在高级语义的鼓励下使用遥操作模式。", "conclusion": "高级语义在人机团队中具有显著的积极影响，能够有效改善人机交互的质量和效率。语义信息的引入不仅减轻了操作员的认知负担，还提高了他们对系统的信任度，并优化了决策反应时间，为移动机器人在复杂环境中的应用提供了重要支持。"}}
{"id": "2507.17379", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17379", "abs": "https://arxiv.org/abs/2507.17379", "authors": ["Shen Tan", "Dong Zhou", "Xiangyu Shao", "Junqiao Wang", "Guanghui Sun"], "title": "Language-Conditioned Open-Vocabulary Mobile Manipulation with Pretrained Models", "comment": "IJCAI 2025", "summary": "Open-vocabulary mobile manipulation (OVMM) that involves the handling of\nnovel and unseen objects across different workspaces remains a significant\nchallenge for real-world robotic applications. In this paper, we propose a\nnovel Language-conditioned Open-Vocabulary Mobile Manipulation framework, named\nLOVMM, incorporating the large language model (LLM) and vision-language model\n(VLM) to tackle various mobile manipulation tasks in household environments.\nOur approach is capable of solving various OVMM tasks with free-form natural\nlanguage instructions (e.g. \"toss the food boxes on the office room desk to the\ntrash bin in the corner\", and \"pack the bottles from the bed to the box in the\nguestroom\"). Extensive experiments simulated in complex household environments\nshow strong zero-shot generalization and multi-task learning abilities of\nLOVMM. Moreover, our approach can also generalize to multiple tabletop\nmanipulation tasks and achieve better success rates compared to other\nstate-of-the-art methods.", "AI": {"tldr": "本文提出了LOVMM框架，结合大语言模型和视觉语言模型来解决开放词汇移动操作任务，能够在家庭环境中处理新颖和未见过的物体，并通过自然语言指令执行复杂的机器人操作任务。", "motivation": "开放词汇移动操作（OVMM）在处理不同工作空间中新颖和未见过的物体时仍然是实际机器人应用的重大挑战，需要一个能够理解自然语言指令并在复杂环境中执行多样化操作任务的框架。", "method": "提出了LOVMM（Language-conditioned Open-Vocabulary Mobile Manipulation）框架，该框架结合了大语言模型（LLM）和视觉语言模型（VLM），能够处理家庭环境中的各种移动操作任务，并可以理解自由形式的自然语言指令。", "result": "在复杂家庭环境的仿真实验中，LOVMM展现出强大的零样本泛化能力和多任务学习能力。此外，该方法还能够泛化到多个桌面操作任务，并相比其他最先进方法取得了更高的成功率。", "conclusion": "LOVMM框架成功地解决了开放词汇移动操作的挑战，通过结合LLM和VLM实现了对复杂自然语言指令的理解和执行，在家庭环境和桌面操作任务中都表现出优异的性能和泛化能力。"}}
{"id": "2507.17383", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.17383", "abs": "https://arxiv.org/abs/2507.17383", "authors": ["Thomas P Zollo", "Richard Zemel"], "title": "Confidence Calibration in Vision-Language-Action Models", "comment": "34 pages, 19 figures", "summary": "Trustworthy robot behavior requires not only high levels of task success but\nalso that the robot can reliably quantify how likely it is to succeed. To this\nend, we present the first systematic study of confidence calibration in\nvision-language-action (VLA) foundation models, which map visual observations\nand natural-language instructions to low-level robot motor commands. We begin\nwith extensive benchmarking to understand the critical relationship between\ntask success and calibration error across multiple datasets and VLA variants,\nfinding that task performance and calibration are not in tension. Next, we\nintroduce prompt ensembles for VLAs, a lightweight, Bayesian-inspired algorithm\nthat averages confidence across paraphrased instructions and consistently\nimproves calibration. We further analyze calibration over the task time\nhorizon, showing that confidence is often most reliable after making some\nprogress, suggesting natural points for risk-aware intervention. Finally, we\nreveal differential miscalibration across action dimensions and propose\naction-wise Platt scaling, a method to recalibrate each action dimension\nindependently to produce better confidence estimates. Our aim in this study is\nto begin to develop the tools and conceptual understanding necessary to render\nVLAs both highly performant and highly trustworthy via reliable uncertainty\nquantification.", "AI": {"tldr": "本研究首次系统性地研究了视觉-语言-动作(VLA)基础模型中的置信度校准问题，提出了提示集成和动作维度独立校准等方法来提高机器人行为的可信度和不确定性量化能力。", "motivation": "可信赖的机器人行为不仅需要高任务成功率，还需要机器人能够可靠地量化其成功概率。现有的VLA模型在置信度校准方面缺乏系统性研究，这限制了机器人在实际应用中的可信度和安全性。", "method": "1) 对多个数据集和VLA变体进行广泛基准测试，分析任务成功与校准误差的关系；2) 提出提示集成算法，通过平均不同释义指令的置信度来改善校准；3) 分析任务时间范围内的校准表现；4) 提出动作维度独立的Platt缩放方法，对每个动作维度进行独立重新校准。", "result": "发现任务性能和校准并不冲突；提示集成算法能够持续改善校准效果；置信度在取得一定进展后往往最为可靠，为风险感知干预提供了自然的时机；不同动作维度存在差异化的误校准现象；动作维度独立校准方法能够产生更好的置信度估计。", "conclusion": "通过系统性研究置信度校准，开发了必要的工具和概念理解，使VLA模型能够通过可靠的不确定性量化实现高性能和高可信度，为构建更加安全可靠的机器人系统奠定了基础。"}}
{"id": "2507.17401", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.17401", "abs": "https://arxiv.org/abs/2507.17401", "authors": ["Rachel Ringe", "Mihai Pomarlan", "Nikolaos Tsiogkas", "Stefano De Giorgis", "Maria Hedblom", "Rainer Malaka"], "title": "The Wilhelm Tell Dataset of Affordance Demonstrations", "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Affordances - i.e. possibilities for action that an environment or objects in\nit provide - are important for robots operating in human environments to\nperceive. Existing approaches train such capabilities on annotated static\nimages or shapes. This work presents a novel dataset for affordance learning of\ncommon household tasks. Unlike previous approaches, our dataset consists of\nvideo sequences demonstrating the tasks from first- and third-person\nperspectives, along with metadata about the affordances that are manifested in\nthe task, and is aimed towards training perception systems to recognize\naffordance manifestations. The demonstrations were collected from several\nparticipants and in total record about seven hours of human activity. The\nvariety of task performances also allows studying preparatory maneuvers that\npeople may perform for a task, such as how they arrange their task space, which\nis also relevant for collaborative service robots.", "AI": {"tldr": "该研究提出了一个新的家庭任务可供性学习数据集，包含第一人称和第三人称视角的视频序列，用于训练机器人识别环境中的行为可能性", "motivation": "现有的可供性学习方法主要基于静态图像或形状标注进行训练，缺乏动态视频数据来帮助机器人更好地理解人类环境中的行为可能性，特别是家庭任务场景中的可供性识别", "method": "构建了一个包含常见家庭任务的新型可供性学习数据集，该数据集包含：1）第一人称和第三人称视角的视频序列；2）任务中体现的可供性元数据；3）多名参与者的任务演示，总计约7小时的人类活动记录", "result": "成功收集了涵盖多种家庭任务表现的视频数据集，能够研究人们执行任务时的准备动作，如任务空间的安排方式，为协作服务机器人提供了有价值的训练数据", "conclusion": "该数据集为机器人可供性感知系统的训练提供了重要资源，特别是在识别家庭环境中的可供性表现方面，同时也有助于研究人类的任务准备行为，这对协作服务机器人的发展具有重要意义"}}
{"id": "2507.17445", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.17445", "abs": "https://arxiv.org/abs/2507.17445", "authors": ["Haichuan Li", "Changda Tian", "Panos Trahanias", "Tomi Westerlund"], "title": "IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception", "comment": null, "summary": "Detecting diverse objects within complex indoor 3D point clouds presents\nsignificant challenges for robotic perception, particularly with varied object\nshapes, clutter, and the co-existence of static and dynamic elements where\ntraditional bounding box methods falter. To address these limitations, we\npropose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoor\nmobile robots.\n  In a BEV method, a 3D scene is projected into a 2D BEV grid which handles\nnaturally occlusions and provides a consistent top-down view aiding to\ndistinguish static obstacles from dynamic agents. The obtained 2D BEV results\nis directly usable to downstream robotic tasks like navigation, motion\nprediction, and planning. Our architecture utilizes an axis compact encoder and\na window-based backbone to extract rich spatial features from this BEV map. A\nquery-based decoder head then employs learned object queries to concurrently\npredict object classes and instance masks in the BEV space. This mask-centric\nformulation effectively captures the footprint of both static and dynamic\nobjects regardless of their shape, offering a robust alternative to bounding\nbox regression. We demonstrate the effectiveness of IndoorBEV on a custom\nindoor dataset featuring diverse object classes including static objects\n  and dynamic elements like robots and miscellaneous items, showcasing its\npotential for robust indoor scene understanding.", "AI": {"tldr": "提出了IndoorBEV，一种基于掩码的鸟瞰视角(BEV)方法，用于室内移动机器人在复杂3D点云中进行多样化物体检测，通过将3D场景投影到2D BEV网格来处理遮挡问题并区分静态障碍物和动态物体。", "motivation": "传统边界框方法在处理室内复杂3D点云中的多样化物体检测时存在局限性，特别是在面对不同物体形状、杂乱环境以及静态和动态元素共存的情况下表现不佳，机器人感知面临重大挑战。", "method": "采用基于掩码的鸟瞰视角(BEV)方法，将3D场景投影到2D BEV网格中；使用轴向紧凑编码器和基于窗口的主干网络从BEV地图中提取丰富的空间特征；采用基于查询的解码器头，利用学习的物体查询同时预测BEV空间中的物体类别和实例掩码。", "result": "在包含多样化物体类别（包括静态物体和机器人、杂项等动态元素）的定制室内数据集上验证了IndoorBEV的有效性，展现了其在鲁棒室内场景理解方面的潜力。", "conclusion": "IndoorBEV通过基于掩码的方法有效捕获静态和动态物体的足迹，无论其形状如何，为边界框回归提供了鲁棒的替代方案，并且得到的2D BEV结果可直接用于导航、运动预测和规划等下游机器人任务。"}}
{"id": "2507.17519", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17519", "abs": "https://arxiv.org/abs/2507.17519", "authors": ["Kostas Karakontis", "Thanos Petsanis", "Athanasios Ch. Kapoutsis", "Pavlos Ch. Kapoutsis", "Elias B. Kosmatopoulos"], "title": "Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners", "comment": null, "summary": "Multi-UAV Coverage Path Planning (mCPP) algorithms in popular commercial\nsoftware typically treat a Region of Interest (RoI) only as a 2D plane,\nignoring important3D structure characteristics. This leads to incomplete\n3Dreconstructions, especially around occluded or vertical surfaces. In this\npaper, we propose a modular algorithm that can extend commercial\ntwo-dimensional path planners to facilitate terrain-aware planning by adjusting\naltitude and camera orientations. To demonstrate it, we extend the well-known\nDARP (Divide Areas for Optimal Multi-Robot Coverage Path Planning) algorithm\nand produce DARP-3D. We present simulation results in multiple 3D environments\nand a real-world flight test using DJI hardware. Compared to baseline, our\napproach consistently captures improved 3D reconstructions, particularly in\nareas with significant vertical features. An open-source implementation of the\nalgorithm is available here:https://github.com/konskara/TerraPlan", "AI": {"tldr": "本文提出了一种模块化算法，将商业二维路径规划器扩展为地形感知的三维多无人机覆盖路径规划，通过调整高度和相机方向改善3D重建效果", "motivation": "现有商业软件中的多无人机覆盖路径规划算法仅将感兴趣区域视为2D平面，忽略了重要的3D结构特征，导致3D重建不完整，特别是在遮挡或垂直表面周围", "method": "提出了一种模块化算法，可以扩展商业二维路径规划器以实现地形感知规划，通过调整高度和相机方向来优化覆盖。作为演示，将知名的DARP算法扩展为DARP-3D", "result": "在多个3D环境中进行仿真测试和使用DJI硬件进行真实飞行测试，结果显示相比基线方法，该方法在具有显著垂直特征的区域能够持续获得改进的3D重建效果", "conclusion": "该模块化算法成功地将2D路径规划扩展到3D地形感知规划，显著改善了3D重建质量，特别是在垂直结构区域。算法的开源实现已公开提供"}}
{"id": "2507.17520", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.17520", "abs": "https://arxiv.org/abs/2507.17520", "authors": ["Shuai Yang", "Hao Li", "Yilun Chen", "Bin Wang", "Yang Tian", "Tai Wang", "Hanqing Wang", "Feng Zhao", "Yiyi Liao", "Jiangmiao Pang"], "title": "InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation", "comment": "38 pages", "summary": "To operate effectively in the real world, robots must integrate multimodal\nreasoning with precise action generation. However, existing\nvision-language-action (VLA) models often sacrifice one for the other, narrow\ntheir abilities to task-specific manipulation data, and suffer catastrophic\nforgetting of pre-trained vision-language capabilities. To bridge this gap, we\nintroduce InstructVLA, an end-to-end VLA model that preserves the flexible\nreasoning of large vision-language models (VLMs) while delivering leading\nmanipulation performance. InstructVLA introduces a novel training paradigm,\nVision-Language-Action Instruction Tuning (VLA-IT), which employs multimodal\ntraining with mixture-of-experts adaptation to jointly optimize textual\nreasoning and action generation on both standard VLM corpora and a curated\n650K-sample VLA-IT dataset. On in-domain SimplerEnv tasks, InstructVLA achieves\n30.5% improvement over SpatialVLA. To evaluate generalization, we introduce\nSimplerEnv-Instruct, an 80-task benchmark requiring closed-loop control and\nhigh-level instruction understanding, where it outperforms a fine-tuned OpenVLA\nby 92% and an action expert aided by GPT-4o by 29%. Additionally, InstructVLA\nsurpasses baseline VLMs on multimodal tasks and exhibits inference-time scaling\nby leveraging textual reasoning to boost manipulation performance in both\nsimulated and real-world settings. These results demonstrate InstructVLA's\npotential for bridging intuitive and steerable human-robot interaction with\nefficient policy learning.", "AI": {"tldr": "InstructVLA是一个端到端的视觉-语言-动作模型，通过新颖的VLA-IT训练范式，在保持大型视觉语言模型灵活推理能力的同时，实现了领先的机器人操作性能", "motivation": "现有的视觉-语言-动作模型往往在多模态推理和精确动作生成之间做出权衡，能力局限于特定任务的操作数据，并且会遗忘预训练的视觉语言能力。需要开发一个既能保持灵活推理又能提供优秀操作性能的统一模型", "method": "提出Vision-Language-Action Instruction Tuning (VLA-IT)训练范式，采用多模态训练和专家混合自适应方法，在标准VLM语料库和精心策划的65万样本VLA-IT数据集上联合优化文本推理和动作生成", "result": "在SimplerEnv任务上比SpatialVLA提升30.5%；在新提出的SimplerEnv-Instruct 80任务基准测试中，比微调的OpenVLA高出92%，比GPT-4o辅助的动作专家高出29%；在多模态任务上超越基线VLM，并展现推理时间缩放能力", "conclusion": "InstructVLA成功实现了直观可控的人机交互与高效策略学习的桥接，为机器人在真实世界中的有效操作提供了新的解决方案，展现了在仿真和真实环境中的强大泛化能力"}}
{"id": "2507.17531", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17531", "abs": "https://arxiv.org/abs/2507.17531", "authors": ["Abdel-Raouf Dannaoui", "Johann Laconte", "Christophe Debain", "Francois Pomerleau", "Paul Checchin"], "title": "When and Where Localization Fails: An Analysis of the Iterative Closest Point in Evolving Environment", "comment": "7 pages, 7 figures, proceedings in European Conference on Mobile\n  Robots (ECMR) 2025", "summary": "Robust relocalization in dynamic outdoor environments remains a key challenge\nfor autonomous systems relying on 3D lidar. While long-term localization has\nbeen widely studied, short-term environmental changes, occurring over days or\nweeks, remain underexplored despite their practical significance. To address\nthis gap, we present a highresolution, short-term multi-temporal dataset\ncollected weekly from February to April 2025 across natural and semi-urban\nsettings. Each session includes high-density point cloud maps, 360 deg\npanoramic images, and trajectory data. Projected lidar scans, derived from the\npoint cloud maps and modeled with sensor-accurate occlusions, are used to\nevaluate alignment accuracy against the ground truth using two Iterative\nClosest Point (ICP) variants: Point-to-Point and Point-to-Plane. Results show\nthat Point-to-Plane offers significantly more stable and accurate registration,\nparticularly in areas with sparse features or dense vegetation. This study\nprovides a structured dataset for evaluating short-term localization\nrobustness, a reproducible framework for analyzing scan-to-map alignment under\nnoise, and a comparative evaluation of ICP performance in evolving outdoor\nenvironments. Our analysis underscores how local geometry and environmental\nvariability affect localization success, offering insights for designing more\nresilient robotic systems.", "AI": {"tldr": "本研究针对动态户外环境中3D激光雷达的短期重定位问题，构建了高分辨率多时间序列数据集，并比较了两种ICP算法的性能，发现Point-to-Plane ICP在稀疏特征和植被密集区域表现更稳定准确。", "motivation": "虽然长期定位已被广泛研究，但在几天到几周内发生的短期环境变化对自主系统3D激光雷达鲁棒重定位的影响仍未得到充分探索，这对实际应用具有重要意义。", "method": "构建了2025年2月至4月期间每周采集的高分辨率短期多时间序列数据集，包含自然和半城市环境的高密度点云地图、360度全景图像和轨迹数据。使用从点云地图投影得到的激光雷达扫描数据，结合传感器精确遮挡建模，通过Point-to-Point和Point-to-Plane两种ICP算法评估对齐精度。", "result": "Point-to-Plane ICP相比Point-to-Point ICP提供了显著更稳定和准确的配准效果，特别是在稀疏特征或植被密集的区域。研究揭示了局部几何形状和环境变化如何影响定位成功率。", "conclusion": "该研究为评估短期定位鲁棒性提供了结构化数据集，建立了在噪声条件下分析扫描到地图对齐的可重现框架，并对evolving户外环境中的ICP性能进行了比较评估，为设计更具弹性的机器人系统提供了洞察。"}}
{"id": "2507.17561", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17561", "abs": "https://arxiv.org/abs/2507.17561", "authors": ["Lorenzo Vianello", "Matthew Short", "Julia Manczurowsky", "Emek Barış Küçüktabak", "Francesco Di Tommaso", "Alessia Noccaro", "Laura Bandini", "Shoshana Clark", "Alaina Fiorenza", "Francesca Lunardini", "Alberto Canton", "Marta Gandolla", "Alessandra L. G. Pedrocchi", "Emilia Ambrosini", "Manuel Murie-Fernandez", "Carmen B. Roman", "Jesus Tornero", "Natacha Leon", "Andrew Sawers", "Jim Patton", "Domenico Formica", "Nevio Luigi Tagliamonte", "Georg Rauter", "Kilian Baur", "Fabian Just", "Christopher J. Hasson", "Vesna D. Novak", "Jose L. Pons"], "title": "Robot-mediated physical Human-Human Interaction in Neurorehabilitation: a position paper", "comment": null, "summary": "Neurorehabilitation conventionally relies on the interaction between a\npatient and a physical therapist. Robotic systems can improve and enrich the\nphysical feedback provided to patients after neurological injury, but they\nunder-utilize the adaptability and clinical expertise of trained therapists. In\nthis position paper, we advocate for a novel approach that integrates the\ntherapist's clinical expertise and nuanced decision-making with the strength,\naccuracy, and repeatability of robotics: Robot-mediated physical Human-Human\nInteraction. This framework, which enables two individuals to physically\ninteract through robotic devices, has been studied across diverse research\ngroups and has recently emerged as a promising link between conventional manual\ntherapy and rehabilitation robotics, harmonizing the strengths of both\napproaches. This paper presents the rationale of a multidisciplinary\nteam-including engineers, doctors, and physical therapists-for conducting\nresearch that utilizes: a unified taxonomy to describe robot-mediated\nrehabilitation, a framework of interaction based on social psychology, and a\ntechnological approach that makes robotic systems seamless facilitators of\nnatural human-human interaction.", "AI": {"tldr": "本文提出了一种新的神经康复方法：机器人介导的人-人物理交互，将治疗师的临床专业知识与机器人的精确性和重复性相结合，为传统手动治疗和康复机器人技术之间搭建桥梁。", "motivation": "传统神经康复依赖患者与物理治疗师的交互，而机器人系统虽能改善物理反馈但未充分利用训练有素的治疗师的适应性和临床专业知识。需要一种方法来整合治疗师的临床专长和细致决策能力与机器人的力量、准确性和重复性。", "method": "提出机器人介导的人-人物理交互框架，使两个人能够通过机器人设备进行物理交互。采用多学科团队方法，包括工程师、医生和物理治疗师，利用统一的分类法描述机器人介导康复、基于社会心理学的交互框架，以及使机器人系统成为自然人-人交互无缝促进者的技术方法。", "result": "该框架已在不同研究团体中得到研究，最近作为连接传统手动治疗和康复机器人技术的有希望的纽带出现，协调了两种方法的优势。", "conclusion": "机器人介导的人-人物理交互代表了一种有前景的康复方法，能够结合传统手动治疗和机器人技术的优势，为神经康复领域提供了新的发展方向。"}}
{"id": "2507.17572", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17572", "abs": "https://arxiv.org/abs/2507.17572", "authors": ["Antoine Groudiev", "Fabian Schramm", "Éloïse Berthier", "Justin Carpentier", "Frederike Dümbgen"], "title": "KernelSOS for Global Sampling-Based Optimal Control and Estimation via Semidefinite Programming", "comment": null, "summary": "Global optimization has gained attraction over the past decades, thanks to\nthe development of both theoretical foundations and efficient numerical\nroutines to cope with optimization problems of various complexities. Among\nrecent methods, Kernel Sum of Squares (KernelSOS) appears as a powerful\nframework, leveraging the potential of sum of squares methods from the\npolynomial optimization community with the expressivity of kernel methods\nwidely used in machine learning. This paper applies the kernel sum of squares\nframework for solving control and estimation problems, which exhibit poor local\nminima. We demonstrate that KernelSOS performs well on a selection of problems\nfrom both domains. In particular, we show that KernelSOS is competitive with\nother sum of squares approaches on estimation problems, while being applicable\nto non-polynomial and non-parametric formulations. The sample-based nature of\nKernelSOS allows us to apply it to trajectory optimization problems with an\nintegrated simulator treated as a black box, both as a standalone method and as\na powerful initialization method for local solvers, facilitating the discovery\nof better solutions.", "AI": {"tldr": "本文将核平方和(KernelSOS)框架应用于控制和估计问题的全局优化，证明了该方法在处理具有局部最优解的问题时表现优异，特别是在轨迹优化中可作为独立方法或局部求解器的初始化方法使用。", "motivation": "控制和估计问题往往存在糟糕的局部最优解，传统优化方法难以找到全局最优解。需要一种既能利用平方和方法的理论基础，又能发挥核方法表达能力的全局优化框架来解决这类问题。", "method": "采用核平方和(KernelSOS)框架，该方法结合了多项式优化中平方和方法的理论基础和机器学习中核方法的表达能力。利用KernelSOS的基于样本的特性，将其应用于轨迹优化问题，并可将集成仿真器视为黑箱处理。", "result": "KernelSOS在控制和估计领域的多个问题上表现良好。在估计问题上与其他平方和方法具有竞争力，同时适用于非多项式和非参数化表述。在轨迹优化问题中，既可作为独立方法使用，也可作为局部求解器的强大初始化方法。", "conclusion": "KernelSOS框架成功地将全局优化技术扩展到控制和估计领域，为解决具有复杂局部最优结构的优化问题提供了有效工具，特别是在轨迹优化中展现了良好的应用前景。"}}
{"id": "2507.17649", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17649", "abs": "https://arxiv.org/abs/2507.17649", "authors": ["J. D. Clark", "P. Ellison"], "title": "Event Detection for Active Lower Limb Prosthesis", "comment": null, "summary": "Accurate event detection is key to the successful design of semi-passive and\npowered prosthetics. Kinematically, the natural knee is complex, with\ntranslation and rotation components that have a substantial impact on gait\ncharacteristics. When simplified to a pin joint, some of this behaviour is\nlost. This study investigates the role of cruciate ligament stretch in event\ndetection. A bicondylar knee design was used, constrained by analogues of the\nanterior and posterior cruciate ligaments. This offers the ability to\ncharacterize knee kinematics by the stretch of the ligaments. The ligament\nstretch was recorded using LVDTs parallel to the ligaments of the Russell knee\non a bent knee crutch. Which was used to capture data on a treadmill at 3\nspeeds. This study finds speed dependence within the stretch of the cruciate\nligaments, prominently around 5\\% and 80\\% of the gait cycle for the posterior\nand anterior. The cycle profile remains consistent with speed; therefore, other\nstatic events such as the turning point feature at around 90\\% and 95\\% of the\ncycle, for the posterior and anterior, respectively, could be used as a\npredictive precursor for initial contact. Likewise at 90\\% and 95\\%, another\npair of turning points that in this case could be used to predict foot flat.\nThis concludes that the use of a bicondylar knee design could improve the\ndetection of events during the gait cycle, and therefore could increase the\naccuracy of subsequent controllers for powered prosthetics.", "AI": {"tldr": "该研究通过双髁膝关节设计和十字韧带拉伸检测来改进假肢步态事件识别，发现韧带拉伸模式可用于预测步态周期中的关键事件，从而提高动力假肢控制器的精度。", "motivation": "传统假肢将膝关节简化为销钉关节会丢失自然膝关节的复杂运动学特性（包括平移和旋转成分），影响步态特征。准确的事件检测是半被动和动力假肢成功设计的关键，因此需要研究十字韧带拉伸在事件检测中的作用。", "method": "使用双髁膝关节设计，通过前后十字韧带类似物进行约束。采用与Russell膝关节韧带平行的线性位移传感器(LVDTs)记录韧带拉伸情况。在弯膝拐杖上进行实验，在跑步机上以3种不同速度采集数据，通过韧带拉伸特征来表征膝关节运动学。", "result": "发现十字韧带拉伸存在速度依赖性，主要出现在步态周期的5%和80%处（后十字韧带和前十字韧带）。循环轮廓随速度保持一致，在90%和95%处分别出现后十字韧带和前十字韧带的转折点特征，可用作初始接触的预测前兆。同样在90%和95%处的另一对转折点可用于预测足平期。", "conclusion": "双髁膝关节设计能够改善步态周期中事件的检测，因此可以提高动力假肢后续控制器的精度。韧带拉伸模式为假肢控制系统提供了新的生物力学反馈机制。"}}
{"id": "2507.17679", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.17679", "abs": "https://arxiv.org/abs/2507.17679", "authors": ["Theodoros Tavoulareas", "Marzia Cescon"], "title": "Safety Assurance for Quadrotor Kinodynamic Motion Planning", "comment": "Accepted for publication at 2025 Modeling, Estimation and Control\n  Conference (MECC)", "summary": "Autonomous drones have gained considerable attention for applications in\nreal-world scenarios, such as search and rescue, inspection, and delivery. As\ntheir use becomes ever more pervasive in civilian applications, failure to\nensure safe operation can lead to physical damage to the system, environmental\npollution, and even loss of human life. Recent work has demonstrated that\nmotion planning techniques effectively generate a collision-free trajectory\nduring navigation. However, these methods, while creating the motion plans, do\nnot inherently consider the safe operational region of the system, leading to\npotential safety constraints violation during deployment. In this paper, we\npropose a method that leverages run time safety assurance in a kinodynamic\nmotion planning scheme to satisfy the system's operational constraints. First,\nwe use a sampling-based geometric planner to determine a high-level\ncollision-free path within a user-defined space. Second, we design a low-level\nsafety assurance filter to provide safety guarantees to the control input of a\nLinear Quadratic Regulator (LQR) designed with the purpose of trajectory\ntracking. We demonstrate our proposed approach in a restricted 3D simulation\nenvironment using a model of the Crazyflie 2.0 drone.", "AI": {"tldr": "提出了一种结合运行时安全保障和运动学动力学运动规划的无人机导航方法，通过采样几何规划器生成无碰撞路径，并使用低级安全保障滤波器为LQR控制器提供安全保证", "motivation": "现有运动规划技术虽能生成无碰撞轨迹，但在规划过程中未考虑系统安全操作区域，可能导致部署时违反安全约束，而自主无人机在民用应用中的安全操作失败可能造成系统损坏、环境污染甚至人员伤亡", "method": "首先使用基于采样的几何规划器在用户定义空间内确定高级无碰撞路径；然后设计低级安全保障滤波器，为用于轨迹跟踪的线性二次调节器(LQR)的控制输入提供安全保证", "result": "在限制性3D仿真环境中使用Crazyflie 2.0无人机模型验证了所提方法的有效性", "conclusion": "该方法成功将运行时安全保障集成到运动学动力学运动规划中，能够在满足系统操作约束的同时实现安全的无人机导航"}}
{"id": "2507.17727", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.17727", "abs": "https://arxiv.org/abs/2507.17727", "authors": ["Robel Mamo", "Taeyeong Choi"], "title": "CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation", "comment": "Accepted for publication at the 12th European Conference on Mobile\n  Robots (ECMR 2025)", "summary": "State-of-the-art visual under-canopy navigation methods are designed with\ndeep learning-based perception models to distinguish traversable space from\ncrop rows. While these models have demonstrated successful performance, they\nrequire large amounts of training data to ensure reliability in real-world\nfield deployment. However, data collection is costly, demanding significant\nhuman resources for in-field sampling and annotation. To address this\nchallenge, various data augmentation techniques are commonly employed during\nmodel training, such as color jittering, Gaussian blur, and horizontal flip, to\ndiversify training data and enhance model robustness. In this paper, we\nhypothesize that utilizing only these augmentation techniques may lead to\nsuboptimal performance, particularly in complex under-canopy environments with\nfrequent occlusions, debris, and non-uniform spacing of crops. Instead, we\npropose a novel augmentation method, so-called Crop-Aligned Cutout (CA-Cut)\nwhich masks random regions out in input images that are spatially distributed\naround crop rows on the sides to encourage trained models to capture high-level\ncontextual features even when fine-grained information is obstructed. Our\nextensive experiments with a public cornfield dataset demonstrate that\nmasking-based augmentations are effective for simulating occlusions and\nsignificantly improving robustness in semantic keypoint predictions for visual\nnavigation. In particular, we show that biasing the mask distribution toward\ncrop rows in CA-Cut is critical for enhancing both prediction accuracy and\ngeneralizability across diverse environments achieving up to a 36.9% reduction\nin prediction error. In addition, we conduct ablation studies to determine the\nnumber of masks, the size of each mask, and the spatial distribution of masks\nto maximize overall performance.", "AI": {"tldr": "本文提出了一种名为Crop-Aligned Cutout (CA-Cut)的新颖数据增强方法，通过在作物行周围空间分布地遮蔽输入图像中的随机区域，来提高农作物冠层下视觉导航模型的鲁棒性和准确性。", "motivation": "现有的冠层下视觉导航深度学习模型需要大量训练数据来确保在实际田间部署的可靠性，但数据收集成本高昂。传统的数据增强技术（如颜色抖动、高斯模糊等）在复杂的冠层下环境中可能导致次优性能，特别是在频繁遮挡、碎片和作物间距不均匀的情况下。", "method": "提出了Crop-Aligned Cutout (CA-Cut)方法，该方法在输入图像中遮蔽作物行两侧空间分布的随机区域，迫使训练模型即使在细粒度信息被遮挡时也能捕获高级上下文特征。通过将遮蔽分布偏向作物行来增强模型的预测准确性和泛化能力。", "result": "在公共玉米田数据集上的广泛实验表明，基于遮蔽的增强技术能有效模拟遮挡并显著提高视觉导航中语义关键点预测的鲁棒性。CA-Cut方法实现了高达36.9%的预测误差降低，并通过消融研究确定了遮蔽数量、大小和空间分布的最优参数。", "conclusion": "CA-Cut数据增强方法通过将遮蔽分布偏向作物行，能够显著提高冠层下视觉导航模型的预测准确性和跨不同环境的泛化能力，为解决农业机器人导航中的数据稀缺问题提供了有效解决方案。"}}
