<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 38]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Summarizing Normative Driving Behavior From Large-Scale NDS Datasets for Vehicle System Development](https://arxiv.org/abs/2507.16839)
*Gregory Beale,Gibran Ali*

Main category: cs.RO

TL;DR: 本研究开发了一套方法论来处理大规模自然驾驶研究数据，分析了超过3400名驾驶员的3400万英里驾驶数据，从速度、车道保持、跟车距离等五个维度描述驾驶行为，并开发了交互式在线分析工具来可视化不同群体间的驾驶行为差异。


<details>
  <summary>Details</summary>
Motivation: 为了支持车辆安全系统和智能交通系统的开发，需要建立一套系统的方法论来处理大规模自然驾驶研究数据，并描述不同路况、车型和驾驶员人口统计学特征下的规范化驾驶行为模式。

Method: 使用SHRP 2自然驾驶研究数据，结合车辆GPS和前向雷达数据，开发了一套处理大规模NDS数据的方法论。从速度、超速、车道保持、跟车距离和车头时距五个车辆指标维度分析驾驶行为，并根据道路特征、车辆类别和驾驶员人口统计学特征进行情境化分析。同时开发了交互式在线分析工具用于可视化和比较不同群体的驾驶行为。

Result: 基于超过3400名驾驶员的3400万英里驾驶数据，成功生成了各项驾驶指标的汇总分析。研究发现，在65英里限速道路上，16-19岁女性驾驶员超速7.5-15英里的频率略高于同龄男性；年轻驾驶员保持1.5秒以下车头时距的频率高于年长驾驶员。开发的交互式分析工具能够实现动态数据选择和分组比较。

Conclusion: 该研究通过量化规范化驾驶行为，为开发更好的车辆系统和更安全的基础设施提供支持，并提供了一套可用于NDS数据集跨群体比较分析的方法论，有助于车辆安全和智能交通系统的发展。

Abstract: This paper presents a methodology to process large-scale naturalistic driving
studies (NDS) to describe the driving behavior for five vehicle metrics,
including speed, speeding, lane keeping, following distance, and headway,
contextualized by roadway characteristics, vehicle classes, and driver
demographics. Such descriptions of normative driving behaviors can aid in the
development of vehicle safety and intelligent transportation systems. The
methodology is demonstrated using data from the Second Strategic Highway
Research Program (SHRP 2) NDS, which includes over 34 million miles of driving
across more than 3,400 drivers. Summaries of each driving metric were generated
using vehicle, GPS, and forward radar data. Additionally, interactive online
analytics tools were developed to visualize and compare driving behavior across
groups through dynamic data selection and grouping. For example, among drivers
on 65-mph roads for the SHRP 2 NDS, females aged 16-19 exceeded the speed limit
by 7.5 to 15 mph slightly more often than their male counterparts, and younger
drivers maintained headways under 1.5 seconds more frequently than older
drivers. This work supports better vehicle systems and safer infrastructure by
quantifying normative driving behaviors and offers a methodology for analyzing
NDS datasets for cross group comparisons.

</details>


### [2] [AquaChat: An LLM-Guided ROV Framework for Adaptive Inspection of Aquaculture Net Pens](https://arxiv.org/abs/2507.16841)
*Waseem Akram,Muhayy Ud Din,Abdelhaleem Saad,Irfan Hussain*

Main category: cs.RO

TL;DR: 本研究提出了AquaChat框架，通过集成大语言模型(LLM)实现智能化水产养殖网箱检查，采用多层架构设计，能够理解自然语言指令并自适应执行检查任务


<details>
  <summary>Details</summary>
Motivation: 传统的水产养殖网箱检查方法依赖预编程任务或人工控制，对动态水下环境和用户特定需求的适应性有限，缺乏智能化和灵活性

Method: 设计了AquaChat远程操作载具(ROV)框架，采用三层架构：(1)高级规划层使用LLM解释自然语言用户指令生成符号化任务计划；(2)中级任务管理层将计划转换为ROV控制序列；(3)低级运动控制层精确执行导航和检查任务。系统还具备实时反馈和事件触发重规划功能

Result: 通过仿真和受控水生环境实验验证，结果显示任务灵活性、检查精度和操作效率均有显著提升

Conclusion: AquaChat展示了将基于语言的人工智能与海洋机器人技术相结合的潜力，能够实现智能化、用户交互式的检查系统，为可持续水产养殖作业提供支持

Abstract: Inspection of aquaculture net pens is essential for maintaining the
structural integrity, biosecurity, and operational efficiency of fish farming
systems. Traditional inspection approaches rely on pre-programmed missions or
manual control, offering limited adaptability to dynamic underwater conditions
and user-specific demands. In this study, we propose AquaChat, a novel Remotely
Operated Vehicle (ROV) framework that integrates Large Language Models (LLMs)
for intelligent and adaptive net pen inspection. The system features a
multi-layered architecture: (1) a high-level planning layer that interprets
natural language user commands using an LLM to generate symbolic task plans;
(2) a mid-level task manager that translates plans into ROV control sequences;
and (3) a low-level motion control layer that executes navigation and
inspection tasks with precision. Real-time feedback and event-triggered
replanning enhance robustness in challenging aquaculture environments. The
framework is validated through experiments in both simulated and controlled
aquatic environments representative of aquaculture net pens. Results
demonstrate improved task flexibility, inspection accuracy, and operational
efficiency. AquaChat illustrates the potential of integrating language-based AI
with marine robotics to enable intelligent, user-interactive inspection systems
for sustainable aquaculture operations.

</details>


### [3] [Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning](https://arxiv.org/abs/2507.16842)
*Yinan Meng,Kun Qian,Jiong Yang,Renbo Su,Zhenhong Li,Charlie C. L. Wang*

Main category: cs.RO

TL;DR: 本文提出了一种传感器空间模仿学习运动学控制(SS-ILKC)框架，通过双重学习策略和仿真到现实转移机制，解决软体机械臂在执行器饱和和环境约束下的鲁棒运动控制问题。


<details>
  <summary>Details</summary>
Motivation: 冗余软体机械臂虽然具有内在柔顺性和高自由度优势，但在面对未知外部载荷变形和执行器饱和问题时，有效的运动学控制仍然极具挑战性，特别是在受限环境中的零空间调节不当会导致执行器饱和。

Method: 提出SS-ILKC框架，采用双重学习策略：(1)基于强化学习原理的多目标传感器空间控制框架在仿真中训练开放空间的鲁棒控制策略；(2)生成对抗模仿学习方法从稀疏专家演示中学习受限空间的有效策略；(3)设计预处理的仿真到现实转移机制来缓解仿真现实差距并准确表征执行器饱和限制。

Result: 实验结果表明该方法能够有效控制气动软体机械臂，在未知载荷条件下的受限环境中实现精确的路径跟踪和物体操作任务。

Conclusion: SS-ILKC框架成功解决了软体机械臂在执行器饱和和环境约束条件下的鲁棒运动控制问题，实现了从仿真到现实的零样本部署，为软体机械臂在复杂环境中的实际应用提供了有效的控制解决方案。

Abstract: The intrinsic compliance and high degree of freedom (DoF) of redundant soft
manipulators facilitate safe interaction and flexible task execution. However,
effective kinematic control remains highly challenging, as it must handle
deformations caused by unknown external loads and avoid actuator saturation due
to improper null-space regulation - particularly in confined environments. In
this paper, we propose a Sensor-Space Imitation Learning Kinematic Control
(SS-ILKC) framework to enable robust kinematic control under actuator
saturation and restrictive environmental constraints. We employ a dual-learning
strategy: a multi-goal sensor-space control framework based on reinforcement
learning principle is trained in simulation to develop robust control policies
for open spaces, while a generative adversarial imitation learning approach
enables effective policy learning from sparse expert demonstrations for
confined spaces. To enable zero-shot real-world deployment, a pre-processed
sim-to-real transfer mechanism is proposed to mitigate the
simulation-to-reality gap and accurately characterize actuator saturation
limits. Experimental results demonstrate that our method can effectively
control a pneumatically actuated soft manipulator, achieving precise
path-following and object manipulation in confined environments under unknown
loading conditions.

</details>


### [4] [Analytical Formulation of Autonomous Vehicle Freeway Merging Control with State-Dependent Discharge Rates](https://arxiv.org/abs/2507.16846)
*Qing Tang,Xianbiao Hu*

Main category: cs.RO

TL;DR: 本文针对高速公路匝道汇入控制问题，提出了一种考虑多阶段动态汇入过程的分析方法，通过动态规划模型同时优化交通效率和安全性，在NGSIM数据集上验证了所提方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的高速公路汇入控制模型忽略了交叉交通对流量的影响，未能准确反映拥堵时汇入点流量下降的实际情况。现有方法缺乏对多阶段动态汇入过程的精确建模，难以同时优化交通效率和安全性。

Method: 首次通过闭式公式解析推导了受多阶段动态汇入过程影响的有效排放率；建立了队列长度和交通延误的性能指标；构建了碰撞风险函数来定量评估汇入过程中的潜在碰撞；将问题表述为动态规划模型，以汇入位置和速度为决策变量，采用反向归纳法求解最小成本方案。

Result: 使用NGSIM数据集验证了推导的有效排放率的准确性；提出的模型在性能上优于两种基准算法；实现了更高效和更安全的汇入过程，同时减少了延误和碰撞风险。

Conclusion: 本文成功建立了考虑多阶段动态汇入的分析框架，能够准确建模汇入点的有效排放率，并通过动态规划方法实现了交通效率和安全性的联合优化，为自动驾驶车辆的高速公路汇入控制提供了有效解决方案。

Abstract: The core of the freeway merging control problem lies in dynamic queue
propagation and dissipation linked to merging vehicle behavior. Traditionally,
queuing is modeled through demand-supply interactions with time varying demand
and fixed capacity. However, field observations show flow rates decrease during
congestion at freeway merges due to the impact of intersecting traffic, a
factor overlooked in fundamental diagrams. This manuscript introduces an
analytical approach to characterize and control the dynamic multi-stage merging
of autonomous vehicles, prioritizing traffic efficiency and safety. For the
first time, the effective discharge rate at the merging point, reduced by the
multi-stage dynamic merging process, is analytically derived using a closed
form formulation. Leveraging this expression, performance metrics such as queue
length and traffic delay are derived as the first objective. Additionally, a
crash risk function is established to quantitatively assess potential
collisions during the merging process, serving as the second objective.
Finally, the problem is formulated as a dynamic programming model to jointly
minimize delay and crash risk, with the merging location and speed as decision
variables. Given the terminal state, the ramp vehicle merging task is
formulated as a recursive optimization problem, employing backward induction to
find the minimum cost solution. Numerical experiments using the NGSIM dataset
validate the derived effective discharge rate. The results indicate that the
proposed model outperforms two benchmark algorithms, leading to a more
efficient and safer merging process.

</details>


### [5] [MobileUse: A GUI Agent with Hierarchical Reflection for Autonomous Mobile Operation](https://arxiv.org/abs/2507.16853)
*Ning Li,Xiangmou Qu,Jiamu Zhou,Jun Wang,Muning Wen,Kounianhua Du,Xingyu Lou,Qiuying Peng,Jun Wang,Weinan Zhang*

Main category: cs.RO

TL;DR: 本文提出了MobileUse，一个用于移动设备任务自动化执行的GUI智能体，通过分层反思架构和主动探索模块解决长期任务执行、错误恢复和冷启动问题，在AndroidWorld和AndroidLab基准测试中达到了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在移动设备应用中面临长期任务执行困难、错误恢复能力差以及在陌生环境中的冷启动问题，需要开发更加鲁棒和自适应的移动任务执行智能体。

Method: 提出MobileUse GUI智能体，包含两个核心模块：1）分层反思架构，能够在多个时间尺度上进行自我监控、错误检测和恢复，采用按需反思策略保持效率；2）主动探索模块，通过自主规划的探索来丰富智能体对环境的理解，解决冷启动问题。

Result: 在AndroidWorld和AndroidLab基准测试中取得了最先进的性能，成功率分别达到62.9%和44.2%。发布了用于物理移动设备自动化任务执行的开箱即用工具包。

Conclusion: MobileUse通过分层反思架构和主动探索模块有效解决了移动智能体面临的关键挑战，在基准测试中达到了新的最先进性能，为移动设备任务自动化提供了实用的解决方案。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled the
development of mobile agents that can understand visual inputs and follow user
instructions, unlocking new possibilities for automating complex tasks on
mobile devices. However, applying these models to real-world mobile scenarios
remains a significant challenge due to the long-horizon task execution,
difficulty in error recovery, and the cold-start problem in unfamiliar
environments. To address these challenges, we propose MobileUse, a GUI agent
designed for robust and adaptive mobile task execution. To improve resilience
in long-horizon tasks and dynamic environments, we introduce a hierarchical
reflection architecture that enables the agent to self-monitor, detect, and
recover from errors across multiple temporal scales-ranging from individual
actions to overall task completion-while maintaining efficiency through a
reflection-on-demand strategy. To tackle cold-start issues, we further
introduce a proactive exploration module, which enriches the agent's
understanding of the environment through self-planned exploration. Evaluations
on AndroidWorld and AndroidLab benchmarks demonstrate that MobileUse
establishes new state-of-the-art performance, achieving success rates of 62.9%
and 44.2%, respectively. To facilitate real-world applications, we release an
out-of-the-box toolkit for automated task execution on physical mobile devices,
which is available at https://github.com/MadeAgents/mobile-use.

</details>


### [6] [Leveraging multi-source and heterogeneous signals for fatigue detection](https://arxiv.org/abs/2507.16859)
*Luobin Cui,Yanlai Wu,Tang Ying,Weikai Li*

Main category: cs.RO

TL;DR: 提出了一个异构多源疲劳检测框架，能够在传感器受限的真实环境中有效监测疲劳状态，通过利用不同配置源域的知识来提升目标域的检测性能


<details>
  <summary>Details</summary>
Motivation: 现有疲劳检测方法依赖高端传感器和受控环境，在真实世界应用中存在局限性。需要开发能够在传感器受限场景下工作的实用疲劳检测系统，特别是在航空、采矿、长途运输等安全关键应用中

Method: 提出异构多源疲劳检测框架，该框架能够自适应地利用目标域中可用的模态，同时从源域的多样化传感器配置中获益。通过知识迁移的方式，将高端传感器在受控环境下获得的知识应用到实际部署的低成本传感器系统中

Result: 在真实部署的传感器设置和两个公开数据集上进行实验验证，结果表明该方法具有实用性、鲁棒性和更好的泛化能力，能够在传感器受限场景下实现有效的疲劳监测

Conclusion: 该框架为在传感器受限的真实世界场景中进行有效疲劳监测铺平了实用道路，解决了现有方法在实际应用中的局限性问题，提升了疲劳检测系统的实用性和可部署性

Abstract: Fatigue detection plays a critical role in safety-critical applications such
as aviation, mining, and long-haul transport. However, most existing methods
rely on high-end sensors and controlled environments, limiting their
applicability in real world settings. This paper formally defines a practical
yet underexplored problem setting for real world fatigue detection, where
systems operating with context-appropriate sensors aim to leverage knowledge
from differently instrumented sources including those using impractical sensors
deployed in controlled environments. To tackle this challenge, we propose a
heterogeneous and multi-source fatigue detection framework that adaptively
utilizes the available modalities in the target domain while benefiting from
the diverse configurations present in source domains. Our experiments,
conducted using a realistic field-deployed sensor setup and two publicly
available datasets, demonstrate the practicality, robustness, and improved
generalization of our approach, paving the practical way for effective fatigue
monitoring in sensor-constrained scenarios.

</details>


### [7] [ResKACNNet: A Residual ChebyKAN Network for Inertial Odometry](https://arxiv.org/abs/2507.16865)
*Shanshan Zhang,Tianshui Wen,Siyue Wang,Qi Zhang,Ziheng Zhou,Huiru Zheng,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出了一种基于ResChebyKAN骨干网络和EKSA模块的惯性定位方法，通过切比雪夫多项式建模复杂运动模式，并有效捕获长期依赖关系，在多个公开数据集上显著降低了轨迹误差。


<details>
  <summary>Details</summary>
Motivation: 传统基于CNN的惯性定位方法难以捕获IMU数据中的非线性运动特征和长期依赖关系，需要开发新的方法来提高低成本精确定位的性能。

Method: 提出ResChebyKAN惯性定位网络，利用切比雪夫多项式的非线性逼近能力建模复杂运动模式，并引入高效核自注意力（EKSA）模块来捕获上下文信息和增强长期依赖建模。

Result: 在RIDI、RoNIN、RNIN-VIO、OxIOD、IMUNet和TLIO等公开数据集上，相比现有基准方法，绝对轨迹误差降低了3.79%到42.32%。实验还表明去除加速度数据中的重力分量可显著提升定位性能。

Conclusion: 基于ResChebyKAN的惯性定位网络能够有效处理IMU数据的非线性特征和长期依赖关系，在多个数据集上取得了显著的性能提升，为低成本精确惯性定位提供了新的解决方案。

Abstract: Inertial Measurement Unit (IMU) has become a key technology for achieving
low-cost and precise positioning. However, traditional CNN-based inertial
positioning methods struggle to capture the nonlinear motion characteristics
and long-term dependencies in IMU data. To address this limitation, we propose
a novel inertial positioning network with a generic backbone called
ResChebyKAN, which leverages the nonlinear approximation capabilities of
Chebyshev polynomials to model complex motion patterns. Additionally, we
introduce an Efficient Kernel-based Self-Attention (EKSA) module to effectively
capture contextual information and enhance long-term dependency modeling.
Experimental results on public datasets (e.g., RIDI, RoNIN, RNIN-VIO, OxIOD,
IMUNet, and TLIO) demonstrate that our method reduces the absolute trajectory
error by 3.79% to 42.32% compared to existing benchmark methods. Furthermore,
we release a preprocessed dataset and empirically show that removing the
gravity component from acceleration data significantly improves inertial
positioning performance.

</details>


### [8] [Multi-agent Reinforcement Learning for Robotized Coral Reef Sample Collection](https://arxiv.org/abs/2507.16941)
*Daniel Correa,Tero Kaarlela,Jose Fuentes,Paulo Padrao,Alain Duran,Leonardo Bobadilla*

Main category: cs.RO

TL;DR: 本文提出了一种用于开发水下机器人珊瑚采样智能体的强化学习环境，通过软件在环和硬件在环的方式，结合数字孪生技术在仿真中训练AI控制器，并在物理实验中验证。该方法的创新点在于将通用游戏引擎、深度强化学习和实时水下动作捕捉系统相结合，实现了有效的零样本仿真到现实转移策略。


<details>
  <summary>Details</summary>
Motivation: 珊瑚礁保护和研究需要自主水下机器人进行珊瑚采样任务，这是一项对海洋生态保护至关重要的工作。传统方法可能存在效率低、精度不够等问题，因此需要开发智能化的水下机器人系统来执行精确的珊瑚采样任务。

Method: 采用强化学习环境开发自主水下机器人珊瑚采样智能体。使用软件在环(SIL)和硬件在环(HIL)方法，在数字孪生仿真环境中训练强化学习AI控制器。结合通用游戏引擎进行仿真、深度强化学习算法，以及实时水下动作捕捉(MOCAP)系统提供3D位置和姿态反馈，实现数字域和物理域之间的精确同步。

Result: 成功开发了基于强化学习的水下机器人AI控制器，并通过物理实验验证了其有效性。水下动作捕捉系统能够提供实时的3D位置和姿态反馈，确保了数字孪生和物理实验之间的精确同步，实现了有效的零样本仿真到现实转移。

Conclusion: 该研究成功展示了将通用游戏引擎、深度强化学习和实时水下动作捕捉技术相结合的可行性，为水下机器人珊瑚采样任务提供了一种有效的智能化解决方案。这种零样本仿真到现实的策略为海洋机器人技术的发展和珊瑚礁保护研究提供了新的技术途径。

Abstract: This paper presents a reinforcement learning (RL) environment for developing
an autonomous underwater robotic coral sampling agent, a crucial coral reef
conservation and research task. Using software-in-the-loop (SIL) and
hardware-in-the-loop (HIL), an RL-trained artificial intelligence (AI)
controller is developed using a digital twin (DT) in simulation and
subsequently verified in physical experiments. An underwater motion capture
(MOCAP) system provides real-time 3D position and orientation feedback during
verification testing for precise synchronization between the digital and
physical domains. A key novelty of this approach is the combined use of a
general-purpose game engine for simulation, deep RL, and real-time underwater
motion capture for an effective zero-shot sim-to-real strategy.

</details>


### [9] [RAPTAR: Radar Radiation Pattern Acquisition through Automated Collaborative Robotics](https://arxiv.org/abs/2507.16988)
*Maaz Qureshi,Mohammad Omid Bagheri,Abdelrahman Elbadrawy,William Melek,George Shaker*

Main category: cs.RO

TL;DR: 该研究提出了RAPTAR系统，一个基于协作机器人的便携式自主系统，用于集成雷达模块的3D辐射方向图测量，无需专用消声室设施。


<details>
  <summary>Details</summary>
Motivation: 现有的探针台技术在片上天线表征方面存在角度覆盖有限、依赖定制硬件、需要频繁手动对准等挑战，且传统测量设置在车辆、无人机、AR/VR头戴设备和生物医学设备等真实世界配置中不实用。

Method: 使用7自由度Franka协作机器人持有接收探头，在半球形空间域内执行无碰撞操作，通过实时运动规划和校准实现精确控制，RMS误差低于0.9毫米，角度分辨率可达2.5度，并与RF仪器无缝集成进行近场和远场功率测量。

Result: 对60 GHz雷达模块的实验扫描显示，与全波电磁仿真基准相比，平均绝对误差小于2 dB。与基线方法相比，RAPTAR系统的平均绝对误差降低了36.5%。

Conclusion: RAPTAR系统成功实现了集成雷达模块的高精度、可重复的3D辐射方向图测量，为现代片上天线表征提供了一种便携式、自主化的解决方案，特别适用于传统测量设置不可行的复杂实际应用场景。

Abstract: Accurate characterization of modern on-chip antennas remains challenging, as
current probe-station techniques offer limited angular coverage, rely on
bespoke hardware, and require frequent manual alignment. This research
introduces RAPTAR (Radiation Pattern Acquisition through Robotic Automation), a
portable, state-of-the-art, and autonomous system based on collaborative
robotics. RAPTAR enables 3D radiation-pattern measurement of integrated radar
modules without dedicated anechoic facilities. The system is designed to
address the challenges of testing radar modules mounted in diverse real-world
configurations, including vehicles, UAVs, AR/VR headsets, and biomedical
devices, where traditional measurement setups are impractical. A
7-degree-of-freedom Franka cobot holds the receiver probe and performs
collision-free manipulation across a hemispherical spatial domain, guided by
real-time motion planning and calibration accuracy with RMS error below 0.9 mm.
The system achieves an angular resolution upto 2.5 degree and integrates
seamlessly with RF instrumentation for near- and far-field power measurements.
Experimental scans of a 60 GHz radar module show a mean absolute error of less
than 2 dB compared to full-wave electromagnetic simulations ground truth.
Benchmarking against baseline method demonstrates 36.5% lower mean absolute
error, highlighting RAPTAR accuracy and repeatability.

</details>


### [10] [Shared Control of Holonomic Wheelchairs through Reinforcement Learning](https://arxiv.org/abs/2507.17055)
*Jannis Bähler,Diego Paez-Granados,Jorge Peña-Queralta*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的智能电动轮椅共享控制方法，能够将用户的2D输入转换为3D运动，在确保安全导航的同时提升用户舒适度并降低认知负荷


<details>
  <summary>Details</summary>
Motivation: 现有的全向系统共享控制方法往往导致用户体验不直观，未能充分利用全向驾驶的潜力，因此需要开发更好的智能轮椅共享控制系统来改善用户体验

Method: 采用强化学习方法，接收2D用户输入并输出3D运动控制；在Isaac Gym中训练，在Gazebo中仿真测试；比较不同的强化学习智能体架构和奖励函数；最终进行仿真到真实环境的迁移

Result: 实现了无碰撞导航，智能控制轮椅方向，在平滑性方面表现优于或与非学习方法相当；成功完成仿真到真实环境的迁移，实现了首个基于强化学习的全向移动平台共享控制真实世界应用

Conclusion: 该方法成功地为全向智能轮椅开发了基于强化学习的共享控制系统，在保证安全性的同时提升了用户舒适度和操作直观性，并首次在真实环境中验证了该技术的可行性

Abstract: Smart electric wheelchairs can improve user experience by supporting the
driver with shared control. State-of-the-art work showed the potential of
shared control in improving safety in navigation for non-holonomic robots.
However, for holonomic systems, current approaches often lead to unintuitive
behavior for the user and fail to utilize the full potential of omnidirectional
driving. Therefore, we propose a reinforcement learning-based method, which
takes a 2D user input and outputs a 3D motion while ensuring user comfort and
reducing cognitive load on the driver. Our approach is trained in Isaac Gym and
tested in simulation in Gazebo. We compare different RL agent architectures and
reward functions based on metrics considering cognitive load and user comfort.
We show that our method ensures collision-free navigation while smartly
orienting the wheelchair and showing better or competitive smoothness compared
to a previous non-learning-based method. We further perform a sim-to-real
transfer and demonstrate, to the best of our knowledge, the first real-world
implementation of RL-based shared control for an omnidirectional mobility
platform.

</details>


### [11] [Deformable Cluster Manipulation via Whole-Arm Policy Learning](https://arxiv.org/abs/2507.17085)
*Jayadeep Jacob,Wenzheng Zhang,Houston Warren,Paulo Borges,Tirthankar Bandyopadhyay,Fabio Ramos*

Main category: cs.RO

TL;DR: 本文提出了一个新颖的无模型强化学习框架，结合3D点云和本体感觉触觉指示器，用于操作可变形物体集群，特别是在电力线路清理场景中实现了创新的全臂接触策略和零样本仿真到现实的策略迁移。


<details>
  <summary>Details</summary>
Motivation: 操作可变形物体集群面临重大挑战，需要接触丰富的全臂交互。现有方法在真实模型合成能力有限、感知不确定性高、缺乏高效空间抽象等方面存在不足，传统的末端执行器操作模式无法满足复杂的接触感知需求。

Method: 提出了一个结合3D点云和本体感觉触觉指示器的无模型强化学习框架，强调具有全身接触感知的操作。采用分布式状态表示和核均值嵌入来提高训练效率和实时推理能力。同时提出了一种新颖的上下文无关遮挡启发式算法，用于清理目标区域的可变形物体。

Result: 在电力线路清理场景中部署该框架，智能体生成了利用多个手臂连接进行去遮挡的创新策略。实现了零样本仿真到现实的策略迁移，使机械臂能够清理具有未知遮挡模式、未见拓扑结构和不确定动力学的真实树枝。

Conclusion: 该框架成功解决了可变形物体集群操作的关键挑战，通过多模态感知和全臂接触策略，在复杂的现实场景中展现了良好的适应性和泛化能力，为接触丰富的机器人操作任务提供了有效解决方案。

Abstract: Manipulating clusters of deformable objects presents a substantial challenge
with widespread applicability, but requires contact-rich whole-arm
interactions. A potential solution must address the limited capacity for
realistic model synthesis, high uncertainty in perception, and the lack of
efficient spatial abstractions, among others. We propose a novel framework for
learning model-free policies integrating two modalities: 3D point clouds and
proprioceptive touch indicators, emphasising manipulation with full body
contact awareness, going beyond traditional end-effector modes. Our
reinforcement learning framework leverages a distributional state
representation, aided by kernel mean embeddings, to achieve improved training
efficiency and real-time inference. Furthermore, we propose a novel
context-agnostic occlusion heuristic to clear deformables from a target region
for exposure tasks. We deploy the framework in a power line clearance scenario
and observe that the agent generates creative strategies leveraging multiple
arm links for de-occlusion. Finally, we perform zero-shot sim-to-real policy
transfer, allowing the arm to clear real branches with unknown occlusion
patterns, unseen topology, and uncertain dynamics.

</details>


### [12] [MARSCalib: Multi-robot, Automatic, Robust, Spherical Target-based Extrinsic Calibration in Field and Extraterrestrial Environments](https://arxiv.org/abs/2507.17130)
*Seokhwan Jeong,Hogyun Kim,Younggun Cho*

Main category: cs.RO

TL;DR: 本文提出了一种基于球形目标的LiDAR-相机外参标定方法，适用于多机器人系统的户外环境，能够处理目标和传感器的损坏情况。


<details>
  <summary>Details</summary>
Motivation: 在户外多机器人系统中，需要一种鲁棒的LiDAR-相机外参标定方法，能够应对目标物体和传感器损坏的情况，现有方法在这些挑战性环境下表现不佳。

Method: 使用球形目标进行标定：1）通过SAM模型分解图像并提取椭圆中心，对透视投影误差进行校正；2）对LiDAR点云使用分层加权求和方法提取球心，以应对球面缺乏平坦区域导致的噪声问题；3）将2D椭圆中心与3D球心配对计算变换矩阵。

Result: 在三种不同类型的LiDAR（旋转式、固态式、非重复式）和三个不同位置的相机上进行测试，球形目标在两种损坏情况下都能被鲁棒检测，性能优于其他目标。在行星测试和野外环境中验证了方法对目标损坏的鲁棒性。

Conclusion: 所提出的球形目标标定方法在处理目标和传感器损坏方面表现出色，为户外多机器人系统提供了一种可靠的LiDAR-相机外参标定解决方案，具有良好的鲁棒性和适用性。

Abstract: This paper presents a novel spherical target-based LiDAR-camera extrinsic
calibration method designed for outdoor environments with multi-robot systems,
considering both target and sensor corruption. The method extracts the 2D
ellipse center from the image and the 3D sphere center from the pointcloud,
which are then paired to compute the transformation matrix. Specifically, the
image is first decomposed using the Segment Anything Model (SAM). Then, a novel
algorithm extracts an ellipse from a potentially corrupted sphere, and the
extracted center of ellipse is corrected for errors caused by the perspective
projection model. For the LiDAR pointcloud, points on the sphere tend to be
highly noisy due to the absence of flat regions. To accurately extract the
sphere from these noisy measurements, we apply a hierarchical weighted sum to
the accumulated pointcloud. Through experiments, we demonstrated that the
sphere can be robustly detected even under both types of corruption,
outperforming other targets. We evaluated our method using three different
types of LiDARs (spinning, solid-state, and non-repetitive) with cameras
positioned in three different locations. Furthermore, we validated the
robustness of our method to target corruption by experimenting with spheres
subjected to various types of degradation. These experiments were conducted in
both a planetary test and a field environment. Our code is available at
https://github.com/sparolab/MARSCalib.

</details>


### [13] [Dynamic Modeling and Dimensional Optimization of Legged Mechanisms for Construction Robot](https://arxiv.org/abs/2507.17132)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文提出了一种基于蚂蚁腿部结构的建筑机器人腿部设计和优化方法，通过拉格朗日动力学建模和几何参数优化，实现了关节扭矩和能耗降低20%以上，为重载高性能建筑机器人提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 建筑行业快速发展中面临恶劣工作环境、高强度高风险任务和劳动力短缺等问题，迫切需要低能耗、高机动性和高负载能力的建筑机器人，因此需要对机器人腿部结构进行设计优化以提升动态性能、降低能耗并增强承载能力。

Method: 基于自然界蚂蚁的腿部构型设计机器人腿部结构，提出新颖的结构优化方法，采用拉格朗日方法建立腿部动力学模型，结合腿部运动轨迹制定多个动态评估指标，对各腿段几何参数进行综合优化研究。

Result: 优化后的腿部结构使峰值关节扭矩和能耗降低超过20%，ADAMS动力学仿真实验显示优化后各关节驱动功率显著降低，验证了所提策略的有效性和合理性。

Conclusion: 该研究为重载、高性能建筑机器人的设计提供了理论基础和技术支撑，证明了基于仿生学的腿部结构优化方法在提升建筑机器人性能方面的有效性。

Abstract: With the rapid development of the construction industry, issues such as harsh
working environments, high-intensity and high-risk tasks, and labor shortages
have become increasingly prominent. This drives higher demands for construction
robots in terms of low energy consumption, high mobility, and high load
capacity. This paper focuses on the design and optimization of leg structures
for construction robots, aiming to improve their dynamic performance, reduce
energy consumption, and enhance load-bearing capabilities. Firstly, based on
the leg configuration of ants in nature, we design a structure for the robot's
leg. Secondly, we propose a novel structural optimization method. Using the
Lagrangian approach, a dynamic model of the leg was established. Combining the
dynamic model with the leg's motion trajectory, we formulated multiple dynamic
evaluation metrics and conducted a comprehensive optimization study on the
geometric parameters of each leg segment. The results show that the optimized
leg structure reduces peak joint torques and energy consumption by over 20%.
Finally, dynamic simulation experiments were conducted using ADAMS. The results
demonstrate a significant reduction in the driving power of each joint after
optimization, validating the effectiveness and rationality of the proposed
strategy. This study provides a theoretical foundation and technical support
for the design of heavy-load, high-performance construction robots.

</details>


### [14] [Dynamic Parameter Identification of a Curtain Wall Installation Robotic Arm](https://arxiv.org/abs/2507.17136)
*Xiao Liu,Yunxiao Cheng,Weijun Wang,Tianlun Huang,Wei Feng*

Main category: cs.RO

TL;DR: 本文设计了一种液压驱动的幕墙安装机械臂，并提出了动态参数识别方法，通过建立D-H模型和液压缸动力学集成的复合参数系统，使用分层递进参数识别策略，实现了高精度的动态参数识别，提升了幕墙安装作业的智能化水平。


<details>
  <summary>Details</summary>
Motivation: 传统建筑施工方法无法满足现代对效率和质量的需求，幕墙安装是建筑项目的关键组成部分，需要提高幕墙安装作业的智能化水平和精度。

Method: 设计液压驱动的幕墙安装机械臂；建立基于D-H模型的复合参数系统，集成液压缸动力学和Stribeck摩擦模型；设计高信噪比位移激励信号和最优激励轨迹；提出分层递进参数识别策略，采用最小二乘估计分别识别和联合标定液压缸和机械臂的动态参数。

Result: 在机械臂平台上的实验验证显示，理论与测量关节力矩之间的残余标准偏差低于0.4 Nm，确认了液压驱动幕墙安装机械臂的高精度动态参数识别效果。

Conclusion: 该方法有效实现了液压驱动幕墙安装机械臂的高精度动态参数识别，显著提升了幕墙安装作业的智能化水平，为建筑行业的自动化发展做出了重要贡献。

Abstract: In the construction industry, traditional methods fail to meet the modern
demands for efficiency and quality. The curtain wall installation is a critical
component of construction projects. We design a hydraulically driven robotic
arm for curtain wall installation and a dynamic parameter identification
method. We establish a Denavit-Hartenberg (D-H) model based on measured robotic
arm structural parameters and integrate hydraulic cylinder dynamics to
construct a composite parametric system driven by a Stribeck friction model. By
designing high-signal-to-noise ratio displacement excitation signals for
hydraulic cylinders and combining Fourier series to construct optimal
excitation trajectories that satisfy joint constraints, this method effectively
excites the characteristics of each parameter in the minimal parameter set of
the dynamic model of the robotic arm. On this basis, a hierarchical progressive
parameter identification strategy is proposed: least squares estimation is
employed to separately identify and jointly calibrate the dynamic parameters of
both the hydraulic cylinder and the robotic arm, yielding Stribeck model curves
for each joint. Experimental validation on a robotic arm platform demonstrates
residual standard deviations below 0.4 Nm between theoretical and measured
joint torques, confirming high-precision dynamic parameter identification for
the hydraulic-driven curtain wall installation robotic arm. This significantly
contributes to enhancing the intelligence level of curtain wall installation
operations.

</details>


### [15] [Multi-Objective Trajectory Planning for a Robotic Arm in Curtain Wall Installation](https://arxiv.org/abs/2507.17140)
*Xiao Liu,Yunxiao Cheng,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文针对幕墙安装任务提出了一种改进的多目标轨迹优化算法NSGA-III-FO，设计了集成串联、并联和折叠臂元素的机械臂，通过引入聚焦算子筛选机制提高算法收敛效率，实验验证了该方法在建筑机器人轨迹规划中的有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 在劳动力短缺和成本上升的背景下，建筑机器人被视为革新传统建筑方法、提高建筑行业效率和质量的关键。传统单目标轨迹优化方法难以满足复杂多变建筑环境的复杂需求，因此需要开发适用于幕墙安装的多目标轨迹优化方法。

Method: 设计了集成串联、并联和折叠臂元素的幕墙安装机械臂，考虑其物理特性和运动特征。提出了NSGA-III-FO算法（带聚焦算子的NSGA-III），通过引入聚焦算子筛选机制加速算法向帕累托前沿收敛，有效平衡建筑机器人的多目标约束。

Result: 在DTLZ3和WFG3测试函数上进行的十次连续试验中，NSGA-III-FO算法相比NSGA-III、MOEA/D和MSOPS-II表现出显著更好的收敛效率。在设计的机械臂平台上进行的两组实验验证了算法在幕墙安装任务多目标轨迹规划问题中的效率和实用性。

Conclusion: NSGA-III-FO算法通过聚焦算子筛选机制有效提高了多目标轨迹优化的收敛效率，能够有效解决建筑机器人在复杂环境中的多目标轨迹规划问题，为幕墙安装机器人的实际应用提供了可行的技术方案。

Abstract: In the context of labor shortages and rising costs, construction robots are
regarded as the key to revolutionizing traditional construction methods and
improving efficiency and quality in the construction industry. In order to
ensure that construction robots can perform tasks efficiently and accurately in
complex construction environments, traditional single-objective trajectory
optimization methods are difficult to meet the complex requirements of the
changing construction environment. Therefore, we propose a multi-objective
trajectory optimization for the robotic arm used in the curtain wall
installation. First, we design a robotic arm for curtain wall installation,
integrating serial, parallel, and folding arm elements, while considering its
physical properties and motion characteristics. In addition, this paper
proposes an NSGA-III-FO algorithm (NSGA-III with Focused Operator, NSGA-III-FO)
that incorporates a focus operator screening mechanism to accelerate the
convergence of the algorithm towards the Pareto front, thereby effectively
balancing the multi-objective constraints of construction robots. The proposed
algorithm is tested against NSGA-III, MOEA/D, and MSOPS-II in ten consecutive
trials on the DTLZ3 and WFG3 test functions, showing significantly better
convergence efficiency than the other algorithms. Finally, we conduct two sets
of experiments on the designed robotic arm platform, which confirm the
efficiency and practicality of the NSGA-III-FO algorithm in solving
multi-objective trajectory planning problems for curtain wall installation
tasks.

</details>


### [16] [Towards Human-level Intelligence via Human-like Whole-Body Manipulation](https://arxiv.org/abs/2507.17141)
*Guang Gao,Jianan Wang,Jinbo Zuo,Junnan Jiang,Jingfan Zhang,Xianwen Zeng,Yuejiang Zhu,Lianyang Ma,Ke Chen,Minhua Sheng,Ruirui Zhang,Zhaohui An*

Main category: cs.RO

TL;DR: Astribot Suite是一个机器人学习套件，通过模仿人类行为和全身操控来实现通用智能机器人，整合了安全硬件、直观遥操作界面和全身视觉运动策略学习算法。


<details>
  <summary>Details</summary>
Motivation: 构建通用智能机器人是机器人学的基本目标。研究者希望模仿人类进化轨迹，通过与环境的持续交互学习，并通过模仿人类行为来驱动早期进展。这需要解决安全硬件设计、可扩展遥操作界面开发和全身视觉运动策略学习三大核心挑战。

Method: 提出Astribot Suite统一框架，包含三个核心组件：(1) 设计具有人类级别物理能力的安全机器人硬件；(2) 开发直观且可扩展的全身遥操作界面用于数据收集；(3) 创建能够从人类演示中学习全身视觉运动策略的算法。通过这三个组件的整合来实现全身操控学习。

Result: 系统在需要全身协调、广泛可达性、人类级别灵巧性和敏捷性的各种活动中展现了有效性。Astribot实现了embodiment（具身化）、遥操作界面和学习管道的cohesive integration（紧密整合），能够处理不同环境中的通用日常任务。

Conclusion: Astribot Suite在实现真实世界通用全身机器人操控方面迈出了重要一步，为下一代智能机器人奠定了基础。该系统成功整合了硬件、接口和算法三个关键组件，为通用机器人操控提供了可行的解决方案。

Abstract: Building general-purpose intelligent robots has long been a fundamental goal
of robotics. A promising approach is to mirror the evolutionary trajectory of
humans: learning through continuous interaction with the environment, with
early progress driven by the imitation of human behaviors. Achieving this goal
presents three core challenges: (1) designing safe robotic hardware with
human-level physical capabilities; (2) developing an intuitive and scalable
whole-body teleoperation interface for data collection; and (3) creating
algorithms capable of learning whole-body visuomotor policies from human
demonstrations. To address these challenges in a unified framework, we propose
Astribot Suite, a robot learning suite for whole-body manipulation aimed at
general daily tasks across diverse environments. We demonstrate the
effectiveness of our system on a wide range of activities that require
whole-body coordination, extensive reachability, human-level dexterity, and
agility. Our results show that Astribot's cohesive integration of embodiment,
teleoperation interface, and learning pipeline marks a significant step towards
real-world, general-purpose whole-body robotic manipulation, laying the
groundwork for the next generation of intelligent robots.

</details>


### [17] [Falconry-like palm landing by a flapping-wing drone based on the human gesture interaction and distance-aware flight planning](https://arxiv.org/abs/2507.17144)
*Kazuki Numazato,Keiichiro Kan,Masaki Kitagawa,Yunong Li,Johannes Kubel,Moju Zhao*

Main category: cs.RO

TL;DR: 本研究首次实现了扑翼无人机与人类的接触式交互，开发了一个仿鹰猎人的交互系统，使扑翼无人机能够安全地降落在人类手掌上。


<details>
  <summary>Details</summary>
Motivation: 扑翼无人机因其低噪音和柔性翅膀等特性被认为更适合人机交互，但缺乏实际的人机交互研究。研究者从鹰猎人引导猛禽降落在手臂上的行为中获得启发，希望将人体作为动态降落平台，在拥挤或空间受限的环境中实现应用。

Method: 设计了一个仿鹰猎人的交互系统，开发了考虑人类安全物理和心理因素（如无人机速度和与用户距离）的轨迹规划方法，使扑翼无人机能够在人类手掌上执行降落动作。使用商业扑翼平台实现运动规划并进行实验评估。

Result: 实验结果表明该方法能够实现安全、平稳的手部降落交互。成功验证了扑翼无人机手掌降落的性能和安全性。

Conclusion: 这是首次实现扑翼无人机与人类之间基于接触的交互，为人机交互领域开辟了新的可能性，特别是在需要近距离接触的应用场景中具有重要意义。

Abstract: Flapping-wing drones have attracted significant attention due to their
biomimetic flight. They are considered more human-friendly due to their
characteristics such as low noise and flexible wings, making them suitable for
human-drone interactions. However, few studies have explored the practical
interaction between humans and flapping-wing drones. On establishing a physical
interaction system with flapping-wing drones, we can acquire inspirations from
falconers who guide birds of prey to land on their arms. This interaction
interprets the human body as a dynamic landing platform, which can be utilized
in various scenarios such as crowded or spatially constrained environments.
Thus, in this study, we propose a falconry-like interaction system in which a
flapping-wing drone performs a palm landing motion on a human hand. To achieve
a safe approach toward humans, we design a trajectory planning method that
considers both physical and psychological factors of the human safety such as
the drone's velocity and distance from the user. We use a commercial flapping
platform with our implemented motion planning and conduct experiments to
evaluate the palm landing performance and safety. The results demonstrate that
our approach enables safe and smooth hand landing interactions. To the best of
our knowledge, it is the first time to achieve a contact-based interaction
between flapping-wing drones and humans.

</details>


### [18] [JAM: Keypoint-Guided Joint Prediction after Classification-Aware Marginal Proposal for Multi-Agent Interaction](https://arxiv.org/abs/2507.17152)
*Fangze Lin,Ying He,Fei Yu,Hong Zhang*

Main category: cs.RO

TL;DR: 提出了一个名为JAM的两阶段多智能体交互预测框架，通过分类感知的边际提议和关键点引导的联合预测来解决自动驾驶中低概率模式生成质量差的问题，在Waymo数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中预测道路参与者的未来运动是关键任务，但现有方法在多智能体联合预测中存在低概率模式生成质量差的问题，需要改进预测框架以更好地捕获和利用关键轨迹信息。

Method: 提出JAM框架，包含两个阶段：第一阶段是边际预测过程，通过轨迹类型对查询进行分类以学习所有类别的轨迹；第二阶段是联合预测过程，以场景上下文和第一阶段的边际提议为输入学习最终联合分布。明确引入关键路径点来引导联合预测模块更好地捕获关键信息。

Result: 在Waymo Open Motion Dataset交互预测基准上进行了广泛实验，方法取得了竞争性能表现。在框架比较实验中，JAM超越了其他预测框架，在交互轨迹预测任务上达到了最先进的性能。

Conclusion: JAM框架通过两阶段设计和关键点引导机制有效解决了多智能体联合预测中低概率模式生成质量差的问题，在真实世界数据集上验证了方法的有效性，为交互轨迹预测提供了新的解决方案。

Abstract: Predicting the future motion of road participants is a critical task in
autonomous driving. In this work, we address the challenge of low-quality
generation of low-probability modes in multi-agent joint prediction. To tackle
this issue, we propose a two-stage multi-agent interactive prediction framework
named \textit{keypoint-guided joint prediction after classification-aware
marginal proposal} (JAM). The first stage is modeled as a marginal prediction
process, which classifies queries by trajectory type to encourage the model to
learn all categories of trajectories, providing comprehensive mode information
for the joint prediction module. The second stage is modeled as a joint
prediction process, which takes the scene context and the marginal proposals
from the first stage as inputs to learn the final joint distribution. We
explicitly introduce key waypoints to guide the joint prediction module in
better capturing and leveraging the critical information from the initial
predicted trajectories. We conduct extensive experiments on the real-world
Waymo Open Motion Dataset interactive prediction benchmark. The results show
that our approach achieves competitive performance. In particular, in the
framework comparison experiments, the proposed JAM outperforms other prediction
frameworks and achieves state-of-the-art performance in interactive trajectory
prediction. The code is available at https://github.com/LinFunster/JAM to
facilitate future research.

</details>


### [19] [Reconfigurable Tendon-Driven Robots: Eliminating Inter-segmental Coupling via Independently Lockable Joints](https://arxiv.org/abs/2507.17163)
*Botao Lin,Shuang Song,Jiaole Wang*

Main category: cs.RO

TL;DR: 本文提出了一种配备创新可锁定关节的可重构腱驱动机器人(RTR)，通过选择性锁定关节来消除段间耦合，从而简化控制并提高在复杂环境中的机动性。


<details>
  <summary>Details</summary>
Motivation: 传统腱驱动机器人虽然具有大工作空间和良好的机动性，但随着机器人段数增加会引入严重的段间耦合问题，需要复杂的模型和更多电机来实现精确控制。

Method: 设计了配备可锁定关节的可重构腱驱动机器人，每个关节的状态（锁定/自由）可通过一对拮抗腱独立控制，且无需持续供电维持状态。操作员可选择性激活目标机器人段，从根本上消除段间耦合。

Result: 仿真比较显示RTR相比传统TDR具有优势，建立了运动学和静力学模型并进行了验证实验。使用七关节RTR原型进行演示，仅用六个电机的执行器包就展现了其可重构性和在复杂环境中的运动能力。

Conclusion: RTR通过创新的可锁定关节设计成功解决了传统腱驱动机器人的段间耦合问题，避免了复杂的协调控制需求，在保持灵活性的同时简化了控制系统。

Abstract: With a slender redundant body, the tendon-driven robot (TDR) has a large
workspace and great maneuverability while working in complex environments. TDR
comprises multiple independently controlled robot segments, each with a set of
driving tendons. While increasing the number of robot segments enhances
dexterity and expands the workspace, this structural expansion also introduces
intensified inter-segmental coupling. Therefore, achieving precise TDR control
requires more complex models and additional motors. This paper presents a
reconfigurable tendon-driven robot (RTR) equipped with innovative lockable
joints. Each joint's state (locked/free) can be individually controlled through
a pair of antagonistic tendons, and its structure eliminates the need for a
continuous power supply to maintain the state. Operators can selectively
actuate the targeted robot segments, and this scheme fundamentally eliminates
the inter-segmental coupling, thereby avoiding the requirement for complex
coordinated control between segments. The workspace of RTR has been simulated
and compared with traditional TDRs' workspace, and RTR's advantages are further
revealed. The kinematics and statics models of the RTR have been derived and
validation experiments have been conducted. Demonstrations have been performed
using a seven-joint RTR prototype to show its reconfigurability and moving
ability in complex environments with an actuator pack comprising only six
motors.

</details>


### [20] [FAST-Calib: LiDAR-Camera Extrinsic Calibration in One Second](https://arxiv.org/abs/2507.17210)
*Chunran Zheng,Fu Zhang*

Main category: cs.RO

TL;DR: 本文提出了FAST-Calib，一种基于定制3D标靶的快速用户友好型LiDAR-相机外参标定工具，支持机械式和固态LiDAR，具有高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR-相机外参标定方法存在精度不足、处理速度慢、对不同LiDAR扫描模式适应性差等问题，需要开发一种快速、准确且用户友好的标定工具。

Method: 设计定制3D标靶，开发与LiDAR扫描模式无关的高效可靠边缘提取算法，通过椭圆拟合补偿LiDAR光斑扩散导致的边缘扩张伪影，支持多场景联合优化。

Result: 在三种LiDAR模型（Ouster、Avia和Mid360）与广角相机的组合上验证，点对点配准误差始终低于6.5mm，总处理时间不到0.7秒，相比现有方法具有更优的精度和鲁棒性。

Conclusion: FAST-Calib提供了一个高效、准确且基于标靶的自动标定流水线，已在GitHub开源代码和数据集以造福机器人社区。

Abstract: This paper proposes FAST-Calib, a fast and user-friendly LiDAR-camera
extrinsic calibration tool based on a custom-made 3D target. FAST-Calib
supports both mechanical and solid-state LiDARs by leveraging an efficient and
reliable edge extraction algorithm that is agnostic to LiDAR scan patterns. It
also compensates for edge dilation artifacts caused by LiDAR spot spread
through ellipse fitting, and supports joint optimization across multiple
scenes. We validate FAST-Calib on three LiDAR models (Ouster, Avia, and
Mid360), each paired with a wide-angle camera. Experimental results demonstrate
superior accuracy and robustness compared to existing methods. With
point-to-point registration errors consistently below 6.5mm and total
processing time under 0.7s, FAST-Calib provides an efficient, accurate, and
target-based automatic calibration pipeline. We have open-sourced our code and
dataset on GitHub to benefit the robotics community.

</details>


### [21] [Optimizing Delivery Logistics: Enhancing Speed and Safety with Drone Technology](https://arxiv.org/abs/2507.17253)
*Maharshi Shastri,Ujjval Shrivastav*

Main category: cs.RO

TL;DR: 本研究开发了一个AI集成的无人机配送系统，采用YOLOv4 Tiny进行目标检测，NEO 6M GPS模块导航，A7670 SIM模块实时通信，通过机器学习、物联网设备和加密协议解决电池效率、监管合规和安全问题，初步研究显示相比传统地面物流在配送时间上有所改善。


<details>
  <summary>Details</summary>
Motivation: 随着对快速且经济高效的最后一公里配送解决方案需求的增长，催化了基于无人机物流的重大进步。研究旨在解决传统地面物流在配送效率方面的局限性，开发更快速、更智能的无人机配送系统。

Method: 系统采用YOLOv4 Tiny进行目标检测，NEO 6M GPS模块进行导航定位，A7670 SIM模块实现实时通信。通过对轻量级AI模型和硬件组件进行比较分析，确定实时无人机配送的最优配置。集成机器学习技术、物联网设备和加密协议来解决关键挑战。使用面部识别技术进行高精度收件人身份验证。

Result: 初步研究表明，与传统地面物流相比，配送时间有所改善。通过面部识别实现了高精度的收件人身份验证。系统架构、设计和初步仿真结果已完成，但实验结果、仿真基准和部署统计数据仍在获取中。

Conclusion: 研究成功开发了AI集成无人机配送系统的架构和设计，解决了电池效率、监管合规（符合FAA、EASA和DGCA标准）和安全考虑等关键挑战。同时讨论了无人机配送的伦理影响和社会接受度。该系统在提高配送效率和安全性方面显示出潜力，但需要进一步的实验验证和全面分析。

Abstract: The increasing demand for fast and cost effective last mile delivery
solutions has catalyzed significant advancements in drone based logistics. This
research describes the development of an AI integrated drone delivery system,
focusing on route optimization, object detection, secure package handling, and
real time tracking. The proposed system leverages YOLOv4 Tiny for object
detection, the NEO 6M GPS module for navigation, and the A7670 SIM module for
real time communication. A comparative analysis of lightweight AI models and
hardware components is conducted to determine the optimal configuration for
real time UAV based delivery. Key challenges including battery efficiency,
regulatory compliance, and security considerations are addressed through the
integration of machine learning techniques, IoT devices, and encryption
protocols. Preliminary studies demonstrate improvement in delivery time
compared to conventional ground based logistics, along with high accuracy
recipient authentication through facial recognition. The study also discusses
ethical implications and societal acceptance of drone deliveries, ensuring
compliance with FAA, EASA and DGCA regulatory standards. Note: This paper
presents the architecture, design, and preliminary simulation results of the
proposed system. Experimental results, simulation benchmarks, and deployment
statistics are currently being acquired. A comprehensive analysis will be
included in the extended version of this work.

</details>


### [22] [Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning](https://arxiv.org/abs/2507.17275)
*Po-Yen Wu,Cheng-Yu Kuo,Yuki Kadokawa,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 本文提出了一个强化学习框架，通过将工具寿命作为优化因子，训练机器人学习既能完成任务又能延长工具使用寿命的策略，在仿真和真实环境中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在不可达环境中，机器人经常依赖缺乏预定义使用策略的通用工具，这些工具的寿命对使用方式高度敏感。如何让机器人学习既能完成任务又能延长工具寿命的使用策略是一个根本性挑战。

Method: 提出一个强化学习框架，将工具寿命纳入策略优化过程。利用有限元分析(FEA)和Miner规则基于累积应力估算剩余使用寿命(RUL)，并将RUL集成到RL奖励中指导策略学习。引入自适应奖励归一化(ARN)机制，根据估计的RUL动态调整奖励缩放，确保稳定的学习信号。

Result: 在仿真和真实世界的工具使用任务中验证了方法的有效性，包括物体移动和开门任务。学习到的策略能够持续延长工具寿命(仿真中最高达8.01倍)，并能有效迁移到真实世界环境中。

Conclusion: 该研究成功解决了机器人在使用通用工具时平衡任务完成和工具寿命延长的难题，证明了学习寿命导向型工具使用策略的实用价值，为机器人在复杂环境中的可持续工具使用提供了新的解决方案。

Abstract: In inaccessible environments with uncertain task demands, robots often rely
on general-purpose tools that lack predefined usage strategies. These tools are
not tailored for particular operations, making their longevity highly sensitive
to how they are used. This creates a fundamental challenge: how can a robot
learn a tool-use policy that both completes the task and prolongs the tool's
lifespan? In this work, we address this challenge by introducing a
reinforcement learning (RL) framework that incorporates tool lifespan as a
factor during policy optimization. Our framework leverages Finite Element
Analysis (FEA) and Miner's Rule to estimate Remaining Useful Life (RUL) based
on accumulated stress, and integrates the RUL into the RL reward to guide
policy learning toward lifespan-guided behavior. To handle the fact that RUL
can only be estimated after task execution, we introduce an Adaptive Reward
Normalization (ARN) mechanism that dynamically adjusts reward scaling based on
estimated RULs, ensuring stable learning signals. We validate our method across
simulated and real-world tool use tasks, including Object-Moving and
Door-Opening with multiple general-purpose tools. The learned policies
consistently prolong tool lifespan (up to 8.01x in simulation) and transfer
effectively to real-world settings, demonstrating the practical value of
learning lifespan-guided tool use strategies.

</details>


### [23] [VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback](https://arxiv.org/abs/2507.17294)
*Jianxin Bi,Kevin Yuchen Ma,Ce Hao,Mike Zheng Shou,Harold Soh*

Main category: cs.RO

TL;DR: VLA-Touch是一种无需微调基础VLA模型就能为通用机器人策略增加触觉感知能力的方法，通过双层触觉反馈集成提升了任务规划效率和执行精度。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作(VLA)模型缺乏解释和使用触觉信号的能力，这限制了它们在接触密集型任务中的有效性。由于缺乏大型多模态数据集，将触觉反馈整合到这些系统中具有挑战性。

Method: 提出VLA-Touch方法，包含两个关键创新：(1)利用预训练触觉-语言模型为高层任务规划提供语义触觉反馈的管道；(2)基于扩散的控制器，使用触觉信号优化VLA生成的动作以实现接触密集型操作。

Result: 通过真实世界实验验证，双层触觉反馈集成提升了任务规划效率，同时增强了执行精度。代码已开源。

Conclusion: VLA-Touch成功实现了在不微调基础VLA模型的情况下，通过双层触觉反馈集成有效提升通用机器人策略在接触密集型任务中的性能。

Abstract: Tactile feedback is generally recognized to be crucial for effective
interaction with the physical world. However, state-of-the-art
Vision-Language-Action (VLA) models lack the ability to interpret and use
tactile signals, limiting their effectiveness in contact-rich tasks.
Incorporating tactile feedback into these systems is challenging due to the
absence of large multi-modal datasets. We present VLA-Touch, an approach that
enhances generalist robot policies with tactile sensing \emph{without
fine-tuning} the base VLA. Our method introduces two key innovations: (1) a
pipeline that leverages a pretrained tactile-language model that provides
semantic tactile feedback for high-level task planning, and (2) a
diffusion-based controller that refines VLA-generated actions with tactile
signals for contact-rich manipulation. Through real-world experiments, we
demonstrate that our dual-level integration of tactile feedback improves task
planning efficiency while enhancing execution precision. Code is open-sourced
at \href{https://github.com/jxbi1010/VLA-Touch}{this URL}.

</details>


### [24] [HuNavSim 2.0](https://arxiv.org/abs/2507.17317)
*Miguel Escudero-Jiménez,Noé Pérez-Higueras,Andrés Martínez-Silva,Fernando Caballero,Luis Merino*

Main category: cs.RO

TL;DR: 本文介绍了Human Navigation Simulator (HuNavSim)的新版本，这是一个开源的人机导航行为仿真工具，基于ROS 2框架开发，可与Gazebo和NVidia Isaac Sim等机器人仿真器集成使用。


<details>
  <summary>Details</summary>
Motivation: 为了促进人机感知机器人导航系统的开发和评估，需要一个能够仿真不同人类-智能体导航行为的工具，特别是在移动机器人场景中模拟复杂且真实的人类行为。

Method: 开发了基于ROS 2框架的Human Navigation Simulator (HuNavSim)工具，该工具可以与多种知名机器人仿真器（如Gazebo或NVidia Isaac Sim）配合使用。新版本扩展了行为树中可组合的动作和条件集合，以构建复杂和真实的人类行为。

Result: 成功推出了HuNavSim的新版本，改进了多个功能并添加了新特性，特别是扩展了行为树系统中的动作和条件集合，使得能够模拟更加复杂和真实的人类导航行为。

Conclusion: 新版本的HuNavSim为人机感知机器人导航系统的仿真开发和评估提供了更强大的工具支持，通过扩展的行为树功能能够更好地模拟复杂的人类导航行为，有助于推进该领域的研究发展。

Abstract: This work presents a new iteration of the Human Navigation Simulator
(HuNavSim), a novel open-source tool for the simulation of different
human-agent navigation behaviors in scenarios with mobile robots. The tool,
programmed under the ROS 2 framework, can be used together with different
well-known robotics simulators such as Gazebo or NVidia Isaac Sim. The main
goal is to facilitate the development and evaluation of human-aware robot
navigation systems in simulation. In this new version, several features have
been improved and new ones added, such as the extended set of actions and
conditions that can be combined in Behavior Trees to compound complex and
realistic human behaviors.

</details>


### [25] [Mobile Manipulation with Active Inference for Long-Horizon Rearrangement Tasks](https://arxiv.org/abs/2507.17338)
*Corrado Pezzato,Ozan Çatal,Toon Van de Maele,Riddhi J. Pitliya,Tim Verbelen*

Main category: cs.RO

TL;DR: 研究提出了一种分层主动推理架构，用于机器人复杂长期任务控制，在Habitat基准测试中超越了现有方法，首次证明主动推理可以扩展到现代机器人复杂任务


<details>
  <summary>Details</summary>
Motivation: 尽管主动推理在机器人控制中受到关注，但其在复杂长期任务中的应用尚未得到验证，存在将主动推理扩展到现实机器人复杂任务的需求

Method: 引入了完全分层的主动推理架构，结合高层主动推理模型选择离散技能和全身主动推理控制器，实现统一的目标导向行为控制方法

Result: 在Habitat移动操作基准测试的三个长期任务中，该方法在所有任务上都超越了最先进的基线方法，展现出灵活的技能组合、在线适应性和任务失败恢复能力

Conclusion: 首次证明了主动推理可以成功扩展到现代机器人基准测试的复杂性水平，为机器人复杂任务控制提供了新的有效解决方案

Abstract: Despite growing interest in active inference for robotic control, its
application to complex, long-horizon tasks remains untested. We address this
gap by introducing a fully hierarchical active inference architecture for
goal-directed behavior in realistic robotic settings. Our model combines a
high-level active inference model that selects among discrete skills realized
via a whole-body active inference controller. This unified approach enables
flexible skill composition, online adaptability, and recovery from task
failures without requiring offline training. Evaluated on the Habitat Benchmark
for mobile manipulation, our method outperforms state-of-the-art baselines
across the three long-horizon tasks, demonstrating for the first time that
active inference can scale to the complexity of modern robotics benchmarks.

</details>


### [26] [An Exploratory Study on Human-Robot Interaction using Semantics-based Situational Awareness](https://arxiv.org/abs/2507.17376)
*Tianshu Ruan,Aniketh Ramesh,Rustam Stolkin,Manolis Chiou*

Main category: cs.RO

TL;DR: 本文研究了高级语义对人机团队和人机交互的影响，提出了一个基于语义的框架，在模拟灾难响应任务中验证了高级语义能够减轻操作员工作负担、提高情境感知信任度并缩短反应时间。


<details>
  <summary>Details</summary>
Motivation: 在移动机器人部署的人机团队中，高级语义对人机交互的益处尚未得到充分探索，且往往模糊难解。特别是在灾难响应等复杂任务中，人类操作员面临高工作负荷和压力，需要在机器人和其他任务间切换注意力，难以快速建立情境感知。

Method: 应用基于语义的框架，该框架能够揭示环境的不同指标（即存在多少语义信息）。在模拟灾难响应任务中进行实验，评估高级语义对人机团队表现的影响。

Result: 实验结果表明，所提出的语义方法能够：1）减轻人类操作员的感知工作负荷；2）增加操作员对情境感知的信任；3）帮助减少在需要时切换自主水平的反应时间。此外，发现对系统信任度较高的参与者更倾向于在高级语义的鼓励下使用遥操作模式。

Conclusion: 高级语义在人机团队中具有显著的积极影响，能够有效改善人机交互的质量和效率。语义信息的引入不仅减轻了操作员的认知负担，还提高了他们对系统的信任度，并优化了决策反应时间，为移动机器人在复杂环境中的应用提供了重要支持。

Abstract: In this paper, we investigate the impact of high-level semantics (evaluation
of the environment) on Human-Robot Teams (HRT) and Human-Robot Interaction
(HRI) in the context of mobile robot deployments. Although semantics has been
widely researched in AI, how high-level semantics can benefit the HRT paradigm
is underexplored, often fuzzy, and intractable. We applied a semantics-based
framework that could reveal different indicators of the environment (i.e. how
much semantic information exists) in a mock-up disaster response mission. In
such missions, semantics are crucial as the HRT should handle complex
situations and respond quickly with correct decisions, where humans might have
a high workload and stress. Especially when human operators need to shift their
attention between robots and other tasks, they will struggle to build
Situational Awareness (SA) quickly. The experiment suggests that the presented
semantics: 1) alleviate the perceived workload of human operators; 2) increase
the operator's trust in the SA; and 3) help to reduce the reaction time in
switching the level of autonomy when needed. Additionally, we find that
participants with higher trust in the system are encouraged by high-level
semantics to use teleoperation mode more.

</details>


### [27] [Language-Conditioned Open-Vocabulary Mobile Manipulation with Pretrained Models](https://arxiv.org/abs/2507.17379)
*Shen Tan,Dong Zhou,Xiangyu Shao,Junqiao Wang,Guanghui Sun*

Main category: cs.RO

TL;DR: 本文提出了LOVMM框架，结合大语言模型和视觉语言模型来解决开放词汇移动操作任务，能够在家庭环境中处理新颖和未见过的物体，并通过自然语言指令执行复杂的机器人操作任务。


<details>
  <summary>Details</summary>
Motivation: 开放词汇移动操作（OVMM）在处理不同工作空间中新颖和未见过的物体时仍然是实际机器人应用的重大挑战，需要一个能够理解自然语言指令并在复杂环境中执行多样化操作任务的框架。

Method: 提出了LOVMM（Language-conditioned Open-Vocabulary Mobile Manipulation）框架，该框架结合了大语言模型（LLM）和视觉语言模型（VLM），能够处理家庭环境中的各种移动操作任务，并可以理解自由形式的自然语言指令。

Result: 在复杂家庭环境的仿真实验中，LOVMM展现出强大的零样本泛化能力和多任务学习能力。此外，该方法还能够泛化到多个桌面操作任务，并相比其他最先进方法取得了更高的成功率。

Conclusion: LOVMM框架成功地解决了开放词汇移动操作的挑战，通过结合LLM和VLM实现了对复杂自然语言指令的理解和执行，在家庭环境和桌面操作任务中都表现出优异的性能和泛化能力。

Abstract: Open-vocabulary mobile manipulation (OVMM) that involves the handling of
novel and unseen objects across different workspaces remains a significant
challenge for real-world robotic applications. In this paper, we propose a
novel Language-conditioned Open-Vocabulary Mobile Manipulation framework, named
LOVMM, incorporating the large language model (LLM) and vision-language model
(VLM) to tackle various mobile manipulation tasks in household environments.
Our approach is capable of solving various OVMM tasks with free-form natural
language instructions (e.g. "toss the food boxes on the office room desk to the
trash bin in the corner", and "pack the bottles from the bed to the box in the
guestroom"). Extensive experiments simulated in complex household environments
show strong zero-shot generalization and multi-task learning abilities of
LOVMM. Moreover, our approach can also generalize to multiple tabletop
manipulation tasks and achieve better success rates compared to other
state-of-the-art methods.

</details>


### [28] [Confidence Calibration in Vision-Language-Action Models](https://arxiv.org/abs/2507.17383)
*Thomas P Zollo,Richard Zemel*

Main category: cs.RO

TL;DR: 本研究首次系统性地研究了视觉-语言-动作(VLA)基础模型中的置信度校准问题，提出了提示集成和动作维度独立校准等方法来提高机器人行为的可信度和不确定性量化能力。


<details>
  <summary>Details</summary>
Motivation: 可信赖的机器人行为不仅需要高任务成功率，还需要机器人能够可靠地量化其成功概率。现有的VLA模型在置信度校准方面缺乏系统性研究，这限制了机器人在实际应用中的可信度和安全性。

Method: 1) 对多个数据集和VLA变体进行广泛基准测试，分析任务成功与校准误差的关系；2) 提出提示集成算法，通过平均不同释义指令的置信度来改善校准；3) 分析任务时间范围内的校准表现；4) 提出动作维度独立的Platt缩放方法，对每个动作维度进行独立重新校准。

Result: 发现任务性能和校准并不冲突；提示集成算法能够持续改善校准效果；置信度在取得一定进展后往往最为可靠，为风险感知干预提供了自然的时机；不同动作维度存在差异化的误校准现象；动作维度独立校准方法能够产生更好的置信度估计。

Conclusion: 通过系统性研究置信度校准，开发了必要的工具和概念理解，使VLA模型能够通过可靠的不确定性量化实现高性能和高可信度，为构建更加安全可靠的机器人系统奠定了基础。

Abstract: Trustworthy robot behavior requires not only high levels of task success but
also that the robot can reliably quantify how likely it is to succeed. To this
end, we present the first systematic study of confidence calibration in
vision-language-action (VLA) foundation models, which map visual observations
and natural-language instructions to low-level robot motor commands. We begin
with extensive benchmarking to understand the critical relationship between
task success and calibration error across multiple datasets and VLA variants,
finding that task performance and calibration are not in tension. Next, we
introduce prompt ensembles for VLAs, a lightweight, Bayesian-inspired algorithm
that averages confidence across paraphrased instructions and consistently
improves calibration. We further analyze calibration over the task time
horizon, showing that confidence is often most reliable after making some
progress, suggesting natural points for risk-aware intervention. Finally, we
reveal differential miscalibration across action dimensions and propose
action-wise Platt scaling, a method to recalibrate each action dimension
independently to produce better confidence estimates. Our aim in this study is
to begin to develop the tools and conceptual understanding necessary to render
VLAs both highly performant and highly trustworthy via reliable uncertainty
quantification.

</details>


### [29] [The Wilhelm Tell Dataset of Affordance Demonstrations](https://arxiv.org/abs/2507.17401)
*Rachel Ringe,Mihai Pomarlan,Nikolaos Tsiogkas,Stefano De Giorgis,Maria Hedblom,Rainer Malaka*

Main category: cs.RO

TL;DR: 该研究提出了一个新的家庭任务可供性学习数据集，包含第一人称和第三人称视角的视频序列，用于训练机器人识别环境中的行为可能性


<details>
  <summary>Details</summary>
Motivation: 现有的可供性学习方法主要基于静态图像或形状标注进行训练，缺乏动态视频数据来帮助机器人更好地理解人类环境中的行为可能性，特别是家庭任务场景中的可供性识别

Method: 构建了一个包含常见家庭任务的新型可供性学习数据集，该数据集包含：1）第一人称和第三人称视角的视频序列；2）任务中体现的可供性元数据；3）多名参与者的任务演示，总计约7小时的人类活动记录

Result: 成功收集了涵盖多种家庭任务表现的视频数据集，能够研究人们执行任务时的准备动作，如任务空间的安排方式，为协作服务机器人提供了有价值的训练数据

Conclusion: 该数据集为机器人可供性感知系统的训练提供了重要资源，特别是在识别家庭环境中的可供性表现方面，同时也有助于研究人类的任务准备行为，这对协作服务机器人的发展具有重要意义

Abstract: Affordances - i.e. possibilities for action that an environment or objects in
it provide - are important for robots operating in human environments to
perceive. Existing approaches train such capabilities on annotated static
images or shapes. This work presents a novel dataset for affordance learning of
common household tasks. Unlike previous approaches, our dataset consists of
video sequences demonstrating the tasks from first- and third-person
perspectives, along with metadata about the affordances that are manifested in
the task, and is aimed towards training perception systems to recognize
affordance manifestations. The demonstrations were collected from several
participants and in total record about seven hours of human activity. The
variety of task performances also allows studying preparatory maneuvers that
people may perform for a task, such as how they arrange their task space, which
is also relevant for collaborative service robots.

</details>


### [30] [IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception](https://arxiv.org/abs/2507.17445)
*Haichuan Li,Changda Tian,Panos Trahanias,Tomi Westerlund*

Main category: cs.RO

TL;DR: 提出了IndoorBEV，一种基于掩码的鸟瞰视角(BEV)方法，用于室内移动机器人在复杂3D点云中进行多样化物体检测，通过将3D场景投影到2D BEV网格来处理遮挡问题并区分静态障碍物和动态物体。


<details>
  <summary>Details</summary>
Motivation: 传统边界框方法在处理室内复杂3D点云中的多样化物体检测时存在局限性，特别是在面对不同物体形状、杂乱环境以及静态和动态元素共存的情况下表现不佳，机器人感知面临重大挑战。

Method: 采用基于掩码的鸟瞰视角(BEV)方法，将3D场景投影到2D BEV网格中；使用轴向紧凑编码器和基于窗口的主干网络从BEV地图中提取丰富的空间特征；采用基于查询的解码器头，利用学习的物体查询同时预测BEV空间中的物体类别和实例掩码。

Result: 在包含多样化物体类别（包括静态物体和机器人、杂项等动态元素）的定制室内数据集上验证了IndoorBEV的有效性，展现了其在鲁棒室内场景理解方面的潜力。

Conclusion: IndoorBEV通过基于掩码的方法有效捕获静态和动态物体的足迹，无论其形状如何，为边界框回归提供了鲁棒的替代方案，并且得到的2D BEV结果可直接用于导航、运动预测和规划等下游机器人任务。

Abstract: Detecting diverse objects within complex indoor 3D point clouds presents
significant challenges for robotic perception, particularly with varied object
shapes, clutter, and the co-existence of static and dynamic elements where
traditional bounding box methods falter. To address these limitations, we
propose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoor
mobile robots.
  In a BEV method, a 3D scene is projected into a 2D BEV grid which handles
naturally occlusions and provides a consistent top-down view aiding to
distinguish static obstacles from dynamic agents. The obtained 2D BEV results
is directly usable to downstream robotic tasks like navigation, motion
prediction, and planning. Our architecture utilizes an axis compact encoder and
a window-based backbone to extract rich spatial features from this BEV map. A
query-based decoder head then employs learned object queries to concurrently
predict object classes and instance masks in the BEV space. This mask-centric
formulation effectively captures the footprint of both static and dynamic
objects regardless of their shape, offering a robust alternative to bounding
box regression. We demonstrate the effectiveness of IndoorBEV on a custom
indoor dataset featuring diverse object classes including static objects
  and dynamic elements like robots and miscellaneous items, showcasing its
potential for robust indoor scene understanding.

</details>


### [31] [Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners](https://arxiv.org/abs/2507.17519)
*Kostas Karakontis,Thanos Petsanis,Athanasios Ch. Kapoutsis,Pavlos Ch. Kapoutsis,Elias B. Kosmatopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种模块化算法，将商业二维路径规划器扩展为地形感知的三维多无人机覆盖路径规划，通过调整高度和相机方向改善3D重建效果


<details>
  <summary>Details</summary>
Motivation: 现有商业软件中的多无人机覆盖路径规划算法仅将感兴趣区域视为2D平面，忽略了重要的3D结构特征，导致3D重建不完整，特别是在遮挡或垂直表面周围

Method: 提出了一种模块化算法，可以扩展商业二维路径规划器以实现地形感知规划，通过调整高度和相机方向来优化覆盖。作为演示，将知名的DARP算法扩展为DARP-3D

Result: 在多个3D环境中进行仿真测试和使用DJI硬件进行真实飞行测试，结果显示相比基线方法，该方法在具有显著垂直特征的区域能够持续获得改进的3D重建效果

Conclusion: 该模块化算法成功地将2D路径规划扩展到3D地形感知规划，显著改善了3D重建质量，特别是在垂直结构区域。算法的开源实现已公开提供

Abstract: Multi-UAV Coverage Path Planning (mCPP) algorithms in popular commercial
software typically treat a Region of Interest (RoI) only as a 2D plane,
ignoring important3D structure characteristics. This leads to incomplete
3Dreconstructions, especially around occluded or vertical surfaces. In this
paper, we propose a modular algorithm that can extend commercial
two-dimensional path planners to facilitate terrain-aware planning by adjusting
altitude and camera orientations. To demonstrate it, we extend the well-known
DARP (Divide Areas for Optimal Multi-Robot Coverage Path Planning) algorithm
and produce DARP-3D. We present simulation results in multiple 3D environments
and a real-world flight test using DJI hardware. Compared to baseline, our
approach consistently captures improved 3D reconstructions, particularly in
areas with significant vertical features. An open-source implementation of the
algorithm is available here:https://github.com/konskara/TerraPlan

</details>


### [32] [InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation](https://arxiv.org/abs/2507.17520)
*Shuai Yang,Hao Li,Yilun Chen,Bin Wang,Yang Tian,Tai Wang,Hanqing Wang,Feng Zhao,Yiyi Liao,Jiangmiao Pang*

Main category: cs.RO

TL;DR: InstructVLA是一个端到端的视觉-语言-动作模型，通过新颖的VLA-IT训练范式，在保持大型视觉语言模型灵活推理能力的同时，实现了领先的机器人操作性能


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型往往在多模态推理和精确动作生成之间做出权衡，能力局限于特定任务的操作数据，并且会遗忘预训练的视觉语言能力。需要开发一个既能保持灵活推理又能提供优秀操作性能的统一模型

Method: 提出Vision-Language-Action Instruction Tuning (VLA-IT)训练范式，采用多模态训练和专家混合自适应方法，在标准VLM语料库和精心策划的65万样本VLA-IT数据集上联合优化文本推理和动作生成

Result: 在SimplerEnv任务上比SpatialVLA提升30.5%；在新提出的SimplerEnv-Instruct 80任务基准测试中，比微调的OpenVLA高出92%，比GPT-4o辅助的动作专家高出29%；在多模态任务上超越基线VLM，并展现推理时间缩放能力

Conclusion: InstructVLA成功实现了直观可控的人机交互与高效策略学习的桥接，为机器人在真实世界中的有效操作提供了新的解决方案，展现了在仿真和真实环境中的强大泛化能力

Abstract: To operate effectively in the real world, robots must integrate multimodal
reasoning with precise action generation. However, existing
vision-language-action (VLA) models often sacrifice one for the other, narrow
their abilities to task-specific manipulation data, and suffer catastrophic
forgetting of pre-trained vision-language capabilities. To bridge this gap, we
introduce InstructVLA, an end-to-end VLA model that preserves the flexible
reasoning of large vision-language models (VLMs) while delivering leading
manipulation performance. InstructVLA introduces a novel training paradigm,
Vision-Language-Action Instruction Tuning (VLA-IT), which employs multimodal
training with mixture-of-experts adaptation to jointly optimize textual
reasoning and action generation on both standard VLM corpora and a curated
650K-sample VLA-IT dataset. On in-domain SimplerEnv tasks, InstructVLA achieves
30.5% improvement over SpatialVLA. To evaluate generalization, we introduce
SimplerEnv-Instruct, an 80-task benchmark requiring closed-loop control and
high-level instruction understanding, where it outperforms a fine-tuned OpenVLA
by 92% and an action expert aided by GPT-4o by 29%. Additionally, InstructVLA
surpasses baseline VLMs on multimodal tasks and exhibits inference-time scaling
by leveraging textual reasoning to boost manipulation performance in both
simulated and real-world settings. These results demonstrate InstructVLA's
potential for bridging intuitive and steerable human-robot interaction with
efficient policy learning.

</details>


### [33] [When and Where Localization Fails: An Analysis of the Iterative Closest Point in Evolving Environment](https://arxiv.org/abs/2507.17531)
*Abdel-Raouf Dannaoui,Johann Laconte,Christophe Debain,Francois Pomerleau,Paul Checchin*

Main category: cs.RO

TL;DR: 本研究针对动态户外环境中3D激光雷达的短期重定位问题，构建了高分辨率多时间序列数据集，并比较了两种ICP算法的性能，发现Point-to-Plane ICP在稀疏特征和植被密集区域表现更稳定准确。


<details>
  <summary>Details</summary>
Motivation: 虽然长期定位已被广泛研究，但在几天到几周内发生的短期环境变化对自主系统3D激光雷达鲁棒重定位的影响仍未得到充分探索，这对实际应用具有重要意义。

Method: 构建了2025年2月至4月期间每周采集的高分辨率短期多时间序列数据集，包含自然和半城市环境的高密度点云地图、360度全景图像和轨迹数据。使用从点云地图投影得到的激光雷达扫描数据，结合传感器精确遮挡建模，通过Point-to-Point和Point-to-Plane两种ICP算法评估对齐精度。

Result: Point-to-Plane ICP相比Point-to-Point ICP提供了显著更稳定和准确的配准效果，特别是在稀疏特征或植被密集的区域。研究揭示了局部几何形状和环境变化如何影响定位成功率。

Conclusion: 该研究为评估短期定位鲁棒性提供了结构化数据集，建立了在噪声条件下分析扫描到地图对齐的可重现框架，并对evolving户外环境中的ICP性能进行了比较评估，为设计更具弹性的机器人系统提供了洞察。

Abstract: Robust relocalization in dynamic outdoor environments remains a key challenge
for autonomous systems relying on 3D lidar. While long-term localization has
been widely studied, short-term environmental changes, occurring over days or
weeks, remain underexplored despite their practical significance. To address
this gap, we present a highresolution, short-term multi-temporal dataset
collected weekly from February to April 2025 across natural and semi-urban
settings. Each session includes high-density point cloud maps, 360 deg
panoramic images, and trajectory data. Projected lidar scans, derived from the
point cloud maps and modeled with sensor-accurate occlusions, are used to
evaluate alignment accuracy against the ground truth using two Iterative
Closest Point (ICP) variants: Point-to-Point and Point-to-Plane. Results show
that Point-to-Plane offers significantly more stable and accurate registration,
particularly in areas with sparse features or dense vegetation. This study
provides a structured dataset for evaluating short-term localization
robustness, a reproducible framework for analyzing scan-to-map alignment under
noise, and a comparative evaluation of ICP performance in evolving outdoor
environments. Our analysis underscores how local geometry and environmental
variability affect localization success, offering insights for designing more
resilient robotic systems.

</details>


### [34] [Robot-mediated physical Human-Human Interaction in Neurorehabilitation: a position paper](https://arxiv.org/abs/2507.17561)
*Lorenzo Vianello,Matthew Short,Julia Manczurowsky,Emek Barış Küçüktabak,Francesco Di Tommaso,Alessia Noccaro,Laura Bandini,Shoshana Clark,Alaina Fiorenza,Francesca Lunardini,Alberto Canton,Marta Gandolla,Alessandra L. G. Pedrocchi,Emilia Ambrosini,Manuel Murie-Fernandez,Carmen B. Roman,Jesus Tornero,Natacha Leon,Andrew Sawers,Jim Patton,Domenico Formica,Nevio Luigi Tagliamonte,Georg Rauter,Kilian Baur,Fabian Just,Christopher J. Hasson,Vesna D. Novak,Jose L. Pons*

Main category: cs.RO

TL;DR: 本文提出了一种新的神经康复方法：机器人介导的人-人物理交互，将治疗师的临床专业知识与机器人的精确性和重复性相结合，为传统手动治疗和康复机器人技术之间搭建桥梁。


<details>
  <summary>Details</summary>
Motivation: 传统神经康复依赖患者与物理治疗师的交互，而机器人系统虽能改善物理反馈但未充分利用训练有素的治疗师的适应性和临床专业知识。需要一种方法来整合治疗师的临床专长和细致决策能力与机器人的力量、准确性和重复性。

Method: 提出机器人介导的人-人物理交互框架，使两个人能够通过机器人设备进行物理交互。采用多学科团队方法，包括工程师、医生和物理治疗师，利用统一的分类法描述机器人介导康复、基于社会心理学的交互框架，以及使机器人系统成为自然人-人交互无缝促进者的技术方法。

Result: 该框架已在不同研究团体中得到研究，最近作为连接传统手动治疗和康复机器人技术的有希望的纽带出现，协调了两种方法的优势。

Conclusion: 机器人介导的人-人物理交互代表了一种有前景的康复方法，能够结合传统手动治疗和机器人技术的优势，为神经康复领域提供了新的发展方向。

Abstract: Neurorehabilitation conventionally relies on the interaction between a
patient and a physical therapist. Robotic systems can improve and enrich the
physical feedback provided to patients after neurological injury, but they
under-utilize the adaptability and clinical expertise of trained therapists. In
this position paper, we advocate for a novel approach that integrates the
therapist's clinical expertise and nuanced decision-making with the strength,
accuracy, and repeatability of robotics: Robot-mediated physical Human-Human
Interaction. This framework, which enables two individuals to physically
interact through robotic devices, has been studied across diverse research
groups and has recently emerged as a promising link between conventional manual
therapy and rehabilitation robotics, harmonizing the strengths of both
approaches. This paper presents the rationale of a multidisciplinary
team-including engineers, doctors, and physical therapists-for conducting
research that utilizes: a unified taxonomy to describe robot-mediated
rehabilitation, a framework of interaction based on social psychology, and a
technological approach that makes robotic systems seamless facilitators of
natural human-human interaction.

</details>


### [35] [KernelSOS for Global Sampling-Based Optimal Control and Estimation via Semidefinite Programming](https://arxiv.org/abs/2507.17572)
*Antoine Groudiev,Fabian Schramm,Éloïse Berthier,Justin Carpentier,Frederike Dümbgen*

Main category: cs.RO

TL;DR: 本文将核平方和(KernelSOS)框架应用于控制和估计问题的全局优化，证明了该方法在处理具有局部最优解的问题时表现优异，特别是在轨迹优化中可作为独立方法或局部求解器的初始化方法使用。


<details>
  <summary>Details</summary>
Motivation: 控制和估计问题往往存在糟糕的局部最优解，传统优化方法难以找到全局最优解。需要一种既能利用平方和方法的理论基础，又能发挥核方法表达能力的全局优化框架来解决这类问题。

Method: 采用核平方和(KernelSOS)框架，该方法结合了多项式优化中平方和方法的理论基础和机器学习中核方法的表达能力。利用KernelSOS的基于样本的特性，将其应用于轨迹优化问题，并可将集成仿真器视为黑箱处理。

Result: KernelSOS在控制和估计领域的多个问题上表现良好。在估计问题上与其他平方和方法具有竞争力，同时适用于非多项式和非参数化表述。在轨迹优化问题中，既可作为独立方法使用，也可作为局部求解器的强大初始化方法。

Conclusion: KernelSOS框架成功地将全局优化技术扩展到控制和估计领域，为解决具有复杂局部最优结构的优化问题提供了有效工具，特别是在轨迹优化中展现了良好的应用前景。

Abstract: Global optimization has gained attraction over the past decades, thanks to
the development of both theoretical foundations and efficient numerical
routines to cope with optimization problems of various complexities. Among
recent methods, Kernel Sum of Squares (KernelSOS) appears as a powerful
framework, leveraging the potential of sum of squares methods from the
polynomial optimization community with the expressivity of kernel methods
widely used in machine learning. This paper applies the kernel sum of squares
framework for solving control and estimation problems, which exhibit poor local
minima. We demonstrate that KernelSOS performs well on a selection of problems
from both domains. In particular, we show that KernelSOS is competitive with
other sum of squares approaches on estimation problems, while being applicable
to non-polynomial and non-parametric formulations. The sample-based nature of
KernelSOS allows us to apply it to trajectory optimization problems with an
integrated simulator treated as a black box, both as a standalone method and as
a powerful initialization method for local solvers, facilitating the discovery
of better solutions.

</details>


### [36] [Event Detection for Active Lower Limb Prosthesis](https://arxiv.org/abs/2507.17649)
*J. D. Clark,P. Ellison*

Main category: cs.RO

TL;DR: 该研究通过双髁膝关节设计和十字韧带拉伸检测来改进假肢步态事件识别，发现韧带拉伸模式可用于预测步态周期中的关键事件，从而提高动力假肢控制器的精度。


<details>
  <summary>Details</summary>
Motivation: 传统假肢将膝关节简化为销钉关节会丢失自然膝关节的复杂运动学特性（包括平移和旋转成分），影响步态特征。准确的事件检测是半被动和动力假肢成功设计的关键，因此需要研究十字韧带拉伸在事件检测中的作用。

Method: 使用双髁膝关节设计，通过前后十字韧带类似物进行约束。采用与Russell膝关节韧带平行的线性位移传感器(LVDTs)记录韧带拉伸情况。在弯膝拐杖上进行实验，在跑步机上以3种不同速度采集数据，通过韧带拉伸特征来表征膝关节运动学。

Result: 发现十字韧带拉伸存在速度依赖性，主要出现在步态周期的5%和80%处（后十字韧带和前十字韧带）。循环轮廓随速度保持一致，在90%和95%处分别出现后十字韧带和前十字韧带的转折点特征，可用作初始接触的预测前兆。同样在90%和95%处的另一对转折点可用于预测足平期。

Conclusion: 双髁膝关节设计能够改善步态周期中事件的检测，因此可以提高动力假肢后续控制器的精度。韧带拉伸模式为假肢控制系统提供了新的生物力学反馈机制。

Abstract: Accurate event detection is key to the successful design of semi-passive and
powered prosthetics. Kinematically, the natural knee is complex, with
translation and rotation components that have a substantial impact on gait
characteristics. When simplified to a pin joint, some of this behaviour is
lost. This study investigates the role of cruciate ligament stretch in event
detection. A bicondylar knee design was used, constrained by analogues of the
anterior and posterior cruciate ligaments. This offers the ability to
characterize knee kinematics by the stretch of the ligaments. The ligament
stretch was recorded using LVDTs parallel to the ligaments of the Russell knee
on a bent knee crutch. Which was used to capture data on a treadmill at 3
speeds. This study finds speed dependence within the stretch of the cruciate
ligaments, prominently around 5\% and 80\% of the gait cycle for the posterior
and anterior. The cycle profile remains consistent with speed; therefore, other
static events such as the turning point feature at around 90\% and 95\% of the
cycle, for the posterior and anterior, respectively, could be used as a
predictive precursor for initial contact. Likewise at 90\% and 95\%, another
pair of turning points that in this case could be used to predict foot flat.
This concludes that the use of a bicondylar knee design could improve the
detection of events during the gait cycle, and therefore could increase the
accuracy of subsequent controllers for powered prosthetics.

</details>


### [37] [Safety Assurance for Quadrotor Kinodynamic Motion Planning](https://arxiv.org/abs/2507.17679)
*Theodoros Tavoulareas,Marzia Cescon*

Main category: cs.RO

TL;DR: 提出了一种结合运行时安全保障和运动学动力学运动规划的无人机导航方法，通过采样几何规划器生成无碰撞路径，并使用低级安全保障滤波器为LQR控制器提供安全保证


<details>
  <summary>Details</summary>
Motivation: 现有运动规划技术虽能生成无碰撞轨迹，但在规划过程中未考虑系统安全操作区域，可能导致部署时违反安全约束，而自主无人机在民用应用中的安全操作失败可能造成系统损坏、环境污染甚至人员伤亡

Method: 首先使用基于采样的几何规划器在用户定义空间内确定高级无碰撞路径；然后设计低级安全保障滤波器，为用于轨迹跟踪的线性二次调节器(LQR)的控制输入提供安全保证

Result: 在限制性3D仿真环境中使用Crazyflie 2.0无人机模型验证了所提方法的有效性

Conclusion: 该方法成功将运行时安全保障集成到运动学动力学运动规划中，能够在满足系统操作约束的同时实现安全的无人机导航

Abstract: Autonomous drones have gained considerable attention for applications in
real-world scenarios, such as search and rescue, inspection, and delivery. As
their use becomes ever more pervasive in civilian applications, failure to
ensure safe operation can lead to physical damage to the system, environmental
pollution, and even loss of human life. Recent work has demonstrated that
motion planning techniques effectively generate a collision-free trajectory
during navigation. However, these methods, while creating the motion plans, do
not inherently consider the safe operational region of the system, leading to
potential safety constraints violation during deployment. In this paper, we
propose a method that leverages run time safety assurance in a kinodynamic
motion planning scheme to satisfy the system's operational constraints. First,
we use a sampling-based geometric planner to determine a high-level
collision-free path within a user-defined space. Second, we design a low-level
safety assurance filter to provide safety guarantees to the control input of a
Linear Quadratic Regulator (LQR) designed with the purpose of trajectory
tracking. We demonstrate our proposed approach in a restricted 3D simulation
environment using a model of the Crazyflie 2.0 drone.

</details>


### [38] [CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation](https://arxiv.org/abs/2507.17727)
*Robel Mamo,Taeyeong Choi*

Main category: cs.RO

TL;DR: 本文提出了一种名为Crop-Aligned Cutout (CA-Cut)的新颖数据增强方法，通过在作物行周围空间分布地遮蔽输入图像中的随机区域，来提高农作物冠层下视觉导航模型的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的冠层下视觉导航深度学习模型需要大量训练数据来确保在实际田间部署的可靠性，但数据收集成本高昂。传统的数据增强技术（如颜色抖动、高斯模糊等）在复杂的冠层下环境中可能导致次优性能，特别是在频繁遮挡、碎片和作物间距不均匀的情况下。

Method: 提出了Crop-Aligned Cutout (CA-Cut)方法，该方法在输入图像中遮蔽作物行两侧空间分布的随机区域，迫使训练模型即使在细粒度信息被遮挡时也能捕获高级上下文特征。通过将遮蔽分布偏向作物行来增强模型的预测准确性和泛化能力。

Result: 在公共玉米田数据集上的广泛实验表明，基于遮蔽的增强技术能有效模拟遮挡并显著提高视觉导航中语义关键点预测的鲁棒性。CA-Cut方法实现了高达36.9%的预测误差降低，并通过消融研究确定了遮蔽数量、大小和空间分布的最优参数。

Conclusion: CA-Cut数据增强方法通过将遮蔽分布偏向作物行，能够显著提高冠层下视觉导航模型的预测准确性和跨不同环境的泛化能力，为解决农业机器人导航中的数据稀缺问题提供了有效解决方案。

Abstract: State-of-the-art visual under-canopy navigation methods are designed with
deep learning-based perception models to distinguish traversable space from
crop rows. While these models have demonstrated successful performance, they
require large amounts of training data to ensure reliability in real-world
field deployment. However, data collection is costly, demanding significant
human resources for in-field sampling and annotation. To address this
challenge, various data augmentation techniques are commonly employed during
model training, such as color jittering, Gaussian blur, and horizontal flip, to
diversify training data and enhance model robustness. In this paper, we
hypothesize that utilizing only these augmentation techniques may lead to
suboptimal performance, particularly in complex under-canopy environments with
frequent occlusions, debris, and non-uniform spacing of crops. Instead, we
propose a novel augmentation method, so-called Crop-Aligned Cutout (CA-Cut)
which masks random regions out in input images that are spatially distributed
around crop rows on the sides to encourage trained models to capture high-level
contextual features even when fine-grained information is obstructed. Our
extensive experiments with a public cornfield dataset demonstrate that
masking-based augmentations are effective for simulating occlusions and
significantly improving robustness in semantic keypoint predictions for visual
navigation. In particular, we show that biasing the mask distribution toward
crop rows in CA-Cut is critical for enhancing both prediction accuracy and
generalizability across diverse environments achieving up to a 36.9% reduction
in prediction error. In addition, we conduct ablation studies to determine the
number of masks, the size of each mask, and the spatial distribution of masks
to maximize overall performance.

</details>
