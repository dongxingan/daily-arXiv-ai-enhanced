<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 11]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning](https://arxiv.org/abs/2508.15874)
*Yijun Liu,Yuwei Liu,Yuan Meng,Jieheng Zhang,Yuwei Zhou,Ye Li,Jiacheng Jiang,Kangye Ji,Shijia Ge,Zhi Wang,Wenwu Zhu*

Main category: cs.RO

TL;DR: 提出了Spatial Policy (SP)框架，通过显式空间建模和推理来解决视觉中心层次化具身模型缺乏空间感知能力的问题，在11个多样化任务中达到86.7%的平均成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉中心层次化具身模型缺乏空间感知能力，限制了其在复杂环境中将视觉计划转化为可执行控制的有效性。

Method: 设计了空间条件具身视频生成模块、基于空间的动作预测模块和空间推理反馈策略，通过空间计划表和双阶段重规划实现统一的空间感知视觉运动机器人操作框架。

Result: SP显著优于最先进的基线方法，相比最佳基线平均提升33.0%，在11个多样化任务中达到86.7%的平均成功率。

Conclusion: SP通过显式空间建模和推理，大幅提升了具身模型在机器人控制应用中的实用性。

Abstract: Vision-centric hierarchical embodied models have demonstrated strong
potential for long-horizon robotic control. However, existing methods lack
spatial awareness capabilities, limiting their effectiveness in bridging visual
plans to actionable control in complex environments. To address this problem,
we propose Spatial Policy (SP), a unified spatial-aware visuomotor robotic
manipulation framework via explicit spatial modeling and reasoning.
Specifically, we first design a spatial-conditioned embodied video generation
module to model spatially guided predictions through a spatial plan table.
Then, we propose a spatial-based action prediction module to infer executable
actions with coordination. Finally, we propose a spatial reasoning feedback
policy to refine the spatial plan table via dual-stage replanning. Extensive
experiments show that SP significantly outperforms state-of-the-art baselines,
achieving a 33.0% average improvement over the best baseline. With an 86.7%
average success rate across 11 diverse tasks, SP substantially enhances the
practicality of embodied models for robotic control applications. Code and
checkpoints are maintained at
https://plantpotatoonmoon.github.io/SpatialPolicy/.

</details>


### [2] [UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation](https://arxiv.org/abs/2508.15972)
*Zhaodong Jiang,Ashish Sinha,Tongtong Cao,Yuan Ren,Bingbing Liu,Binbin Xu*

Main category: cs.RO

TL;DR: UnPose是一个零样本、无模型的6D物体姿态估计和重建框架，利用预训练扩散模型的3D先验和不确定性估计，通过3D高斯泼溅表示和增量优化实现高精度姿态估计和3D重建。


<details>
  <summary>Details</summary>
Motivation: 传统6D姿态估计需要物体CAD模型，但获取成本高且不实用。现有方法虽然尝试绕过这一要求，但通常需要额外训练或产生幻觉几何。

Method: 从单视角RGB-D帧开始，使用多视角扩散模型估计初始3D高斯泼溅模型和不确定性。随着新观测的加入，基于不确定性指导增量优化3D模型，并通过姿态图优化确保全局一致性。

Result: 大量实验表明，UnPose在6D姿态估计精度和3D重建质量上显著优于现有方法，并在真实机器人操作任务中展示了实用性。

Conclusion: UnPose提供了一个有效的零样本解决方案，无需CAD模型或额外训练，通过扩散模型先验和不确定性指导的增量优化实现了高质量的6D姿态估计和3D重建。

Abstract: Estimating the 6D pose of novel objects is a fundamental yet challenging
problem in robotics, often relying on access to object CAD models. However,
acquiring such models can be costly and impractical. Recent approaches aim to
bypass this requirement by leveraging strong priors from foundation models to
reconstruct objects from single or multi-view images, but typically require
additional training or produce hallucinated geometry. To this end, we propose
UnPose, a novel framework for zero-shot, model-free 6D object pose estimation
and reconstruction that exploits 3D priors and uncertainty estimates from a
pre-trained diffusion model. Specifically, starting from a single-view RGB-D
frame, UnPose uses a multi-view diffusion model to estimate an initial 3D model
using 3D Gaussian Splatting (3DGS) representation, along with pixel-wise
epistemic uncertainty estimates. As additional observations become available,
we incrementally refine the 3DGS model by fusing new views guided by the
diffusion model's uncertainty, thereby continuously improving the pose
estimation accuracy and 3D reconstruction quality. To ensure global
consistency, the diffusion prior-generated views and subsequent observations
are further integrated in a pose graph and jointly optimized into a coherent
3DGS field. Extensive experiments demonstrate that UnPose significantly
outperforms existing approaches in both 6D pose estimation accuracy and 3D
reconstruction quality. We further showcase its practical applicability in
real-world robotic manipulation tasks.

</details>


### [3] [GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System](https://arxiv.org/abs/2508.15990)
*Hung-Jui Huang,Mohammad Amin Mirzaee,Michael Kaess,Wenzhen Yuan*

Main category: cs.RO

TL;DR: GelSLAM是一种基于触觉传感的实时3D SLAM系统，能够长时间估计物体姿态并以高保真度重建物体形状，无需视觉输入


<details>
  <summary>Details</summary>
Motivation: 精确感知物体姿态和形状对于精确抓取和操作至关重要。相比视觉方法，触觉传感在跟踪和重建接触物体时具有精度高、抗遮挡的优势，特别适合手内操作等高精度任务

Method: 使用触觉传感获取的表面法线和曲率进行鲁棒跟踪和闭环检测，而非传统的点云方法。系统能够实时跟踪物体运动并重建形状

Result: 能够以低误差和最小漂移实时跟踪物体运动，重建形状精度达到亚毫米级别，即使对于木质工具等低纹理物体也有效

Conclusion: GelSLAM将触觉传感从局部接触扩展到全局、长时程的空间感知，为涉及手内物体交互的精确操作任务提供了基础

Abstract: Accurately perceiving an object's pose and shape is essential for precise
grasping and manipulation. Compared to common vision-based methods, tactile
sensing offers advantages in precision and immunity to occlusion when tracking
and reconstructing objects in contact. This makes it particularly valuable for
in-hand and other high-precision manipulation tasks. In this work, we present
GelSLAM, a real-time 3D SLAM system that relies solely on tactile sensing to
estimate object pose over long periods and reconstruct object shapes with high
fidelity. Unlike traditional point cloud-based approaches, GelSLAM uses
tactile-derived surface normals and curvatures for robust tracking and loop
closure. It can track object motion in real time with low error and minimal
drift, and reconstruct shapes with submillimeter accuracy, even for low-texture
objects such as wooden tools. GelSLAM extends tactile sensing beyond local
contact to enable global, long-horizon spatial perception, and we believe it
will serve as a foundation for many precise manipulation tasks involving
interaction with objects in hand. The video demo is available on our website:
https://joehjhuang.github.io/gelslam.

</details>


### [4] [Self-Aligning EPM Connector: A Versatile Solution for Adaptive and Multi-Modal Interfaces](https://arxiv.org/abs/2508.16008)
*Bingchao Wang,Adam A. Stokes*

Main category: cs.RO

TL;DR: 基于电永磁技术的多功能连接器，集成了自对准、机械耦合、流体传输和数据通信功能，适用于模块化机器人、电动汽车充电等多种应用场景


<details>
  <summary>Details</summary>
Motivation: 开发一种紧凑型多功能连接器，能够同时处理机械连接、流体传输和数据通信，解决传统连接器在复杂应用场景中的局限性

Method: 采用电永磁技术，通过SLA 3D打印制造紧凑结构，集成自对准机制、流体传输通道和数据通信电子控制系统

Result: 实验证明连接器具有可靠的自对准性能、高效的流体传输能力（单回路和双通道模式）、稳定的数据传输，并能适应轴向、角度和横向偏差，同时保持低能耗

Conclusion: 该电永磁多功能连接器技术成熟，具有高度灵活性和低能耗特点，非常适合模块化机器人、电动汽车充电、家用机器人平台和航空航天对接等应用领域

Abstract: This paper presents a multifunctional connector based on electro-permanent
magnet (EPM) technology, integrating self-alignment, mechanical coupling, fluid
transfer, and data communication within a compact SLA-3D printed structure.
Experimental results demonstrate reliable self-alignment, efficient fluid
transfer in single-loop and dual-channel modes, and robust data transmission
via integrated electronic control. The connector exhibits high flexibility in
accommodating axial, angular, and lateral misalignments while maintaining low
energy consumption. These features make it highly suitable for modular
robotics, electric vehicle charging, household robotic platforms, and aerospace
docking applications.

</details>


### [5] [Take That for Me: Multimodal Exophora Resolution with Interactive Questioning for Ambiguous Out-of-View Instructions](https://arxiv.org/abs/2508.16143)
*Akira Oyama,Shoichi Hasegawa,Akira Taniguchi,Yoshinobu Hagiwara,Tadahiro Taniguchi*

Main category: cs.RO

TL;DR: MIEL是一个多模态外指消解框架，通过声音定位、语义地图和交互式提问来解决机器人视野外物体的指代问题，性能比现有方法提升1.3-2.0倍


<details>
  <summary>Details</summary>
Motivation: 现有外指消解方法主要依赖视觉数据，无法处理用户或物体不在机器人视野内的真实场景

Method: 结合声音源定位(SSL)确定用户位置，构建语义地图，使用视觉语言模型(VLMs)和GPT-4o进行交互式提问

Result: 实验显示，用户可见时性能提升约1.3倍，用户不可见时提升约2.0倍

Conclusion: MIEL框架通过多模态融合和主动交互，有效解决了真实环境中视野外物体的指代消解问题

Abstract: Daily life support robots must interpret ambiguous verbal instructions
involving demonstratives such as ``Bring me that cup,'' even when objects or
users are out of the robot's view. Existing approaches to exophora resolution
primarily rely on visual data and thus fail in real-world scenarios where the
object or user is not visible. We propose Multimodal Interactive Exophora
resolution with user Localization (MIEL), which is a multimodal exophora
resolution framework leveraging sound source localization (SSL), semantic
mapping, visual-language models (VLMs), and interactive questioning with
GPT-4o. Our approach first constructs a semantic map of the environment and
estimates candidate objects from a linguistic query with the user's skeletal
data. SSL is utilized to orient the robot toward users who are initially
outside its visual field, enabling accurate identification of user gestures and
pointing directions. When ambiguities remain, the robot proactively interacts
with the user, employing GPT-4o to formulate clarifying questions. Experiments
in a real-world environment showed results that were approximately 1.3 times
better when the user was visible to the robot and 2.0 times better when the
user was not visible to the robot, compared to the methods without SSL and
interactive questioning. The project website is
https://emergentsystemlabstudent.github.io/MIEL/.

</details>


### [6] [GPL-SLAM: A Laser SLAM Framework with Gaussian Process Based Extended Landmarks](https://arxiv.org/abs/2508.16459)
*Ali Emre Balcı,Erhan Ege Keyvan,Emre Özkan*

Main category: cs.RO

TL;DR: 提出了一种基于高斯过程的SLAM方法，使用GP轮廓表示物体地标，在贝叶斯框架下联合推断机器人位姿和物体地图，提供语义信息和形状置信度


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法使用网格地图或点云配准，缺乏语义信息和物体级别的环境表示，需要更高效的内存使用和更丰富的环境理解

Method: 采用高斯过程(GP)基于轮廓的物体表示方法，通过递归方案在线更新轮廓，在完全贝叶斯框架下制定SLAM问题，联合推断机器人位姿和基于物体的地图

Result: 在合成和真实世界实验中验证了方法，在不同结构化环境中实现了准确的定位和建图性能，提供了物体数量和面积等语义信息

Conclusion: GP基于轮廓的表示方法为SLAM提供了语义丰富的环境模型，支持概率测量到物体的关联，为安全导航和探索等下游任务提供有价值的形状置信度信息

Abstract: We present a novel Simultaneous Localization and Mapping (SLAM) method that
employs Gaussian Process (GP) based landmark (object) representations. Instead
of conventional grid maps or point cloud registration, we model the environment
on a per object basis using GP based contour representations. These contours
are updated online through a recursive scheme, enabling efficient memory usage.
The SLAM problem is formulated within a fully Bayesian framework, allowing
joint inference over the robot pose and object based map. This representation
provides semantic information such as the number of objects and their areas,
while also supporting probabilistic measurement to object associations.
Furthermore, the GP based contours yield confidence bounds on object shapes,
offering valuable information for downstream tasks like safe navigation and
exploration. We validate our method on synthetic and real world experiments,
and show that it delivers accurate localization and mapping performance across
diverse structured environments.

</details>


### [7] [Swarming Without an Anchor (SWA): Robot Swarms Adapt Better to Localization Dropouts Then a Single Robot](https://arxiv.org/abs/2508.16460)
*Jiri Horyna,Roland Jung,Stephan Weiss,Eliseo Ferrante,Martin Saska*

Main category: cs.RO

TL;DR: SWA方法通过融合分散状态估计、鲁棒相互感知和机载传感器数据，使无人机群在个体定位丢失时仅使用相对信息维持横向稳定和速度一致性


<details>
  <summary>Details</summary>
Motivation: 解决无人机群在个体定位系统间歇性失效时的状态估计问题，提高多无人机系统的可靠性和弹性

Method: 融合分散状态估计、鲁棒相互感知和机载传感器数据，利用相对信息估计无人机横向状态并识别相对于局部星座的无歧义状态

Result: 实现了速度一致性（双积分器同步问题），除了整个群集的均匀平移漂移外，所有干扰和性能下降都被衰减

Conclusion: 模拟和真实实验验证了该方法在主要定位不可靠或不可用的情况下维持凝聚群行为的有效性，为紧密合作提高多无人机系统可靠性提供了新机会

Abstract: In this paper, we present the Swarming Without an Anchor (SWA) approach to
state estimation in swarms of Unmanned Aerial Vehicles (UAVs) experiencing
ego-localization dropout, where individual agents are laterally stabilized
using relative information only. We propose to fuse decentralized state
estimation with robust mutual perception and onboard sensor data to maintain
accurate state awareness despite intermittent localization failures. Thus, the
relative information used to estimate the lateral state of UAVs enables the
identification of the unambiguous state of UAVs with respect to the local
constellation. The resulting behavior reaches velocity consensus, as this task
can be referred to as the double integrator synchronization problem. All
disturbances and performance degradations except a uniform translation drift of
the swarm as a whole is attenuated which is enabling new opportunities in using
tight cooperation for increasing reliability and resilience of multi-UAV
systems. Simulations and real-world experiments validate the effectiveness of
our approach, demonstrating its capability to sustain cohesive swarm behavior
in challenging conditions of unreliable or unavailable primary localization.

</details>


### [8] [Terrain Classification for the Spot Quadrupedal Mobile Robot Using Only Proprioceptive Sensing](https://arxiv.org/abs/2508.16504)
*Sophie Villemure,Jefferson Silveira,Joshua A. Marshall*

Main category: cs.RO

TL;DR: 四足机器人地形分类器，利用自感信号识别不同地形类型，准确率达97%，为机器人安全航行提供支撑


<details>
  <summary>Details</summary>
Motivation: 四足机器人在挑战性地形上容易出现滑移和下沉等不良行为，需要地形识别技术来提升航行安全性

Method: 采用维度降屈技术处理Spot机器人提供的100多个自感信号，包括脚部突破、力量、关节角度等，然后进行分类识别

Result: 在代表性地面测试中，该地形分类器能够识别三种不同地形类型，准确率约为97%

Conclusion: 通过自感信号分析可以高效识别地形，为四足机器人的航行安全提供重要的地形可通行性信息

Abstract: Quadrupedal mobile robots can traverse a wider range of terrain types than
their wheeled counterparts but do not perform the same on all terrain types.
These robots are prone to undesirable behaviours like sinking and slipping on
challenging terrains. To combat this issue, we propose a terrain classifier
that provides information on terrain type that can be used in robotic systems
to create a traversability map to plan safer paths for the robot to navigate.
The work presented here is a terrain classifier developed for a Boston Dynamics
Spot robot. Spot provides over 100 measured proprioceptive signals describing
the motions of the robot and its four legs (e.g., foot penetration, forces,
joint angles, etc.). The developed terrain classifier combines dimensionality
reduction techniques to extract relevant information from the signals and then
applies a classification technique to differentiate terrain based on
traversability. In representative field testing, the resulting terrain
classifier was able to identify three different terrain types with an accuracy
of approximately 97%

</details>


### [9] [On Kinodynamic Global Planning in a Simplicial Complex Environment: A Mixed Integer Approach](https://arxiv.org/abs/2508.16511)
*Otobong Jerome,Alexandr Klimchik,Alexander Maloletov,Geesara Kulathunga*

Main category: cs.RO

TL;DR: 该研究将类车车辆的动力学规划问题转化为优化任务，计算最小时间轨迹和速度曲线，同时满足速度、加速度和转向的边界条件约束。


<details>
  <summary>Details</summary>
Motivation: 为了解决类车车辆在复杂3D地形中的动力学规划问题，需要同时优化空间路径和控制序列，确保从初始状态到目标状态的连续运动，并避免局部最优解。

Method: 将问题建模为混合整数分数规划，通过变量变换转化为混合整数双线性目标，再使用McCormick包络松弛为混合整数线性规划，在单纯复形环境中高效运算。

Result: 与MPPI和log-MPPI等规划器相比，该方法生成解决方案的速度快104倍，且严格满足所有约束条件。

Conclusion: 该方法能够高效解决类车车辆的动力学规划问题，在复杂地形中快速生成满足约束的最优轨迹，具有显著的性能优势。

Abstract: This work casts the kinodynamic planning problem for car-like vehicles as an
optimization task to compute a minimum-time trajectory and its associated
velocity profile, subject to boundary conditions on velocity, acceleration, and
steering. The approach simultaneously optimizes both the spatial path and the
sequence of acceleration and steering controls, ensuring continuous motion from
a specified initial position and velocity to a target end position and
velocity.The method analyzes the admissible control space and terrain to avoid
local minima. The proposed method operates efficiently in simplicial complex
environments, a preferred terrain representation for capturing intricate 3D
landscapes. The problem is initially posed as a mixed-integer fractional
program with quadratic constraints, which is then reformulated into a
mixed-integer bilinear objective through a variable transformation and
subsequently relaxed to a mixed-integer linear program using McCormick
envelopes. Comparative simulations against planners such as MPPI and log-MPPI
demonstrate that the proposed approach generates solutions 104 times faster
while strictly adhering to the specified constraints

</details>


### [10] [Comparative Analysis of UAV Path Planning Algorithms for Efficient Navigation in Urban 3D Environments](https://arxiv.org/abs/2508.16515)
*Hichem Cheriet,Khellat Kihel Badra,Chouraqui Samira*

Main category: cs.RO

TL;DR: 本文通过三维城市环境实验比较A*、RRT*和PSO三种路径规划算法，发现A*在计算效率和路径质量方面表现最佳，PSO适合密集环境，RRT*在各种场景下表现均衡。


<details>
  <summary>Details</summary>
Motivation: 无人机路径规划面临诸多挑战，现有算法虽能解决问题但存在局限性，需要通过系统实验评估主流算法的性能表现。

Method: 在三维城市环境中设计三组实验，每组包含两种场景，测试不同地图尺寸、飞行高度、障碍物密度和大小条件下的算法性能。

Result: A*算法在计算效率和路径质量方面表现最优；PSO算法特别适合密集环境和急转弯；RRT*算法因其随机搜索特性在所有实验中表现均衡。

Conclusion: 不同算法各有优势，A*综合性能最佳，PSO适合特定密集场景，RRT*具有较好的通用性，为无人机路径规划算法选择提供了实证依据。

Abstract: The most crucial challenges for UAVs are planning paths and avoiding
obstacles in their way. In recent years, a wide variety of path-planning
algorithms have been developed. These algorithms have successfully solved
path-planning problems; however, they suffer from multiple challenges and
limitations. To test the effectiveness and efficiency of three widely used
algorithms, namely A*, RRT*, and Particle Swarm Optimization (PSO), this paper
conducts extensive experiments in 3D urban city environments cluttered with
obstacles. Three experiments were designed with two scenarios each to test the
aforementioned algorithms. These experiments consider different city map sizes,
different altitudes, and varying obstacle densities and sizes in the
environment. According to the experimental results, the A* algorithm
outperforms the others in both computation efficiency and path quality. PSO is
especially suitable for tight turns and dense environments, and RRT* offers a
balance and works well across all experiments due to its randomized approach to
finding solutions.

</details>


### [11] [Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems](https://arxiv.org/abs/2508.16574)
*Yizhi Wang,Degang Xu,Yongfang Xie,Shuzhong Tan,Xianan Zhou,Peng Chen*

Main category: cs.RO

TL;DR: 本文提出了一种用于四轮独立转向驾驶系统的层次决策框架，结合深度强化学习和模糊逻辑控制，实现了更高效稳定的自主导航能力。


<details>
  <summary>Details</summary>
Motivation: 解决纯粹深度强化学习在四轮独立轮轮轮系统中导致的机械压力和轮胎滑移问题，提高导航的安全性和可靠性。

Method: 采用层次决策框架，高层使用深度强化学习生成全局运动指令，低层使用模糊逻辑控制器确保运动学约束和物理可行性。

Result: 模拟实验表明该框架在训练效率、稳定性和行为表现方面都超过传统方法，并在实际工业环境中验证了其安全有效导航能力。

Conclusion: 该工作为四轮独立轮轮轮系统提供了一种可扩展、可靠的解决方案，适用于复杂的实际应用场景。

Abstract: This paper presents a hierarchical decision-making framework for autonomous
navigation in four-wheel independent steering and driving (4WISD) systems. The
proposed approach integrates deep reinforcement learning (DRL) for high-level
navigation with fuzzy logic for low-level control to ensure both task
performance and physical feasibility. The DRL agent generates global motion
commands, while the fuzzy logic controller enforces kinematic constraints to
prevent mechanical strain and wheel slippage. Simulation experiments
demonstrate that the proposed framework outperforms traditional navigation
methods, offering enhanced training efficiency and stability and mitigating
erratic behaviors compared to purely DRL-based solutions. Real-world
validations further confirm the framework's ability to navigate safely and
effectively in dynamic industrial settings. Overall, this work provides a
scalable and reliable solution for deploying 4WISD mobile robots in complex,
real-world scenarios.

</details>
