{"id": "2508.05773", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.05773", "abs": "https://arxiv.org/abs/2508.05773", "authors": ["Keyvan Majd", "Hardik Parwana", "Bardh Hoxha", "Steven Hong", "Hideki Okamoto", "Georgios Fainekos"], "title": "GPU-Accelerated Barrier-Rate Guided MPPI Control for Tractor-Trailer Systems", "comment": "Accepted to IEEE ITSC 2025", "summary": "Articulated vehicles such as tractor-trailers, yard trucks, and similar\nplatforms must often reverse and maneuver in cluttered spaces where pedestrians\nare present. We present how Barrier-Rate guided Model Predictive Path Integral\n(BR-MPPI) control can solve navigation in such challenging environments.\nBR-MPPI embeds Control Barrier Function (CBF) constraints directly into the\npath-integral update. By steering the importance-sampling distribution toward\ncollision-free, dynamically feasible trajectories, BR-MPPI enhances the\nexploration strength of MPPI and improves robustness of resulting trajectories.\nThe method is evaluated in the high-fidelity CarMaker simulator on a 12 [m]\ntractor-trailer tasked with reverse and forward parking in a parking lot.\nBR-MPPI computes control inputs in above 100 [Hz] on a single GPU (for\nscenarios with eight obstacles) and maintains better parking clearance than a\nstandard MPPI baseline and an MPPI with collision cost baseline.", "AI": {"tldr": "BR-MPPI方法通过结合控制屏障函数（CBF）约束，提升了MPPI在复杂环境中的导航能力，并在高保真模拟器中验证了其高效性和鲁棒性。", "motivation": "解决铰接式车辆（如拖车、堆场卡车等）在拥挤空间中倒车和机动时的导航挑战，尤其是在行人存在的情况下。", "method": "将控制屏障函数（CBF）约束直接嵌入路径积分更新中，引导重要性采样分布朝向无碰撞且动态可行的轨迹。", "result": "在CarMaker模拟器中，BR-MPPI在12米拖车倒车和前进停车任务中表现出色，计算速度超过100Hz，停车间隙优于标准MPPI和带碰撞成本的MPPI基线。", "conclusion": "BR-MPPI通过增强探索能力和轨迹鲁棒性，为复杂环境中的车辆导航提供了高效且可靠的解决方案。"}}
{"id": "2508.05838", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY", "68T07, 68T40, 90C40, 93E35", "I.2.6; I.2.9; I.2.10"], "pdf": "https://arxiv.org/pdf/2508.05838", "abs": "https://arxiv.org/abs/2508.05838", "authors": ["Ahmad Farooq", "Kamran Iqbal"], "title": "Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction", "comment": "Published in the Proceedings of the 2025 3rd International Conference\n  on Robotics, Control and Vision Engineering (RCVE'25). 6 pages, 3 figures, 1\n  table", "summary": "This paper presents a novel approach that integrates vision foundation models\nwith reinforcement learning to enhance object interaction capabilities in\nsimulated environments. By combining the Segment Anything Model (SAM) and\nYOLOv5 with a Proximal Policy Optimization (PPO) agent operating in the\nAI2-THOR simulation environment, we enable the agent to perceive and interact\nwith objects more effectively. Our comprehensive experiments, conducted across\nfour diverse indoor kitchen settings, demonstrate significant improvements in\nobject interaction success rates and navigation efficiency compared to a\nbaseline agent without advanced perception. The results show a 68% increase in\naverage cumulative reward, a 52.5% improvement in object interaction success\nrate, and a 33% increase in navigation efficiency. These findings highlight the\npotential of integrating foundation models with reinforcement learning for\ncomplex robotic tasks, paving the way for more sophisticated and capable\nautonomous agents.", "AI": {"tldr": "本文提出了一种结合视觉基础模型与强化学习的新方法，显著提升了模拟环境中物体交互的能力。", "motivation": "通过结合视觉基础模型（如SAM和YOLOv5）与强化学习（PPO），旨在提升智能体在复杂环境中的感知与交互能力。", "method": "使用Segment Anything Model (SAM)和YOLOv5作为视觉基础模型，结合PPO强化学习算法，在AI2-THOR模拟环境中进行实验。", "result": "实验结果显示，与基线相比，平均累积奖励提升了68%，物体交互成功率提高了52.5%，导航效率提升了33%。", "conclusion": "该研究表明，结合视觉基础模型与强化学习可显著提升复杂机器人任务的表现，为更先进的自主智能体铺平了道路。"}}
{"id": "2508.05936", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.05936", "abs": "https://arxiv.org/abs/2508.05936", "authors": ["Haohui Pan", "Takuya Kiyokawa", "Tomoki Ishikura", "Shingo Hamada", "Genichiro Matsuda", "Kensuke Harada"], "title": "Modular Vacuum-Based Fixturing System for Adaptive Disassembly Workspace Integration", "comment": "8 pages, 9 figures", "summary": "The disassembly of small household appliances poses significant challenges\ndue to their complex and curved geometries, which render traditional rigid\nfixtures inadequate. In this paper, we propose a modular vacuum-based fixturing\nsystem that leverages commercially available balloon-type soft grippers to\nconform to arbitrarily shaped surfaces and provide stable support during\nscrew-removal tasks. To enable a reliable deployment of the system, we develop\na stability-aware planning framework that samples the bottom surface of the\ntarget object, filters candidate contact points based on geometric continuity,\nand evaluates support configurations using convex hull-based static stability\ncriteria. We compare the quality of object placement under different numbers\nand configurations of balloon hands. In addition, real-world experiments were\nconducted to compare the success rates of traditional rigid fixtures with our\nproposed system. The results demonstrate that our method consistently achieves\nhigher success rates and superior placement stability during screw removal\ntasks.", "AI": {"tldr": "提出了一种基于模块化真空夹具的系统，利用软气球夹持器适应复杂几何形状，提升螺丝拆卸任务的稳定性。", "motivation": "传统刚性夹具难以适应小型家电的复杂曲面几何形状，导致拆卸任务效率低下。", "method": "开发了稳定性感知规划框架，通过采样目标物体底面、筛选接触点并评估支撑配置，优化夹具部署。", "result": "与传统刚性夹具相比，新系统在螺丝拆卸任务中表现出更高的成功率和稳定性。", "conclusion": "模块化真空夹具系统显著提升了复杂几何形状家电的拆卸效率和稳定性。"}}
{"id": "2508.05937", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.05937", "abs": "https://arxiv.org/abs/2508.05937", "authors": ["Gen Sako", "Takuya Kiyokawa", "Kensuke Harada", "Tomoki Ishikura", "Naoya Miyaji", "Genichiro Matsuda"], "title": "Affordance-Guided Dual-Armed Disassembly Teleoperation for Mating Parts", "comment": "6 pages, 9 figures", "summary": "Robotic non-destructive disassembly of mating parts remains challenging due\nto the need for flexible manipulation and the limited visibility of internal\nstructures. This study presents an affordance-guided teleoperation system that\nenables intuitive human demonstrations for dual-arm fix-and-disassemble tasks\nfor mating parts. The system visualizes feasible grasp poses and disassembly\ndirections in a virtual environment, both derived from the object's geometry,\nto address occlusions and structural complexity. To prevent excessive position\ntracking under load when following the affordance, we integrate a hybrid\ncontroller that combines position and impedance control into the teleoperated\ndisassembly arm. Real-world experiments validate the effectiveness of the\nproposed system, showing improved task success rates and reduced object pose\ndeviation.", "AI": {"tldr": "提出了一种基于直觉演示的双臂拆卸系统，通过虚拟环境可视化抓取和拆卸方向，结合混合控制提高任务成功率。", "motivation": "解决机器人拆卸配对零件时因内部结构不可见和操作灵活性不足带来的挑战。", "method": "设计了一种基于几何的虚拟环境可视化系统，结合位置和阻抗控制的混合控制器。", "result": "实验验证了系统的有效性，任务成功率提高，物体位姿偏差减少。", "conclusion": "该系统为复杂拆卸任务提供了一种直观且高效的解决方案。"}}
{"id": "2508.05941", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.05941", "abs": "https://arxiv.org/abs/2508.05941", "authors": ["Zhanyi Sun", "Shuran Song"], "title": "Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution", "comment": null, "summary": "Visuomotor policies trained via behavior cloning are vulnerable to covariate\nshift, where small deviations from expert trajectories can compound into\nfailure. Common strategies to mitigate this issue involve expanding the\ntraining distribution through human-in-the-loop corrections or synthetic data\naugmentation. However, these approaches are often labor-intensive, rely on\nstrong task assumptions, or compromise the quality of imitation. We introduce\nLatent Policy Barrier, a framework for robust visuomotor policy learning.\nInspired by Control Barrier Functions, LPB treats the latent embeddings of\nexpert demonstrations as an implicit barrier separating safe, in-distribution\nstates from unsafe, out-of-distribution (OOD) ones. Our approach decouples the\nrole of precise expert imitation and OOD recovery into two separate modules: a\nbase diffusion policy solely on expert data, and a dynamics model trained on\nboth expert and suboptimal policy rollout data. At inference time, the dynamics\nmodel predicts future latent states and optimizes them to stay within the\nexpert distribution. Both simulated and real-world experiments show that LPB\nimproves both policy robustness and data efficiency, enabling reliable\nmanipulation from limited expert data and without additional human correction\nor annotation.", "AI": {"tldr": "Latent Policy Barrier (LPB) 是一种通过分离专家模仿和OOD恢复的框架，提升视觉运动策略的鲁棒性和数据效率。", "motivation": "行为克隆训练的视觉运动策略容易受到协变量偏移的影响，常见缓解方法（如人工干预或数据增强）成本高或效果有限。", "method": "LPB 将专家演示的潜在嵌入视为隐式屏障，分为基础扩散策略和动态模型两部分，分别处理专家模仿和OOD恢复。", "result": "实验表明，LPB 在模拟和真实场景中均提高了策略的鲁棒性和数据效率。", "conclusion": "LPB 能够仅依赖有限专家数据实现可靠操作，无需额外人工干预。"}}
{"id": "2508.05946", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.05946", "abs": "https://arxiv.org/abs/2508.05946", "authors": ["Nello Balossino", "Rossana Damiano", "Cristina Gena", "Alberto Lillo", "Anna Maria Marras", "Claudio Mattutino", "Antonio Pizzo", "Alessia Prin", "Fabiana Vernero"], "title": "Social and Telepresence Robots for Accessibility and Inclusion in Small Museums", "comment": null, "summary": "There are still many museums that present accessibility barriers,\nparticularly regarding perceptual, cultural, and cognitive aspects. This is\nespecially evident in low-density population areas. The aim of the ROBSO-PM\nproject is to improve the accessibility of small museums through the use of\nsocial robots and social telepresence robots, focusing on three museums as case\nstudies: the Museum of the Holy Shroud in Turin, a small but globally known\ninstitution, and two lesser known mountain museums: the Museum of the Champlas\ndu Col Carnival and the Pragelato Museum of Alpine Peoples' Costumes and\nTraditions. The project explores two main applications for robots: as guides\nsupporting inclusive visits for foreign or disabled visitors, and as\ntelepresence tools allowing people with limited mobility to access museums\nremotely. From a research perspective, key topics include storytelling, robot\npersonality, empathy, personalization, and, in the case of telepresence,\ncollaboration between the robot and the person, with clearly defined roles and\nautonomy.", "AI": {"tldr": "ROBSO-PM项目旨在通过社交机器人和远程社交机器人提升小型博物馆的可访问性，重点关注感知、文化和认知障碍。", "motivation": "许多博物馆，尤其是低人口密度地区的博物馆，存在可访问性障碍，项目希望通过技术手段改善这一问题。", "method": "项目以三个博物馆为案例研究，探索机器人作为导览和远程访问工具的应用，涉及讲故事、机器人个性化和协作等研究主题。", "result": "项目提出机器人可作为导览支持包容性访问，或作为远程访问工具帮助行动不便者。", "conclusion": "通过社交机器人技术，小型博物馆的可访问性有望显著提升。"}}
{"id": "2508.05972", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.05972", "abs": "https://arxiv.org/abs/2508.05972", "authors": ["Shaoting Liu", "Zhou Liu"], "title": "Dynamical Trajectory Planning of Disturbance Consciousness for Air-Land Bimodal Unmanned Aerial Vehicles", "comment": null, "summary": "Air-land bimodal vehicles provide a promising solution for navigating complex\nenvironments by combining the flexibility of aerial locomotion with the energy\nefficiency of ground mobility. To enhance the robustness of trajectory planning\nunder environmental disturbances, this paper presents a disturbance-aware\nplanning framework that incorporates real-time disturbance estimation into both\npath searching and trajectory optimization. A key component of the framework is\na disturbance-adaptive safety boundary adjustment mechanism, which dynamically\nmodifies the vehicle's feasible dynamic boundaries based on estimated\ndisturbances to ensure trajectory feasibility. Leveraging the dynamics model of\nthe bimodal vehicle, the proposed approach achieves adaptive and reliable\nmotion planning across different terrains and operating conditions. A series of\nreal-world experiments and benchmark comparisons on a custom-built platform\nvalidate the effectiveness and robustness of the method, demonstrating\nimprovements in tracking accuracy, task efficiency, and energy performance\nunder both ground and aerial disturbances.", "AI": {"tldr": "提出了一种扰动感知的规划框架，通过实时扰动估计优化路径搜索和轨迹规划，提升双模态车辆在复杂环境中的鲁棒性。", "motivation": "双模态车辆结合了空中和地面移动的优势，但环境扰动会影响轨迹规划的鲁棒性，因此需要一种扰动感知的规划方法。", "method": "采用扰动自适应安全边界调整机制，基于实时扰动估计动态调整车辆的可行动态边界，并结合车辆动力学模型进行运动规划。", "result": "实验验证了该方法在跟踪精度、任务效率和能源性能上的提升，尤其是在地面和空中扰动下的表现。", "conclusion": "该框架有效提升了双模态车辆在复杂环境中的鲁棒性和适应性。"}}
{"id": "2508.06053", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06053", "abs": "https://arxiv.org/abs/2508.06053", "authors": ["Kaixuan Wu", "Yuanzhuo Xu", "Zejun Zhang", "Weiping Zhu", "Steve Drew", "Xiaoguang Niu"], "title": "ReNiL: Relative Neural Inertial Locator with Any-Scale Bayesian Inference", "comment": null, "summary": "Pedestrian inertial localization is key for mobile and IoT services because\nit provides infrastructure-free positioning. Yet most learning-based methods\ndepend on fixed sliding-window integration, struggle to adapt to diverse motion\nscales and cadences, and yield inconsistent uncertainty, limiting real-world\nuse. We present ReNiL, a Bayesian deep-learning framework for accurate,\nefficient, and uncertainty-aware pedestrian localization. ReNiL introduces\nInertial Positioning Demand Points (IPDPs) to estimate motion at contextually\nmeaningful waypoints instead of dense tracking, and supports inference on IMU\nsequences at any scale so cadence can match application needs. It couples a\nmotion-aware orientation filter with an Any-Scale Laplace Estimator (ASLE), a\ndual-task network that blends patch-based self-supervision with Bayesian\nregression. By modeling displacements with a Laplace distribution, ReNiL\nprovides homogeneous Euclidean uncertainty that integrates cleanly with other\nsensors. A Bayesian inference chain links successive IPDPs into consistent\ntrajectories. On RoNIN-ds and a new WUDataset covering indoor and outdoor\nmotion from 28 participants, ReNiL achieves state-of-the-art displacement\naccuracy and uncertainty consistency, outperforming TLIO, CTIN, iMoT, and RoNIN\nvariants while reducing computation. Application studies further show\nrobustness and practicality for mobile and IoT localization, making ReNiL a\nscalable, uncertainty-aware foundation for next-generation positioning.", "AI": {"tldr": "ReNiL是一个基于贝叶斯深度学习的框架，用于高效、准确且具有不确定性感知的行人惯性定位。它通过IPDPs和ASLE技术，解决了传统方法在运动尺度和步频适应性上的不足。", "motivation": "现有基于学习的方法在惯性定位中存在固定滑动窗口集成、难以适应多样化运动尺度和步频的问题，且不确定性估计不一致，限制了实际应用。", "method": "ReNiL引入IPDPs来估计上下文有意义的路径点运动，结合ASLE网络（融合自监督和贝叶斯回归）和运动感知方向滤波器，提供均匀的欧几里得不确定性。", "result": "在RoNIN-ds和WUDataset上，ReNiL在位移精度和不确定性一致性上达到最优，计算量更低，优于TLIO、CTIN等方法。", "conclusion": "ReNiL为移动和IoT定位提供了可扩展、不确定性感知的基础，具有实际应用的鲁棒性和实用性。"}}
{"id": "2508.06095", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06095", "abs": "https://arxiv.org/abs/2508.06095", "authors": ["Mitchell Abrams", "Thies Oelerich", "Christian Hartl-Nesic", "Andreas Kugi", "Matthias Scheutz"], "title": "Incremental Language Understanding for Online Motion Planning of Robot Manipulators", "comment": "8 pages, 9 figures, accepted at IROS 2025", "summary": "Human-robot interaction requires robots to process language incrementally,\nadapting their actions in real-time based on evolving speech input. Existing\napproaches to language-guided robot motion planning typically assume fully\nspecified instructions, resulting in inefficient stop-and-replan behavior when\ncorrections or clarifications occur. In this paper, we introduce a novel\nreasoning-based incremental parser which integrates an online motion planning\nalgorithm within the cognitive architecture. Our approach enables continuous\nadaptation to dynamic linguistic input, allowing robots to update motion plans\nwithout restarting execution. The incremental parser maintains multiple\ncandidate parses, leveraging reasoning mechanisms to resolve ambiguities and\nrevise interpretations when needed. By combining symbolic reasoning with online\nmotion planning, our system achieves greater flexibility in handling speech\ncorrections and dynamically changing constraints. We evaluate our framework in\nreal-world human-robot interaction scenarios, demonstrating online adaptions of\ngoal poses, constraints, or task objectives. Our results highlight the\nadvantages of integrating incremental language understanding with real-time\nmotion planning for natural and fluid human-robot collaboration. The\nexperiments are demonstrated in the accompanying video at\nwww.acin.tuwien.ac.at/42d5.", "AI": {"tldr": "提出了一种基于推理的增量解析器，将在线运动规划算法集成到认知架构中，实现动态语言输入的实时适应。", "motivation": "现有方法假设指令完全明确，导致修正或澄清时需停止并重新规划，效率低下。", "method": "结合符号推理与在线运动规划，维护多个候选解析，动态调整运动计划。", "result": "在真实人机交互场景中验证了系统对目标位姿、约束或任务目标的在线适应能力。", "conclusion": "增量语言理解与实时运动规划的结合提升了人机协作的自然性和流畅性。"}}
{"id": "2508.06096", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06096", "abs": "https://arxiv.org/abs/2508.06096", "authors": ["Eric Jing", "Abdeslam Boularias"], "title": "Bounding Distributional Shifts in World Modeling through Novelty Detection", "comment": "7 pages, 6 figures", "summary": "Recent work on visual world models shows significant promise in latent state\ndynamics obtained from pre-trained image backbones. However, most of the\ncurrent approaches are sensitive to training quality, requiring near-complete\ncoverage of the action and state space during training to prevent divergence\nduring inference. To make a model-based planning algorithm more robust to the\nquality of the learned world model, we propose in this work to use a\nvariational autoencoder as a novelty detector to ensure that proposed action\ntrajectories during planning do not cause the learned model to deviate from the\ntraining data distribution. To evaluate the effectiveness of this approach, a\nseries of experiments in challenging simulated robot environments was carried\nout, with the proposed method incorporated into a model-predictive control\npolicy loop extending the DINO-WM architecture. The results clearly show that\nthe proposed method improves over state-of-the-art solutions in terms of data\nefficiency.", "AI": {"tldr": "论文提出了一种基于变分自编码器的新颖性检测方法，用于增强视觉世界模型的鲁棒性，提高数据效率。", "motivation": "当前视觉世界模型对训练质量敏感，需要近乎完整的动作和状态空间覆盖以防止推理时发散。", "method": "使用变分自编码器作为新颖性检测器，确保规划中的动作轨迹不偏离训练数据分布，并将其集成到DINO-WM架构的模型预测控制策略中。", "result": "在模拟机器人环境中的实验表明，该方法在数据效率上优于现有技术。", "conclusion": "提出的方法显著提升了视觉世界模型的鲁棒性和数据效率。"}}
{"id": "2508.06181", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06181", "abs": "https://arxiv.org/abs/2508.06181", "authors": ["Jan Węgrzynowski", "Piotr Kicki", "Grzegorz Czechmanowski", "Maciej Krupka", "Krzysztof Walas"], "title": "Beyond Constant Parameters: Hyper Prediction Models and HyperMPC", "comment": null, "summary": "Model Predictive Control (MPC) is among the most widely adopted and reliable\nmethods for robot control, relying critically on an accurate dynamics model.\nHowever, existing dynamics models used in the gradient-based MPC are limited by\ncomputational complexity and state representation. To address this limitation,\nwe propose the Hyper Prediction Model (HyperPM) - a novel approach in which we\nproject the unmodeled dynamics onto a time-dependent dynamics model. This\ntime-dependency is captured through time-varying model parameters, whose\nevolution over the MPC prediction horizon is learned using a neural network.\nSuch formulation preserves the computational efficiency and robustness of the\nbase model while equipping it with the capacity to anticipate previously\nunmodeled phenomena. We evaluated the proposed approach on several challenging\nsystems, including real-world F1TENTH autonomous racing, and demonstrated that\nit significantly reduces long-horizon prediction errors. Moreover, when\nintegrated within the MPC framework (HyperMPC), our method consistently\noutperforms existing state-of-the-art techniques.", "AI": {"tldr": "提出了一种名为HyperPM的新方法，通过时间依赖的动态模型解决现有梯度MPC中动态模型的局限性，显著减少了长期预测误差。", "motivation": "现有梯度MPC中的动态模型受限于计算复杂性和状态表示，无法准确预测未建模的动态现象。", "method": "提出HyperPM，将未建模动态投影到时间依赖的动态模型上，通过神经网络学习时间变化参数。", "result": "在F1TENTH自动驾驶赛车等挑战性系统中，HyperPM显著减少了长期预测误差，并在MPC框架（HyperMPC）中优于现有技术。", "conclusion": "HyperPM在保持计算效率和鲁棒性的同时，提高了动态模型的预测能力，为机器人控制提供了更可靠的解决方案。"}}
{"id": "2508.06206", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.06206", "abs": "https://arxiv.org/abs/2508.06206", "authors": ["Hanqing Wang", "Shaoyang Wang", "Yiming Zhong", "Zemin Yang", "Jiamin Wang", "Zhiqing Cui", "Jiahao Yuan", "Yifan Han", "Mingyu Liu", "Yuexin Ma"], "title": "Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model", "comment": null, "summary": "Affordance grounding focuses on predicting the specific regions of objects\nthat are associated with the actions to be performed by robots. It plays a\nvital role in the fields of human-robot interaction, human-object interaction,\nembodied manipulation, and embodied perception. Existing models often neglect\nthe affordance shared among different objects because they lack the\nChain-of-Thought(CoT) reasoning abilities, limiting their out-of-domain (OOD)\ngeneralization and explicit reasoning capabilities. To address these\nchallenges, we propose Affordance-R1, the first unified affordance grounding\nframework that integrates cognitive CoT guided Group Relative Policy\nOptimization (GRPO) within a reinforcement learning paradigm. Specifically, we\ndesigned a sophisticated affordance function, which contains format,\nperception, and cognition rewards to effectively guide optimization directions.\nFurthermore, we constructed a high-quality affordance-centric reasoning\ndataset, ReasonAff, to support training. Trained exclusively via reinforcement\nlearning with GRPO and without explicit reasoning data, Affordance-R1 achieves\nrobust zero-shot generalization and exhibits emergent test-time reasoning\ncapabilities. Comprehensive experiments demonstrate that our model outperforms\nwell-established methods and exhibits open-world generalization. To the best of\nour knowledge, Affordance-R1 is the first to integrate GRPO-based RL with\nreasoning into affordance reasoning. The code of our method and our dataset is\nreleased on https://github.com/hq-King/Affordance-R1.", "AI": {"tldr": "Affordance-R1是一个统一的affordance grounding框架，结合了认知CoT和GRPO强化学习，提升了OOD泛化和推理能力。", "motivation": "现有模型缺乏CoT推理能力，限制了泛化和显式推理能力，因此需要一种新方法。", "method": "设计了包含格式、感知和认知奖励的affordance函数，并构建了ReasonAff数据集，通过GRPO强化学习训练。", "result": "Affordance-R1在零样本泛化和推理能力上表现优异，优于现有方法。", "conclusion": "Affordance-R1首次将GRPO强化学习与推理结合，展示了开放世界泛化能力。"}}
{"id": "2508.06207", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06207", "abs": "https://arxiv.org/abs/2508.06207", "authors": ["Andrea Dal Prete", "Seyram Ofori", "Chan Yon Sin", "Ashwin Narayan", "Francesco Braghin", "Marta Gandolla", "Haoyong Yu"], "title": "Computer Vision-based Adaptive Control for Back Exoskeleton Performance Optimization", "comment": null, "summary": "Back exoskeletons can reduce musculoskeletal strain, but their effectiveness\ndepends on support modulation and adaptive control. This study addresses two\nchallenges: defining optimal support strategies and developing adaptive control\nbased on payload estimation. We introduce an optimization space based on muscle\nactivity reduction, perceived discomfort, and user preference, constructing\nfunctions to identify optimal strategies. Experiments with 12 subjects revealed\noptimal operating regions, highlighting the need for dynamic modulation. Based\non these insights, we developed a vision-based adaptive control pipeline that\nestimates payloads in real-time by enhancing exoskeleton contextual\nunderstanding, minimising latency and enabling support adaptation within the\ndefined optimisation space. Validation with 12 more subjects showed over 80%\naccuracy and improvements across all metrics. Compared to static control,\nadaptive modulation reduced peak back muscle activation by up to 23% while\npreserving user preference and minimising discomfort. These findings validate\nthe proposed framework and highlight the potential of intelligent,\ncontext-aware control in industrial exoskeletons.", "AI": {"tldr": "研究提出了一种基于肌肉活动减少、不适感和用户偏好的优化空间，开发了实时负载估计的自适应控制方法，显著降低了背部肌肉激活峰值。", "motivation": "解决背部外骨骼在支持策略和自适应控制方面的挑战，以提高其减轻肌肉骨骼负荷的效果。", "method": "构建优化空间以确定最佳支持策略，开发基于视觉的自适应控制管道实时估计负载。", "result": "实验显示自适应控制比静态控制更有效，峰值背部肌肉激活减少23%，且用户偏好和不适感得到优化。", "conclusion": "智能、情境感知的控制方法在工业外骨骼中具有潜力，验证了所提框架的有效性。"}}
{"id": "2508.06229", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06229", "abs": "https://arxiv.org/abs/2508.06229", "authors": ["Zihao Xu", "Ce Hao", "Chunzheng Wang", "Kuankuan Sima", "Fan Shi", "Jin Song Dong"], "title": "REBot: Reflexive Evasion Robot for Instantaneous Dynamic Obstacle Avoidance", "comment": null, "summary": "Dynamic obstacle avoidance (DOA) is critical for quadrupedal robots operating\nin environments with moving obstacles or humans. Existing approaches typically\nrely on navigation-based trajectory replanning, which assumes sufficient\nreaction time and leading to fails when obstacles approach rapidly. In such\nscenarios, quadrupedal robots require reflexive evasion capabilities to perform\ninstantaneous, low-latency maneuvers. This paper introduces Reflexive Evasion\nRobot (REBot), a control framework that enables quadrupedal robots to achieve\nreal-time reflexive obstacle avoidance. REBot integrates an avoidance policy\nand a recovery policy within a finite-state machine. With carefully designed\nlearning curricula and by incorporating regularization and adaptive rewards,\nREBot achieves robust evasion and rapid stabilization in instantaneous DOA\ntasks. We validate REBot through extensive simulations and real-world\nexperiments, demonstrating notable improvements in avoidance success rates,\nenergy efficiency, and robustness to fast-moving obstacles. Videos and appendix\nare available on https://rebot-2025.github.io/.", "AI": {"tldr": "本文提出了一种名为REBot的控制框架，用于四足机器人在动态障碍物环境中的实时反射性避障。", "motivation": "现有方法依赖导航轨迹重规划，反应时间不足，无法应对快速接近的障碍物，因此需要一种低延迟的反射性避障能力。", "method": "REBot结合避障策略和恢复策略，通过有限状态机实现，并采用精心设计的学习课程、正则化和自适应奖励。", "result": "实验表明，REBot在避障成功率、能效和对快速移动障碍物的鲁棒性方面均有显著提升。", "conclusion": "REBot为四足机器人提供了高效的实时反射性避障能力。"}}
{"id": "2508.06266", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06266", "abs": "https://arxiv.org/abs/2508.06266", "authors": ["Zezeng Li", "Rui Yang", "Ruochen Chen", "ZhongXuan Luo", "Liming Chen"], "title": "ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints", "comment": null, "summary": "Diffusion policies have recently emerged as a powerful class of visuomotor\ncontrollers for robot manipulation, offering stable training and expressive\nmulti-modal action modeling. However, existing approaches typically treat\naction generation as an unconstrained denoising process, ignoring valuable a\npriori knowledge about geometry and control structure. In this work, we propose\nthe Adaptive Diffusion Policy (ADP), a test-time adaptation method that\nintroduces two key inductive biases into the diffusion. First, we embed a\ngeometric manifold constraint that aligns denoising updates with task-relevant\nsubspaces, leveraging the fact that the relative pose between the end-effector\nand target scene provides a natural gradient direction, and guiding denoising\nalong the geodesic path of the manipulation manifold. Then, to reduce\nunnecessary exploration and accelerate convergence, we propose an analytically\nguided initialization: rather than sampling from an uninformative prior, we\ncompute a rough registration between the gripper and target scenes to propose a\nstructured initial noisy action. ADP is compatible with pre-trained diffusion\npolicies and requires no retraining, enabling test-time adaptation that tailors\nthe policy to specific tasks, thereby enhancing generalization across novel\ntasks and environments. Experiments on RLBench, CALVIN, and real-world dataset\nshow that ADPro, an implementation of ADP, improves success rates,\ngeneralization, and sampling efficiency, achieving up to 25% faster execution\nand 9% points over strong diffusion baselines.", "AI": {"tldr": "ADP是一种自适应扩散策略，通过引入几何流形约束和解析引导初始化，优化了机器人操作中的动作生成过程，提升了泛化能力和效率。", "motivation": "现有扩散策略在动作生成中忽略了几何和控制结构的先验知识，限制了性能和泛化能力。", "method": "ADP引入几何流形约束和解析引导初始化，优化扩散过程，无需重新训练即可适配任务。", "result": "实验表明，ADP在RLBench、CALVIN和真实数据集上提升了成功率和效率，执行速度提升25%，成功率提高9%。", "conclusion": "ADP通过引入先验知识，显著提升了扩散策略的性能和泛化能力。"}}
{"id": "2508.06276", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06276", "abs": "https://arxiv.org/abs/2508.06276", "authors": ["Juan Heredia", "Christian Schlette", "Mikkel Baun Kjærgaard"], "title": "EcBot: Data-Driven Energy Consumption Open-Source MATLAB Library for Manipulators", "comment": null, "summary": "Existing literature proposes models for estimating the electrical power of\nmanipulators, yet two primary limitations prevail. First, most models are\npredominantly tested using traditional industrial robots. Second, these models\noften lack accuracy. To address these issues, we introduce an open source\nMatlab-based library designed to automatically generate \\ac{ec} models for\nmanipulators. The necessary inputs for the library are Denavit-Hartenberg\nparameters, link masses, and centers of mass. Additionally, our model is\ndata-driven and requires real operational data, including joint positions,\nvelocities, accelerations, electrical power, and corresponding timestamps. We\nvalidated our methodology by testing on four lightweight robots sourced from\nthree distinct manufacturers: Universal Robots, Franka Emika, and Kinova. The\nmodel underwent testing, and the results demonstrated an RMSE ranging from 1.42\nW to 2.80 W for the training dataset and from 1.45 W to 5.25 W for the testing\ndataset.", "AI": {"tldr": "提出了一种基于Matlab的开源库，用于自动生成机械臂的能耗模型，解决了现有模型局限于传统工业机器人和精度不足的问题。", "motivation": "现有机械臂能耗模型多针对传统工业机器人且精度不足，需改进。", "method": "使用Denavit-Hartenberg参数、质量、质心等输入，结合数据驱动方法（包括关节位置、速度、加速度等实时数据），开发开源Matlab库。", "result": "在四种轻量级机器人上验证，训练集RMSE为1.42-2.80 W，测试集为1.45-5.25 W。", "conclusion": "该方法有效提高了机械臂能耗模型的通用性和精度。"}}
{"id": "2508.06278", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06278", "abs": "https://arxiv.org/abs/2508.06278", "authors": ["Petr Novak", "Stefan Biffl", "Marek Obitko", "Petr Kadera"], "title": "Mitigating Undesired Conditions in Flexible Production with Product-Process-Resource Asset Knowledge Graphs", "comment": "3 pages, 1 figure", "summary": "Contemporary industrial cyber-physical production systems (CPPS) composed of\nrobotic workcells face significant challenges in the analysis of undesired\nconditions due to the flexibility of Industry 4.0 that disrupts traditional\nquality assurance mechanisms. This paper presents a novel industry-oriented\nsemantic model called Product-Process-Resource Asset Knowledge Graph (PPR-AKG),\nwhich is designed to analyze and mitigate undesired conditions in flexible\nCPPS. Built on top of the well-proven Product-Process-Resource (PPR) model\noriginating from ISA-95 and VDI-3682, a comprehensive OWL ontology addresses\nshortcomings of conventional model-driven engineering for CPPS, particularly\ninadequate undesired condition and error handling representation. The\nintegration of semantic technologies with large language models (LLMs) provides\nintuitive interfaces for factory operators, production planners, and engineers\nto interact with the entire model using natural language. Evaluation with the\nuse case addressing electric vehicle battery remanufacturing demonstrates that\nthe PPR-AKG approach efficiently supports resource allocation based on\nexplicitly represented capabilities as well as identification and mitigation of\nundesired conditions in production. The key contributions include (1) a\nholistic PPR-AKG model capturing multi-dimensional production knowledge, and\n(2) the useful combination of the PPR-AKG with LLM-based chatbots for human\ninteraction.", "AI": {"tldr": "论文提出了一种名为PPR-AKG的语义模型，用于分析和缓解工业4.0中灵活CPPS的不良条件，结合语义技术和大型语言模型（LLMs），提供自然语言交互接口。", "motivation": "工业4.0的灵活性破坏了传统的质量保证机制，导致CPPS中不良条件的分析面临挑战。", "method": "基于PPR模型，开发了全面的OWL本体，结合语义技术和LLMs，提供自然语言接口。", "result": "在电动汽车电池再制造的案例中，PPR-AKG有效支持资源分配和不良条件的识别与缓解。", "conclusion": "PPR-AKG模型和LLM聊天机器人的结合为CPPS提供了多维生产知识和直观的人机交互方式。"}}
{"id": "2508.06283", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06283", "abs": "https://arxiv.org/abs/2508.06283", "authors": ["Saad Ejaz", "Marco Giberna", "Muhammad Shaheer", "Jose Andres Millan-Romera", "Ali Tourani", "Paul Kremer", "Holger Voos", "Jose Luis Sanchez-Lopez"], "title": "Situationally-aware Path Planning Exploiting 3D Scene Graphs", "comment": null, "summary": "3D Scene Graphs integrate both metric and semantic information, yet their\nstructure remains underutilized for improving path planning efficiency and\ninterpretability. In this work, we present S-Path, a situationally-aware path\nplanner that leverages the metric-semantic structure of indoor 3D Scene Graphs\nto significantly enhance planning efficiency. S-Path follows a two-stage\nprocess: it first performs a search over a semantic graph derived from the\nscene graph to yield a human-understandable high-level path. This also\nidentifies relevant regions for planning, which later allows the decomposition\nof the problem into smaller, independent subproblems that can be solved in\nparallel. We also introduce a replanning mechanism that, in the event of an\ninfeasible path, reuses information from previously solved subproblems to\nupdate semantic heuristics and prioritize reuse to further improve the\nefficiency of future planning attempts. Extensive experiments on both\nreal-world and simulated environments show that S-Path achieves average\nreductions of 5.7x in planning time while maintaining comparable path\noptimality to classical sampling-based planners and surpassing them in complex\nscenarios, making it an efficient and interpretable path planner for\nenvironments represented by indoor 3D Scene Graphs.", "AI": {"tldr": "S-Path利用3D场景图的语义结构提升路径规划效率，通过两阶段规划和动态重规划机制，显著减少规划时间并保持路径最优性。", "motivation": "3D场景图的结构未被充分利用于提升路径规划的效率和可解释性，S-Path旨在解决这一问题。", "method": "采用两阶段规划：先在语义图上搜索高层路径，再分解为并行子问题；引入动态重规划机制优化效率。", "result": "实验显示，S-Path平均减少5.7倍规划时间，路径最优性与传统方法相当，复杂场景表现更优。", "conclusion": "S-Path是一种高效且可解释的路径规划方法，适用于室内3D场景图环境。"}}
{"id": "2508.06291", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06291", "abs": "https://arxiv.org/abs/2508.06291", "authors": ["Christian Rauch", "Björn Ellensohn", "Linus Nwankwo", "Vedant Dave", "Elmar Rueckert"], "title": "Real-Time 3D Vision-Language Embedding Mapping", "comment": null, "summary": "A metric-accurate semantic 3D representation is essential for many robotic\ntasks. This work proposes a simple, yet powerful, way to integrate the 2D\nembeddings of a Vision-Language Model in a metric-accurate 3D representation at\nreal-time. We combine a local embedding masking strategy, for a more distinct\nembedding distribution, with a confidence-weighted 3D integration for more\nreliable 3D embeddings. The resulting metric-accurate embedding representation\nis task-agnostic and can represent semantic concepts on a global multi-room, as\nwell as on a local object-level. This enables a variety of interactive robotic\napplications that require the localisation of objects-of-interest via natural\nlanguage. We evaluate our approach on a variety of real-world sequences and\ndemonstrate that these strategies achieve a more accurate object-of-interest\nlocalisation while improving the runtime performance in order to meet our\nreal-time constraints. We further demonstrate the versatility of our approach\nin a variety of interactive handheld, mobile robotics and manipulation tasks,\nrequiring only raw image data.", "AI": {"tldr": "提出了一种将2D视觉语言模型嵌入到实时、高精度的3D表示中的方法，结合局部嵌入掩码和置信度加权3D集成，实现了任务无关的语义3D表示。", "motivation": "为机器人任务提供高精度的语义3D表示，支持自然语言交互的物体定位。", "method": "采用局部嵌入掩码策略和置信度加权3D集成，生成任务无关的语义3D表示。", "result": "在真实场景序列中验证了方法的有效性，实现了更准确的物体定位和实时性能。", "conclusion": "该方法适用于多种交互式机器人任务，仅需原始图像数据。"}}
{"id": "2508.06295", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06295", "abs": "https://arxiv.org/abs/2508.06295", "authors": ["Juan Heredia", "Emil Stubbe Kolvig-Raun", "Sune Lundo Sorensen", "Mikkel Baun Kjaergaard"], "title": "Evaluating Robot Program Performance with Power Consumption Driven Metrics in Lightweight Industrial Robots", "comment": null, "summary": "The code performance of industrial robots is typically analyzed through CPU\nmetrics, which overlook the physical impact of code on robot behavior. This\nstudy introduces a novel framework for assessing robot program performance from\nan embodiment perspective by analyzing the robot's electrical power profile.\nOur approach diverges from conventional CPU based evaluations and instead\nleverages a suite of normalized metrics, namely, the energy utilization\ncoefficient, the energy conversion metric, and the reliability coefficient, to\ncapture how efficiently and reliably energy is used during task execution.\nComplementing these metrics, the established robot wear metric provides further\ninsight into long term reliability. Our approach is demonstrated through an\nexperimental case study in machine tending, comparing four programs with\ndiverse strategies using a UR5e robot. The proposed metrics directly compare\nand categorize different robot programs, regardless of the specific task, by\nlinking code performance to its physical manifestation through power\nconsumption patterns. Our results reveal the strengths and weaknesses of each\nstrategy, offering actionable insights for optimizing robot programming\npractices. Enhancing energy efficiency and reliability through this embodiment\ncentric approach not only improves individual robot performance but also\nsupports broader industrial objectives such as sustainable manufacturing and\ncost reduction.", "AI": {"tldr": "该研究提出了一种基于机器人电力功耗的新型框架，用于从体现角度评估机器人程序性能，替代传统的CPU指标。", "motivation": "传统CPU指标忽视了代码对机器人行为的物理影响，本研究旨在通过电力功耗分析更全面地评估程序性能。", "method": "采用归一化指标（能量利用系数、能量转换指标和可靠性系数）及机器人磨损指标，分析任务执行中的能量效率和可靠性。", "result": "通过UR5e机器人的实验案例研究，比较了四种不同策略的程序，揭示了各策略的优缺点。", "conclusion": "该体现中心方法不仅提升机器人性能，还支持可持续制造和成本降低等工业目标。"}}
{"id": "2508.06313", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06313", "abs": "https://arxiv.org/abs/2508.06313", "authors": ["Amir Hossein Barjini", "Mohammad Bahari", "Mahdi Hejrati", "Jouni Mattila"], "title": "Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators", "comment": "This is submitted to IEEE T-ASE", "summary": "This paper presents a unified system-level modeling and control framework for\nan all-electric heavy-duty robotic manipulator (HDRM) driven by\nelectromechanical linear actuators (EMLAs). A surrogate-enhanced actuator\nmodel, combining integrated electromechanical dynamics with a neural network\ntrained on a dedicated testbed, is integrated into an extended virtual\ndecomposition control (VDC) architecture augmented by a natural adaptation law.\nThe derived analytical HDRM model supports a hierarchical control structure\nthat seamlessly maps high-level force and velocity objectives to real-time\nactuator commands, accompanied by a Lyapunov-based stability proof. In\nmulti-domain simulations of both cubic and a custom planar triangular\ntrajectory, the proposed adaptive modular controller achieves sub-centimeter\nCartesian tracking accuracy. Experimental validation of the same 1-DoF platform\nunder realistic load emulation confirms the efficacy of the proposed control\nstrategy. These findings demonstrate that a surrogate-enhanced EMLA model\nembedded in the VDC approach can enable modular, real-time control of an\nall-electric HDRM, supporting its deployment in next-generation mobile working\nmachines.", "AI": {"tldr": "提出了一种基于电机械线性执行器的全电动重型机械臂的统一系统级建模与控制框架，通过增强的虚拟分解控制和自适应律实现高精度跟踪。", "motivation": "为全电动重型机械臂开发一种模块化、实时控制的解决方案，以支持下一代移动工作机器的部署。", "method": "结合电机械动力学与神经网络的增强执行器模型，集成到扩展的虚拟分解控制架构中，并通过自然适应律优化。", "result": "在多域仿真和实验验证中，实现了亚厘米级的笛卡尔跟踪精度。", "conclusion": "增强的EMLA模型与VDC方法结合，能够实现全电动HDRM的模块化实时控制。"}}
{"id": "2508.06319", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06319", "abs": "https://arxiv.org/abs/2508.06319", "authors": ["Sagar Parekh", "Heramb Nemlekar", "Dylan P. Losey"], "title": "Towards Balanced Behavior Cloning from Imbalanced Datasets", "comment": null, "summary": "Robots should be able to learn complex behaviors from human demonstrations.\nIn practice, these human-provided datasets are inevitably imbalanced: i.e., the\nhuman demonstrates some subtasks more frequently than others. State-of-the-art\nmethods default to treating each element of the human's dataset as equally\nimportant. So if -- for instance -- the majority of the human's data focuses on\nreaching a goal, and only a few state-action pairs move to avoid an obstacle,\nthe learning algorithm will place greater emphasis on goal reaching. More\ngenerally, misalignment between the relative amounts of data and the importance\nof that data causes fundamental problems for imitation learning approaches. In\nthis paper we analyze and develop learning methods that automatically account\nfor mixed datasets. We formally prove that imbalanced data leads to imbalanced\npolicies when each state-action pair is weighted equally; these policies\nemulate the most represented behaviors, and not the human's complex, multi-task\ndemonstrations. We next explore algorithms that rebalance offline datasets\n(i.e., reweight the importance of different state-action pairs) without human\noversight. Reweighting the dataset can enhance the overall policy performance.\nHowever, there is no free lunch: each method for autonomously rebalancing\nbrings its own pros and cons. We formulate these advantages and disadvantages,\nhelping other researchers identify when each type of approach is most\nappropriate. We conclude by introducing a novel meta-gradient rebalancing\nalgorithm that addresses the primary limitations behind existing approaches.\nOur experiments show that dataset rebalancing leads to better downstream\nlearning, improving the performance of general imitation learning algorithms\nwithout requiring additional data collection. See our project website:\nhttps://collab.me.vt.edu/data_curation/.", "AI": {"tldr": "论文探讨了机器人从人类演示中学习复杂行为时数据不平衡的问题，提出了一种自动调整数据集权重的方法，以提高模仿学习的效果。", "motivation": "人类提供的演示数据通常不平衡，导致现有方法过度关注高频子任务，而忽视低频但重要的行为。这影响了模仿学习的性能。", "method": "论文分析了数据不平衡对策略的影响，并提出了一种无需人工干预的自动重新平衡数据集的算法，包括一种新的元梯度重新平衡算法。", "result": "实验表明，重新平衡数据集可以显著提升模仿学习算法的性能，而无需额外数据收集。", "conclusion": "通过自动重新平衡数据集，可以更好地学习人类的多任务演示，提升模仿学习的整体效果。"}}
{"id": "2508.06330", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.06330", "abs": "https://arxiv.org/abs/2508.06330", "authors": ["Baorun Li", "Chengrui Zhu", "Siyi Du", "Bingran Chen", "Jie Ren", "Wenfei Wang", "Yong Liu", "Jiajun Lv"], "title": "L2Calib: $SE(3)$-Manifold Reinforcement Learning for Robust Extrinsic Calibration with Degenerate Motion Resilience", "comment": "IROS2025", "summary": "Extrinsic calibration is essential for multi-sensor fusion, existing methods\nrely on structured targets or fully-excited data, limiting real-world\napplicability. Online calibration further suffers from weak excitation, leading\nto unreliable estimates. To address these limitations, we propose a\nreinforcement learning (RL)-based extrinsic calibration framework that\nformulates extrinsic calibration as a decision-making problem, directly\noptimizes $SE(3)$ extrinsics to enhance odometry accuracy. Our approach\nleverages a probabilistic Bingham distribution to model 3D rotations, ensuring\nstable optimization while inherently retaining quaternion symmetry. A\ntrajectory alignment reward mechanism enables robust calibration without\nstructured targets by quantitatively evaluating estimated tightly-coupled\ntrajectory against a reference trajectory. Additionally, an automated data\nselection module filters uninformative samples, significantly improving\nefficiency and scalability for large-scale datasets. Extensive experiments on\nUAVs, UGVs, and handheld platforms demonstrate that our method outperforms\ntraditional optimization-based approaches, achieving high-precision calibration\neven under weak excitation conditions. Our framework simplifies deployment on\ndiverse robotic platforms by eliminating the need for high-quality initial\nextrinsics and enabling calibration from routine operating data. The code is\navailable at https://github.com/APRIL-ZJU/learn-to-calibrate.", "AI": {"tldr": "提出了一种基于强化学习的外参标定框架，通过直接优化SE(3)外参提升里程计精度，无需结构化目标或高质量初始外参。", "motivation": "现有外参标定方法依赖结构化目标或完全激励数据，限制了实际应用；在线标定因弱激励导致估计不可靠。", "method": "将外参标定建模为决策问题，利用Bingham分布建模3D旋转确保稳定优化，轨迹对齐奖励机制实现无结构化目标的标定，自动数据选择模块提升效率。", "result": "在无人机、无人车和手持平台上实验表明，该方法优于传统优化方法，在弱激励条件下仍能实现高精度标定。", "conclusion": "该框架简化了多样化机器人平台的部署，支持从常规操作数据中完成标定。"}}
{"id": "2508.06404", "categories": ["cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.06404", "abs": "https://arxiv.org/abs/2508.06404", "authors": ["Abdullah Zareh Andaryan", "Michael G. H. Bell", "Mohsen Ramezani", "Glenn Geers"], "title": "V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles", "comment": null, "summary": "Autonomous vehicle navigation in structured environments requires planners\ncapable of generating time-optimal, collision-free trajectories that satisfy\ndynamic and kinematic constraints. We introduce V*, a graph-based motion\nplanner that represents speed and direction as explicit state variables within\na discretised space-time-velocity lattice. Unlike traditional methods that\ndecouple spatial search from dynamic feasibility or rely on post-hoc smoothing,\nV* integrates both motion dimensions directly into graph construction through\ndynamic graph generation during search expansion. To manage the complexity of\nhigh-dimensional search, we employ a hexagonal discretisation strategy and\nprovide formal mathematical proofs establishing optimal waypoint spacing and\nminimal node redundancy under constrained heading transitions for\nvelocity-aware motion planning. We develop a mathematical formulation for\ntransient steering dynamics in the kinematic bicycle model, modelling steering\nangle convergence with exponential behaviour, and deriving the relationship for\nconvergence rate parameters. This theoretical foundation, combined with\ngeometric pruning strategies that eliminate expansions leading to infeasible\nsteering configurations, enables V* to evaluate dynamically admissible\nmanoeuvres, ensuring each trajectory is physically realisable without further\nrefinement. We further demonstrate V*'s performance in simulation studies with\ncluttered and dynamic environments involving moving obstacles, showing its\nability to avoid conflicts, yield proactively, and generate safe, efficient\ntrajectories with temporal reasoning capabilities for waiting behaviours and\ndynamic coordination.", "AI": {"tldr": "V*是一种基于图的运动规划器，通过在离散时空速度格中显式表示速度和方向状态变量，直接集成动态可行性，避免了传统方法的解耦或后处理平滑。", "motivation": "在结构化环境中，自动驾驶车辆需要能够生成时间最优、无碰撞且满足动态和运动学约束的轨迹。传统方法往往将空间搜索与动态可行性解耦或依赖后处理平滑，存在局限性。", "method": "V*采用六边形离散化策略，动态生成图，并通过几何剪枝策略消除不可行的转向配置。同时，建立了运动学自行车模型中瞬态转向动力学的数学公式。", "result": "仿真研究表明，V*能够在复杂动态环境中避免冲突、主动避让，并生成安全高效的轨迹，具备时间推理能力。", "conclusion": "V*通过直接集成动态可行性，提供了一种高效且理论完备的运动规划方法，适用于自动驾驶车辆在结构化环境中的导航。"}}
{"id": "2508.06426", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.06426", "abs": "https://arxiv.org/abs/2508.06426", "authors": ["Youguang Xing", "Xu Luo", "Junlin Xie", "Lianli Gao", "Hengtao Shen", "Jingkuan Song"], "title": "Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation", "comment": "CoRL 2025", "summary": "Generalist robot policies trained on large-scale datasets such as Open\nX-Embodiment (OXE) demonstrate strong performance across a wide range of tasks.\nHowever, they often struggle to generalize beyond the distribution of their\ntraining data. In this paper, we investigate the underlying cause of this\nlimited generalization capability. We identify shortcut learning -- the\nreliance on task-irrelevant features -- as a key impediment to generalization.\nThrough comprehensive theoretical and empirical analysis, we uncover two\nprimary contributors to shortcut learning: (1) limited diversity within\nindividual sub-datasets, and (2) significant distributional disparities across\nsub-datasets, leading to dataset fragmentation. These issues arise from the\ninherent structure of large-scale datasets like OXE, which are typically\ncomposed of multiple sub-datasets collected independently across varied\nenvironments and embodiments. Our findings provide critical insights into\ndataset collection strategies that can reduce shortcut learning and enhance the\ngeneralization ability of generalist robot policies. Moreover, in scenarios\nwhere acquiring new large-scale data is impractical, we demonstrate that\ncarefully selected robotic data augmentation strategies can effectively reduce\nshortcut learning in existing offline datasets, thereby improving\ngeneralization capabilities of generalist robot policies, e.g., $\\pi_0$, in\nboth simulation and real-world environments. More information at\nhttps://lucky-light-sun.github.io/proj/shortcut-learning-in-grps/.", "AI": {"tldr": "论文探讨了通用机器人策略在训练数据分布外泛化能力不足的原因，发现捷径学习是关键障碍，并提出数据集收集和增强策略以改善泛化能力。", "motivation": "通用机器人策略在大规模数据集（如OXE）上表现良好，但在训练数据分布外泛化能力有限，研究旨在揭示其根本原因。", "method": "通过理论和实证分析，识别捷径学习的两个主要来源：子数据集内多样性不足和子数据集间分布差异。", "result": "发现数据集结构和子数据集差异导致捷径学习，提出数据收集和增强策略以提升泛化能力。", "conclusion": "优化数据集结构和采用数据增强策略可有效减少捷径学习，提升通用机器人策略的泛化能力。"}}
