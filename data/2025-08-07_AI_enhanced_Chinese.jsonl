{"id": "2508.04009", "categories": ["cs.RO", "cs.NE", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.04009", "abs": "https://arxiv.org/abs/2508.04009", "authors": ["Vu Ngoc Son", "Pham Van Cuong", "Dao Thi My Linh", "Le Tieu Nien"], "title": "Optimization of sliding control parameters for a 3-dof robot arm using genetic algorithm (GA)", "comment": null, "summary": "This paper presents a method for optimizing the sliding mode control (SMC)\nparameter for a robot manipulator applying a genetic algorithm (GA). The\nobjective of the SMC is to achieve precise and consistent tracking of the\ntrajectory of the robot manipulator under uncertain and disturbed conditions.\nHowever, the system effectiveness and robustness depend on the choice of the\nSMC parameters, which is a difficult and crucial task. To solve this problem, a\ngenetic algorithm is used to locate the optimal values of these parameters that\ngratify the capability criteria. The proposed method is efficient compared with\nthe conventional SMC and Fuzzy-SMC. The simulation results show that the\ngenetic algorithm with SMC can achieve better tracking capability and reduce\nthe chattering effect.", "AI": {"tldr": "使用遗传算法优化机器人操纵器的滑模控制参数，提高轨迹跟踪精度和鲁棒性。", "motivation": "在不确定和干扰条件下，滑模控制（SMC）的参数选择对系统性能和鲁棒性至关重要，但参数优化困难。", "method": "采用遗传算法（GA）自动寻找最优SMC参数，满足性能标准。", "result": "仿真结果表明，遗传算法优化的SMC比传统SMC和模糊SMC具有更好的跟踪能力和更小的抖动效应。", "conclusion": "遗传算法优化SMC参数是一种高效方法，显著提升了机器人操纵器的控制性能。"}}
{"id": "2508.04436", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.04436", "abs": "https://arxiv.org/abs/2508.04436", "authors": ["Yujia Lu", "Chong Wei", "Lu Ma"], "title": "Reliable and Real-Time Highway Trajectory Planning via Hybrid Learning-Optimization Frameworks", "comment": null, "summary": "Autonomous highway driving presents a high collision risk due to\nfast-changing environments and limited reaction time, necessitating reliable\nand efficient trajectory planning. This paper proposes a hybrid trajectory\nplanning framework that integrates the adaptability of learning-based methods\nwith the formal safety guarantees of optimization-based approaches. The\nframework features a two-layer architecture: an upper layer employing a graph\nneural network (GNN) trained on real-world highway data to predict human-like\nlongitudinal velocity profiles, and a lower layer utilizing path optimization\nformulated as a mixed-integer quadratic programming (MIQP) problem. The primary\ncontribution is the lower-layer path optimization model, which introduces a\nlinear approximation of discretized vehicle geometry to substantially reduce\ncomputational complexity, while enforcing strict spatiotemporal non-overlapping\nconstraints to formally guarantee collision avoidance throughout the planning\nhorizon. Experimental results demonstrate that the planner generates highly\nsmooth, collision-free trajectories in complex real-world emergency scenarios,\nachieving success rates exceeding 97% with average planning times of 54 ms,\nthereby confirming real-time capability.", "AI": {"tldr": "论文提出了一种混合轨迹规划框架，结合学习方法的适应性和优化方法的安全性保证，用于高速公路自动驾驶。", "motivation": "高速公路驾驶环境变化快且反应时间有限，碰撞风险高，需要可靠高效的轨迹规划。", "method": "采用双层架构：上层用图神经网络预测纵向速度，下层用混合整数二次规划优化路径，引入线性近似降低计算复杂度。", "result": "在复杂紧急场景中生成平滑无碰撞轨迹，成功率超97%，平均规划时间54毫秒。", "conclusion": "框架具备实时能力，能有效保证安全性和效率。"}}
{"id": "2508.03890", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.03890", "abs": "https://arxiv.org/abs/2508.03890", "authors": ["Sanghun Jung", "Daehoon Gwak", "Byron Boots", "James Hays"], "title": "Uncertainty-aware Accurate Elevation Modeling for Off-road Navigation via Neural Processes", "comment": "CoRL 2025", "summary": "Terrain elevation modeling for off-road navigation aims to accurately\nestimate changes in terrain geometry in real-time and quantify the\ncorresponding uncertainties. Having precise estimations and uncertainties plays\na crucial role in planning and control algorithms to explore safe and reliable\nmaneuver strategies. However, existing approaches, such as Gaussian Processes\n(GPs) and neural network-based methods, often fail to meet these needs. They\nare either unable to perform in real-time due to high computational demands,\nunderestimating sharp geometry changes, or harming elevation accuracy when\nlearned with uncertainties. Recently, Neural Processes (NPs) have emerged as a\npromising approach that integrates the Bayesian uncertainty estimation of GPs\nwith the efficiency and flexibility of neural networks. Inspired by NPs, we\npropose an effective NP-based method that precisely estimates sharp elevation\nchanges and quantifies the corresponding predictive uncertainty without losing\nelevation accuracy. Our method leverages semantic features from LiDAR and\ncamera sensors to improve interpolation and extrapolation accuracy in\nunobserved regions. Also, we introduce a local ball-query attention mechanism\nto effectively reduce the computational complexity of global attention by 17\\%\nwhile preserving crucial local and spatial information. We evaluate our method\non off-road datasets having interesting geometric features, collected from\ntrails, deserts, and hills. Our results demonstrate superior performance over\nbaselines and showcase the potential of neural processes for effective and\nexpressive terrain modeling in complex off-road environments.", "AI": {"tldr": "提出了一种基于神经过程（NPs）的地形高程建模方法，结合贝叶斯不确定性估计和神经网络效率，显著提升了实时性和精度。", "motivation": "现有方法（如高斯过程和神经网络）无法同时满足实时性、准确性和不确定性量化的需求，限制了复杂越野环境中的导航规划与控制。", "method": "利用LiDAR和相机传感器的语义特征，结合局部球查询注意力机制，降低计算复杂度并提升插值和外推精度。", "result": "在越野数据集上表现优于基线方法，计算复杂度降低17%，同时保持了地形高程的精确估计和不确定性量化。", "conclusion": "神经过程为复杂越野环境中的地形建模提供了一种高效且表达力强的方法。"}}
{"id": "2508.03944", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03944", "abs": "https://arxiv.org/abs/2508.03944", "authors": ["Kevin Lin", "Varun Ragunath", "Andrew McAlinden", "Aaditya Prasad", "Jimmy Wu", "Yuke Zhu", "Jeannette Bohg"], "title": "Constraint-Preserving Data Generation for Visuomotor Policy Learning", "comment": "CoRL 2025. Website: https://cp-gen.github.io", "summary": "Large-scale demonstration data has powered key breakthroughs in robot\nmanipulation, but collecting that data remains costly and time-consuming. We\npresent Constraint-Preserving Data Generation (CP-Gen), a method that uses a\nsingle expert trajectory to generate robot demonstrations containing novel\nobject geometries and poses. These generated demonstrations are used to train\nclosed-loop visuomotor policies that transfer zero-shot to the real world and\ngeneralize across variations in object geometries and poses. Similar to prior\nwork using pose variations for data generation, CP-Gen first decomposes expert\ndemonstrations into free-space motions and robot skills. But unlike those\nworks, we achieve geometry-aware data generation by formulating robot skills as\nkeypoint-trajectory constraints: keypoints on the robot or grasped object must\ntrack a reference trajectory defined relative to a task-relevant object. To\ngenerate a new demonstration, CP-Gen samples pose and geometry transforms for\neach task-relevant object, then applies these transforms to the object and its\nassociated keypoints or keypoint trajectories. We optimize robot joint\nconfigurations so that the keypoints on the robot or grasped object track the\ntransformed keypoint trajectory, and then motion plan a collision-free path to\nthe first optimized joint configuration. Experiments on 16 simulation tasks and\nfour real-world tasks, featuring multi-stage, non-prehensile and\ntight-tolerance manipulation, show that policies trained using CP-Gen achieve\nan average success rate of 77%, outperforming the best baseline that achieves\nan average of 50%.", "AI": {"tldr": "CP-Gen是一种利用单条专家轨迹生成机器人演示数据的方法，支持新物体几何和姿态，训练出的策略在真实世界中零样本迁移且泛化性强。", "motivation": "大规模机器人演示数据收集成本高且耗时，需要一种高效生成多样化数据的方法。", "method": "将专家轨迹分解为自由空间运动和机器人技能，通过关键点轨迹约束实现几何感知数据生成，采样变换后优化机器人关节配置。", "result": "在16个仿真任务和4个真实任务中，CP-Gen训练的策略平均成功率达77%，优于基线方法的50%。", "conclusion": "CP-Gen通过几何感知数据生成显著提升了机器人策略的性能和泛化能力。"}}
{"id": "2508.04056", "categories": ["cs.RO", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2508.04056", "abs": "https://arxiv.org/abs/2508.04056", "authors": ["Yuelin Deng", "Hinayah Rojas de Oliveira", "Richard M. Voyles", "Upinder Kaur"], "title": "SCOUT: An in-vivo Methane Sensing System for Real-time Monitoring of Enteric Emissions in Cattle with ex-vivo Validation", "comment": null, "summary": "Accurate measurement of enteric methane emissions remains a critical\nbottleneck for advancing livestock sustainability through genetic selection and\nprecision management. Existing ambient sampling approaches suffer from low data\nretention rates, environmental interference, and limited temporal resolution.\nWe developed SCOUT (Smart Cannula-mounted Optical Unit for Trace-methane), the\nfirst robust in-vivo sensing system enabling continuous, high-resolution\nmonitoring of ruminal methane concentrations through an innovative closed-loop\ngas recirculation design. We conducted comprehensive validation with two\ncannulated Simmental heifers under contrasting dietary treatments, with\ncross-platform comparison against established ambient sniffer systems. SCOUT\nachieved exceptional performance with 82% data retention compared to 17% for\nconventional sniffer systems, while capturing methane concentrations 100-1000x\nhigher than ambient approaches. Cross-platform validation demonstrated strong\nscale-dependent correlations, with optimal correlation strength (r = -0.564\n$\\pm$ 0.007) at biologically relevant 40-minute windows and 100% statistical\nsignificance. High-frequency monitoring revealed novel behavior-emission\ncoupling, including rapid concentration changes (14.5 $\\pm$ 11.3k ppm)\ntriggered by postural transitions within 15 minutes, insights previously\ninaccessible through existing technologies. The SCOUT system represents a\ntransformative advancement, enabling accurate, continuous emission phenotyping\nessential for genomic selection programs and sustainable precision livestock\nmanagement. This validation framework establishes new benchmarks for\nagricultural sensor performance while generating unprecedented biological\ninsights into ruminal methane dynamics, contributing essential tools for\nsustainable livestock production in climate-conscious agricultural systems.", "AI": {"tldr": "SCOUT系统是一种创新的体内甲烷监测技术，解决了传统环境采样方法的局限性，实现了高分辨率连续监测，为畜牧业的可持续发展提供了新工具。", "motivation": "准确测量肠道甲烷排放是推动畜牧业可持续发展的关键瓶颈，现有方法存在数据保留率低、环境干扰和分辨率不足等问题。", "method": "开发了SCOUT系统，采用闭环气体循环设计，通过高分辨率连续监测瘤胃甲烷浓度，并与传统环境采样系统进行交叉验证。", "result": "SCOUT数据保留率高达82%（传统方法仅17%），甲烷浓度测量范围更高（100-1000倍），并揭示了行为与排放的新关联。", "conclusion": "SCOUT系统是一项突破性技术，为基因组选择和精准畜牧管理提供了可靠工具，同时为甲烷动态研究提供了新视角。"}}
{"id": "2508.04066", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04066", "abs": "https://arxiv.org/abs/2508.04066", "authors": ["Longling Geng", "Huangxing Li", "Viktor Lado Naess", "Mert Pilanci"], "title": "DRIVE: Dynamic Rule Inference and Verified Evaluation for Constraint-Aware Autonomous Driving", "comment": null, "summary": "Understanding and adhering to soft constraints is essential for safe and\nsocially compliant autonomous driving. However, such constraints are often\nimplicit, context-dependent, and difficult to specify explicitly. In this work,\nwe present DRIVE, a novel framework for Dynamic Rule Inference and Verified\nEvaluation that models and evaluates human-like driving constraints from expert\ndemonstrations. DRIVE leverages exponential-family likelihood modeling to\nestimate the feasibility of state transitions, constructing a probabilistic\nrepresentation of soft behavioral rules that vary across driving contexts.\nThese learned rule distributions are then embedded into a convex\noptimization-based planning module, enabling the generation of trajectories\nthat are not only dynamically feasible but also compliant with inferred human\npreferences. Unlike prior approaches that rely on fixed constraint forms or\npurely reward-based modeling, DRIVE offers a unified framework that tightly\ncouples rule inference with trajectory-level decision-making. It supports both\ndata-driven constraint generalization and principled feasibility verification.\nWe validate DRIVE on large-scale naturalistic driving datasets, including inD,\nhighD, and RoundD, and benchmark it against representative inverse constraint\nlearning and planning baselines. Experimental results show that DRIVE achieves\n0.0% soft constraint violation rates, smoother trajectories, and stronger\ngeneralization across diverse driving scenarios. Verified evaluations further\ndemonstrate the efficiency, explanability, and robustness of the framework for\nreal-world deployment.", "AI": {"tldr": "DRIVE框架通过动态规则推断和验证评估，从专家演示中建模人类驾驶约束，结合概率建模和优化规划，生成符合人类偏好的轨迹。", "motivation": "自动驾驶需遵守隐含且上下文相关的软约束，但现有方法难以明确建模这些约束。", "method": "DRIVE使用指数族似然建模估计状态转移可行性，构建概率化行为规则，并通过凸优化规划生成轨迹。", "result": "实验表明，DRIVE在多个数据集上实现0.0%的约束违反率，轨迹更平滑且泛化能力更强。", "conclusion": "DRIVE框架高效、可解释且鲁棒，适用于实际部署。"}}
{"id": "2508.04146", "categories": ["cs.RO", "I.2.9; I.2.10; J.7"], "pdf": "https://arxiv.org/pdf/2508.04146", "abs": "https://arxiv.org/abs/2508.04146", "authors": ["Luai Abuelsamen", "Harsh Rana", "Ho-Wei Lu", "Wenhan Tang", "Swati Priyadarshini", "Gabriel Gomes"], "title": "Industrial Robot Motion Planning with GPUs: Integration of cuRobo for Extended DOF Systems", "comment": "8 pages, 2 figures, 2 tables. Submitted to IEEE International\n  Conference on Robotics and Automation (ICRA) 2025", "summary": "Efficient motion planning remains a key challenge in industrial robotics,\nespecially for multi-axis systems operating in complex environments. This paper\naddresses that challenge by integrating GPU-accelerated motion planning through\nNVIDIA's cuRobo library into Vention's modular automation platform. By\nleveraging accurate CAD-based digital twins and real-time parallel\noptimization, our system enables rapid trajectory generation and dynamic\ncollision avoidance for pick-and-place tasks. We demonstrate this capability on\nrobots equipped with additional degrees of freedom, including a 7th-axis\ngantry, and benchmark performance across various scenarios. The results show\nsignificant improvements in planning speed and robustness, highlighting the\npotential of GPU-based planning pipelines for scalable, adaptable deployment in\nmodern industrial workflows.", "AI": {"tldr": "论文提出了一种基于GPU加速的运动规划方法，通过集成NVIDIA的cuRobo库，显著提升了工业机器人在复杂环境中的运动规划效率和鲁棒性。", "motivation": "工业机器人（尤其是多轴系统）在复杂环境中的高效运动规划仍是一个关键挑战，需要更快的轨迹生成和动态避障能力。", "method": "利用NVIDIA的cuRobo库和基于CAD的数字孪生技术，结合实时并行优化，实现了快速的轨迹生成和动态碰撞避免。", "result": "在配备额外自由度（如第7轴龙门架）的机器人上验证了性能，结果显示规划速度和鲁棒性显著提升。", "conclusion": "GPU加速的运动规划管道在现代工业工作流程中具有可扩展和适应性强的潜力。"}}
{"id": "2508.04338", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.04338", "abs": "https://arxiv.org/abs/2508.04338", "authors": ["Shaohong Zhong", "Alessandro Albini", "Giammarco Caroleo", "Giorgio Cannata", "Perla Maiolino"], "title": "Improving Tactile Gesture Recognition with Optical Flow", "comment": "7 pages, 7 figures, paper accepted by the 2025 34th IEEE\n  International Conference on Robot and Human Interactive Communication (ROMAN)", "summary": "Tactile gesture recognition systems play a crucial role in Human-Robot\nInteraction (HRI) by enabling intuitive communication between humans and\nrobots. The literature mainly addresses this problem by applying machine\nlearning techniques to classify sequences of tactile images encoding the\npressure distribution generated when executing the gestures. However, some\ngestures can be hard to differentiate based on the information provided by\ntactile images alone. In this paper, we present a simple yet effective way to\nimprove the accuracy of a gesture recognition classifier. Our approach focuses\nsolely on processing the tactile images used as input by the classifier. In\nparticular, we propose to explicitly highlight the dynamics of the contact in\nthe tactile image by computing the dense optical flow. This additional\ninformation makes it easier to distinguish between gestures that produce\nsimilar tactile images but exhibit different contact dynamics. We validate the\nproposed approach in a tactile gesture recognition task, showing that a\nclassifier trained on tactile images augmented with optical flow information\nachieved a 9% improvement in gesture classification accuracy compared to one\ntrained on standard tactile images.", "AI": {"tldr": "提出了一种通过计算密集光流来增强触觉图像动态信息的方法，显著提高了触觉手势识别的准确性。", "motivation": "现有触觉手势识别系统仅依赖触觉图像的压力分布信息，难以区分动态相似但静态图像相似的手势。", "method": "在触觉图像中计算密集光流，突出接触动态信息，作为分类器的额外输入。", "result": "实验表明，使用光流增强的触觉图像训练的分类器，手势分类准确率提高了9%。", "conclusion": "通过增强触觉图像的动态信息，可以有效提升手势识别的准确性。"}}
{"id": "2508.04372", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.04372", "abs": "https://arxiv.org/abs/2508.04372", "authors": ["Morten Roed Frederiksen", "Kasper Støy", "Maja Matarić"], "title": "Tactile Comfort: Lowering Heart Rate Through Interactions", "comment": "6 pages, 4 figures, Proceedings from 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS). IEEE, 2024", "summary": "Children diagnosed with anxiety disorders are taught a range of strategies to\nnavigate situations of heightened anxiety. Techniques such as deep breathing\nand repetition of mantras are commonly employed, as they are known to be\ncalming and reduce elevated heart rates. Although these strategies are often\neffective, their successful application relies on prior training of the\nchildren for successful use when faced with challenging situations. This paper\ninvestigates a pocket-sized companion robot designed to offer a relaxation\ntechnique requiring no prior training, with a focus on immediate impact on the\nuser's heart rate. The robot utilizes a tactile game to divert the user's\nattention, thereby promoting relaxation. We conducted two studies with children\nwho were not diagnosed with anxiety: a 14-day pilot study with two children\n(age 8) and a main study with 18 children (ages 7-8). Both studies employed a\nwithin-subjects design and focused on measuring heart rate during tactile\ninteraction with the robot and during non-use. Interacting with the robot was\nfound to significantly lower the study participants' heart rate (p$<$0.01)\ncompared to the non-use condition, indicating a consistent calming effect\nacross all participants. These results suggest that tactile companion robots\nhave the potential to enhance the therapeutic value of relaxation techniques.", "AI": {"tldr": "研究探讨了一种无需训练即可降低儿童心率的袖珍陪伴机器人，通过触觉游戏分散注意力，显著降低心率。", "motivation": "现有焦虑管理策略需预先训练，研究旨在开发一种即时有效的放松工具。", "method": "采用触觉游戏机器人，通过两项研究（14天试点和18人主研究）测量心率变化。", "result": "机器人互动显著降低儿童心率（p<0.01），显示一致镇静效果。", "conclusion": "触觉陪伴机器人可增强放松技术的治疗效果。"}}
{"id": "2508.04384", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.04384", "abs": "https://arxiv.org/abs/2508.04384", "authors": ["Eric R. Damm", "Eli S. Lancaster", "Felix A. Sanchez", "Kiana Bronder", "Jason M. Gregory", "Thomas M. Howard"], "title": "Incorporating Stochastic Models of Controller Behavior into Kinodynamic Efficiently Adaptive State Lattices for Mobile Robot Motion Planning in Off-Road Environments", "comment": "Accepted to the International Symposium on Experimental Robotics\n  (ISER) 2025", "summary": "Mobile robot motion planners rely on theoretical models to predict how the\nrobot will move through the world. However, when deployed on a physical robot,\nthese models are subject to errors due to real-world physics and uncertainty in\nhow the lower-level controller follows the planned trajectory. In this work, we\naddress this problem by presenting three methods of incorporating stochastic\ncontroller behavior into the recombinant search space of the Kinodynamic\nEfficiently Adaptive State Lattice (KEASL) planner. To demonstrate this work,\nwe analyze the results of experiments performed on a Clearpath Robotics Warthog\nUnmanned Ground Vehicle (UGV) in an off-road, unstructured environment using\ntwo different perception algorithms, and performed an ablation study using a\nfull spectrum of simulated environment map complexities. Analysis of the data\nfound that incorporating stochastic controller sampling into KEASL leads to\nmore conservative trajectories that decrease predicted collision likelihood\nwhen compared to KEASL without sampling. When compared to baseline planning\nwith expanded obstacle footprints, the predicted likelihood of collisions\nbecomes more comparable, but reduces the planning success rate for baseline\nsearch.", "AI": {"tldr": "论文提出三种方法将随机控制器行为整合到KEASL规划器中，实验表明该方法能生成更保守的轨迹，降低碰撞概率，但可能减少规划成功率。", "motivation": "解决物理机器人部署中因实际物理和控制器不确定性导致的运动规划模型误差问题。", "method": "在KEASL规划器中引入随机控制器行为的三种方法，并在真实和模拟环境中进行实验验证。", "result": "整合随机控制器行为后，轨迹更保守，碰撞概率降低，但与基线规划相比，规划成功率有所下降。", "conclusion": "随机控制器行为的整合能有效减少碰撞风险，但需权衡规划成功率。"}}
{"id": "2508.04537", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.04537", "abs": "https://arxiv.org/abs/2508.04537", "authors": ["Alkesh K. Srivastava", "Aamodh Suresh", "Carlos Nieto-Granda"], "title": "Behaviorally Adaptive Multi-Robot Hazard Localization in Failure-Prone, Communication-Denied Environments", "comment": null, "summary": "We address the challenge of multi-robot autonomous hazard mapping in\nhigh-risk, failure-prone, communication-denied environments such as\npost-disaster zones, underground mines, caves, and planetary surfaces. In these\nmissions, robots must explore and map hazards while minimizing the risk of\nfailure due to environmental threats or hardware limitations. We introduce a\nbehavior-adaptive, information-theoretic planning framework for multi-robot\nteams grounded in the concept of Behavioral Entropy (BE), that generalizes\nShannon entropy (SE) to capture diverse human-like uncertainty evaluations.\nBuilding on this formulation, we propose the Behavior-Adaptive Path Planning\n(BAPP) framework, which modulates information gathering strategies via a\ntunable risk-sensitivity parameter, and present two planning algorithms:\nBAPP-TID for intelligent triggering of high-fidelity robots, and BAPP-SIG for\nsafe deployment under high risk. We provide theoretical insights on the\ninformativeness of the proposed BAPP framework and validate its effectiveness\nthrough both single-robot and multi-robot simulations. Our results show that\nthe BAPP stack consistently outperforms Shannon-based and random strategies:\nBAPP-TID accelerates entropy reduction, while BAPP-SIG improves robot\nsurvivability with minimal loss in information gain. In multi-agent\ndeployments, BAPP scales effectively through spatial partitioning, mobile base\nrelocation, and role-aware heterogeneity. These findings underscore the value\nof behavior-adaptive planning for robust, risk-sensitive exploration in\ncomplex, failure-prone environments.", "AI": {"tldr": "提出了一种基于行为熵的多机器人自适应路径规划框架（BAPP），用于高风险环境中的自主危险地图绘制，优于传统方法。", "motivation": "解决高风险、通信受限环境中多机器人探索与地图绘制的挑战，减少机器人因环境威胁或硬件限制导致的失败风险。", "method": "引入行为熵（BE）概念，提出BAPP框架，包含两种算法：BAPP-TID（智能触发高保真机器人）和BAPP-SIG（高风险下安全部署）。", "result": "BAPP框架在单机器人和多机器人模拟中表现优异，BAPP-TID加速熵减，BAPP-SIG提高机器人存活率且信息损失最小。", "conclusion": "行为自适应规划在复杂、高风险环境中具有显著优势，BAPP框架通过空间分区和角色异构实现高效扩展。"}}
{"id": "2508.04598", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.04598", "abs": "https://arxiv.org/abs/2508.04598", "authors": ["Lingfeng Zhang", "Xiaoshuai Hao", "Yingbo Tang", "Haoxiang Fu", "Xinyu Zheng", "Pengwei Wang", "Zhongyuan Wang", "Wenbo Ding", "Shanghang Zhang"], "title": "$NavA^3$: Understanding Any Instruction, Navigating Anywhere, Finding Anything", "comment": null, "summary": "Embodied navigation is a fundamental capability of embodied intelligence,\nenabling robots to move and interact within physical environments. However,\nexisting navigation tasks primarily focus on predefined object navigation or\ninstruction following, which significantly differs from human needs in\nreal-world scenarios involving complex, open-ended scenes. To bridge this gap,\nwe introduce a challenging long-horizon navigation task that requires\nunderstanding high-level human instructions and performing spatial-aware object\nnavigation in real-world environments. Existing embodied navigation methods\nstruggle with such tasks due to their limitations in comprehending high-level\nhuman instructions and localizing objects with an open vocabulary. In this\npaper, we propose $NavA^3$, a hierarchical framework divided into two stages:\nglobal and local policies. In the global policy, we leverage the reasoning\ncapabilities of Reasoning-VLM to parse high-level human instructions and\nintegrate them with global 3D scene views. This allows us to reason and\nnavigate to regions most likely to contain the goal object. In the local\npolicy, we have collected a dataset of 1.0 million samples of spatial-aware\nobject affordances to train the NaviAfford model (PointingVLM), which provides\nrobust open-vocabulary object localization and spatial awareness for precise\ngoal identification and navigation in complex environments. Extensive\nexperiments demonstrate that $NavA^3$ achieves SOTA results in navigation\nperformance and can successfully complete longhorizon navigation tasks across\ndifferent robot embodiments in real-world settings, paving the way for\nuniversal embodied navigation. The dataset and code will be made available.\nProject website: https://NavigationA3.github.io/.", "AI": {"tldr": "论文提出了一种名为$NavA^3$的分层框架，用于解决复杂开放场景中的长时程导航任务，结合全局和局部策略，显著提升了导航性能。", "motivation": "现有导航任务局限于预定义对象或指令跟随，无法满足真实场景中复杂开放需求，需开发能理解高级指令和开放词汇定位的方法。", "method": "采用分层框架：全局策略利用Reasoning-VLM解析指令并整合3D场景视图；局部策略通过NaviAfford模型（基于1.0百万样本数据集）实现开放词汇对象定位。", "result": "$NavA^3$在导航性能上达到SOTA，能成功完成不同机器人平台的长时程导航任务。", "conclusion": "$NavA^3$为通用导航提供了可行方案，数据集和代码将开源。"}}
{"id": "2508.04642", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.04642", "abs": "https://arxiv.org/abs/2508.04642", "authors": ["Baihui Xiao", "Chengjian Feng", "Zhijian Huang", "Feng yan", "Yujie Zhong", "Lin Ma"], "title": "RoboTron-Sim: Improving Real-World Driving via Simulated Hard-Case", "comment": "ICCV 2025", "summary": "Collecting real-world data for rare high-risk scenarios, long-tailed driving\nevents, and complex interactions remains challenging, leading to poor\nperformance of existing autonomous driving systems in these critical\nsituations. In this paper, we propose RoboTron-Sim that improves real-world\ndriving in critical situations by utilizing simulated hard cases. First, we\ndevelop a simulated dataset called Hard-case Augmented Synthetic Scenarios\n(HASS), which covers 13 high-risk edge-case categories, as well as balanced\nenvironmental conditions such as day/night and sunny/rainy. Second, we\nintroduce Scenario-aware Prompt Engineering (SPE) and an Image-to-Ego Encoder\n(I2E Encoder) to enable multimodal large language models to effectively learn\nreal-world challenging driving skills from HASS, via adapting to environmental\ndeviations and hardware differences between real-world and simulated scenarios.\nExtensive experiments on nuScenes show that RoboTron-Sim improves driving\nperformance in challenging scenarios by around 50%, achieving state-of-the-art\nresults in real-world open-loop planning. Qualitative results further\ndemonstrate the effectiveness of RoboTron-Sim in better managing rare high-risk\ndriving scenarios. Project page: https://stars79689.github.io/RoboTron-Sim/", "AI": {"tldr": "RoboTron-Sim通过模拟高风险场景提升自动驾驶系统在复杂情况下的性能，使用HASS数据集和SPE/I2E Encoder方法，实验显示性能提升50%。", "motivation": "解决自动驾驶系统在罕见高风险场景中数据不足导致的性能问题。", "method": "开发HASS模拟数据集，结合SPE和I2E Encoder方法，利用多模态大语言模型学习驾驶技能。", "result": "在nuScenes数据集上性能提升约50%，达到开环规划的最先进水平。", "conclusion": "RoboTron-Sim能有效提升自动驾驶在复杂场景中的表现。"}}
{"id": "2508.04678", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.04678", "abs": "https://arxiv.org/abs/2508.04678", "authors": ["Joel Loo", "Zhanxin Wu", "David Hsu"], "title": "Open Scene Graphs for Open-World Object-Goal Navigation", "comment": "In IJRR Special Issue: Foundation Models and Neuro-symbolic AI for\n  Robotics. Journal extension to arXiv:2407.02473", "summary": "How can we build general-purpose robot systems for open-world semantic\nnavigation, e.g., searching a novel environment for a target object specified\nin natural language? To tackle this challenge, we introduce OSG Navigator, a\nmodular system composed of foundation models, for open-world Object-Goal\nNavigation (ObjectNav). Foundation models provide enormous semantic knowledge\nabout the world, but struggle to organise and maintain spatial information\neffectively at scale. Key to OSG Navigator is the Open Scene Graph\nrepresentation, which acts as spatial memory for OSG Navigator. It organises\nspatial information hierarchically using OSG schemas, which are templates, each\ndescribing the common structure of a class of environments. OSG schemas can be\nautomatically generated from simple semantic labels of a given environment,\ne.g., \"home\" or \"supermarket\". They enable OSG Navigator to adapt zero-shot to\nnew environment types. We conducted experiments using both Fetch and Spot\nrobots in simulation and in the real world, showing that OSG Navigator achieves\nstate-of-the-art performance on ObjectNav benchmarks and generalises zero-shot\nover diverse goals, environments, and robot embodiments.", "AI": {"tldr": "OSG Navigator是一个模块化系统，利用基础模型和开放场景图（OSG）表示，实现开放世界中的语义导航任务。", "motivation": "解决开放世界语义导航的挑战，如在新环境中根据自然语言指令搜索目标物体。", "method": "采用模块化设计，结合基础模型和OSG表示，通过OSG模式自动生成环境模板，实现零样本适应。", "result": "在Fetch和Spot机器人上的实验表明，OSG Navigator在ObjectNav基准测试中达到最优性能，并能零样本泛化到多样目标、环境和机器人平台。", "conclusion": "OSG Navigator通过结合基础模型和OSG表示，有效解决了开放世界语义导航问题，具有广泛适用性。"}}
{"id": "2508.04691", "categories": ["cs.RO", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.04691", "abs": "https://arxiv.org/abs/2508.04691", "authors": ["Yuanchen Bai", "Zijian Ding", "Shaoyue Wen", "Xiang Chang", "Angelique Taylor"], "title": "From MAS to MARS: Coordination Failures and Reasoning Trade-offs in Hierarchical Multi-Agent Robotic Systems within a Healthcare Scenario", "comment": null, "summary": "Multi-agent robotic systems (MARS) build upon multi-agent systems by\nintegrating physical and task-related constraints, increasing the complexity of\naction execution and agent coordination. However, despite the availability of\nadvanced multi-agent frameworks, their real-world deployment on robots remains\nlimited, hindering the advancement of MARS research in practice. To bridge this\ngap, we conducted two studies to investigate performance trade-offs of\nhierarchical multi-agent frameworks in a simulated real-world multi-robot\nhealthcare scenario. In Study 1, using CrewAI, we iteratively refine the\nsystem's knowledge base, to systematically identify and categorize coordination\nfailures (e.g., tool access violations, lack of timely handling of failure\nreports) not resolvable by providing contextual knowledge alone. In Study 2,\nusing AutoGen, we evaluate a redesigned bidirectional communication structure\nand further measure the trade-offs between reasoning and non-reasoning models\noperating within the same robotic team setting. Drawing from our empirical\nfindings, we emphasize the tension between autonomy and stability and the\nimportance of edge-case testing to improve system reliability and safety for\nfuture real-world deployment. Supplementary materials, including codes, task\nagent setup, trace outputs, and annotated examples of coordination failures and\nreasoning behaviors, are available at:\nhttps://byc-sophie.github.io/mas-to-mars/.", "AI": {"tldr": "论文研究了多智能体机器人系统（MARS）在实际部署中的性能权衡，通过两个实验改进了协调机制和通信结构，强调了自主性与稳定性之间的张力。", "motivation": "尽管多智能体框架技术先进，但其在机器人上的实际应用仍有限，阻碍了MARS研究的进展。", "method": "研究1使用CrewAI迭代优化知识库，识别协调失败；研究2使用AutoGen评估双向通信结构，比较推理与非推理模型的性能。", "result": "研究发现协调失败需更多改进，双向通信结构能提升性能，同时揭示了自主性与稳定性的矛盾。", "conclusion": "强调边缘案例测试对提升系统可靠性和安全性的重要性，为未来实际部署提供参考。"}}
{"id": "2508.04696", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.04696", "abs": "https://arxiv.org/abs/2508.04696", "authors": ["Vyacheslav Kovalev", "Ekaterina Chaikovskaia", "Egor Davydenko", "Roman Gorbachev"], "title": "Achieving Precise and Reliable Locomotion with Differentiable Simulation-Based System Identification", "comment": "6 pages, Accepted for IROS 2025", "summary": "Accurate system identification is crucial for reducing trajectory drift in\nbipedal locomotion, particularly in reinforcement learning and model-based\ncontrol. In this paper, we present a novel control framework that integrates\nsystem identification into the reinforcement learning training loop using\ndifferentiable simulation. Unlike traditional approaches that rely on direct\ntorque measurements, our method estimates system parameters using only\ntrajectory data (positions, velocities) and control inputs. We leverage the\ndifferentiable simulator MuJoCo-XLA to optimize system parameters, ensuring\nthat simulated robot behavior closely aligns with real-world motion. This\nframework enables scalable and flexible parameter optimization. Accurate system\nidentification is crucial for reducing trajectory drift in bipedal locomotion,\nparticularly in reinforcement learning and model-based control. In this paper,\nwe present a novel control framework that integrates system identification into\nthe reinforcement learning training loop using differentiable simulation.\nUnlike traditional approaches that rely on direct torque measurements, our\nmethod estimates system parameters using only trajectory data (positions,\nvelocities) and control inputs. We leverage the differentiable simulator\nMuJoCo-XLA to optimize system parameters, ensuring that simulated robot\nbehavior closely aligns with real-world motion. This framework enables scalable\nand flexible parameter optimization. It supports fundamental physical\nproperties such as mass and inertia. Additionally, it handles complex system\nnonlinear behaviors, including advanced friction models, through neural network\napproximations. Experimental results show that our framework significantly\nimproves trajectory following.", "AI": {"tldr": "提出了一种基于可微分仿真的新型控制框架，将系统辨识集成到强化学习训练中，仅使用轨迹数据和输入控制优化系统参数，显著减少双足运动中的轨迹漂移。", "motivation": "双足运动中的轨迹漂移问题在强化学习和基于模型的控制中尤为突出，传统方法依赖直接扭矩测量，限制了灵活性和可扩展性。", "method": "利用可微分仿真器MuJoCo-XLA，仅通过轨迹数据（位置、速度）和控制输入估计系统参数，优化模拟行为以匹配真实运动。", "result": "实验表明，该框架显著提高了轨迹跟踪性能，支持质量和惯性等物理属性，并通过神经网络近似处理复杂非线性行为。", "conclusion": "该框架为系统辨识提供了一种灵活且可扩展的方法，适用于复杂动态系统的优化。"}}
