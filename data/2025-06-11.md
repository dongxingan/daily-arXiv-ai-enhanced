<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 72]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [AI Magnetic Levitation (Maglev) Conveyor for Automated Assembly Production](https://arxiv.org/abs/2506.08039)
*Ray Wai Man Kong*

Main category: cs.RO

TL;DR: AI Maglev Conveyor系统结合磁悬浮技术和AI，提升制造效率，降低成本，支持可持续生产。


<details>
  <summary>Details</summary>
Motivation: 现代制造需要高效、快速和精确的系统，传统方法存在摩擦和维护成本高的问题。

Method: 结合磁悬浮技术和AI，实现无摩擦运输、实时监控和自适应控制。

Result: 减少维护成本、提高效率、支持灵活生产，适应市场需求变化。

Conclusion: AI Maglev Conveyor系统是高效、灵活且经济的制造解决方案，适用于多种行业。

Abstract: Efficiency, speed, and precision are essential in modern manufacturing. AI
Maglev Conveyor system, combining magnetic levitation (maglev) technology with
artificial intelligence (AI), revolutionizes automated production processes.
This system reduces maintenance costs and downtime by eliminating friction,
enhancing operational efficiency. It transports goods swiftly with minimal
energy consumption, optimizing resource use and supporting sustainability. AI
integration enables real-time monitoring and adaptive control, allowing
businesses to respond to production demand fluctuations and streamline supply
chain operations.
  The AI Maglev Conveyor offers smooth, silent operation, accommodating diverse
product types and sizes for flexible manufacturing without extensive
reconfiguration. AI algorithms optimize routing, reduce cycle times, and
improve throughput, creating an agile production line adaptable to market
changes.
  This applied research paper introduces the Maglev Conveyor system, featuring
an electromagnetic controller and multiple movers to enhance automation. It
offers cost savings as an alternative to setups using six-axis robots or linear
motors, with precise adjustments for robotic arm loading. Operating at high
speeds minimizes treatment time for delicate components while maintaining
precision. Its adaptable design accommodates various materials, facilitating
integration of processing stations alongside electronic product assembly.
Positioned between linear-axis and robotic systems in cost, the Maglev Conveyor
is ideal for flat parts requiring minimal travel, transforming production
efficiency across industries. It explores its technical advantages,
flexibility, cost reductions, and overall benefits.

</details>


### [2] [UAVs Meet Agentic AI: A Multidomain Survey of Autonomous Aerial Intelligence and Agentic UAVs](https://arxiv.org/abs/2506.08045)
*Ranjan Sapkota,Konstantinos I. Roumeliotis,Manoj Karkee*

Main category: cs.RO

TL;DR: 本文综述了Agentic UAVs（自主智能无人机）的架构、技术优势、应用领域及未来挑战，提出了未来发展的路线图。


<details>
  <summary>Details</summary>
Motivation: 传统无人机在复杂环境中的自主性和适应性不足，而Agentic UAVs通过整合感知、决策、记忆和协作规划，展现出更强的智能性和灵活性。

Method: 通过比较分析Agentic UAVs与传统无人机的技术差异，探讨其在七个高影响力领域的应用，并分析技术、法规和数据可靠性方面的挑战。

Result: Agentic UAVs在多个领域展现出广泛的社会价值，同时面临硬件、学习和人机交互等方面的挑战。

Conclusion: 本文为Agentic UAVs的未来发展、部署和治理提供了基础框架，并提出了自进化生态系统和可持续部署的未来方向。

Abstract: Agentic UAVs represent a new frontier in autonomous aerial intelligence,
integrating perception, decision-making, memory, and collaborative planning to
operate adaptively in complex, real-world environments. Driven by recent
advances in Agentic AI, these systems surpass traditional UAVs by exhibiting
goal-driven behavior, contextual reasoning, and interactive autonomy. We
provide a comprehensive foundation for understanding the architectural
components and enabling technologies that distinguish Agentic UAVs from
traditional autonomous UAVs. Furthermore, a detailed comparative analysis
highlights advancements in autonomy with AI agents, learning, and mission
flexibility. This study explores seven high-impact application domains
precision agriculture, construction & mining, disaster response, environmental
monitoring, infrastructure inspection, logistics, security, and wildlife
conservation, illustrating the broad societal value of agentic aerial
intelligence. Furthermore, we identify key challenges in technical constraints,
regulatory limitations, and data-model reliability, and we present emerging
solutions across hardware innovation, learning architectures, and human-AI
interaction. Finally, a future roadmap is proposed, outlining pathways toward
self-evolving aerial ecosystems, system-level collaboration, and sustainable,
equitable deployments. This survey establishes a foundational framework for the
future development, deployment, and governance of agentic aerial systems
(Agentic UAVs) across diverse societal and industrial domains.

</details>


### [3] [Adaptive Per-Tree Canopy Volume Estimation Using Mobile LiDAR in Structured and Unstructured Orchards](https://arxiv.org/abs/2506.08061)
*Ali Abedi,Fernando Cladera,Mohsen Farajijalal,Reza Ehsani*

Main category: cs.RO

TL;DR: 提出了一种基于移动LiDAR数据的实时系统，用于估计单棵树冠体积，适用于结构多样的果园环境。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态扫描或假设果园结构均匀，无法适应多样化的田间几何形状。

Method: 结合LiDAR-惯性里程计、自适应分割和几何重建的集成流程，采用DBSCAN和谱聚类的混合聚类策略。

Result: 在两种商业果园中测试，成功率为93%（开心果）和80%（杏仁），与无人机数据一致。

Conclusion: 该系统为结构多样的果园提供了可扩展、非侵入式的树木监测方案。

Abstract: We present a real-time system for per-tree canopy volume estimation using
mobile LiDAR data collected during routine robotic navigation. Unlike prior
approaches that rely on static scans or assume uniform orchard structures, our
method adapts to varying field geometries via an integrated pipeline of
LiDAR-inertial odometry, adaptive segmentation, and geometric reconstruction.
We evaluate the system across two commercial orchards, one pistachio orchard
with regular spacing and one almond orchard with dense, overlapping crowns. A
hybrid clustering strategy combining DBSCAN and spectral clustering enables
robust per-tree segmentation, achieving 93% success in pistachio and 80% in
almond, with strong agreement to drone derived canopy volume estimates. This
work advances scalable, non-intrusive tree monitoring for structurally diverse
orchard environments.

</details>


### [4] [Ego-centric Learning of Communicative World Models for Autonomous Driving](https://arxiv.org/abs/2506.08149)
*Hang Wang,Dechen Gao,Junshan Zhang*

Main category: cs.RO

TL;DR: 论文提出CALL方法，通过生成式AI和世界模型的潜在表示，解决多智能体强化学习中的部分可观测性和非平稳性问题，同时减少通信开销。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）在复杂高维环境中（如自动驾驶）面临部分可观测性和非平稳性问题，信息共享虽常用但存在通信开销和可扩展性问题。

Method: CALL方法利用世界模型的潜在表示，将智能体的状态和意图编码为低维表示，通过轻量级通信共享，并结合自我中心学习提升预测和规划能力。

Result: 实验在CARLA平台上进行，证明了CALL在局部轨迹规划任务中的性能提升。

Conclusion: CALL通过轻量级信息共享和潜在表示，有效提升了MARL的性能，同时解决了通信开销问题。

Abstract: We study multi-agent reinforcement learning (MARL) for tasks in complex
high-dimensional environments, such as autonomous driving. MARL is known to
suffer from the \textit{partial observability} and \textit{non-stationarity}
issues. To tackle these challenges, information sharing is often employed,
which however faces major hurdles in practice, including overwhelming
communication overhead and scalability concerns. By making use of generative AI
embodied in world model together with its latent representation, we develop
{\it CALL}, \underline{C}ommunic\underline{a}tive Wor\underline{l}d
Mode\underline{l}, for MARL, where 1) each agent first learns its world model
that encodes its state and intention into low-dimensional latent representation
with smaller memory footprint, which can be shared with other agents of
interest via lightweight communication; and 2) each agent carries out
ego-centric learning while exploiting lightweight information sharing to enrich
her world model, and then exploits its generalization capacity to improve
prediction for better planning. We characterize the gain on the prediction
accuracy from the information sharing and its impact on performance gap.
Extensive experiments are carried out on the challenging local trajectory
planning tasks in the CARLA platform to demonstrate the performance gains of
using \textit{CALL}.

</details>


### [5] [TensorTouch: Calibration of Tactile Sensors for High Resolution Stress Tensor and Deformation for Dexterous Manipulation](https://arxiv.org/abs/2506.08291)
*Won Kyung Do,Matthew Strong,Aiden Swann,Boshu Lei,Monroe Kennedy III*

Main category: cs.RO

TL;DR: TensorTouch通过结合有限元分析和深度学习，从光学触觉传感器中提取高分辨率接触信息，解决了多触点操作的挑战。


<details>
  <summary>Details</summary>
Motivation: 多触点操作（如从地面捏硬币或操作交织物体）对机器人系统仍具挑战性，需要高分辨率触觉传感。

Method: TensorTouch框架结合有限元分析和深度学习，提取应力张量、变形场和力分布等接触信息。

Result: 实验验证显示，TensorTouch在选择性抓取任务中达到90%成功率，支持大变形操作。

Conclusion: TensorTouch为机器人系统提供了新的高精度触觉操作能力。

Abstract: Advanced dexterous manipulation involving multiple simultaneous contacts
across different surfaces, like pinching coins from ground or manipulating
intertwined objects, remains challenging for robotic systems. Such tasks exceed
the capabilities of vision and proprioception alone, requiring high-resolution
tactile sensing with calibrated physical metrics. Raw optical tactile sensor
images, while information-rich, lack interpretability and cross-sensor
transferability, limiting their real-world utility. TensorTouch addresses this
challenge by integrating finite element analysis with deep learning to extract
comprehensive contact information from optical tactile sensors, including
stress tensors, deformation fields, and force distributions at pixel-level
resolution. The TensorTouch framework achieves sub-millimeter position accuracy
and precise force estimation while supporting large sensor deformations crucial
for manipulating soft objects. Experimental validation demonstrates 90% success
in selectively grasping one of two strings based on detected motion, enabling
new contact-rich manipulation capabilities previously inaccessible to robotic
systems.

</details>


### [6] [HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation](https://arxiv.org/abs/2506.08296)
*Hongjun Wu,Heng Zhang,Pengsong Zhang,Jin Wang,Cong Wang*

Main category: cs.RO

TL;DR: HiBerNAC是一种基于神经科学启发的分层多智能体框架，通过结合多模态VLA规划和神经启发的反射机制，显著提升了复杂机器人操作任务的执行效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 解决复杂机器人操作任务中的持久上下文记忆、多智能体协调和动态长时规划等挑战。

Method: 结合多模态VLA规划和神经启发的多智能体机制，采用分层决策和动态智能体专业化。

Result: 相比现有VLA模型，HiBerNAC将长时任务完成时间减少23%，并在多路径任务中实现12-31%的成功率。

Conclusion: HiBerNAC为生物认知与机器人学习机制的融合提供了初步证据。

Abstract: Recent advances in multimodal vision-language-action (VLA) models have
revolutionized traditional robot learning, enabling systems to interpret
vision, language, and action in unified frameworks for complex task planning.
However, mastering complex manipulation tasks remains an open challenge,
constrained by limitations in persistent contextual memory, multi-agent
coordination under uncertainty, and dynamic long-horizon planning across
variable sequences. To address this challenge, we propose \textbf{HiBerNAC}, a
\textbf{Hi}erarchical \textbf{B}rain-\textbf{e}mulated \textbf{r}obotic
\textbf{N}eural \textbf{A}gent \textbf{C}ollective, inspired by breakthroughs
in neuroscience, particularly in neural circuit mechanisms and hierarchical
decision-making. Our framework combines: (1) multimodal VLA planning and
reasoning with (2) neuro-inspired reflection and multi-agent mechanisms,
specifically designed for complex robotic manipulation tasks. By leveraging
neuro-inspired functional modules with decentralized multi-agent collaboration,
our approach enables robust and enhanced real-time execution of complex
manipulation tasks. In addition, the agentic system exhibits scalable
collective intelligence via dynamic agent specialization, adapting its
coordination strategy to variable task horizons and complexity. Through
extensive experiments on complex manipulation tasks compared with
state-of-the-art VLA models, we demonstrate that \textbf{HiBerNAC} reduces
average long-horizon task completion time by 23\%, and achieves non-zero
success rates (12\textendash 31\%) on multi-path tasks where prior
state-of-the-art VLA models consistently fail. These results provide indicative
evidence for bridging biological cognition and robotic learning mechanisms.

</details>


### [7] [Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning](https://arxiv.org/abs/2506.08344)
*Neşet Ünver Akmandor,Sarvesh Prajapati,Mark Zolotas,Taşkın Padır*

Main category: cs.RO

TL;DR: 提出了一种名为Re4MPC的新型多模型运动规划方法，通过结合非线性模型预测控制（NMPC）和深度强化学习（DRL），实现了高效的运动轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 传统的高自由度机器人运动规划方法计算成本高，难以应用于实际场景，因此需要一种更高效的方法。

Method: Re4MPC通过动态选择NMPC的模型、成本和约束条件，结合DRL学习决策策略，实现了高效轨迹规划。

Result: 实验表明，Re4MPC在计算效率和任务成功率上均优于传统NMPC方法。

Conclusion: Re4MPC为高自由度机器人的运动规划提供了一种高效且可靠的解决方案。

Abstract: Traditional motion planning methods for robots with many degrees-of-freedom,
such as mobile manipulators, are often computationally prohibitive for
real-world settings. In this paper, we propose a novel multi-model motion
planning pipeline, termed Re4MPC, which computes trajectories using Nonlinear
Model Predictive Control (NMPC). Re4MPC generates trajectories in a
computationally efficient manner by reactively selecting the model, cost, and
constraints of the NMPC problem depending on the complexity of the task and
robot state. The policy for this reactive decision-making is learned via a Deep
Reinforcement Learning (DRL) framework. We introduce a mathematical formulation
to integrate NMPC into this DRL framework. To validate our methodology and
design choices, we evaluate DRL training and test outcomes in a physics-based
simulation involving a mobile manipulator. Experimental results demonstrate
that Re4MPC is more computationally efficient and achieves higher success rates
in reaching end-effector goals than the NMPC baseline, which computes
whole-body trajectories without our learning mechanism.

</details>


### [8] [Periodic Bipedal Gait Learning Using Reward Composition Based on a Novel Gait Planner for Humanoid Robots](https://arxiv.org/abs/2506.08416)
*Bolin Li,Linwei Sun,Xuecong Huang,Yuzhi Jiang,Lijun Zhu*

Main category: cs.RO

TL;DR: 提出一种基于奖励组合的周期性双足步态学习方法，结合实时步态规划器，用于人形机器人。


<details>
  <summary>Details</summary>
Motivation: 旨在通过奖励组合和实时步态规划，减少机器人学习时间并提升运动性能。

Method: 1. 引入新型步态规划器，将3D模型解耦为两个2D模型并近似为混合倒立摆（H-LIP）进行轨迹规划；2. 在强化学习框架中设计三种奖励函数，形成奖励组合以实现周期性步态。

Result: 通过步态设计示例和性能对比验证了方法的有效性。

Conclusion: 该方法显著减少了学习时间并提升了运动性能，适用于人形机器人的周期性步态学习。

Abstract: This paper presents a periodic bipedal gait learning method using reward
composition, integrated with a real-time gait planner for humanoid robots.
First, we introduce a novel gait planner that incorporates dynamics to design
the desired joint trajectory. In the gait design process, the 3D robot model is
decoupled into two 2D models, which are then approximated as hybrid inverted
pendulums (H-LIP) for trajectory planning. The gait planner operates in
parallel in real time within the robot's learning environment. Second, based on
this gait planner, we design three effective reward functions within a
reinforcement learning framework, forming a reward composition to achieve
periodic bipedal gait. This reward composition reduces the robot's learning
time and enhances locomotion performance. Finally, a gait design example and
performance comparison are presented to demonstrate the effectiveness of the
proposed method.

</details>


### [9] [Attention-based Learning for 3D Informative Path Planning](https://arxiv.org/abs/2506.08434)
*Rui Zhao,Xingjian Zhang,Yuhong Cao,Yizhuo Wang,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 提出了一种基于注意力的深度强化学习方法，用于解决3D空间中的自适应信息路径规划问题，通过平衡感知范围和精度，优化信息收集。


<details>
  <summary>Details</summary>
Motivation: 解决自适应信息路径规划问题，使空中机器人能够在时间和距离约束下动态调整路径，最大化信息收集。

Method: 利用注意力机制捕捉全局空间依赖关系，构建上下文信念表示，优化短期和长期搜索目标。

Result: 在有限预算下显著降低环境不确定性，平衡探索与利用，并在不同规模环境中表现良好。

Conclusion: 该方法在自适应路径规划中表现优异，具有广泛的实际应用潜力。

Abstract: In this work, we propose an attention-based deep reinforcement learning
approach to address the adaptive informative path planning (IPP) problem in 3D
space, where an aerial robot equipped with a downward-facing sensor must
dynamically adjust its 3D position to balance sensing footprint and accuracy,
and finally obtain a high-quality belief of an underlying field of interest
over a given domain (e.g., presence of specific plants, hazardous gas,
geological structures, etc.). In adaptive IPP tasks, the agent is tasked with
maximizing information collected under time/distance constraints, continuously
adapting its path based on newly acquired sensor data. To this end, we leverage
attention mechanisms for their strong ability to capture global spatial
dependencies across large action spaces, allowing the agent to learn an
implicit estimation of environmental transitions. Our model builds a contextual
belief representation over the entire domain, guiding sequential movement
decisions that optimize both short- and long-term search objectives.
Comparative evaluations against state-of-the-art planners demonstrate that our
approach significantly reduces environmental uncertainty within constrained
budgets, thus allowing the agent to effectively balance exploration and
exploitation. We further show our model generalizes well to environments of
varying sizes, highlighting its potential for many real-world applications.

</details>


### [10] [TGRPO :Fine-tuning Vision-Language-Action Model via Trajectory-wise Group Relative Policy Optimization](https://arxiv.org/abs/2506.08440)
*Zengjue Chen,Runliang Niu,He Kong,Qi Wang*

Main category: cs.RO

TL;DR: 论文提出了一种名为TGRPO的方法，通过结合步级和轨迹级优势信号，改进了GRPO的组级优势估计，适用于VLA模型的在线强化学习训练。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在新环境中仍需任务特定的微调，且依赖静态轨迹数据集，无法利用实时交互和反馈。强化学习提供了一种闭环交互的替代方案。

Method: 提出TGRPO方法，融合步级和轨迹级优势信号，改进GRPO的组级优势估计。

Result: 在十个操作任务上的实验表明，TGRPO优于多种基线方法，能生成更稳健和高效的政策。

Conclusion: TGRPO是一种有效的在线强化学习方法，适用于VLA模型的训练，具有广泛的应用潜力。

Abstract: Recent advances in Vision-Language-Action (VLA) model have demonstrated
strong generalization capabilities across diverse scenes, tasks, and robotic
platforms when pretrained at large-scale datasets. However, these models still
require task-specific fine-tuning in novel environments, a process that relies
almost exclusively on supervised fine-tuning (SFT) using static trajectory
datasets. Such approaches neither allow robot to interact with environment nor
do they leverage feedback from live execution. Also, their success is
critically dependent on the size and quality of the collected trajectories.
Reinforcement learning (RL) offers a promising alternative by enabling
closed-loop interaction and aligning learned policies directly with task
objectives. In this work, we draw inspiration from the ideas of GRPO and
propose the Trajectory-wise Group Relative Policy Optimization (TGRPO) method.
By fusing step-level and trajectory-level advantage signals, this method
improves GRPO's group-level advantage estimation, thereby making the algorithm
more suitable for online reinforcement learning training of VLA. Experimental
results on ten manipulation tasks from the libero-object benchmark demonstrate
that TGRPO consistently outperforms various baseline methods, capable of
generating more robust and efficient policies across multiple tested scenarios.
Our source codes are available at: https://github.com/hahans/TGRPO

</details>


### [11] [Diffusion Models for Safety Validation of Autonomous Driving Systems](https://arxiv.org/abs/2506.08459)
*Juanran Wang,Marc R. Schlichting,Harrison Delecki,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 使用去噪扩散模型生成自动驾驶系统的潜在故障案例，无需外部数据集，适用于交通路口安全验证。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的安全验证因高风险、高成本及潜在故障的罕见性和多样性而极具挑战性。

Method: 训练去噪扩散模型，根据初始交通状态生成自动驾驶车辆的潜在故障案例。

Result: 实验表明，该模型能生成多样且真实的故障样本，适用于多种场景。

Conclusion: 该方法无需外部数据集，计算资源需求低，适用于交通路口的安全验证。

Abstract: Safety validation of autonomous driving systems is extremely challenging due
to the high risks and costs of real-world testing as well as the rarity and
diversity of potential failures. To address these challenges, we train a
denoising diffusion model to generate potential failure cases of an autonomous
vehicle given any initial traffic state. Experiments on a four-way intersection
problem show that in a variety of scenarios, the diffusion model can generate
realistic failure samples while capturing a wide variety of potential failures.
Our model does not require any external training dataset, can perform training
and inference with modest computing resources, and does not assume any prior
knowledge of the system under test, with applicability to safety validation for
traffic intersections.

</details>


### [12] [Noise Analysis and Hierarchical Adaptive Body State Estimator For Biped Robot Walking With ESVC Foot](https://arxiv.org/abs/2506.08578)
*Boyang Chen,Xizhe Zang,Chao Song,Yue Zhang,Xuehe Zhang,Jie Zhao*

Main category: cs.RO

TL;DR: 论文提出了一种针对ESVC脚的机器人状态估计方法，通过噪声分析和分层自适应状态估计器提高了行走效率和精度。


<details>
  <summary>Details</summary>
Motivation: ESVC脚虽然提升了机器人行走的能量效率，但由于支撑腿倾斜导致接触模型误差放大，增加了状态估计的难度。

Method: 通过物理实验分析噪声影响，建立噪声-时间回归模型，并提出分层自适应状态估计器（包括预估计和后估计阶段）。

Result: 提出的状态估计器在精度和收敛速度上优于EKF和自适应EKF。

Conclusion: 分层自适应状态估计器有效解决了ESVC脚机器人行走中的状态估计问题，提升了性能。

Abstract: The ESVC(Ellipse-based Segmental Varying Curvature) foot, a robot foot design
inspired by the rollover shape of the human foot, significantly enhances the
energy efficiency of the robot walking gait. However, due to the tilt of the
supporting leg, the error of the contact model are amplified, making robot
state estimation more challenging. Therefore, this paper focuses on the noise
analysis and state estimation for robot walking with the ESVC foot. First,
through physical robot experiments, we investigate the effect of the ESVC foot
on robot measurement noise and process noise. and a noise-time regression model
using sliding window strategy is developed. Then, a hierarchical adaptive state
estimator for biped robots with the ESVC foot is proposed. The state estimator
consists of two stages: pre-estimation and post-estimation. In the
pre-estimation stage, a data fusion-based estimation is employed to process the
sensory data. During post-estimation, the acceleration of center of mass is
first estimated, and then the noise covariance matrices are adjusted based on
the regression model. Following that, an EKF(Extended Kalman Filter) based
approach is applied to estimate the centroid state during robot walking.
Physical experiments demonstrate that the proposed adaptive state estimator for
biped robot walking with the ESVC foot not only provides higher precision than
both EKF and Adaptive EKF, but also converges faster under varying noise
conditions.

</details>


### [13] [Deep Reinforcement Learning-Based Motion Planning and PDE Control for Flexible Manipulators](https://arxiv.org/abs/2506.08639)
*Amir Hossein Barjini,Seyed Adel Alizadeh Kolagar,Sadeq Yaqubi,Jouni Mattila*

Main category: cs.RO

TL;DR: 提出了一种结合深度强化学习（DRL）和非线性偏微分方程（PDE）控制器的柔性机械臂运动规划与控制框架，显著减少振动并提高跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅关注控制，而忽略了期望轨迹对端点振动的影响，因此需要一种新的方法来优化轨迹并抑制振动。

Method: 使用软演员-评论家（SAC）算法的DRL运动规划器生成优化轨迹，结合非线性PDE控制器计算扭矩并确保闭环稳定性。

Result: 通过仿真和实验验证，该方法在振动抑制和跟踪精度上优于传统方法。

Conclusion: 结合学习型运动规划与基于模型的控制，可显著提升柔性机械臂的精度和稳定性。

Abstract: This article presents a motion planning and control framework for flexible
robotic manipulators, integrating deep reinforcement learning (DRL) with a
nonlinear partial differential equation (PDE) controller. Unlike conventional
approaches that focus solely on control, we demonstrate that the desired
trajectory significantly influences endpoint vibrations. To address this, a DRL
motion planner, trained using the soft actor-critic (SAC) algorithm, generates
optimized trajectories that inherently minimize vibrations. The PDE nonlinear
controller then computes the required torques to track the planned trajectory
while ensuring closed-loop stability using Lyapunov analysis. The proposed
methodology is validated through both simulations and real-world experiments,
demonstrating superior vibration suppression and tracking accuracy compared to
traditional methods. The results underscore the potential of combining
learning-based motion planning with model-based control for enhancing the
precision and stability of flexible robotic manipulators.

</details>


### [14] [ROS-related Robotic Systems Development with V-model-based Application of MeROS Metamodel](https://arxiv.org/abs/2506.08706)
*Tomasz Winiarski,Jan Kaniuka,Daniel Giełdowski,Jakub Ostrysz,Krystian Radlak,Dmytro Kushnir*

Main category: cs.RO

TL;DR: 本文提出了一种结合ROS和MBSE的方法，通过MeROS和V模型提升机器人系统开发的规范性和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统复杂性和安全关键性的增加，现有工具如ROS和MBSE缺乏有效整合，亟需一种结构化开发方法。

Method: 提出了一种基于MeROS和V模型的领域特定方法，支持ROS和ROS 2，强调灵活性和可重用性。

Result: 通过HeROS平台的案例验证了方法的有效性，提升了系统一致性和可追溯性。

Conclusion: 该方法为ROS项目提供了结构化、工具无关的MBSE实践基础，具有扩展性和适应性。

Abstract: As robotic systems grow increasingly complex, heterogeneous, and
safety-critical, the need for structured development methodologies becomes
paramount. Although frameworks like the Robot Operating System (ROS) and
Model-Based Systems Engineering (MBSE) offer foundational tools, they often
lack integration when used together. This paper addresses that gap by aligning
the widely recognized V-model development paradigm with the MeROS metamodel
SysML-based modeling language tailored for ROS-based systems.
  We propose a domain-specific methodology that bridges ROS-centric modelling
with systems engineering practices. Our approach formalises the structure,
behaviour, and validation processes of robotic systems using MeROS, while
extending it with a generalized, adaptable V-model compatible with both ROS and
ROS 2. Rather than prescribing a fixed procedure, the approach supports
project-specific flexibility and reuse, offering guidance across all stages of
development.
  The approach is validated through a comprehensive case study on HeROS, a
heterogeneous multi-robot platform comprising manipulators, mobile units, and
dynamic test environments. This example illustrates how the MeROS-compatible
V-model enhances traceability and system consistency while remaining accessible
and extensible for future adaptation. The work contributes a structured,
tool-agnostic foundation for developers and researchers seeking to apply MBSE
practices in ROS-based projects.

</details>


### [15] [PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly](https://arxiv.org/abs/2506.08708)
*Liang Ma,Jiajun Wen,Min Lin,Rongtao Xu,Xiwen Liang,Bingqian Lin,Jun Ma,Yongxin Wang,Ziming Wei,Haokun Lin,Mingfei Han,Meng Cao,Bokui Chen,Ivan Laptev,Xiaodan Liang*

Main category: cs.RO

TL;DR: PhyBlock是一个评估视觉语言模型（VLMs）在物理理解和规划能力的基准测试，通过3D积木组装任务和视觉问答（VQA）任务，揭示了VLMs在高级规划和空间推理上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在理解物理现象和结构化3D环境中的能力有限，需要一种评估工具来推动其发展。

Method: 提出PhyBlock基准，包含2600个任务（400个组装任务和2200个VQA任务），评估模型在部分完成、故障诊断和规划鲁棒性三个维度上的表现。

Result: 测试21个先进VLMs，发现其在高级规划和空间推理上表现显著不足，任务复杂度增加时性能下降明显。

Conclusion: PhyBlock为提升VLMs在物理问题解决和空间推理能力提供了统一测试平台。

Abstract: While vision-language models (VLMs) have demonstrated promising capabilities
in reasoning and planning for embodied agents, their ability to comprehend
physical phenomena, particularly within structured 3D environments, remains
severely limited. To close this gap, we introduce PhyBlock, a progressive
benchmark designed to assess VLMs on physical understanding and planning
through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level
cognitive hierarchy assembly task alongside targeted Visual Question Answering
(VQA) samples, collectively aimed at evaluating progressive spatial reasoning
and fundamental physical comprehension, including object properties, spatial
relationships, and holistic scene understanding. PhyBlock includes 2600 block
tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three
key dimensions: partial completion, failure diagnosis, and planning robustness.
We benchmark 21 state-of-the-art VLMs, highlighting their strengths and
limitations in physically grounded, multi-step planning. Our empirical findings
indicate that the performance of VLMs exhibits pronounced limitations in
high-level planning and reasoning capabilities, leading to a notable decline in
performance for the growing complexity of the tasks. Error analysis reveals
persistent difficulties in spatial orientation and dependency reasoning.
Surprisingly, chain-of-thought prompting offers minimal improvements,
suggesting spatial tasks heavily rely on intuitive model comprehension. We
position PhyBlock as a unified testbed to advance embodied reasoning, bridging
vision-language understanding and real-world physical problem-solving.

</details>


### [16] [Bayesian Inverse Physics for Neuro-Symbolic Robot Learning](https://arxiv.org/abs/2506.08756)
*Octavio Arriaga,Rebecca Adam,Melvin Laux,Lisa Gutzeit,Marco Ragni,Jan Peters,Frank Kirchner*

Main category: cs.RO

TL;DR: 论文提出了一种结合数据驱动学习与结构化推理的混合神经符号架构，以解决机器人在未知动态环境中高效可靠运行的挑战。


<details>
  <summary>Details</summary>
Motivation: 现实机器人应用需要自适应、可解释且数据高效的学习方法，但现有深度学习模型在未知动态环境中表现不足。

Method: 提出利用可微分物理建模、贝叶斯推理和元学习，将物理符号推理嵌入神经模型。

Result: 这种混合架构有望使机器人泛化训练数据之外、推理新情境并持续扩展知识。

Conclusion: 混合神经符号架构是下一代自主系统的关键，并提供了研究路线图以加速其发展。

Abstract: Real-world robotic applications, from autonomous exploration to assistive
technologies, require adaptive, interpretable, and data-efficient learning
paradigms. While deep learning architectures and foundation models have driven
significant advances in diverse robotic applications, they remain limited in
their ability to operate efficiently and reliably in unknown and dynamic
environments. In this position paper, we critically assess these limitations
and introduce a conceptual framework for combining data-driven learning with
deliberate, structured reasoning. Specifically, we propose leveraging
differentiable physics for efficient world modeling, Bayesian inference for
uncertainty-aware decision-making, and meta-learning for rapid adaptation to
new tasks. By embedding physical symbolic reasoning within neural models,
robots could generalize beyond their training data, reason about novel
situations, and continuously expand their knowledge. We argue that such hybrid
neuro-symbolic architectures are essential for the next generation of
autonomous systems, and to this end, we provide a research roadmap to guide and
accelerate their development.

</details>


### [17] [Towards Biosignals-Free Autonomous Prosthetic Hand Control via Imitation Learning](https://arxiv.org/abs/2506.08795)
*Kaijie Shi,Wanglong Lu,Hanli Zhao,Vinicius Prado da Fonseca,Ting Zou,Xianta Jiang*

Main category: cs.RO

TL;DR: 开发了一种基于摄像头和模仿学习的全自主假手控制系统，无需用户生成肌电信号，自动抓取和释放物体。


<details>
  <summary>Details</summary>
Motivation: 传统肌电信号方法对用户身体和心理负担大，需简化假手控制，提高生活质量。

Method: 通过摄像头和模仿学习训练模型，利用人类示范数据实现自主控制。

Result: 模型仅需少量数据即可高成功率运行，并能泛化到不同用户和未见物体。

Conclusion: 该系统显著降低了使用假手的心理负担，提供了一种易用的控制接口。

Abstract: Limb loss affects millions globally, impairing physical function and reducing
quality of life. Most traditional surface electromyographic (sEMG) and
semi-autonomous methods require users to generate myoelectric signals for each
control, imposing physically and mentally taxing demands. This study aims to
develop a fully autonomous control system that enables a prosthetic hand to
automatically grasp and release objects of various shapes using only a camera
attached to the wrist. By placing the hand near an object, the system will
automatically execute grasping actions with a proper grip force in response to
the hand's movements and the environment. To release the object being grasped,
just naturally place the object close to the table and the system will
automatically open the hand. Such a system would provide individuals with limb
loss with a very easy-to-use prosthetic control interface and greatly reduce
mental effort while using. To achieve this goal, we developed a teleoperation
system to collect human demonstration data for training the prosthetic hand
control model using imitation learning, which mimics the prosthetic hand
actions from human. Through training the model using only a few objects' data
from one single participant, we have shown that the imitation learning
algorithm can achieve high success rates, generalizing to more individuals and
unseen objects with a variation of weights. The demonstrations are available at
\href{https://sites.google.com/view/autonomous-prosthetic-hand}{https://sites.google.com/view/autonomous-prosthetic-hand}

</details>


### [18] [FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency](https://arxiv.org/abs/2506.08822)
*Yifei Su,Ning Liu,Dong Chen,Zhen Zhao,Kun Wu,Meng Li,Zhiyuan Xu,Zhengping Che,Jian Tang*

Main category: cs.RO

TL;DR: FreqPolicy通过频率一致性约束提升基于生成模型的视觉运动策略的效率，支持高质量的一步动作生成，并在仿真和实际机器人任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 生成模型在机器人操作中因能建模多模态动作分布而被广泛采用，但其多步采样的高推理成本限制了实时应用。现有方法虽加速采样，但忽略了动作轨迹的时间依赖性。

Method: 提出FreqPolicy，通过频率一致性约束和自适应一致性损失，有效捕捉时间结构，实现高效高质量的一步动作生成。

Result: 在3个仿真基准的53个任务中表现优异，集成到VLA模型后在40个任务中实现加速且无性能损失，实际机器人任务中推理频率达93.5Hz。

Conclusion: FreqPolicy通过频率一致性约束显著提升生成模型在实时机器人系统中的适用性，兼具高效性和有效性。

Abstract: Generative modeling-based visuomotor policies have been widely adopted in
robotic manipulation attributed to their ability to model multimodal action
distributions. However, the high inference cost of multi-step sampling limits
their applicability in real-time robotic systems. To address this issue,
existing approaches accelerate the sampling process in generative
modeling-based visuomotor policies by adapting acceleration techniques
originally developed for image generation. Despite this progress, a major
distinction remains: image generation typically involves producing independent
samples without temporal dependencies, whereas robotic manipulation involves
generating time-series action trajectories that require continuity and temporal
coherence. To effectively exploit temporal information in robotic manipulation,
we propose FreqPolicy, a novel approach that first imposes frequency
consistency constraints on flow-based visuomotor policies. Our work enables the
action model to capture temporal structure effectively while supporting
efficient, high-quality one-step action generation. We introduce a frequency
consistency constraint that enforces alignment of frequency-domain action
features across different timesteps along the flow, thereby promoting
convergence of one-step action generation toward the target distribution. In
addition, we design an adaptive consistency loss to capture structural temporal
variations inherent in robotic manipulation tasks. We assess FreqPolicy on 53
tasks across 3 simulation benchmarks, proving its superiority over existing
one-step action generators. We further integrate FreqPolicy into the
vision-language-action (VLA) model and achieve acceleration without performance
degradation on the 40 tasks of Libero. Besides, we show efficiency and
effectiveness in real-world robotic scenarios with an inference frequency
93.5Hz. The code will be publicly available.

</details>


### [19] [MoRE: Mixture of Residual Experts for Humanoid Lifelike Gaits Learning on Complex Terrains](https://arxiv.org/abs/2506.08840)
*Dewei Wang,Xinmiao Wang,Xinzhe Liu,Jiyuan Shi,Yingnan Zhao,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: 提出了一种基于混合潜在残差专家和多判别器的RL框架，用于训练能够在复杂地形中以可控、逼真步态行走的人形机器人。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅适用于平坦地形且依赖本体感知，无法在复杂地形中实现逼真步态。

Method: 采用两阶段训练流程，先通过深度相机训练策略适应复杂地形，再实现步态切换；设计了步态奖励以调整行为。

Result: 仿真和实际实验表明，该框架在复杂地形中表现优异，并能无缝切换多种步态。

Conclusion: 该框架显著提升了人形机器人在复杂地形中的行走能力和步态逼真度。

Abstract: Humanoid robots have demonstrated robust locomotion capabilities using
Reinforcement Learning (RL)-based approaches. Further, to obtain human-like
behaviors, existing methods integrate human motion-tracking or motion prior in
the RL framework. However, these methods are limited in flat terrains with
proprioception only, restricting their abilities to traverse challenging
terrains with human-like gaits. In this work, we propose a novel framework
using a mixture of latent residual experts with multi-discriminators to train
an RL policy, which is capable of traversing complex terrains in controllable
lifelike gaits with exteroception. Our two-stage training pipeline first
teaches the policy to traverse complex terrains using a depth camera, and then
enables gait-commanded switching between human-like gait patterns. We also
design gait rewards to adjust human-like behaviors like robot base height.
Simulation and real-world experiments demonstrate that our framework exhibits
exceptional performance in traversing complex terrains, and achieves seamless
transitions between multiple human-like gait patterns.

</details>


### [20] [Deploying SICNav in the Field: Safe and Interactive Crowd Navigation using MPC and Bilevel Optimization](https://arxiv.org/abs/2506.08851)
*Sepehr Samavi,Garvish Bhutani,Florian Shkurti,Angela P. Schoellig*

Main category: cs.RO

TL;DR: SICNav是一种双层MPC框架，将预测和规划结合为一个优化问题，显式建模人机交互，解决了传统方法因忽略闭环交互而导致的机器人卡顿问题。


<details>
  <summary>Details</summary>
Motivation: 在拥挤环境中安全高效导航是机器人服务任务（如送餐或自主轮椅移动）的关键挑战，传统方法因忽略人机闭环交互而存在缺陷。

Method: 提出SICNav方法，通过双层MPC框架将预测与规划结合为一个优化问题，显式建模人机交互。

Result: 在室内外环境中进行了近7公里、两小时的自主导航测试，系统运行良好。

Conclusion: SICNav通过显式建模交互，有效解决了传统方法在拥挤环境中的导航问题。

Abstract: Safe and efficient navigation in crowded environments remains a critical
challenge for robots that provide a variety of service tasks such as food
delivery or autonomous wheelchair mobility. Classical robot crowd navigation
methods decouple human motion prediction from robot motion planning, which
neglects the closed-loop interactions between humans and robots. This lack of a
model for human reactions to the robot plan (e.g. moving out of the way) can
cause the robot to get stuck. Our proposed Safe and Interactive Crowd
Navigation (SICNav) method is a bilevel Model Predictive Control (MPC)
framework that combines prediction and planning into one optimization problem,
explicitly modeling interactions among agents. In this paper, we present a
systems overview of the crowd navigation platform we use to deploy SICNav in
previously unseen indoor and outdoor environments. We provide a preliminary
analysis of the system's operation over the course of nearly 7 km of autonomous
navigation over two hours in both indoor and outdoor environments.

</details>


### [21] [Fast Estimation of Globally Optimal Independent Contact Regions for Robust Grasping and Manipulation](https://arxiv.org/abs/2506.08856)
*Jonathan P. King,Harnoor Ahluwalia,Michael Zhang,Nancy S. Pollard*

Main category: cs.RO

TL;DR: 提出了一种快速算法，用于计算全局最优的独立接触区域（ICRs），该算法基于增量n维Delaunay三角剖分，适用于实时规划。


<details>
  <summary>Details</summary>
Motivation: ICRs的位置可以为抓取和操作规划、学习及策略迁移提供指导，但现有方法计算成本高，限制了其应用。

Method: 采用分治法，基于增量n维Delaunay三角剖分，计算具有有界次优性的ICRs。

Result: 实验显示，该方法在速度和性能上显著优于现有方法，速度提升达100倍以上。

Conclusion: 该方法为实时规划提供了高效工具，并为进一步扩展到3D实现奠定了基础。

Abstract: This work presents a fast anytime algorithm for computing globally optimal
independent contact regions (ICRs). ICRs are regions such that one contact
within each region enables a valid grasp. Locations of ICRs can provide
guidance for grasp and manipulation planning, learning, and policy transfer.
However, ICRs for modern applications have been little explored, in part due to
the expense of computing them, as they have a search space exponential in the
number of contacts. We present a divide and conquer algorithm based on
incremental n-dimensional Delaunay triangulation that produces results with
bounded suboptimality in times sufficient for real-time planning. This paper
presents the base algorithm for grasps where contacts lie within a plane. Our
experiments show substantial benefits over competing grasp quality metrics and
speedups of 100X and more for competing approaches to computing ICRs. We
explore robustness of a policy guided by ICRs and outline a path to general 3D
implementation. Code will be released on publication to facilitate further
development and applications.

</details>


### [22] [MOMAV: A highly symmetrical fully-actuated multirotor drone using optimizing control allocation](https://arxiv.org/abs/2506.08868)
*Marco Ruggia*

Main category: cs.RO

TL;DR: MOMAV是一种全驱动、高度对称的多旋翼无人机，通过独特的八面体转子臂设计和主动旋转臂实现高效飞行，采用SQP控制算法，飞行测试显示其位置和姿态误差极低。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够独立控制位置和方向的高效全驱动无人机，解决传统无人机在飞行效率和控制灵活性上的限制。

Method: 采用八面体排列的六转子臂设计，每个臂可主动旋转，配备滑环实现连续旋转，并使用基于SQP的控制分配算法计算油门和臂角设定点。

Result: 飞行测试显示，MOMAV在位置和姿态控制上表现出色，位置误差平均6.6mm，姿态误差平均2.1度，标准差分别为3.0mm和1.0度。

Conclusion: MOMAV通过创新的设计和控制算法，实现了高效且精确的全驱动飞行，为无人机技术提供了新的可能性。

Abstract: MOMAV (Marco's Omnidirectional Micro Aerial Vehicle) is a multirotor drone
that is fully actuated, meaning it can control its orientation independently of
its position. MOMAV is also highly symmetrical, making its flight efficiency
largely unaffected by its current orientation. These characteristics are
achieved by a novel drone design where six rotor arms align with the vertices
of an octahedron, and where each arm can actively rotate along its long axis.
Various standout features of MOMAV are presented: The high flight efficiency
compared to arm configuration of other fully-actuated drones, the design of an
original rotating arm assembly featuring slip-rings used to enable continuous
arm rotation, and a novel control allocation algorithm based on sequential
quadratic programming (SQP) used to calculate throttle and arm-angle setpoints
in flight. Flight tests have shown that MOMAV is able to achieve remarkably low
mean position/orientation errors of 6.6mm, 2.1{\deg} ({\sigma}: 3.0mm,
1.0{\deg}) when sweeping position setpoints, and 11.8mm, 3.3{\deg} ({\sigma}:
8.6mm, 2.0{\deg}) when sweeping orientation setpoints.

</details>


### [23] [Human-Robot Teaming Field Deployments: A Comparison Between Verbal and Non-verbal Communication](https://arxiv.org/abs/2506.08890)
*Tauhid Tanjim,Promise Ekpo,Huajie Cao,Jonathan St. George,Kevin Ching,Hee Rin Lee,Angelique Taylor*

Main category: cs.RO

TL;DR: 研究比较了机器人急救车（RCC）的语音与非语音通信方式对医护人员工作负荷和态度的影响，发现语音通信显著降低心理需求和努力。


<details>
  <summary>Details</summary>
Motivation: 医护人员在急救中快速获取医疗用品面临挑战，机器人急救车可能提供帮助，但通信方式的有效性尚未充分研究。

Method: 通过对比实验，比较RCC的语音与非语音通信方式与传统急救车在复苏场景中的表现。

Result: 语音通信显著降低心理需求和努力，尽管与机器人合作时挫折感略有增加。

Conclusion: 研究结果为高风险环境中人机协作提供了重要启示。

Abstract: Healthcare workers (HCWs) encounter challenges in hospitals, such as
retrieving medical supplies quickly from crash carts, which could potentially
result in medical errors and delays in patient care. Robotic crash carts (RCCs)
have shown promise in assisting healthcare teams during medical tasks through
guided object searches and task reminders. Limited exploration has been done to
determine what communication modalities are most effective and least disruptive
to patient care in real-world settings. To address this gap, we conducted a
between-subjects experiment comparing the RCC's verbal and non-verbal
communication of object search with a standard crash cart in resuscitation
scenarios to understand the impact of robot communication on workload and
attitudes toward using robots in the workplace. Our findings indicate that
verbal communication significantly reduced mental demand and effort compared to
visual cues and with a traditional crash cart. Although frustration levels were
slightly higher during collaborations with the robot compared to a traditional
cart, these research insights provide valuable implications for human-robot
teamwork in high-stakes environments.

</details>


### [24] [CLONE: Closed-Loop Whole-Body Humanoid Teleoperation for Long-Horizon Tasks](https://arxiv.org/abs/2506.08931)
*Yixuan Li,Yutang Lin,Jieming Cui,Tengyu Liu,Wei Liang,Yixin Zhu,Siyuan Huang*

Main category: cs.RO

TL;DR: CLONE是一种基于MoE的远程操作系统，通过闭环误差校正实现高保真全身远程操作，解决了现有系统在协调性和漂移问题上的限制。


<details>
  <summary>Details</summary>
Motivation: 当前远程操作系统存在上下半身控制分离和开环操作导致的漂移问题，限制了自然协调和长时间精确操作。

Method: 采用MoE框架和闭环误差校正技术，仅需MR头显的手部和头部跟踪数据，实现长时间低漂移的全身远程操作。

Result: CLONE系统在长距离轨迹上保持最小位置漂移，支持复杂协调动作（如从地面拾取物体），显著提升了操作保真度。

Conclusion: CLONE为长时间全身人形远程操作设立了新标杆，适用于复杂人形-场景交互任务。

Abstract: Humanoid teleoperation plays a vital role in demonstrating and collecting
data for complex humanoid-scene interactions. However, current teleoperation
systems face critical limitations: they decouple upper- and lower-body control
to maintain stability, restricting natural coordination, and operate open-loop
without real-time position feedback, leading to accumulated drift. The
fundamental challenge is achieving precise, coordinated whole-body
teleoperation over extended durations while maintaining accurate global
positioning. Here we show that an MoE-based teleoperation system, CLONE, with
closed-loop error correction enables unprecedented whole-body teleoperation
fidelity, maintaining minimal positional drift over long-range trajectories
using only head and hand tracking from an MR headset. Unlike previous methods
that either sacrifice coordination for stability or suffer from unbounded
drift, CLONE learns diverse motion skills while preventing tracking error
accumulation through real-time feedback, enabling complex coordinated movements
such as ``picking up objects from the ground.'' These results establish a new
milestone for whole-body humanoid teleoperation for long-horizon humanoid-scene
interaction tasks.

</details>


### [25] [AI Magnetic Levitation (Maglev) Conveyor for Automated Assembly Production](https://arxiv.org/abs/2506.08039)
*Ray Wai Man Kong*

Main category: cs.RO

TL;DR: AI Maglev Conveyor系统结合磁悬浮技术和人工智能，提升现代制造业的效率、速度和精度，减少维护成本，优化资源使用。


<details>
  <summary>Details</summary>
Motivation: 现代制造业对效率、速度和精度的需求日益增长，传统系统存在摩擦和维护成本高的问题。

Method: 结合磁悬浮技术和AI，实现无摩擦运输、实时监控和自适应控制，优化路由和吞吐量。

Result: 系统运行平稳、静音，适应多样化产品，减少周期时间，提高生产效率，降低成本。

Conclusion: AI Maglev Conveyor系统为制造业提供了高效、灵活且经济的解决方案，适用于多种行业。

Abstract: Efficiency, speed, and precision are essential in modern manufacturing. AI
Maglev Conveyor system, combining magnetic levitation (maglev) technology with
artificial intelligence (AI), revolutionizes automated production processes.
This system reduces maintenance costs and downtime by eliminating friction,
enhancing operational efficiency. It transports goods swiftly with minimal
energy consumption, optimizing resource use and supporting sustainability. AI
integration enables real-time monitoring and adaptive control, allowing
businesses to respond to production demand fluctuations and streamline supply
chain operations.
  The AI Maglev Conveyor offers smooth, silent operation, accommodating diverse
product types and sizes for flexible manufacturing without extensive
reconfiguration. AI algorithms optimize routing, reduce cycle times, and
improve throughput, creating an agile production line adaptable to market
changes.
  This applied research paper introduces the Maglev Conveyor system, featuring
an electromagnetic controller and multiple movers to enhance automation. It
offers cost savings as an alternative to setups using six-axis robots or linear
motors, with precise adjustments for robotic arm loading. Operating at high
speeds minimizes treatment time for delicate components while maintaining
precision. Its adaptable design accommodates various materials, facilitating
integration of processing stations alongside electronic product assembly.
Positioned between linear-axis and robotic systems in cost, the Maglev Conveyor
is ideal for flat parts requiring minimal travel, transforming production
efficiency across industries. It explores its technical advantages,
flexibility, cost reductions, and overall benefits.

</details>


### [26] [UAVs Meet Agentic AI: A Multidomain Survey of Autonomous Aerial Intelligence and Agentic UAVs](https://arxiv.org/abs/2506.08045)
*Ranjan Sapkota,Konstantinos I. Roumeliotis,Manoj Karkee*

Main category: cs.RO

TL;DR: Agentic UAVs integrate advanced AI for autonomous operation in complex environments, surpassing traditional UAVs with goal-driven behavior and contextual reasoning. The paper covers their architecture, applications, challenges, and future directions.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive understanding of Agentic UAVs, highlighting their advancements over traditional UAVs and their potential societal impact.

Method: A detailed comparative analysis of architectural components, enabling technologies, and application domains, along with challenges and emerging solutions.

Result: Identifies seven high-impact application domains and key challenges, proposing solutions and a future roadmap for Agentic UAVs.

Conclusion: The study establishes a framework for the future development and governance of Agentic UAVs, emphasizing their broad societal value.

Abstract: Agentic UAVs represent a new frontier in autonomous aerial intelligence,
integrating perception, decision-making, memory, and collaborative planning to
operate adaptively in complex, real-world environments. Driven by recent
advances in Agentic AI, these systems surpass traditional UAVs by exhibiting
goal-driven behavior, contextual reasoning, and interactive autonomy. We
provide a comprehensive foundation for understanding the architectural
components and enabling technologies that distinguish Agentic UAVs from
traditional autonomous UAVs. Furthermore, a detailed comparative analysis
highlights advancements in autonomy with AI agents, learning, and mission
flexibility. This study explores seven high-impact application domains
precision agriculture, construction & mining, disaster response, environmental
monitoring, infrastructure inspection, logistics, security, and wildlife
conservation, illustrating the broad societal value of agentic aerial
intelligence. Furthermore, we identify key challenges in technical constraints,
regulatory limitations, and data-model reliability, and we present emerging
solutions across hardware innovation, learning architectures, and human-AI
interaction. Finally, a future roadmap is proposed, outlining pathways toward
self-evolving aerial ecosystems, system-level collaboration, and sustainable,
equitable deployments. This survey establishes a foundational framework for the
future development, deployment, and governance of agentic aerial systems
(Agentic UAVs) across diverse societal and industrial domains.

</details>


### [27] [Adaptive Per-Tree Canopy Volume Estimation Using Mobile LiDAR in Structured and Unstructured Orchards](https://arxiv.org/abs/2506.08061)
*Ali Abedi,Fernando Cladera,Mohsen Farajijalal,Reza Ehsani*

Main category: cs.RO

TL;DR: 提出了一种基于移动LiDAR数据的实时系统，用于估计单棵树冠体积，适用于结构多样的果园环境。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态扫描或假设果园结构均匀，无法适应多样化的田间几何形状。

Method: 结合LiDAR-惯性里程计、自适应分割和几何重建的集成流程，采用DBSCAN和谱聚类的混合聚类策略。

Result: 在两种商业果园中测试，成功率为93%（开心果）和80%（杏仁），与无人机估计结果一致。

Conclusion: 该系统为结构多样的果园环境提供了可扩展、非侵入式的树木监测方案。

Abstract: We present a real-time system for per-tree canopy volume estimation using
mobile LiDAR data collected during routine robotic navigation. Unlike prior
approaches that rely on static scans or assume uniform orchard structures, our
method adapts to varying field geometries via an integrated pipeline of
LiDAR-inertial odometry, adaptive segmentation, and geometric reconstruction.
We evaluate the system across two commercial orchards, one pistachio orchard
with regular spacing and one almond orchard with dense, overlapping crowns. A
hybrid clustering strategy combining DBSCAN and spectral clustering enables
robust per-tree segmentation, achieving 93% success in pistachio and 80% in
almond, with strong agreement to drone derived canopy volume estimates. This
work advances scalable, non-intrusive tree monitoring for structurally diverse
orchard environments.

</details>


### [28] [Ego-centric Learning of Communicative World Models for Autonomous Driving](https://arxiv.org/abs/2506.08149)
*Hang Wang,Dechen Gao,Junshan Zhang*

Main category: cs.RO

TL;DR: 论文提出了一种名为CALL的多智能体强化学习方法，通过生成式AI和世界模型的潜在表示，解决了部分可观测性和非平稳性问题，同时减少了通信开销。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）在复杂高维环境中（如自动驾驶）面临部分可观测性和非平稳性问题，传统信息共享方法存在通信开销大和可扩展性问题。

Method: CALL方法利用世界模型的潜在表示，将状态和意图编码为低维表示，通过轻量级通信共享信息，并结合自我中心学习提升预测和规划能力。

Result: 实验在CARLA平台上进行，证明了CALL在局部轨迹规划任务中的性能提升，并分析了信息共享对预测准确性和性能差距的影响。

Conclusion: CALL通过轻量级信息共享和潜在表示学习，有效解决了MARL中的挑战，并在复杂任务中表现出优越性能。

Abstract: We study multi-agent reinforcement learning (MARL) for tasks in complex
high-dimensional environments, such as autonomous driving. MARL is known to
suffer from the \textit{partial observability} and \textit{non-stationarity}
issues. To tackle these challenges, information sharing is often employed,
which however faces major hurdles in practice, including overwhelming
communication overhead and scalability concerns. By making use of generative AI
embodied in world model together with its latent representation, we develop
{\it CALL}, \underline{C}ommunic\underline{a}tive Wor\underline{l}d
Mode\underline{l}, for MARL, where 1) each agent first learns its world model
that encodes its state and intention into low-dimensional latent representation
with smaller memory footprint, which can be shared with other agents of
interest via lightweight communication; and 2) each agent carries out
ego-centric learning while exploiting lightweight information sharing to enrich
her world model, and then exploits its generalization capacity to improve
prediction for better planning. We characterize the gain on the prediction
accuracy from the information sharing and its impact on performance gap.
Extensive experiments are carried out on the challenging local trajectory
planning tasks in the CARLA platform to demonstrate the performance gains of
using \textit{CALL}.

</details>


### [29] [TensorTouch: Calibration of Tactile Sensors for High Resolution Stress Tensor and Deformation for Dexterous Manipulation](https://arxiv.org/abs/2506.08291)
*Won Kyung Do,Matthew Strong,Aiden Swann,Boshu Lei,Monroe Kennedy III*

Main category: cs.RO

TL;DR: TensorTouch通过结合有限元分析和深度学习，从光学触觉传感器中提取全面的接触信息，解决了多触点操作的挑战。


<details>
  <summary>Details</summary>
Motivation: 高级灵巧操作（如从地面捏硬币或操作交织物体）需要高分辨率触觉感知，但现有光学触觉传感器的原始图像缺乏可解释性和跨传感器可转移性。

Method: TensorTouch框架整合有限元分析和深度学习，提取应力张量、变形场和力分布等接触信息。

Result: 实验验证显示，TensorTouch在选择性抓取两根绳子中的一根时达到90%的成功率，并支持大变形操作。

Conclusion: TensorTouch为机器人系统提供了以前无法实现的丰富接触操作能力。

Abstract: Advanced dexterous manipulation involving multiple simultaneous contacts
across different surfaces, like pinching coins from ground or manipulating
intertwined objects, remains challenging for robotic systems. Such tasks exceed
the capabilities of vision and proprioception alone, requiring high-resolution
tactile sensing with calibrated physical metrics. Raw optical tactile sensor
images, while information-rich, lack interpretability and cross-sensor
transferability, limiting their real-world utility. TensorTouch addresses this
challenge by integrating finite element analysis with deep learning to extract
comprehensive contact information from optical tactile sensors, including
stress tensors, deformation fields, and force distributions at pixel-level
resolution. The TensorTouch framework achieves sub-millimeter position accuracy
and precise force estimation while supporting large sensor deformations crucial
for manipulating soft objects. Experimental validation demonstrates 90% success
in selectively grasping one of two strings based on detected motion, enabling
new contact-rich manipulation capabilities previously inaccessible to robotic
systems.

</details>


### [30] [HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation](https://arxiv.org/abs/2506.08296)
*Hongjun Wu,Heng Zhang,Pengsong Zhang,Jin Wang,Cong Wang*

Main category: cs.RO

TL;DR: HiBerNAC是一种分层脑模拟机器人神经代理集体，结合多模态VLA规划和神经启发的反射机制，显著提升了复杂机器人操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态VLA模型在复杂操作任务中存在局限性，如持久上下文记忆不足、多代理协调困难等，HiBerNAC旨在解决这些问题。

Method: 结合多模态VLA规划和神经启发的反射机制，采用分散式多代理协作，实现动态任务规划和实时执行。

Result: 相比现有VLA模型，HiBerNAC将长时任务完成时间减少23%，并在多路径任务中实现12-31%的成功率。

Conclusion: HiBerNAC通过神经启发机制和多代理协作，为复杂机器人操作任务提供了高效解决方案，并展示了生物认知与机器人学习的潜在联系。

Abstract: Recent advances in multimodal vision-language-action (VLA) models have
revolutionized traditional robot learning, enabling systems to interpret
vision, language, and action in unified frameworks for complex task planning.
However, mastering complex manipulation tasks remains an open challenge,
constrained by limitations in persistent contextual memory, multi-agent
coordination under uncertainty, and dynamic long-horizon planning across
variable sequences. To address this challenge, we propose \textbf{HiBerNAC}, a
\textbf{Hi}erarchical \textbf{B}rain-\textbf{e}mulated \textbf{r}obotic
\textbf{N}eural \textbf{A}gent \textbf{C}ollective, inspired by breakthroughs
in neuroscience, particularly in neural circuit mechanisms and hierarchical
decision-making. Our framework combines: (1) multimodal VLA planning and
reasoning with (2) neuro-inspired reflection and multi-agent mechanisms,
specifically designed for complex robotic manipulation tasks. By leveraging
neuro-inspired functional modules with decentralized multi-agent collaboration,
our approach enables robust and enhanced real-time execution of complex
manipulation tasks. In addition, the agentic system exhibits scalable
collective intelligence via dynamic agent specialization, adapting its
coordination strategy to variable task horizons and complexity. Through
extensive experiments on complex manipulation tasks compared with
state-of-the-art VLA models, we demonstrate that \textbf{HiBerNAC} reduces
average long-horizon task completion time by 23\%, and achieves non-zero
success rates (12\textendash 31\%) on multi-path tasks where prior
state-of-the-art VLA models consistently fail. These results provide indicative
evidence for bridging biological cognition and robotic learning mechanisms.

</details>


### [31] [Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning](https://arxiv.org/abs/2506.08344)
*Neşet Ünver Akmandor,Sarvesh Prajapati,Mark Zolotas,Taşkın Padır*

Main category: cs.RO

TL;DR: 提出了一种名为Re4MPC的多模型运动规划方法，结合非线性模型预测控制（NMPC）和深度强化学习（DRL），显著提高了计算效率和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统的高自由度机器人运动规划方法计算成本高，难以适用于实际场景。

Method: 通过DRL框架学习反应性决策策略，动态选择NMPC的模型、成本和约束条件。

Result: 实验表明，Re4MPC比传统NMPC更高效且成功率更高。

Conclusion: Re4MPC为复杂机器人运动规划提供了一种高效且可靠的解决方案。

Abstract: Traditional motion planning methods for robots with many degrees-of-freedom,
such as mobile manipulators, are often computationally prohibitive for
real-world settings. In this paper, we propose a novel multi-model motion
planning pipeline, termed Re4MPC, which computes trajectories using Nonlinear
Model Predictive Control (NMPC). Re4MPC generates trajectories in a
computationally efficient manner by reactively selecting the model, cost, and
constraints of the NMPC problem depending on the complexity of the task and
robot state. The policy for this reactive decision-making is learned via a Deep
Reinforcement Learning (DRL) framework. We introduce a mathematical formulation
to integrate NMPC into this DRL framework. To validate our methodology and
design choices, we evaluate DRL training and test outcomes in a physics-based
simulation involving a mobile manipulator. Experimental results demonstrate
that Re4MPC is more computationally efficient and achieves higher success rates
in reaching end-effector goals than the NMPC baseline, which computes
whole-body trajectories without our learning mechanism.

</details>


### [32] [Periodic Bipedal Gait Learning Using Reward Composition Based on a Novel Gait Planner for Humanoid Robots](https://arxiv.org/abs/2506.08416)
*Bolin Li,Linwei Sun,Xuecong Huang,Yuzhi Jiang,Lijun Zhu*

Main category: cs.RO

TL;DR: 提出了一种基于奖励组合的周期性双足步态学习方法，结合实时步态规划器，用于人形机器人。


<details>
  <summary>Details</summary>
Motivation: 通过结合动态规划和强化学习，提高双足步态的周期性和性能，减少学习时间。

Method: 1. 设计新型步态规划器，将3D模型解耦为2D模型并用混合倒立摆（H-LIP）规划轨迹；2. 在强化学习框架中设计三种奖励函数，组合成奖励组合。

Result: 实验展示了步态设计实例和性能对比，验证了方法的有效性。

Conclusion: 该方法通过奖励组合和实时规划器，显著提升了双足步态的学习效率和运动性能。

Abstract: This paper presents a periodic bipedal gait learning method using reward
composition, integrated with a real-time gait planner for humanoid robots.
First, we introduce a novel gait planner that incorporates dynamics to design
the desired joint trajectory. In the gait design process, the 3D robot model is
decoupled into two 2D models, which are then approximated as hybrid inverted
pendulums (H-LIP) for trajectory planning. The gait planner operates in
parallel in real time within the robot's learning environment. Second, based on
this gait planner, we design three effective reward functions within a
reinforcement learning framework, forming a reward composition to achieve
periodic bipedal gait. This reward composition reduces the robot's learning
time and enhances locomotion performance. Finally, a gait design example and
performance comparison are presented to demonstrate the effectiveness of the
proposed method.

</details>


### [33] [Attention-based Learning for 3D Informative Path Planning](https://arxiv.org/abs/2506.08434)
*Rui Zhao,Xingjian Zhang,Yuhong Cao,Yizhuo Wang,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 提出一种基于注意力的深度强化学习方法，用于解决3D空间中的自适应信息路径规划问题，通过动态调整无人机位置以优化感知覆盖和精度。


<details>
  <summary>Details</summary>
Motivation: 解决自适应信息路径规划问题，无人机需在时间和距离约束下最大化信息收集，同时根据新获取的传感器数据动态调整路径。

Method: 利用注意力机制捕捉全局空间依赖关系，构建上下文信念表示，指导优化短期和长期搜索目标的序列移动决策。

Result: 在约束预算内显著降低环境不确定性，有效平衡探索与利用，且模型能泛化到不同规模的环境。

Conclusion: 该方法在多种实际应用中具有潜力，尤其在需要动态路径规划和环境感知的场景中表现优异。

Abstract: In this work, we propose an attention-based deep reinforcement learning
approach to address the adaptive informative path planning (IPP) problem in 3D
space, where an aerial robot equipped with a downward-facing sensor must
dynamically adjust its 3D position to balance sensing footprint and accuracy,
and finally obtain a high-quality belief of an underlying field of interest
over a given domain (e.g., presence of specific plants, hazardous gas,
geological structures, etc.). In adaptive IPP tasks, the agent is tasked with
maximizing information collected under time/distance constraints, continuously
adapting its path based on newly acquired sensor data. To this end, we leverage
attention mechanisms for their strong ability to capture global spatial
dependencies across large action spaces, allowing the agent to learn an
implicit estimation of environmental transitions. Our model builds a contextual
belief representation over the entire domain, guiding sequential movement
decisions that optimize both short- and long-term search objectives.
Comparative evaluations against state-of-the-art planners demonstrate that our
approach significantly reduces environmental uncertainty within constrained
budgets, thus allowing the agent to effectively balance exploration and
exploitation. We further show our model generalizes well to environments of
varying sizes, highlighting its potential for many real-world applications.

</details>


### [34] [TGRPO :Fine-tuning Vision-Language-Action Model via Trajectory-wise Group Relative Policy Optimization](https://arxiv.org/abs/2506.08440)
*Zengjue Chen,Runliang Niu,He Kong,Qi Wang*

Main category: cs.RO

TL;DR: 论文提出了一种名为TGRPO的方法，通过结合步级和轨迹级优势信号，改进了GRPO的组级优势估计，适用于VLA模型的在线强化学习训练。实验表明，TGRPO在多个任务中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在新环境中仍需任务特定的微调，且依赖静态轨迹数据集，无法利用实时执行反馈。强化学习（RL）提供了一种闭环交互的替代方案。

Method: 提出TGRPO方法，融合步级和轨迹级优势信号，改进GRPO的组级优势估计，适用于VLA模型的在线强化学习训练。

Result: 在十个操作任务上，TGRPO表现优于基线方法，生成更鲁棒和高效的政策。

Conclusion: TGRPO通过改进优势估计，为VLA模型的在线强化学习训练提供了有效方法，实验验证了其优越性。

Abstract: Recent advances in Vision-Language-Action (VLA) model have demonstrated
strong generalization capabilities across diverse scenes, tasks, and robotic
platforms when pretrained at large-scale datasets. However, these models still
require task-specific fine-tuning in novel environments, a process that relies
almost exclusively on supervised fine-tuning (SFT) using static trajectory
datasets. Such approaches neither allow robot to interact with environment nor
do they leverage feedback from live execution. Also, their success is
critically dependent on the size and quality of the collected trajectories.
Reinforcement learning (RL) offers a promising alternative by enabling
closed-loop interaction and aligning learned policies directly with task
objectives. In this work, we draw inspiration from the ideas of GRPO and
propose the Trajectory-wise Group Relative Policy Optimization (TGRPO) method.
By fusing step-level and trajectory-level advantage signals, this method
improves GRPO's group-level advantage estimation, thereby making the algorithm
more suitable for online reinforcement learning training of VLA. Experimental
results on ten manipulation tasks from the libero-object benchmark demonstrate
that TGRPO consistently outperforms various baseline methods, capable of
generating more robust and efficient policies across multiple tested scenarios.
Our source codes are available at: https://github.com/hahans/TGRPO

</details>


### [35] [Diffusion Models for Safety Validation of Autonomous Driving Systems](https://arxiv.org/abs/2506.08459)
*Juanran Wang,Marc R. Schlichting,Harrison Delecki,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 使用去噪扩散模型生成自动驾驶系统的潜在故障案例，无需外部数据集，适用于交通路口的安全验证。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的安全验证成本高且风险大，潜在故障案例稀少且多样，需要一种高效的方法生成故障案例。

Method: 训练去噪扩散模型，根据初始交通状态生成自动驾驶车辆的潜在故障案例。

Result: 实验表明，该模型能在多种场景下生成真实的故障样本，并捕捉多种潜在故障。

Conclusion: 该模型无需外部数据集，计算资源需求低，适用于交通路口的安全验证。

Abstract: Safety validation of autonomous driving systems is extremely challenging due
to the high risks and costs of real-world testing as well as the rarity and
diversity of potential failures. To address these challenges, we train a
denoising diffusion model to generate potential failure cases of an autonomous
vehicle given any initial traffic state. Experiments on a four-way intersection
problem show that in a variety of scenarios, the diffusion model can generate
realistic failure samples while capturing a wide variety of potential failures.
Our model does not require any external training dataset, can perform training
and inference with modest computing resources, and does not assume any prior
knowledge of the system under test, with applicability to safety validation for
traffic intersections.

</details>


### [36] [Noise Analysis and Hierarchical Adaptive Body State Estimator For Biped Robot Walking With ESVC Foot](https://arxiv.org/abs/2506.08578)
*Boyang Chen,Xizhe Zang,Chao Song,Yue Zhang,Xuehe Zhang,Jie Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种针对ESVC脚双足机器人的分层自适应状态估计器，通过噪声分析和回归模型改进状态估计精度和收敛速度。


<details>
  <summary>Details</summary>
Motivation: ESVC脚虽提升机器人行走能效，但因支撑腿倾斜导致接触模型误差放大，状态估计更具挑战性。

Method: 1. 通过实验分析ESVC脚对噪声的影响，建立噪声-时间回归模型；2. 提出两阶段分层状态估计器（预估计和后估计），结合数据融合和EKF。

Result: 实验表明，该估计器比EKF和自适应EKF精度更高，且在变化噪声条件下收敛更快。

Conclusion: 分层自适应状态估计器有效解决了ESVC脚机器人的状态估计问题，提升了性能和适应性。

Abstract: The ESVC(Ellipse-based Segmental Varying Curvature) foot, a robot foot design
inspired by the rollover shape of the human foot, significantly enhances the
energy efficiency of the robot walking gait. However, due to the tilt of the
supporting leg, the error of the contact model are amplified, making robot
state estimation more challenging. Therefore, this paper focuses on the noise
analysis and state estimation for robot walking with the ESVC foot. First,
through physical robot experiments, we investigate the effect of the ESVC foot
on robot measurement noise and process noise. and a noise-time regression model
using sliding window strategy is developed. Then, a hierarchical adaptive state
estimator for biped robots with the ESVC foot is proposed. The state estimator
consists of two stages: pre-estimation and post-estimation. In the
pre-estimation stage, a data fusion-based estimation is employed to process the
sensory data. During post-estimation, the acceleration of center of mass is
first estimated, and then the noise covariance matrices are adjusted based on
the regression model. Following that, an EKF(Extended Kalman Filter) based
approach is applied to estimate the centroid state during robot walking.
Physical experiments demonstrate that the proposed adaptive state estimator for
biped robot walking with the ESVC foot not only provides higher precision than
both EKF and Adaptive EKF, but also converges faster under varying noise
conditions.

</details>


### [37] [Deep Reinforcement Learning-Based Motion Planning and PDE Control for Flexible Manipulators](https://arxiv.org/abs/2506.08639)
*Amir Hossein Barjini,Seyed Adel Alizadeh Kolagar,Sadeq Yaqubi,Jouni Mattila*

Main category: cs.RO

TL;DR: 本文提出了一种结合深度强化学习（DRL）和非线性偏微分方程（PDE）控制器的柔性机械臂运动规划与控制框架，通过优化轨迹显著减少振动。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅关注控制，忽略了期望轨迹对端点振动的影响，因此需要一种更全面的方法。

Method: 使用软演员-评论家（SAC）算法训练的DRL运动规划器生成优化轨迹，结合PDE非线性控制器计算扭矩并确保闭环稳定性。

Result: 仿真和实验验证了该方法在振动抑制和跟踪精度上优于传统方法。

Conclusion: 结合学习型运动规划和模型控制可显著提升柔性机械臂的精度和稳定性。

Abstract: This article presents a motion planning and control framework for flexible
robotic manipulators, integrating deep reinforcement learning (DRL) with a
nonlinear partial differential equation (PDE) controller. Unlike conventional
approaches that focus solely on control, we demonstrate that the desired
trajectory significantly influences endpoint vibrations. To address this, a DRL
motion planner, trained using the soft actor-critic (SAC) algorithm, generates
optimized trajectories that inherently minimize vibrations. The PDE nonlinear
controller then computes the required torques to track the planned trajectory
while ensuring closed-loop stability using Lyapunov analysis. The proposed
methodology is validated through both simulations and real-world experiments,
demonstrating superior vibration suppression and tracking accuracy compared to
traditional methods. The results underscore the potential of combining
learning-based motion planning with model-based control for enhancing the
precision and stability of flexible robotic manipulators.

</details>


### [38] [ROS-related Robotic Systems Development with V-model-based Application of MeROS Metamodel](https://arxiv.org/abs/2506.08706)
*Tomasz Winiarski,Jan Kaniuka,Daniel Giełdowski,Jakub Ostrysz,Krystian Radlak,Dmytro Kushnir*

Main category: cs.RO

TL;DR: 本文提出了一种结合ROS和MBSE的方法，通过MeROS和V模型提升机器人系统开发的集成性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统复杂性和安全需求的增加，ROS和MBSE工具的集成不足成为问题，本文旨在填补这一空白。

Method: 提出了一种基于MeROS和V模型的领域特定方法，支持ROS和ROS 2的灵活开发。

Result: 通过HeROS平台的案例研究验证了方法的有效性，增强了系统一致性和可追溯性。

Conclusion: 为ROS项目提供了一种结构化的MBSE实践基础，具有灵活性和扩展性。

Abstract: As robotic systems grow increasingly complex, heterogeneous, and
safety-critical, the need for structured development methodologies becomes
paramount. Although frameworks like the Robot Operating System (ROS) and
Model-Based Systems Engineering (MBSE) offer foundational tools, they often
lack integration when used together. This paper addresses that gap by aligning
the widely recognized V-model development paradigm with the MeROS metamodel
SysML-based modeling language tailored for ROS-based systems.
  We propose a domain-specific methodology that bridges ROS-centric modelling
with systems engineering practices. Our approach formalises the structure,
behaviour, and validation processes of robotic systems using MeROS, while
extending it with a generalized, adaptable V-model compatible with both ROS and
ROS 2. Rather than prescribing a fixed procedure, the approach supports
project-specific flexibility and reuse, offering guidance across all stages of
development.
  The approach is validated through a comprehensive case study on HeROS, a
heterogeneous multi-robot platform comprising manipulators, mobile units, and
dynamic test environments. This example illustrates how the MeROS-compatible
V-model enhances traceability and system consistency while remaining accessible
and extensible for future adaptation. The work contributes a structured,
tool-agnostic foundation for developers and researchers seeking to apply MBSE
practices in ROS-based projects.

</details>


### [39] [PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly](https://arxiv.org/abs/2506.08708)
*Liang Ma,Jiajun Wen,Min Lin,Rongtao Xu,Xiwen Liang,Bingqian Lin,Jun Ma,Yongxin Wang,Ziming Wei,Haokun Lin,Mingfei Han,Meng Cao,Bokui Chen,Ivan Laptev,Xiaodan Liang*

Main category: cs.RO

TL;DR: PhyBlock是一个用于评估视觉语言模型（VLMs）在物理理解和规划能力的渐进式基准测试，通过3D积木组装任务和视觉问答（VQA）任务，揭示了VLMs在高级规划和空间推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在物理现象理解和结构化3D环境中的规划能力有限，需要一种新的评估方法来填补这一空白。

Method: 提出PhyBlock基准测试，包含2600个任务（400个组装任务和2200个VQA任务），评估模型在部分完成、故障诊断和规划鲁棒性三个维度的表现。

Result: 21个先进VLMs的测试结果显示，它们在高级规划和空间推理方面表现不佳，任务复杂度增加时性能显著下降。

Conclusion: PhyBlock为提升具身推理能力提供了统一测试平台，揭示了VLMs在物理问题解决中的关键挑战。

Abstract: While vision-language models (VLMs) have demonstrated promising capabilities
in reasoning and planning for embodied agents, their ability to comprehend
physical phenomena, particularly within structured 3D environments, remains
severely limited. To close this gap, we introduce PhyBlock, a progressive
benchmark designed to assess VLMs on physical understanding and planning
through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level
cognitive hierarchy assembly task alongside targeted Visual Question Answering
(VQA) samples, collectively aimed at evaluating progressive spatial reasoning
and fundamental physical comprehension, including object properties, spatial
relationships, and holistic scene understanding. PhyBlock includes 2600 block
tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three
key dimensions: partial completion, failure diagnosis, and planning robustness.
We benchmark 21 state-of-the-art VLMs, highlighting their strengths and
limitations in physically grounded, multi-step planning. Our empirical findings
indicate that the performance of VLMs exhibits pronounced limitations in
high-level planning and reasoning capabilities, leading to a notable decline in
performance for the growing complexity of the tasks. Error analysis reveals
persistent difficulties in spatial orientation and dependency reasoning.
Surprisingly, chain-of-thought prompting offers minimal improvements,
suggesting spatial tasks heavily rely on intuitive model comprehension. We
position PhyBlock as a unified testbed to advance embodied reasoning, bridging
vision-language understanding and real-world physical problem-solving.

</details>


### [40] [Bayesian Inverse Physics for Neuro-Symbolic Robot Learning](https://arxiv.org/abs/2506.08756)
*Octavio Arriaga,Rebecca Adam,Melvin Laux,Lisa Gutzeit,Marco Ragni,Jan Peters,Frank Kirchner*

Main category: cs.RO

TL;DR: 论文提出了一种结合数据驱动学习和结构化推理的混合神经符号架构，以提高机器人在未知和动态环境中的适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习在机器人应用中存在效率低和可靠性不足的问题，特别是在未知和动态环境中。

Method: 提出了一个框架，结合可微分物理、贝叶斯推理和元学习，将物理符号推理嵌入神经模型中。

Result: 这种架构有望使机器人超越训练数据泛化，适应新任务，并持续扩展知识。

Conclusion: 混合神经符号架构是下一代自主系统的关键，并提供了研究路线图以加速其发展。

Abstract: Real-world robotic applications, from autonomous exploration to assistive
technologies, require adaptive, interpretable, and data-efficient learning
paradigms. While deep learning architectures and foundation models have driven
significant advances in diverse robotic applications, they remain limited in
their ability to operate efficiently and reliably in unknown and dynamic
environments. In this position paper, we critically assess these limitations
and introduce a conceptual framework for combining data-driven learning with
deliberate, structured reasoning. Specifically, we propose leveraging
differentiable physics for efficient world modeling, Bayesian inference for
uncertainty-aware decision-making, and meta-learning for rapid adaptation to
new tasks. By embedding physical symbolic reasoning within neural models,
robots could generalize beyond their training data, reason about novel
situations, and continuously expand their knowledge. We argue that such hybrid
neuro-symbolic architectures are essential for the next generation of
autonomous systems, and to this end, we provide a research roadmap to guide and
accelerate their development.

</details>


### [41] [Towards Biosignals-Free Autonomous Prosthetic Hand Control via Imitation Learning](https://arxiv.org/abs/2506.08795)
*Kaijie Shi,Wanglong Lu,Hanli Zhao,Vinicius Prado da Fonseca,Ting Zou,Xianta Jiang*

Main category: cs.RO

TL;DR: 研究开发了一种基于摄像头和模仿学习的全自主假手控制系统，能够自动抓取和释放物体，减少用户的心理负担。


<details>
  <summary>Details</summary>
Motivation: 传统肌电信号控制方法对用户要求高且繁琐，本研究旨在提供一种更易用的假手控制方案。

Method: 通过模仿学习训练假手控制模型，利用摄像头和人类示范数据实现自主抓取与释放。

Result: 模型仅需少量数据即可实现高成功率，并能泛化到不同用户和未见过的物体。

Conclusion: 该系统显著简化了假手控制，提升了用户体验，具有广泛应用潜力。

Abstract: Limb loss affects millions globally, impairing physical function and reducing
quality of life. Most traditional surface electromyographic (sEMG) and
semi-autonomous methods require users to generate myoelectric signals for each
control, imposing physically and mentally taxing demands. This study aims to
develop a fully autonomous control system that enables a prosthetic hand to
automatically grasp and release objects of various shapes using only a camera
attached to the wrist. By placing the hand near an object, the system will
automatically execute grasping actions with a proper grip force in response to
the hand's movements and the environment. To release the object being grasped,
just naturally place the object close to the table and the system will
automatically open the hand. Such a system would provide individuals with limb
loss with a very easy-to-use prosthetic control interface and greatly reduce
mental effort while using. To achieve this goal, we developed a teleoperation
system to collect human demonstration data for training the prosthetic hand
control model using imitation learning, which mimics the prosthetic hand
actions from human. Through training the model using only a few objects' data
from one single participant, we have shown that the imitation learning
algorithm can achieve high success rates, generalizing to more individuals and
unseen objects with a variation of weights. The demonstrations are available at
\href{https://sites.google.com/view/autonomous-prosthetic-hand}{https://sites.google.com/view/autonomous-prosthetic-hand}

</details>


### [42] [FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency](https://arxiv.org/abs/2506.08822)
*Yifei Su,Ning Liu,Dong Chen,Zhen Zhao,Kun Wu,Meng Li,Zhiyuan Xu,Zhengping Che,Jian Tang*

Main category: cs.RO

TL;DR: FreqPolicy通过频率一致性约束改进基于生成模型的视觉运动策略，实现高效的一步动作生成，并在仿真和实际机器人任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 生成模型在机器人操作中因能建模多模态动作分布而被广泛应用，但其多步采样的高推理成本限制了实时性。现有方法虽加速采样，但忽视了动作轨迹的时间连续性。

Method: 提出FreqPolicy，通过频率一致性约束和自适应一致性损失，使动作模型有效捕捉时间结构，支持高效高质量的一步动作生成。

Result: 在3个仿真基准的53个任务中优于现有一步动作生成器，集成到VLA模型后在40个任务上实现加速且性能无损，实际机器人任务中推理频率达93.5Hz。

Conclusion: FreqPolicy通过频率一致性约束显著提升生成模型在机器人操作中的效率和性能，适用于实时系统。

Abstract: Generative modeling-based visuomotor policies have been widely adopted in
robotic manipulation attributed to their ability to model multimodal action
distributions. However, the high inference cost of multi-step sampling limits
their applicability in real-time robotic systems. To address this issue,
existing approaches accelerate the sampling process in generative
modeling-based visuomotor policies by adapting acceleration techniques
originally developed for image generation. Despite this progress, a major
distinction remains: image generation typically involves producing independent
samples without temporal dependencies, whereas robotic manipulation involves
generating time-series action trajectories that require continuity and temporal
coherence. To effectively exploit temporal information in robotic manipulation,
we propose FreqPolicy, a novel approach that first imposes frequency
consistency constraints on flow-based visuomotor policies. Our work enables the
action model to capture temporal structure effectively while supporting
efficient, high-quality one-step action generation. We introduce a frequency
consistency constraint that enforces alignment of frequency-domain action
features across different timesteps along the flow, thereby promoting
convergence of one-step action generation toward the target distribution. In
addition, we design an adaptive consistency loss to capture structural temporal
variations inherent in robotic manipulation tasks. We assess FreqPolicy on 53
tasks across 3 simulation benchmarks, proving its superiority over existing
one-step action generators. We further integrate FreqPolicy into the
vision-language-action (VLA) model and achieve acceleration without performance
degradation on the 40 tasks of Libero. Besides, we show efficiency and
effectiveness in real-world robotic scenarios with an inference frequency
93.5Hz. The code will be publicly available.

</details>


### [43] [MoRE: Mixture of Residual Experts for Humanoid Lifelike Gaits Learning on Complex Terrains](https://arxiv.org/abs/2506.08840)
*Dewei Wang,Xinmiao Wang,Xinzhe Liu,Jiyuan Shi,Yingnan Zhao,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: 提出了一种基于混合潜在残差专家和多判别器的RL框架，用于训练能够在复杂地形中以可控仿人步态行走的机器人。


<details>
  <summary>Details</summary>
Motivation: 现有方法在平坦地形中表现良好，但在复杂地形中难以实现仿人步态。

Method: 采用两阶段训练流程，先通过深度相机训练策略适应复杂地形，再实现步态切换。

Result: 仿真和实物实验表明，该框架在复杂地形中表现优异，并能无缝切换多种仿人步态。

Conclusion: 该框架显著提升了机器人在复杂地形中的仿人步态行走能力。

Abstract: Humanoid robots have demonstrated robust locomotion capabilities using
Reinforcement Learning (RL)-based approaches. Further, to obtain human-like
behaviors, existing methods integrate human motion-tracking or motion prior in
the RL framework. However, these methods are limited in flat terrains with
proprioception only, restricting their abilities to traverse challenging
terrains with human-like gaits. In this work, we propose a novel framework
using a mixture of latent residual experts with multi-discriminators to train
an RL policy, which is capable of traversing complex terrains in controllable
lifelike gaits with exteroception. Our two-stage training pipeline first
teaches the policy to traverse complex terrains using a depth camera, and then
enables gait-commanded switching between human-like gait patterns. We also
design gait rewards to adjust human-like behaviors like robot base height.
Simulation and real-world experiments demonstrate that our framework exhibits
exceptional performance in traversing complex terrains, and achieves seamless
transitions between multiple human-like gait patterns.

</details>


### [44] [Deploying SICNav in the Field: Safe and Interactive Crowd Navigation using MPC and Bilevel Optimization](https://arxiv.org/abs/2506.08851)
*Sepehr Samavi,Garvish Bhutani,Florian Shkurti,Angela P. Schoellig*

Main category: cs.RO

TL;DR: SICNav是一种双层MPC框架，将预测和规划结合为一个优化问题，解决了机器人导航中忽略人机交互的问题。


<details>
  <summary>Details</summary>
Motivation: 解决拥挤环境中机器人导航的挑战，避免因忽略人机闭环交互而导致机器人卡住。

Method: 提出SICNav方法，结合预测与规划，显式建模多智能体交互。

Result: 在室内外环境中进行了近7公里的自主导航测试，初步验证了系统的可行性。

Conclusion: SICNav通过显式建模交互，提高了机器人在拥挤环境中的导航安全性和效率。

Abstract: Safe and efficient navigation in crowded environments remains a critical
challenge for robots that provide a variety of service tasks such as food
delivery or autonomous wheelchair mobility. Classical robot crowd navigation
methods decouple human motion prediction from robot motion planning, which
neglects the closed-loop interactions between humans and robots. This lack of a
model for human reactions to the robot plan (e.g. moving out of the way) can
cause the robot to get stuck. Our proposed Safe and Interactive Crowd
Navigation (SICNav) method is a bilevel Model Predictive Control (MPC)
framework that combines prediction and planning into one optimization problem,
explicitly modeling interactions among agents. In this paper, we present a
systems overview of the crowd navigation platform we use to deploy SICNav in
previously unseen indoor and outdoor environments. We provide a preliminary
analysis of the system's operation over the course of nearly 7 km of autonomous
navigation over two hours in both indoor and outdoor environments.

</details>


### [45] [Fast Estimation of Globally Optimal Independent Contact Regions for Robust Grasping and Manipulation](https://arxiv.org/abs/2506.08856)
*Jonathan P. King,Harnoor Ahluwalia,Michael Zhang,Nancy S. Pollard*

Main category: cs.RO

TL;DR: 提出了一种快速算法，用于计算全局最优的独立接触区域（ICRs），适用于实时规划。


<details>
  <summary>Details</summary>
Motivation: ICRs的位置为抓取和操作规划、学习及策略迁移提供指导，但现有方法计算成本高。

Method: 基于增量n维Delaunay三角剖分的分治算法，支持平面接触。

Result: 实验显示比竞争方法快100倍以上，且抓取质量更优。

Conclusion: 算法高效且鲁棒，未来将扩展到3D实现，代码将开源。

Abstract: This work presents a fast anytime algorithm for computing globally optimal
independent contact regions (ICRs). ICRs are regions such that one contact
within each region enables a valid grasp. Locations of ICRs can provide
guidance for grasp and manipulation planning, learning, and policy transfer.
However, ICRs for modern applications have been little explored, in part due to
the expense of computing them, as they have a search space exponential in the
number of contacts. We present a divide and conquer algorithm based on
incremental n-dimensional Delaunay triangulation that produces results with
bounded suboptimality in times sufficient for real-time planning. This paper
presents the base algorithm for grasps where contacts lie within a plane. Our
experiments show substantial benefits over competing grasp quality metrics and
speedups of 100X and more for competing approaches to computing ICRs. We
explore robustness of a policy guided by ICRs and outline a path to general 3D
implementation. Code will be released on publication to facilitate further
development and applications.

</details>


### [46] [MOMAV: A highly symmetrical fully-actuated multirotor drone using optimizing control allocation](https://arxiv.org/abs/2506.08868)
*Marco Ruggia*

Main category: cs.RO

TL;DR: MOMAV是一种全驱动、高度对称的多旋翼无人机，通过独特的八面体转子臂设计和主动旋转机制实现高效飞行，控制算法基于SQP，飞行测试显示其位置和姿态误差极低。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够独立控制位置和姿态的全驱动无人机，同时保持高飞行效率。

Method: 采用六转子臂八面体排列设计，每个臂可主动旋转，结合基于SQP的控制分配算法。

Result: 飞行测试显示位置误差6.6mm、姿态误差2.1°，性能优于其他全驱动无人机。

Conclusion: MOMAV通过创新设计和控制算法，实现了高效、精确的全驱动飞行。

Abstract: MOMAV (Marco's Omnidirectional Micro Aerial Vehicle) is a multirotor drone
that is fully actuated, meaning it can control its orientation independently of
its position. MOMAV is also highly symmetrical, making its flight efficiency
largely unaffected by its current orientation. These characteristics are
achieved by a novel drone design where six rotor arms align with the vertices
of an octahedron, and where each arm can actively rotate along its long axis.
Various standout features of MOMAV are presented: The high flight efficiency
compared to arm configuration of other fully-actuated drones, the design of an
original rotating arm assembly featuring slip-rings used to enable continuous
arm rotation, and a novel control allocation algorithm based on sequential
quadratic programming (SQP) used to calculate throttle and arm-angle setpoints
in flight. Flight tests have shown that MOMAV is able to achieve remarkably low
mean position/orientation errors of 6.6mm, 2.1{\deg} ({\sigma}: 3.0mm,
1.0{\deg}) when sweeping position setpoints, and 11.8mm, 3.3{\deg} ({\sigma}:
8.6mm, 2.0{\deg}) when sweeping orientation setpoints.

</details>


### [47] [Human-Robot Teaming Field Deployments: A Comparison Between Verbal and Non-verbal Communication](https://arxiv.org/abs/2506.08890)
*Tauhid Tanjim,Promise Ekpo,Huajie Cao,Jonathan St. George,Kevin Ching,Hee Rin Lee,Angelique Taylor*

Main category: cs.RO

TL;DR: 研究比较了机器人急救车（RCC）的语音与非语音通信方式对医护人员工作负荷和态度的影响，发现语音通信显著降低心理需求和努力。


<details>
  <summary>Details</summary>
Motivation: 医护人员在急救场景中快速获取医疗用品时面临挑战，机器人急救车可能通过有效通信方式减少干扰并提高效率。

Method: 采用被试间实验设计，比较RCC的语音与非语音通信方式与传统急救车在复苏场景中的效果。

Result: 语音通信显著降低心理需求和努力，尽管与机器人合作时挫败感略高。

Conclusion: 研究为高风险环境中人机协作提供了有价值的见解，支持语音通信在机器人辅助医疗中的应用。

Abstract: Healthcare workers (HCWs) encounter challenges in hospitals, such as
retrieving medical supplies quickly from crash carts, which could potentially
result in medical errors and delays in patient care. Robotic crash carts (RCCs)
have shown promise in assisting healthcare teams during medical tasks through
guided object searches and task reminders. Limited exploration has been done to
determine what communication modalities are most effective and least disruptive
to patient care in real-world settings. To address this gap, we conducted a
between-subjects experiment comparing the RCC's verbal and non-verbal
communication of object search with a standard crash cart in resuscitation
scenarios to understand the impact of robot communication on workload and
attitudes toward using robots in the workplace. Our findings indicate that
verbal communication significantly reduced mental demand and effort compared to
visual cues and with a traditional crash cart. Although frustration levels were
slightly higher during collaborations with the robot compared to a traditional
cart, these research insights provide valuable implications for human-robot
teamwork in high-stakes environments.

</details>


### [48] [CLONE: Closed-Loop Whole-Body Humanoid Teleoperation for Long-Horizon Tasks](https://arxiv.org/abs/2506.08931)
*Yixuan Li,Yutang Lin,Jieming Cui,Tengyu Liu,Wei Liang,Yixin Zhu,Siyuan Huang*

Main category: cs.RO

TL;DR: CLONE是一种基于MoE的遥操作系统，通过闭环误差校正实现高保真全身遥操作，解决了现有系统协调性和漂移问题。


<details>
  <summary>Details</summary>
Motivation: 当前遥操作系统存在上下肢控制分离和开环操作导致的协调性不足和漂移问题，需要一种能实现精确、协调且长时间稳定的全身遥操作方案。

Method: 采用MoE架构和闭环误差校正技术，仅需MR头显的手部和头部跟踪数据，实现实时反馈和误差控制。

Result: CLONE系统在长距离轨迹中保持极低的位置漂移，支持复杂协调动作（如从地面拾取物体），显著提升了遥操作性能。

Conclusion: CLONE为长时间全身人形遥操作设立了新标准，适用于复杂人形场景交互任务。

Abstract: Humanoid teleoperation plays a vital role in demonstrating and collecting
data for complex humanoid-scene interactions. However, current teleoperation
systems face critical limitations: they decouple upper- and lower-body control
to maintain stability, restricting natural coordination, and operate open-loop
without real-time position feedback, leading to accumulated drift. The
fundamental challenge is achieving precise, coordinated whole-body
teleoperation over extended durations while maintaining accurate global
positioning. Here we show that an MoE-based teleoperation system, CLONE, with
closed-loop error correction enables unprecedented whole-body teleoperation
fidelity, maintaining minimal positional drift over long-range trajectories
using only head and hand tracking from an MR headset. Unlike previous methods
that either sacrifice coordination for stability or suffer from unbounded
drift, CLONE learns diverse motion skills while preventing tracking error
accumulation through real-time feedback, enabling complex coordinated movements
such as ``picking up objects from the ground.'' These results establish a new
milestone for whole-body humanoid teleoperation for long-horizon humanoid-scene
interaction tasks.

</details>


### [49] [AI Magnetic Levitation (Maglev) Conveyor for Automated Assembly Production](https://arxiv.org/abs/2506.08039)
*Ray Wai Man Kong*

Main category: cs.RO

TL;DR: AI Maglev Conveyor系统结合磁悬浮技术和AI，提升制造效率、速度和精度，减少维护成本，支持可持续性。


<details>
  <summary>Details</summary>
Motivation: 现代制造需要高效、快速和精确的解决方案，传统系统存在摩擦和维护问题。

Method: 结合磁悬浮技术和AI，实现无摩擦运输、实时监控和自适应控制。

Result: 系统减少维护成本、提高效率，适应多样化生产需求，优化供应链。

Conclusion: AI Maglev Conveyor是高效、灵活且经济的制造解决方案，适用于多种行业。

Abstract: Efficiency, speed, and precision are essential in modern manufacturing. AI
Maglev Conveyor system, combining magnetic levitation (maglev) technology with
artificial intelligence (AI), revolutionizes automated production processes.
This system reduces maintenance costs and downtime by eliminating friction,
enhancing operational efficiency. It transports goods swiftly with minimal
energy consumption, optimizing resource use and supporting sustainability. AI
integration enables real-time monitoring and adaptive control, allowing
businesses to respond to production demand fluctuations and streamline supply
chain operations.
  The AI Maglev Conveyor offers smooth, silent operation, accommodating diverse
product types and sizes for flexible manufacturing without extensive
reconfiguration. AI algorithms optimize routing, reduce cycle times, and
improve throughput, creating an agile production line adaptable to market
changes.
  This applied research paper introduces the Maglev Conveyor system, featuring
an electromagnetic controller and multiple movers to enhance automation. It
offers cost savings as an alternative to setups using six-axis robots or linear
motors, with precise adjustments for robotic arm loading. Operating at high
speeds minimizes treatment time for delicate components while maintaining
precision. Its adaptable design accommodates various materials, facilitating
integration of processing stations alongside electronic product assembly.
Positioned between linear-axis and robotic systems in cost, the Maglev Conveyor
is ideal for flat parts requiring minimal travel, transforming production
efficiency across industries. It explores its technical advantages,
flexibility, cost reductions, and overall benefits.

</details>


### [50] [UAVs Meet Agentic AI: A Multidomain Survey of Autonomous Aerial Intelligence and Agentic UAVs](https://arxiv.org/abs/2506.08045)
*Ranjan Sapkota,Konstantinos I. Roumeliotis,Manoj Karkee*

Main category: cs.RO

TL;DR: 本文综述了Agentic UAVs（自主无人机）的技术架构、应用领域、挑战及未来发展方向，强调其在复杂环境中的智能适应性。


<details>
  <summary>Details</summary>
Motivation: 传统无人机在复杂环境中的自主性有限，而Agentic UAVs通过整合感知、决策、记忆和协作规划，展现出更高的智能和适应性。

Method: 通过分析Agentic UAVs的架构组件、技术实现和比较传统无人机，探讨其在七个高影响力领域的应用。

Result: Agentic UAVs在多个领域展现出广泛的社会价值，但也面临技术、法规和数据可靠性等挑战。

Conclusion: 未来需通过硬件创新、学习架构改进和人类-AI交互优化，推动Agentic UAVs的可持续发展和广泛应用。

Abstract: Agentic UAVs represent a new frontier in autonomous aerial intelligence,
integrating perception, decision-making, memory, and collaborative planning to
operate adaptively in complex, real-world environments. Driven by recent
advances in Agentic AI, these systems surpass traditional UAVs by exhibiting
goal-driven behavior, contextual reasoning, and interactive autonomy. We
provide a comprehensive foundation for understanding the architectural
components and enabling technologies that distinguish Agentic UAVs from
traditional autonomous UAVs. Furthermore, a detailed comparative analysis
highlights advancements in autonomy with AI agents, learning, and mission
flexibility. This study explores seven high-impact application domains
precision agriculture, construction & mining, disaster response, environmental
monitoring, infrastructure inspection, logistics, security, and wildlife
conservation, illustrating the broad societal value of agentic aerial
intelligence. Furthermore, we identify key challenges in technical constraints,
regulatory limitations, and data-model reliability, and we present emerging
solutions across hardware innovation, learning architectures, and human-AI
interaction. Finally, a future roadmap is proposed, outlining pathways toward
self-evolving aerial ecosystems, system-level collaboration, and sustainable,
equitable deployments. This survey establishes a foundational framework for the
future development, deployment, and governance of agentic aerial systems
(Agentic UAVs) across diverse societal and industrial domains.

</details>


### [51] [Adaptive Per-Tree Canopy Volume Estimation Using Mobile LiDAR in Structured and Unstructured Orchards](https://arxiv.org/abs/2506.08061)
*Ali Abedi,Fernando Cladera,Mohsen Farajijalal,Reza Ehsani*

Main category: cs.RO

TL;DR: 提出了一种基于移动LiDAR数据的实时系统，用于估计单棵树冠体积，适用于结构多样的果园环境。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态扫描或假设果园结构均匀，无法适应实际果园的多样性。

Method: 结合LiDAR-惯性里程计、自适应分割和几何重建的集成流程，采用DBSCAN和谱聚类的混合聚类策略。

Result: 在两种果园中测试，成功率为93%（开心果）和80%（杏仁），与无人机测量结果一致。

Conclusion: 该系统为结构多样的果园提供了可扩展、非侵入式的树木监测方案。

Abstract: We present a real-time system for per-tree canopy volume estimation using
mobile LiDAR data collected during routine robotic navigation. Unlike prior
approaches that rely on static scans or assume uniform orchard structures, our
method adapts to varying field geometries via an integrated pipeline of
LiDAR-inertial odometry, adaptive segmentation, and geometric reconstruction.
We evaluate the system across two commercial orchards, one pistachio orchard
with regular spacing and one almond orchard with dense, overlapping crowns. A
hybrid clustering strategy combining DBSCAN and spectral clustering enables
robust per-tree segmentation, achieving 93% success in pistachio and 80% in
almond, with strong agreement to drone derived canopy volume estimates. This
work advances scalable, non-intrusive tree monitoring for structurally diverse
orchard environments.

</details>


### [52] [Ego-centric Learning of Communicative World Models for Autonomous Driving](https://arxiv.org/abs/2506.08149)
*Hang Wang,Dechen Gao,Junshan Zhang*

Main category: cs.RO

TL;DR: 论文提出了一种名为CALL的多智能体强化学习方法，通过生成式AI和世界模型的潜在表示解决部分可观测性和非平稳性问题，同时减少通信开销。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）在复杂高维环境（如自动驾驶）中面临部分可观测性和非平稳性问题，信息共享虽常用但存在通信开销和可扩展性挑战。

Method: CALL方法利用生成式AI的世界模型及其潜在表示，将智能体的状态和意图编码为低维表示，通过轻量级通信共享，并结合自我中心学习提升预测和规划能力。

Result: 实验在CARLA平台上进行，验证了CALL在局部轨迹规划任务中的性能提升，并量化了信息共享对预测准确性和性能差距的影响。

Conclusion: CALL通过轻量级信息共享和世界模型的泛化能力，有效解决了MARL中的关键问题，并在实际任务中表现出显著优势。

Abstract: We study multi-agent reinforcement learning (MARL) for tasks in complex
high-dimensional environments, such as autonomous driving. MARL is known to
suffer from the \textit{partial observability} and \textit{non-stationarity}
issues. To tackle these challenges, information sharing is often employed,
which however faces major hurdles in practice, including overwhelming
communication overhead and scalability concerns. By making use of generative AI
embodied in world model together with its latent representation, we develop
{\it CALL}, \underline{C}ommunic\underline{a}tive Wor\underline{l}d
Mode\underline{l}, for MARL, where 1) each agent first learns its world model
that encodes its state and intention into low-dimensional latent representation
with smaller memory footprint, which can be shared with other agents of
interest via lightweight communication; and 2) each agent carries out
ego-centric learning while exploiting lightweight information sharing to enrich
her world model, and then exploits its generalization capacity to improve
prediction for better planning. We characterize the gain on the prediction
accuracy from the information sharing and its impact on performance gap.
Extensive experiments are carried out on the challenging local trajectory
planning tasks in the CARLA platform to demonstrate the performance gains of
using \textit{CALL}.

</details>


### [53] [TensorTouch: Calibration of Tactile Sensors for High Resolution Stress Tensor and Deformation for Dexterous Manipulation](https://arxiv.org/abs/2506.08291)
*Won Kyung Do,Matthew Strong,Aiden Swann,Boshu Lei,Monroe Kennedy III*

Main category: cs.RO

TL;DR: TensorTouch通过结合有限元分析和深度学习，从光学触觉传感器中提取全面的接触信息，解决了多接触点操作中的挑战。


<details>
  <summary>Details</summary>
Motivation: 多接触点操作（如从地面捏硬币或操作交织物体）对机器人系统仍具挑战性，需要高分辨率触觉传感和物理校准。

Method: TensorTouch整合有限元分析和深度学习，提取应力张量、变形场和力分布等像素级接触信息。

Result: 实验验证显示，TensorTouch在选择性抓取两根绳子中的一根时成功率高达90%。

Conclusion: TensorTouch框架为机器人系统提供了以前无法实现的接触丰富操作能力。

Abstract: Advanced dexterous manipulation involving multiple simultaneous contacts
across different surfaces, like pinching coins from ground or manipulating
intertwined objects, remains challenging for robotic systems. Such tasks exceed
the capabilities of vision and proprioception alone, requiring high-resolution
tactile sensing with calibrated physical metrics. Raw optical tactile sensor
images, while information-rich, lack interpretability and cross-sensor
transferability, limiting their real-world utility. TensorTouch addresses this
challenge by integrating finite element analysis with deep learning to extract
comprehensive contact information from optical tactile sensors, including
stress tensors, deformation fields, and force distributions at pixel-level
resolution. The TensorTouch framework achieves sub-millimeter position accuracy
and precise force estimation while supporting large sensor deformations crucial
for manipulating soft objects. Experimental validation demonstrates 90% success
in selectively grasping one of two strings based on detected motion, enabling
new contact-rich manipulation capabilities previously inaccessible to robotic
systems.

</details>


### [54] [HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation](https://arxiv.org/abs/2506.08296)
*Hongjun Wu,Heng Zhang,Pengsong Zhang,Jin Wang,Cong Wang*

Main category: cs.RO

TL;DR: HiBerNAC是一种层次化脑模拟机器人神经代理集体，结合多模态VLA规划和神经启发的多代理机制，显著提升复杂操作任务的执行效率。


<details>
  <summary>Details</summary>
Motivation: 解决复杂操作任务中持久上下文记忆、多代理协调和动态长时规划等挑战。

Method: 结合多模态VLA规划和神经启发的反射与多代理机制，采用分散式多代理协作。

Result: 相比现有VLA模型，HiBerNAC将长时任务完成时间减少23%，并在多路径任务中实现12-31%的成功率。

Conclusion: HiBerNAC为生物认知与机器人学习机制的融合提供了初步证据。

Abstract: Recent advances in multimodal vision-language-action (VLA) models have
revolutionized traditional robot learning, enabling systems to interpret
vision, language, and action in unified frameworks for complex task planning.
However, mastering complex manipulation tasks remains an open challenge,
constrained by limitations in persistent contextual memory, multi-agent
coordination under uncertainty, and dynamic long-horizon planning across
variable sequences. To address this challenge, we propose \textbf{HiBerNAC}, a
\textbf{Hi}erarchical \textbf{B}rain-\textbf{e}mulated \textbf{r}obotic
\textbf{N}eural \textbf{A}gent \textbf{C}ollective, inspired by breakthroughs
in neuroscience, particularly in neural circuit mechanisms and hierarchical
decision-making. Our framework combines: (1) multimodal VLA planning and
reasoning with (2) neuro-inspired reflection and multi-agent mechanisms,
specifically designed for complex robotic manipulation tasks. By leveraging
neuro-inspired functional modules with decentralized multi-agent collaboration,
our approach enables robust and enhanced real-time execution of complex
manipulation tasks. In addition, the agentic system exhibits scalable
collective intelligence via dynamic agent specialization, adapting its
coordination strategy to variable task horizons and complexity. Through
extensive experiments on complex manipulation tasks compared with
state-of-the-art VLA models, we demonstrate that \textbf{HiBerNAC} reduces
average long-horizon task completion time by 23\%, and achieves non-zero
success rates (12\textendash 31\%) on multi-path tasks where prior
state-of-the-art VLA models consistently fail. These results provide indicative
evidence for bridging biological cognition and robotic learning mechanisms.

</details>


### [55] [Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning](https://arxiv.org/abs/2506.08344)
*Neşet Ünver Akmandor,Sarvesh Prajapati,Mark Zolotas,Taşkın Padır*

Main category: cs.RO

TL;DR: 提出了一种名为Re4MPC的多模型运动规划方法，结合非线性模型预测控制（NMPC）和深度强化学习（DRL），显著提高了计算效率和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统的高自由度机器人运动规划方法计算成本高，难以适应实际场景需求。

Method: 通过DRL框架学习反应性决策策略，动态选择NMPC的模型、成本和约束条件。

Result: 在物理仿真中，Re4MPC比传统NMPC方法更高效且成功率更高。

Conclusion: Re4MPC为高自由度机器人提供了一种高效的运动规划解决方案。

Abstract: Traditional motion planning methods for robots with many degrees-of-freedom,
such as mobile manipulators, are often computationally prohibitive for
real-world settings. In this paper, we propose a novel multi-model motion
planning pipeline, termed Re4MPC, which computes trajectories using Nonlinear
Model Predictive Control (NMPC). Re4MPC generates trajectories in a
computationally efficient manner by reactively selecting the model, cost, and
constraints of the NMPC problem depending on the complexity of the task and
robot state. The policy for this reactive decision-making is learned via a Deep
Reinforcement Learning (DRL) framework. We introduce a mathematical formulation
to integrate NMPC into this DRL framework. To validate our methodology and
design choices, we evaluate DRL training and test outcomes in a physics-based
simulation involving a mobile manipulator. Experimental results demonstrate
that Re4MPC is more computationally efficient and achieves higher success rates
in reaching end-effector goals than the NMPC baseline, which computes
whole-body trajectories without our learning mechanism.

</details>


### [56] [Periodic Bipedal Gait Learning Using Reward Composition Based on a Novel Gait Planner for Humanoid Robots](https://arxiv.org/abs/2506.08416)
*Bolin Li,Linwei Sun,Xuecong Huang,Yuzhi Jiang,Lijun Zhu*

Main category: cs.RO

TL;DR: 提出了一种基于奖励组合的周期性双足步态学习方法，结合实时步态规划器，用于人形机器人。


<details>
  <summary>Details</summary>
Motivation: 旨在通过动态规划和强化学习结合，减少机器人学习时间并提升运动性能。

Method: 1. 引入动态步态规划器，将3D模型解耦为2D混合倒立摆（H-LIP）进行轨迹规划；2. 设计三种奖励函数，组合成强化学习框架。

Result: 实验表明，该方法有效减少了学习时间并提升了运动性能。

Conclusion: 通过动态规划和奖励组合，成功实现了周期性双足步态的高效学习。

Abstract: This paper presents a periodic bipedal gait learning method using reward
composition, integrated with a real-time gait planner for humanoid robots.
First, we introduce a novel gait planner that incorporates dynamics to design
the desired joint trajectory. In the gait design process, the 3D robot model is
decoupled into two 2D models, which are then approximated as hybrid inverted
pendulums (H-LIP) for trajectory planning. The gait planner operates in
parallel in real time within the robot's learning environment. Second, based on
this gait planner, we design three effective reward functions within a
reinforcement learning framework, forming a reward composition to achieve
periodic bipedal gait. This reward composition reduces the robot's learning
time and enhances locomotion performance. Finally, a gait design example and
performance comparison are presented to demonstrate the effectiveness of the
proposed method.

</details>


### [57] [Attention-based Learning for 3D Informative Path Planning](https://arxiv.org/abs/2506.08434)
*Rui Zhao,Xingjian Zhang,Yuhong Cao,Yizhuo Wang,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 提出了一种基于注意力的深度强化学习方法，用于解决3D空间中的自适应信息路径规划问题，通过动态调整无人机位置以优化感知覆盖和精度。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在3D空间中动态调整路径以最大化信息收集的问题，同时平衡感知范围和精度，适用于多种实际应用场景。

Method: 利用注意力机制捕捉全局空间依赖关系，构建环境信念表示，指导无人机在约束条件下优化短期和长期搜索目标。

Result: 实验表明，该方法显著降低了环境不确定性，优于现有规划器，并能泛化到不同规模的环境。

Conclusion: 该方法在自适应信息路径规划中表现出色，具有广泛的实际应用潜力。

Abstract: In this work, we propose an attention-based deep reinforcement learning
approach to address the adaptive informative path planning (IPP) problem in 3D
space, where an aerial robot equipped with a downward-facing sensor must
dynamically adjust its 3D position to balance sensing footprint and accuracy,
and finally obtain a high-quality belief of an underlying field of interest
over a given domain (e.g., presence of specific plants, hazardous gas,
geological structures, etc.). In adaptive IPP tasks, the agent is tasked with
maximizing information collected under time/distance constraints, continuously
adapting its path based on newly acquired sensor data. To this end, we leverage
attention mechanisms for their strong ability to capture global spatial
dependencies across large action spaces, allowing the agent to learn an
implicit estimation of environmental transitions. Our model builds a contextual
belief representation over the entire domain, guiding sequential movement
decisions that optimize both short- and long-term search objectives.
Comparative evaluations against state-of-the-art planners demonstrate that our
approach significantly reduces environmental uncertainty within constrained
budgets, thus allowing the agent to effectively balance exploration and
exploitation. We further show our model generalizes well to environments of
varying sizes, highlighting its potential for many real-world applications.

</details>


### [58] [TGRPO :Fine-tuning Vision-Language-Action Model via Trajectory-wise Group Relative Policy Optimization](https://arxiv.org/abs/2506.08440)
*Zengjue Chen,Runliang Niu,He Kong,Qi Wang*

Main category: cs.RO

TL;DR: 论文提出了一种名为TGRPO的方法，通过结合步级和轨迹级优势信号，改进了GRPO的组级优势估计，适用于VLA模型的在线强化学习训练。实验表明，TGRPO在多个任务中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在新环境中仍需任务特定的微调，且依赖静态轨迹数据集，无法利用实时交互反馈。强化学习（RL）提供了一种闭环交互的替代方案。

Method: 提出TGRPO方法，融合步级和轨迹级优势信号，改进GRPO的组级优势估计，适用于VLA的在线强化学习训练。

Result: 在libero-object基准测试的十个操作任务中，TGRPO表现优于多种基线方法，生成更稳健和高效的政策。

Conclusion: TGRPO通过改进优势估计，为VLA模型的在线强化学习提供了一种有效方法，实验验证了其优越性。

Abstract: Recent advances in Vision-Language-Action (VLA) model have demonstrated
strong generalization capabilities across diverse scenes, tasks, and robotic
platforms when pretrained at large-scale datasets. However, these models still
require task-specific fine-tuning in novel environments, a process that relies
almost exclusively on supervised fine-tuning (SFT) using static trajectory
datasets. Such approaches neither allow robot to interact with environment nor
do they leverage feedback from live execution. Also, their success is
critically dependent on the size and quality of the collected trajectories.
Reinforcement learning (RL) offers a promising alternative by enabling
closed-loop interaction and aligning learned policies directly with task
objectives. In this work, we draw inspiration from the ideas of GRPO and
propose the Trajectory-wise Group Relative Policy Optimization (TGRPO) method.
By fusing step-level and trajectory-level advantage signals, this method
improves GRPO's group-level advantage estimation, thereby making the algorithm
more suitable for online reinforcement learning training of VLA. Experimental
results on ten manipulation tasks from the libero-object benchmark demonstrate
that TGRPO consistently outperforms various baseline methods, capable of
generating more robust and efficient policies across multiple tested scenarios.
Our source codes are available at: https://github.com/hahans/TGRPO

</details>


### [59] [Diffusion Models for Safety Validation of Autonomous Driving Systems](https://arxiv.org/abs/2506.08459)
*Juanran Wang,Marc R. Schlichting,Harrison Delecki,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 论文提出了一种基于去噪扩散模型的方法，用于生成自动驾驶系统在初始交通状态下的潜在故障案例，以低成本和高效率解决安全验证的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于真实世界测试的高风险和成本，以及潜在故障的罕见性和多样性，自动驾驶系统的安全验证极具挑战性。

Method: 训练一个去噪扩散模型，生成自动驾驶车辆在任意初始交通状态下的潜在故障案例。

Result: 实验表明，该模型能够在多种场景下生成真实的故障样本，并捕捉广泛的潜在故障类型。

Conclusion: 该方法无需外部训练数据集，计算资源需求适中，适用于交通路口的安全验证。

Abstract: Safety validation of autonomous driving systems is extremely challenging due
to the high risks and costs of real-world testing as well as the rarity and
diversity of potential failures. To address these challenges, we train a
denoising diffusion model to generate potential failure cases of an autonomous
vehicle given any initial traffic state. Experiments on a four-way intersection
problem show that in a variety of scenarios, the diffusion model can generate
realistic failure samples while capturing a wide variety of potential failures.
Our model does not require any external training dataset, can perform training
and inference with modest computing resources, and does not assume any prior
knowledge of the system under test, with applicability to safety validation for
traffic intersections.

</details>


### [60] [Noise Analysis and Hierarchical Adaptive Body State Estimator For Biped Robot Walking With ESVC Foot](https://arxiv.org/abs/2506.08578)
*Boyang Chen,Xizhe Zang,Chao Song,Yue Zhang,Xuehe Zhang,Jie Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种针对ESVC足机器人行走的分层自适应状态估计器，通过噪声分析和回归模型优化状态估计精度和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 由于ESVC足在机器人行走中会放大接触模型误差，导致状态估计困难，因此需要研究噪声分析和改进状态估计方法。

Method: 通过物理实验分析噪声影响，建立噪声-时间回归模型，并设计分层状态估计器（预估计和后估计阶段），结合EKF优化估计精度。

Result: 实验表明，该方法比EKF和自适应EKF具有更高的精度和更快的收敛速度。

Conclusion: 提出的自适应状态估计器有效解决了ESVC足机器人行走中的状态估计问题，提升了性能和适应性。

Abstract: The ESVC(Ellipse-based Segmental Varying Curvature) foot, a robot foot design
inspired by the rollover shape of the human foot, significantly enhances the
energy efficiency of the robot walking gait. However, due to the tilt of the
supporting leg, the error of the contact model are amplified, making robot
state estimation more challenging. Therefore, this paper focuses on the noise
analysis and state estimation for robot walking with the ESVC foot. First,
through physical robot experiments, we investigate the effect of the ESVC foot
on robot measurement noise and process noise. and a noise-time regression model
using sliding window strategy is developed. Then, a hierarchical adaptive state
estimator for biped robots with the ESVC foot is proposed. The state estimator
consists of two stages: pre-estimation and post-estimation. In the
pre-estimation stage, a data fusion-based estimation is employed to process the
sensory data. During post-estimation, the acceleration of center of mass is
first estimated, and then the noise covariance matrices are adjusted based on
the regression model. Following that, an EKF(Extended Kalman Filter) based
approach is applied to estimate the centroid state during robot walking.
Physical experiments demonstrate that the proposed adaptive state estimator for
biped robot walking with the ESVC foot not only provides higher precision than
both EKF and Adaptive EKF, but also converges faster under varying noise
conditions.

</details>


### [61] [Deep Reinforcement Learning-Based Motion Planning and PDE Control for Flexible Manipulators](https://arxiv.org/abs/2506.08639)
*Amir Hossein Barjini,Seyed Adel Alizadeh Kolagar,Sadeq Yaqubi,Jouni Mattila*

Main category: cs.RO

TL;DR: 结合深度强化学习与非线性PDE控制器的柔性机械臂运动规划与控制框架，显著减少振动并提高跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅关注控制，忽略了期望轨迹对端点振动的影响，因此需要一种更全面的方法。

Method: 使用SAC算法的DRL运动规划器生成优化轨迹，结合非线性PDE控制器计算扭矩，并通过Lyapunov分析确保稳定性。

Result: 仿真和实验验证了该方法在振动抑制和跟踪精度上的优越性。

Conclusion: 结合学习型运动规划与模型控制可提升柔性机械臂的精度与稳定性。

Abstract: This article presents a motion planning and control framework for flexible
robotic manipulators, integrating deep reinforcement learning (DRL) with a
nonlinear partial differential equation (PDE) controller. Unlike conventional
approaches that focus solely on control, we demonstrate that the desired
trajectory significantly influences endpoint vibrations. To address this, a DRL
motion planner, trained using the soft actor-critic (SAC) algorithm, generates
optimized trajectories that inherently minimize vibrations. The PDE nonlinear
controller then computes the required torques to track the planned trajectory
while ensuring closed-loop stability using Lyapunov analysis. The proposed
methodology is validated through both simulations and real-world experiments,
demonstrating superior vibration suppression and tracking accuracy compared to
traditional methods. The results underscore the potential of combining
learning-based motion planning with model-based control for enhancing the
precision and stability of flexible robotic manipulators.

</details>


### [62] [ROS-related Robotic Systems Development with V-model-based Application of MeROS Metamodel](https://arxiv.org/abs/2506.08706)
*Tomasz Winiarski,Jan Kaniuka,Daniel Giełdowski,Jakub Ostrysz,Krystian Radlak,Dmytro Kushnir*

Main category: cs.RO

TL;DR: 本文提出了一种结合ROS和MBSE的结构化开发方法，通过MeROS和V模型提升机器人系统的可追溯性和一致性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统日益复杂和安全关键性增强，ROS和MBSE工具的整合需求凸显。

Method: 提出了一种基于MeROS和V模型的领域特定方法，支持ROS和ROS 2的灵活开发。

Result: 通过HeROS案例验证了方法的有效性，增强了系统一致性和可追溯性。

Conclusion: 该方法为ROS项目提供了结构化、工具无关的MBSE实践基础。

Abstract: As robotic systems grow increasingly complex, heterogeneous, and
safety-critical, the need for structured development methodologies becomes
paramount. Although frameworks like the Robot Operating System (ROS) and
Model-Based Systems Engineering (MBSE) offer foundational tools, they often
lack integration when used together. This paper addresses that gap by aligning
the widely recognized V-model development paradigm with the MeROS metamodel
SysML-based modeling language tailored for ROS-based systems.
  We propose a domain-specific methodology that bridges ROS-centric modelling
with systems engineering practices. Our approach formalises the structure,
behaviour, and validation processes of robotic systems using MeROS, while
extending it with a generalized, adaptable V-model compatible with both ROS and
ROS 2. Rather than prescribing a fixed procedure, the approach supports
project-specific flexibility and reuse, offering guidance across all stages of
development.
  The approach is validated through a comprehensive case study on HeROS, a
heterogeneous multi-robot platform comprising manipulators, mobile units, and
dynamic test environments. This example illustrates how the MeROS-compatible
V-model enhances traceability and system consistency while remaining accessible
and extensible for future adaptation. The work contributes a structured,
tool-agnostic foundation for developers and researchers seeking to apply MBSE
practices in ROS-based projects.

</details>


### [63] [PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly](https://arxiv.org/abs/2506.08708)
*Liang Ma,Jiajun Wen,Min Lin,Rongtao Xu,Xiwen Liang,Bingqian Lin,Jun Ma,Yongxin Wang,Ziming Wei,Haokun Lin,Mingfei Han,Meng Cao,Bokui Chen,Ivan Laptev,Xiaodan Liang*

Main category: cs.RO

TL;DR: PhyBlock是一个评估视觉语言模型（VLMs）在3D块组装任务中物理理解和规划能力的渐进式基准，揭示了VLMs在高级规划和空间推理上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在理解物理现象（尤其是结构化3D环境中的现象）方面能力有限，需要一种评估工具来推动其在具身推理中的进步。

Method: PhyBench通过2600个块任务（400个组装任务和2200个VQA任务）评估VLMs，涵盖部分完成、失败诊断和规划鲁棒性三个维度。

Result: 21个先进VLMs的测试显示，它们在高级规划和空间推理上表现不佳，任务复杂度增加时性能显著下降。

Conclusion: PhyBlock为具身推理提供了统一测试平台，揭示了VLMs在物理问题解决中的局限性，并强调了空间直觉的重要性。

Abstract: While vision-language models (VLMs) have demonstrated promising capabilities
in reasoning and planning for embodied agents, their ability to comprehend
physical phenomena, particularly within structured 3D environments, remains
severely limited. To close this gap, we introduce PhyBlock, a progressive
benchmark designed to assess VLMs on physical understanding and planning
through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level
cognitive hierarchy assembly task alongside targeted Visual Question Answering
(VQA) samples, collectively aimed at evaluating progressive spatial reasoning
and fundamental physical comprehension, including object properties, spatial
relationships, and holistic scene understanding. PhyBlock includes 2600 block
tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three
key dimensions: partial completion, failure diagnosis, and planning robustness.
We benchmark 21 state-of-the-art VLMs, highlighting their strengths and
limitations in physically grounded, multi-step planning. Our empirical findings
indicate that the performance of VLMs exhibits pronounced limitations in
high-level planning and reasoning capabilities, leading to a notable decline in
performance for the growing complexity of the tasks. Error analysis reveals
persistent difficulties in spatial orientation and dependency reasoning.
Surprisingly, chain-of-thought prompting offers minimal improvements,
suggesting spatial tasks heavily rely on intuitive model comprehension. We
position PhyBlock as a unified testbed to advance embodied reasoning, bridging
vision-language understanding and real-world physical problem-solving.

</details>


### [64] [Bayesian Inverse Physics for Neuro-Symbolic Robot Learning](https://arxiv.org/abs/2506.08756)
*Octavio Arriaga,Rebecca Adam,Melvin Laux,Lisa Gutzeit,Marco Ragni,Jan Peters,Frank Kirchner*

Main category: cs.RO

TL;DR: 论文提出了一种结合数据驱动学习和结构化推理的混合神经符号架构，以解决机器人在未知和动态环境中高效可靠运行的问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的机器人应用需要适应性、可解释性和数据高效的学习范式，而现有深度学习方法在未知和动态环境中表现有限。

Method: 提出利用可微分物理进行高效世界建模、贝叶斯推理实现不确定性感知决策，以及元学习快速适应新任务。

Result: 通过将物理符号推理嵌入神经模型，机器人可以泛化到训练数据之外，推理新情境并持续扩展知识。

Conclusion: 混合神经符号架构是下一代自主系统的关键，并提供了研究路线图以加速其发展。

Abstract: Real-world robotic applications, from autonomous exploration to assistive
technologies, require adaptive, interpretable, and data-efficient learning
paradigms. While deep learning architectures and foundation models have driven
significant advances in diverse robotic applications, they remain limited in
their ability to operate efficiently and reliably in unknown and dynamic
environments. In this position paper, we critically assess these limitations
and introduce a conceptual framework for combining data-driven learning with
deliberate, structured reasoning. Specifically, we propose leveraging
differentiable physics for efficient world modeling, Bayesian inference for
uncertainty-aware decision-making, and meta-learning for rapid adaptation to
new tasks. By embedding physical symbolic reasoning within neural models,
robots could generalize beyond their training data, reason about novel
situations, and continuously expand their knowledge. We argue that such hybrid
neuro-symbolic architectures are essential for the next generation of
autonomous systems, and to this end, we provide a research roadmap to guide and
accelerate their development.

</details>


### [65] [Towards Biosignals-Free Autonomous Prosthetic Hand Control via Imitation Learning](https://arxiv.org/abs/2506.08795)
*Kaijie Shi,Wanglong Lu,Hanli Zhao,Vinicius Prado da Fonseca,Ting Zou,Xianta Jiang*

Main category: cs.RO

TL;DR: 开发了一种基于摄像头的全自主假手控制系统，通过模仿学习实现自动抓取和释放物体，减少用户负担。


<details>
  <summary>Details</summary>
Motivation: 传统肌电信号控制假手需要用户持续生成信号，对身心负担大，需开发更易用的自主控制系统。

Method: 利用摄像头和模仿学习算法，通过人类示范数据训练假手控制模型，实现自动抓取和释放。

Result: 模型仅需少量数据即可实现高成功率，并能泛化到不同用户和未见过的物体。

Conclusion: 该系统显著降低了假手使用的心理负担，提供了一种更自然、易用的控制方式。

Abstract: Limb loss affects millions globally, impairing physical function and reducing
quality of life. Most traditional surface electromyographic (sEMG) and
semi-autonomous methods require users to generate myoelectric signals for each
control, imposing physically and mentally taxing demands. This study aims to
develop a fully autonomous control system that enables a prosthetic hand to
automatically grasp and release objects of various shapes using only a camera
attached to the wrist. By placing the hand near an object, the system will
automatically execute grasping actions with a proper grip force in response to
the hand's movements and the environment. To release the object being grasped,
just naturally place the object close to the table and the system will
automatically open the hand. Such a system would provide individuals with limb
loss with a very easy-to-use prosthetic control interface and greatly reduce
mental effort while using. To achieve this goal, we developed a teleoperation
system to collect human demonstration data for training the prosthetic hand
control model using imitation learning, which mimics the prosthetic hand
actions from human. Through training the model using only a few objects' data
from one single participant, we have shown that the imitation learning
algorithm can achieve high success rates, generalizing to more individuals and
unseen objects with a variation of weights. The demonstrations are available at
\href{https://sites.google.com/view/autonomous-prosthetic-hand}{https://sites.google.com/view/autonomous-prosthetic-hand}

</details>


### [66] [FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency](https://arxiv.org/abs/2506.08822)
*Yifei Su,Ning Liu,Dong Chen,Zhen Zhao,Kun Wu,Meng Li,Zhiyuan Xu,Zhengping Che,Jian Tang*

Main category: cs.RO

TL;DR: FreqPolicy通过频率一致性约束提升基于生成模型的视觉运动策略的效率，支持高质量的一步动作生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在机器人操作中生成动作轨迹时缺乏时间连续性，限制了实时性。

Method: 提出FreqPolicy，通过频率一致性约束和自适应一致性损失，优化流式视觉运动策略。

Result: 在53个任务和3个仿真基准测试中表现优异，并在真实场景中实现93.5Hz的推理频率。

Conclusion: FreqPolicy在保持性能的同时显著提升了生成效率，适用于实时机器人系统。

Abstract: Generative modeling-based visuomotor policies have been widely adopted in
robotic manipulation attributed to their ability to model multimodal action
distributions. However, the high inference cost of multi-step sampling limits
their applicability in real-time robotic systems. To address this issue,
existing approaches accelerate the sampling process in generative
modeling-based visuomotor policies by adapting acceleration techniques
originally developed for image generation. Despite this progress, a major
distinction remains: image generation typically involves producing independent
samples without temporal dependencies, whereas robotic manipulation involves
generating time-series action trajectories that require continuity and temporal
coherence. To effectively exploit temporal information in robotic manipulation,
we propose FreqPolicy, a novel approach that first imposes frequency
consistency constraints on flow-based visuomotor policies. Our work enables the
action model to capture temporal structure effectively while supporting
efficient, high-quality one-step action generation. We introduce a frequency
consistency constraint that enforces alignment of frequency-domain action
features across different timesteps along the flow, thereby promoting
convergence of one-step action generation toward the target distribution. In
addition, we design an adaptive consistency loss to capture structural temporal
variations inherent in robotic manipulation tasks. We assess FreqPolicy on 53
tasks across 3 simulation benchmarks, proving its superiority over existing
one-step action generators. We further integrate FreqPolicy into the
vision-language-action (VLA) model and achieve acceleration without performance
degradation on the 40 tasks of Libero. Besides, we show efficiency and
effectiveness in real-world robotic scenarios with an inference frequency
93.5Hz. The code will be publicly available.

</details>


### [67] [MoRE: Mixture of Residual Experts for Humanoid Lifelike Gaits Learning on Complex Terrains](https://arxiv.org/abs/2506.08840)
*Dewei Wang,Xinmiao Wang,Xinzhe Liu,Jiyuan Shi,Yingnan Zhao,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: 提出了一种基于混合潜在残差专家和多判别器的RL框架，用于训练人形机器人在复杂地形中以可控的拟人步态行走。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅适用于平坦地形且依赖本体感知，无法在复杂地形中实现拟人步态。

Method: 采用两阶段训练流程，先利用深度相机训练策略适应复杂地形，再通过步态奖励调整拟人行为。

Result: 仿真和实际实验表明，该框架在复杂地形中表现优异，并能无缝切换多种拟人步态。

Conclusion: 该框架成功解决了复杂地形中拟人步态的挑战，实现了高效且自然的机器人行走。

Abstract: Humanoid robots have demonstrated robust locomotion capabilities using
Reinforcement Learning (RL)-based approaches. Further, to obtain human-like
behaviors, existing methods integrate human motion-tracking or motion prior in
the RL framework. However, these methods are limited in flat terrains with
proprioception only, restricting their abilities to traverse challenging
terrains with human-like gaits. In this work, we propose a novel framework
using a mixture of latent residual experts with multi-discriminators to train
an RL policy, which is capable of traversing complex terrains in controllable
lifelike gaits with exteroception. Our two-stage training pipeline first
teaches the policy to traverse complex terrains using a depth camera, and then
enables gait-commanded switching between human-like gait patterns. We also
design gait rewards to adjust human-like behaviors like robot base height.
Simulation and real-world experiments demonstrate that our framework exhibits
exceptional performance in traversing complex terrains, and achieves seamless
transitions between multiple human-like gait patterns.

</details>


### [68] [Deploying SICNav in the Field: Safe and Interactive Crowd Navigation using MPC and Bilevel Optimization](https://arxiv.org/abs/2506.08851)
*Sepehr Samavi,Garvish Bhutani,Florian Shkurti,Angela P. Schoellig*

Main category: cs.RO

TL;DR: SICNav方法通过双层MPC框架将预测与规划结合，解决了机器人拥挤环境中导航的交互问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法忽视人机交互闭环，导致机器人可能卡住，需改进。

Method: 提出SICNav方法，结合预测与规划，显式建模多智能体交互。

Result: 在室内外环境中完成近7公里自主导航，初步验证有效性。

Conclusion: SICNav通过建模交互提升导航安全性和效率。

Abstract: Safe and efficient navigation in crowded environments remains a critical
challenge for robots that provide a variety of service tasks such as food
delivery or autonomous wheelchair mobility. Classical robot crowd navigation
methods decouple human motion prediction from robot motion planning, which
neglects the closed-loop interactions between humans and robots. This lack of a
model for human reactions to the robot plan (e.g. moving out of the way) can
cause the robot to get stuck. Our proposed Safe and Interactive Crowd
Navigation (SICNav) method is a bilevel Model Predictive Control (MPC)
framework that combines prediction and planning into one optimization problem,
explicitly modeling interactions among agents. In this paper, we present a
systems overview of the crowd navigation platform we use to deploy SICNav in
previously unseen indoor and outdoor environments. We provide a preliminary
analysis of the system's operation over the course of nearly 7 km of autonomous
navigation over two hours in both indoor and outdoor environments.

</details>


### [69] [Fast Estimation of Globally Optimal Independent Contact Regions for Robust Grasping and Manipulation](https://arxiv.org/abs/2506.08856)
*Jonathan P. King,Harnoor Ahluwalia,Michael Zhang,Nancy S. Pollard*

Main category: cs.RO

TL;DR: 提出了一种快速算法，用于计算全局最优的独立接触区域（ICRs），解决了ICRs计算复杂度高的问题，并在实验中显示出显著优势。


<details>
  <summary>Details</summary>
Motivation: ICRs的位置可以为抓取和操作规划、学习及策略转移提供指导，但由于计算复杂度高，现代应用中对ICRs的探索较少。

Method: 基于增量n维Delaunay三角剖分的分治算法，能够在实时规划时间内生成有界次优结果。

Result: 实验显示，该算法在抓取质量指标上优于竞争方法，速度提升100倍以上，并探索了基于ICRs的策略鲁棒性。

Conclusion: 该算法为ICRs的计算提供了高效解决方案，并为进一步的3D实现奠定了基础，代码将在发表后开源。

Abstract: This work presents a fast anytime algorithm for computing globally optimal
independent contact regions (ICRs). ICRs are regions such that one contact
within each region enables a valid grasp. Locations of ICRs can provide
guidance for grasp and manipulation planning, learning, and policy transfer.
However, ICRs for modern applications have been little explored, in part due to
the expense of computing them, as they have a search space exponential in the
number of contacts. We present a divide and conquer algorithm based on
incremental n-dimensional Delaunay triangulation that produces results with
bounded suboptimality in times sufficient for real-time planning. This paper
presents the base algorithm for grasps where contacts lie within a plane. Our
experiments show substantial benefits over competing grasp quality metrics and
speedups of 100X and more for competing approaches to computing ICRs. We
explore robustness of a policy guided by ICRs and outline a path to general 3D
implementation. Code will be released on publication to facilitate further
development and applications.

</details>


### [70] [MOMAV: A highly symmetrical fully-actuated multirotor drone using optimizing control allocation](https://arxiv.org/abs/2506.08868)
*Marco Ruggia*

Main category: cs.RO

TL;DR: MOMAV是一种全驱动、高度对称的多旋翼无人机，通过独特的八面体转子臂设计和主动旋转机制实现高效飞行。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够独立控制位置和方向的全驱动无人机，同时保持高飞行效率。

Method: 采用六臂八面体排列设计，每个臂可主动旋转，并使用基于SQP的控制分配算法。

Result: 飞行测试显示，MOMAV在位置和方向控制上表现出色，误差极低。

Conclusion: MOMAV的设计和控制算法有效实现了高效、精确的全驱动飞行。

Abstract: MOMAV (Marco's Omnidirectional Micro Aerial Vehicle) is a multirotor drone
that is fully actuated, meaning it can control its orientation independently of
its position. MOMAV is also highly symmetrical, making its flight efficiency
largely unaffected by its current orientation. These characteristics are
achieved by a novel drone design where six rotor arms align with the vertices
of an octahedron, and where each arm can actively rotate along its long axis.
Various standout features of MOMAV are presented: The high flight efficiency
compared to arm configuration of other fully-actuated drones, the design of an
original rotating arm assembly featuring slip-rings used to enable continuous
arm rotation, and a novel control allocation algorithm based on sequential
quadratic programming (SQP) used to calculate throttle and arm-angle setpoints
in flight. Flight tests have shown that MOMAV is able to achieve remarkably low
mean position/orientation errors of 6.6mm, 2.1{\deg} ({\sigma}: 3.0mm,
1.0{\deg}) when sweeping position setpoints, and 11.8mm, 3.3{\deg} ({\sigma}:
8.6mm, 2.0{\deg}) when sweeping orientation setpoints.

</details>


### [71] [Human-Robot Teaming Field Deployments: A Comparison Between Verbal and Non-verbal Communication](https://arxiv.org/abs/2506.08890)
*Tauhid Tanjim,Promise Ekpo,Huajie Cao,Jonathan St. George,Kevin Ching,Hee Rin Lee,Angelique Taylor*

Main category: cs.RO

TL;DR: 研究比较了机器人急救车（RCC）的语音与非语音通信方式对医护人员工作负荷和态度的影响，发现语音通信显著降低心理需求和努力。


<details>
  <summary>Details</summary>
Motivation: 医护人员在急救场景中快速获取医疗用品面临挑战，机器人急救车可能通过有效通信方式减少干扰并提高效率。

Method: 采用被试间实验设计，比较RCC的语音与非语音通信方式与传统急救车在复苏场景中的效果。

Result: 语音通信显著降低心理需求和努力，尽管与机器人合作时挫败感略高。

Conclusion: 研究为高风险环境中人机协作提供了重要启示，语音通信是更优选择。

Abstract: Healthcare workers (HCWs) encounter challenges in hospitals, such as
retrieving medical supplies quickly from crash carts, which could potentially
result in medical errors and delays in patient care. Robotic crash carts (RCCs)
have shown promise in assisting healthcare teams during medical tasks through
guided object searches and task reminders. Limited exploration has been done to
determine what communication modalities are most effective and least disruptive
to patient care in real-world settings. To address this gap, we conducted a
between-subjects experiment comparing the RCC's verbal and non-verbal
communication of object search with a standard crash cart in resuscitation
scenarios to understand the impact of robot communication on workload and
attitudes toward using robots in the workplace. Our findings indicate that
verbal communication significantly reduced mental demand and effort compared to
visual cues and with a traditional crash cart. Although frustration levels were
slightly higher during collaborations with the robot compared to a traditional
cart, these research insights provide valuable implications for human-robot
teamwork in high-stakes environments.

</details>


### [72] [CLONE: Closed-Loop Whole-Body Humanoid Teleoperation for Long-Horizon Tasks](https://arxiv.org/abs/2506.08931)
*Yixuan Li,Yutang Lin,Jieming Cui,Tengyu Liu,Wei Liang,Yixin Zhu,Siyuan Huang*

Main category: cs.RO

TL;DR: CLONE系统通过闭环误差校正实现高保真全身远程操作，解决了现有系统在协调性和定位漂移上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有远程操作系统在协调性和定位漂移上存在局限，限制了自然协调和长时间操作的精确性。

Method: 采用基于MoE的闭环误差校正系统，仅需MR头显的头手追踪数据。

Result: 实现了高保真全身远程操作，长时间轨迹中漂移极小，支持复杂协调动作。

Conclusion: CLONE为长时间人机交互任务中的全身远程操作设立了新里程碑。

Abstract: Humanoid teleoperation plays a vital role in demonstrating and collecting
data for complex humanoid-scene interactions. However, current teleoperation
systems face critical limitations: they decouple upper- and lower-body control
to maintain stability, restricting natural coordination, and operate open-loop
without real-time position feedback, leading to accumulated drift. The
fundamental challenge is achieving precise, coordinated whole-body
teleoperation over extended durations while maintaining accurate global
positioning. Here we show that an MoE-based teleoperation system, CLONE, with
closed-loop error correction enables unprecedented whole-body teleoperation
fidelity, maintaining minimal positional drift over long-range trajectories
using only head and hand tracking from an MR headset. Unlike previous methods
that either sacrifice coordination for stability or suffer from unbounded
drift, CLONE learns diverse motion skills while preventing tracking error
accumulation through real-time feedback, enabling complex coordinated movements
such as ``picking up objects from the ground.'' These results establish a new
milestone for whole-body humanoid teleoperation for long-horizon humanoid-scene
interaction tasks.

</details>
