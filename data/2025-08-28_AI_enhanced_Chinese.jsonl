{"id": "2508.19367", "categories": ["cs.RO", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.19367", "abs": "https://arxiv.org/abs/2508.19367", "authors": ["Alex Cuellar", "Ho Chit Siu", "Julie A Shah"], "title": "Inference of Human-derived Specifications of Object Placement via Demonstration", "comment": null, "summary": "As robots' manipulation capabilities improve for pick-and-place tasks (e.g.,\nobject packing, sorting, and kitting), methods focused on understanding\nhuman-acceptable object configurations remain limited expressively with regard\nto capturing spatial relationships important to humans. To advance robotic\nunderstanding of human rules for object arrangement, we introduce\npositionally-augmented RCC (PARCC), a formal logic framework based on region\nconnection calculus (RCC) for describing the relative position of objects in\nspace. Additionally, we introduce an inference algorithm for learning PARCC\nspecifications via demonstrations. Finally, we present the results from a human\nstudy, which demonstrate our framework's ability to capture a human's intended\nspecification and the benefits of learning from demonstration approaches over\nhuman-provided specifications.", "AI": {"tldr": "提出了PARCC框架，基于区域连接演算(RCC)的形式化逻辑系统，用于描述物体间的空间相对位置关系，并通过演示学习算法来推断人类可接受的物体配置规则。", "motivation": "当前机器人操作能力在拾取放置任务中有所提升，但理解人类可接受的物体配置方法在表达空间关系方面仍然有限，需要更好地捕捉对人类重要的空间关系规则。", "method": "开发了positionally-augmented RCC (PARCC)形式化逻辑框架，基于区域连接演算，并设计了通过演示学习PARCC规范的推理算法。", "result": "人类研究结果表明，该框架能够有效捕捉人类的意图规范，且演示学习方法优于人类直接提供的规范说明。", "conclusion": "PARCC框架为机器人理解人类物体排列规则提供了有效的形式化工具，演示学习方法在获取人类空间关系偏好方面表现出优越性。"}}
{"id": "2508.19380", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19380", "abs": "https://arxiv.org/abs/2508.19380", "authors": ["Diancheng Li", "Nia Ralston", "Bastiaan Hagen", "Phoebe Tan", "Matthew A. Robertson"], "title": "FlipWalker: Jacob's Ladder toy-inspired robot for locomotion across diverse, complex terrain", "comment": "2025 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS 2025)", "summary": "This paper introduces FlipWalker, a novel underactuated robot locomotion\nsystem inspired by Jacob's Ladder illusion toy, designed to traverse\nchallenging terrains where wheeled robots often struggle. Like the Jacob's\nLadder toy, FlipWalker features two interconnected segments joined by flexible\ncables, enabling it to pivot and flip around singularities in a manner\nreminiscent of the toy's cascading motion. Actuation is provided by\nmotor-driven legs within each segment that push off either the ground or the\nopposing segment, depending on the robot's current configuration. A\nphysics-based model of the underactuated flipping dynamics is formulated to\nelucidate the critical design parameters governing forward motion and obstacle\nclearance or climbing. The untethered prototype weighs 0.78 kg, achieves a\nmaximum flipping speed of 0.2 body lengths per second. Experimental trials on\nartificial grass, river rocks, and snow demonstrate that FlipWalker's flipping\nstrategy, which relies on ground reaction forces applied normal to the surface,\noffers a promising alternative to traditional locomotion for navigating\nirregular outdoor terrain.", "AI": {"tldr": "FlipWalker是一种受雅各布天梯玩具启发的欠驱动机器人系统，通过翻转运动在复杂地形中移动，比轮式机器人更具优势", "motivation": "轮式机器人在不规则户外地形中表现不佳，需要一种新的运动策略来应对草地、岩石和雪地等挑战性环境", "method": "采用两段式结构通过柔性电缆连接，模仿雅各布天梯玩具的级联运动。每个段内的电机驱动腿根据配置推动地面或相对段，基于物理模型设计翻转动力学", "result": "原型机重0.78kg，最大翻转速度达0.2体长/秒，在人工草地、河石和雪地等不同地形上成功验证了运动性能", "conclusion": "FlipWalker的翻转策略依靠垂直于表面的地面反作用力，为不规则户外地形的导航提供了有前景的传统运动替代方案"}}
{"id": "2508.19391", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19391", "abs": "https://arxiv.org/abs/2508.19391", "authors": ["Chaoran Zhu", "Hengyi Wang", "Yik Lung Pang", "Changjae Oh"], "title": "LaVA-Man: Learning Visual Action Representations for Robot Manipulation", "comment": null, "summary": "Visual-textual understanding is essential for language-guided robot\nmanipulation. Recent works leverage pre-trained vision-language models to\nmeasure the similarity between encoded visual observations and textual\ninstructions, and then train a model to map this similarity to robot actions.\nHowever, this two-step approach limits the model to capture the relationship\nbetween visual observations and textual instructions, leading to reduced\nprecision in manipulation tasks. We propose to learn visual-textual\nassociations through a self-supervised pretext task: reconstructing a masked\ngoal image conditioned on an input image and textual instructions. This\nformulation allows the model to learn visual-action representations without\nrobot action supervision. The learned representations can then be fine-tuned\nfor manipulation tasks with only a few demonstrations. We also introduce the\n\\textit{Omni-Object Pick-and-Place} dataset, which consists of annotated robot\ntabletop manipulation episodes, including 180 object classes and 3,200\ninstances with corresponding textual instructions. This dataset enables the\nmodel to acquire diverse object priors and allows for a more comprehensive\nevaluation of its generalisation capability across object instances.\nExperimental results on the five benchmarks, including both simulated and\nreal-robot validations, demonstrate that our method outperforms prior art.", "AI": {"tldr": "提出了一种通过自监督预训练任务学习视觉-文本关联的方法，通过重构被遮挡的目标图像来学习视觉-动作表示，无需机器人动作监督，然后在少量演示样本上微调用于操作任务。", "motivation": "现有的两步方法（先编码视觉观察和文本指令的相似度，再映射到机器人动作）限制了模型捕捉视觉观察和文本指令之间的关系，导致操作任务精度降低。", "method": "使用自监督预训练任务：基于输入图像和文本指令重构被遮挡的目标图像，学习视觉-文本关联。然后使用少量演示样本对学习到的表示进行微调用于操作任务。", "result": "在五个基准测试（包括仿真和真实机器人验证）上，该方法优于现有技术。", "conclusion": "通过自监督预训练学习视觉-文本关联的方法有效提升了语言引导机器人操作的性能，且只需少量演示样本即可微调用于具体任务。"}}
{"id": "2508.19425", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19425", "abs": "https://arxiv.org/abs/2508.19425", "authors": ["John M. Scanlon", "Timothy L McMurry", "Yin-Hsiu Chen", "Kristofer D. Kusano", "Trent Victor"], "title": "From Stoplights to On-Ramps: A Comprehensive Set of Crash Rate Benchmarks for Freeway and Surface Street ADS Evaluation", "comment": null, "summary": "This paper presents crash rate benchmarks for evaluating US-based Automated\nDriving Systems (ADS) for multiple urban areas. The purpose of this study was\nto extend prior benchmarks focused only on surface streets to additionally\ncapture freeway crash risk for future ADS safety performance assessments. Using\npublicly available police-reported crash and vehicle miles traveled (VMT) data,\nthe methodology details the isolation of in-transport passenger vehicles, road\ntype classification, and crash typology. Key findings revealed that freeway\ncrash rates exhibit large geographic dependence variations with\nany-injury-reported crash rates being nearly 3.5 times higher in Atlanta (2.4\nIPMM; the highest) when compared to Phoenix (0.7 IPMM; the lowest). The results\nshow the critical need for location-specific benchmarks to avoid biased safety\nevaluations and provide insights into the vehicle miles traveled (VMT) required\nto achieve statistical significance for various safety impact levels. The\ndistribution of crash types depended on the outcome severity level. Higher\nseverity outcomes (e.g., fatal crashes) had a larger proportion of\nsingle-vehicle, vulnerable road users (VRU), and opposite-direction collisions\ncompared to lower severity (police-reported) crashes. Given heterogeneity in\ncrash types by severity, performance in low-severity scenarios may not be\npredictive of high-severity outcomes. These benchmarks are additionally used to\nquantify at the required mileage to show statistically significant deviations\nfrom human performance. This is the first paper to generate freeway-specific\nbenchmarks for ADS evaluation and provides a foundational framework for future\nADS benchmarking by evaluators and developers.", "AI": {"tldr": "本文提出了美国自动驾驶系统(ADS)的出突率基准，特别关注高速公路出突风险评估，发现不同地区存在显著差异，并量化了评估ADS安全性所需的量产量要求。", "motivation": "扩展以前仅聚焦城市道路的出突率基准，需要包含高速公路出突风险评估，以更全面地评估自动驾驶系统的安全性能。", "method": "利用公开的警察报告出突数据和车辆行驶里程(VMT)数据，进行在运客车分离、路网类型分类和出突类型分析。", "result": "发现高速公路出突率存在显著地域差异，亚特兰大与凤凰城的伤害出突率相差3.5倍；不同严重程度出突的类型分布不同，低严重性能无法预测高严重性能。", "conclusion": "需要基于具体位置的基准来避免偏差的安全性评估，本研究提供了首个高速公路特定的ADS评估基准框架，为开发者和评估者提供了基础支持。"}}
{"id": "2508.19429", "categories": ["cs.RO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2508.19429", "abs": "https://arxiv.org/abs/2508.19429", "authors": ["Gustavo A. Cardona", "Kaier Liang", "Cristian-Ioan Vasile"], "title": "An Iterative Approach for Heterogeneous Multi-Agent Route Planning with Resource Transportation Uncertainty and Temporal Logic Goals", "comment": null, "summary": "This paper presents an iterative approach for heterogeneous multi-agent route\nplanning in environments with unknown resource distributions. We focus on a\nteam of robots with diverse capabilities tasked with executing missions\nspecified using Capability Temporal Logic (CaTL), a formal framework built on\nSignal Temporal Logic to handle spatial, temporal, capability, and resource\nconstraints. The key challenge arises from the uncertainty in the initial\ndistribution and quantity of resources in the environment. To address this, we\nintroduce an iterative algorithm that dynamically balances exploration and task\nfulfillment. Robots are guided to explore the environment, identifying resource\nlocations and quantities while progressively refining their understanding of\nthe resource landscape. At the same time, they aim to maximally satisfy the\nmission objectives based on the current information, adapting their strategies\nas new data is uncovered. This approach provides a robust solution for planning\nin dynamic, resource-constrained environments, enabling efficient coordination\nof heterogeneous teams even under conditions of uncertainty. Our method's\neffectiveness and performance are demonstrated through simulated case studies.", "AI": {"tldr": "提出了一种迭代方法用于未知资源分布环境中的异构多智能体路径规划，通过动态平衡探索和任务执行来处理资源不确定性。", "motivation": "解决异构机器人团队在未知资源分布环境中执行复杂任务时的规划挑战，特别是处理资源初始分布和数量的不确定性。", "method": "使用基于信号时序逻辑的能力时序逻辑(CaTL)来规范任务，开发迭代算法动态平衡环境探索和任务完成，机器人根据当前信息逐步完善对资源环境的理解并调整策略。", "result": "通过模拟案例研究证明了方法的有效性和性能，能够在动态资源受限环境中实现异构团队的高效协调。", "conclusion": "该方法为不确定条件下的异构多智能体规划提供了鲁棒解决方案，能够有效处理资源不确定性并实现任务目标的最大化满足。"}}
{"id": "2508.19476", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19476", "abs": "https://arxiv.org/abs/2508.19476", "authors": ["Dane Brouwer", "Joshua Citron", "Heather Nolte", "Jeannette Bohg", "Mark Cutkosky"], "title": "Gentle Object Retraction in Dense Clutter Using Multimodal Force Sensing and Imitation Learning", "comment": "Submitted to IEEE Robotics and Automation Letters (RA-L)", "summary": "Dense collections of movable objects are common in everyday spaces -- from\ncabinets in a home to shelves in a warehouse. Safely retracting objects from\nsuch collections is difficult for robots, yet people do it easily, using\nnon-prehensile tactile sensing on the sides and backs of their hands and arms.\nWe investigate the role of such sensing for training robots to gently reach\ninto constrained clutter and extract objects. The available sensing modalities\nare (1) \"eye-in-hand\" vision, (2) proprioception, (3) non-prehensile triaxial\ntactile sensing, (4) contact wrenches estimated from joint torques, and (5) a\nmeasure of successful object acquisition obtained by monitoring the vacuum line\nof a suction cup. We use imitation learning to train policies from a set of\ndemonstrations on randomly generated scenes, then conduct an ablation study of\nwrench and tactile information. We evaluate each policy's performance across 40\nunseen environment configurations. Policies employing any force sensing show\nfewer excessive force failures, an increased overall success rate, and faster\ncompletion times. The best performance is achieved using both tactile and\nwrench information, producing an 80% improvement above the baseline without\nforce information.", "AI": {"tldr": "研究探索了非抓取触觉传感在机器人从密集物体集合中安全提取物体的作用，通过模仿学习训练策略，发现力传感显著提升性能", "motivation": "日常空间中密集可移动物体集合很常见，机器人安全提取这些物体很困难，而人类通过手和手臂的非抓取触觉传感能轻松完成", "method": "使用模仿学习从随机生成场景的演示中训练策略，对比五种传感模态：手眼视觉、本体感觉、三轴触觉传感、关节力矩估计的接触力矩、真空吸盘成功获取物体的测量", "result": "使用任何力传感的策略都表现出更少的过度力失败、更高的总体成功率和更快的完成时间。同时使用触觉和力矩信息获得最佳性能，比无力信息基线提升80%", "conclusion": "非抓取触觉传感对于机器人安全地从受限杂乱环境中提取物体至关重要，力传感信息显著改善了机器人操作的性能和安全性"}}
{"id": "2508.19508", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.19508", "abs": "https://arxiv.org/abs/2508.19508", "authors": ["Tian Qiu", "Alan Zoubi", "Yiyuan Lin", "Ruiming Du", "Lailiang Cheng", "Yu Jiang"], "title": "DATR: Diffusion-based 3D Apple Tree Reconstruction Framework with Sparse-View", "comment": null, "summary": "Digital twin applications offered transformative potential by enabling\nreal-time monitoring and robotic simulation through accurate virtual replicas\nof physical assets. The key to these systems is 3D reconstruction with high\ngeometrical fidelity. However, existing methods struggled under field\nconditions, especially with sparse and occluded views. This study developed a\ntwo-stage framework (DATR) for the reconstruction of apple trees from sparse\nviews. The first stage leverages onboard sensors and foundation models to\nsemi-automatically generate tree masks from complex field images. Tree masks\nare used to filter out background information in multi-modal data for the\nsingle-image-to-3D reconstruction at the second stage. This stage consists of a\ndiffusion model and a large reconstruction model for respective multi view and\nimplicit neural field generation. The training of the diffusion model and LRM\nwas achieved by using realistic synthetic apple trees generated by a Real2Sim\ndata generator. The framework was evaluated on both field and synthetic\ndatasets. The field dataset includes six apple trees with field-measured ground\ntruth, while the synthetic dataset featured structurally diverse trees.\nEvaluation results showed that our DATR framework outperformed existing 3D\nreconstruction methods across both datasets and achieved domain-trait\nestimation comparable to industrial-grade stationary laser scanners while\nimproving the throughput by $\\sim$360 times, demonstrating strong potential for\nscalable agricultural digital twin systems.", "AI": {"tldr": "提出DATR两阶段框架，通过扩散模型和大型重建模型从稀疏视图重建苹果树3D模型，在真实和合成数据集上均优于现有方法，吞吐量提升360倍", "motivation": "数字孪生应用需要高精度3D重建，但现有方法在野外稀疏和遮挡视图条件下表现不佳，特别是针对苹果树等复杂农业场景", "method": "两阶段框架：第一阶段使用机载传感器和基础模型半自动生成树掩码；第二阶段使用扩散模型生成多视图，大型重建模型生成隐式神经场，基于Real2Sim生成器合成的逼真苹果树数据进行训练", "result": "在真实和合成数据集上均优于现有3D重建方法，域特征估计达到工业级固定激光扫描仪水平，吞吐量提升约360倍", "conclusion": "DATR框架展示了可扩展农业数字孪生系统的强大潜力，能够从稀疏视图实现高质量的苹果树3D重建"}}
{"id": "2508.19595", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.19595", "abs": "https://arxiv.org/abs/2508.19595", "authors": ["Maryam Kazemi Eskeri", "Thomas Wiedemann", "Ville Kyrki", "Dominik Baumann", "Tomasz Piotr Kucner"], "title": "A Lightweight Crowd Model for Robot Social Navigation", "comment": "7 pages, 6 figures, accepted in ECMR 2025", "summary": "Robots operating in human-populated environments must navigate safely and\nefficiently while minimizing social disruption. Achieving this requires\nestimating crowd movement to avoid congested areas in real-time. Traditional\nmicroscopic models struggle to scale in dense crowds due to high computational\ncost, while existing macroscopic crowd prediction models tend to be either\noverly simplistic or computationally intensive. In this work, we propose a\nlightweight, real-time macroscopic crowd prediction model tailored for human\nmotion, which balances prediction accuracy and computational efficiency. Our\napproach simplifies both spatial and temporal processing based on the inherent\ncharacteristics of pedestrian flow, enabling robust generalization without the\noverhead of complex architectures. We demonstrate a 3.6 times reduction in\ninference time, while improving prediction accuracy by 3.1 %. Integrated into a\nsocially aware planning framework, the model enables efficient and socially\ncompliant robot navigation in dynamic environments. This work highlights that\nefficient human crowd modeling enables robots to navigate dense environments\nwithout costly computations.", "AI": {"tldr": "这篇论文提出了一种轻量级的实时宏观流动预测模型，用于人群运动预测，在保持准确性的同时大幅提升计算效率，从而支持机器人在密集环境中的社交式导航。", "motivation": "传统微观模型在密集人群中计算成本高，而现有宏观模型要么过于简单要么计算量大，需要找到预测准确性和计算效率之间的平衡。", "method": "基于行人流的内在特性，简化空间和时间处理，设计了一种轻量级实时宏观人群预测模型，无需复杂的架构即可实现稳健的泛化能力。", "result": "模型实现了推理时间减少3.6倍，同时预测准确性提高3.1%，集成到社交式规划框架后，能够支持机器人在动态环境中高效且社交合规的导航。", "conclusion": "这项工作证明，通过高效的人群建模技术，机器人可以在不需要高成本计算的情况下完成密集环境中的导航任务。"}}
{"id": "2508.19607", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19607", "abs": "https://arxiv.org/abs/2508.19607", "authors": ["Amin Berjaoui Tahmaz", "Ravi Prakash", "Jens Kober"], "title": "Impedance Primitive-augmented Hierarchical Reinforcement Learning for Sequential Tasks", "comment": "This article is accepted for publication in IEEE International\n  Conference on Robotics and Automation (ICRA) 2025", "summary": "This paper presents an Impedance Primitive-augmented hierarchical\nreinforcement learning framework for efficient robotic manipulation in\nsequential contact tasks. We leverage this hierarchical structure to\nsequentially execute behavior primitives with variable stiffness control\ncapabilities for contact tasks. Our proposed approach relies on three key\ncomponents: an action space enabling variable stiffness control, an adaptive\nstiffness controller for dynamic stiffness adjustments during primitive\nexecution, and affordance coupling for efficient exploration while encouraging\ncompliance. Through comprehensive training and evaluation, our framework learns\nefficient stiffness control capabilities and demonstrates improvements in\nlearning efficiency, compositionality in primitive selection, and success rates\ncompared to the state-of-the-art. The training environments include block\nlifting, door opening, object pushing, and surface cleaning. Real world\nevaluations further confirm the framework's sim2real capability. This work lays\nthe foundation for more adaptive and versatile robotic manipulation systems,\nwith potential applications in more complex contact-based tasks.", "AI": {"tldr": "提出了一种基于阻抗原语的层次强化学习框架，用于序列接触任务中的高效机器人操作，通过可变刚度控制和仿射耦合实现更好的学习效率和成功率。", "motivation": "为了解决序列接触任务中机器人操作的效率和适应性挑战，需要开发能够动态调整刚度并有效探索接触行为的控制框架。", "method": "采用层次强化学习结构，包含三个关键组件：支持可变刚度控制的动作空间、自适应刚度控制器、以及用于高效探索的仿射耦合机制。", "result": "在方块抓取、开门、物体推动和表面清洁等任务中，相比现有技术表现出更好的学习效率、原语组合性和成功率，并验证了sim2real能力。", "conclusion": "该框架为更自适应和通用的机器人操作系统奠定了基础，在复杂接触任务中具有应用潜力。"}}
{"id": "2508.19608", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19608", "abs": "https://arxiv.org/abs/2508.19608", "authors": ["Dongjae Lee", "Byeongjun Kim", "H. Jin Kim"], "title": "Autonomous Aerial Manipulation at Arbitrary Pose in SE(3) with Robust Control and Whole-body Planning", "comment": null, "summary": "Aerial manipulators based on conventional multirotors can conduct\nmanipulation only in small roll and pitch angles due to the underactuatedness\nof the multirotor base. If the multirotor base is capable of hovering at\narbitrary orientation, the robot can freely locate itself at any point in\n$\\mathsf{SE}(3)$, significantly extending its manipulation workspace and\nenabling a manipulation task that was originally not viable. In this work, we\npresent a geometric robust control and whole-body motion planning framework for\nan omnidirectional aerial manipulator (OAM). To maximize the strength of OAM,\nwe first propose a geometric robust controller for a floating base. Since the\nmotion of the robotic arm and the interaction forces during manipulation affect\nthe stability of the floating base, the base should be capable of mitigating\nthese adverse effects while controlling its 6D pose. We then design a two-step\noptimization-based whole-body motion planner, jointly considering the pose of\nthe floating base and the joint angles of the robotic arm to harness the entire\nconfiguration space. The devised two-step approach facilitates real-time\napplicability and enhances convergence of the optimization problem with\nnon-convex and non-Euclidean search space. The proposed approach enables the\nbase to be stationary at any 6D pose while autonomously carrying out\nsophisticated manipulation near obstacles without any collision. We demonstrate\nthe effectiveness of the proposed framework through experiments in which an OAM\nperforms grasping and pulling of an object in multiple scenarios, including\nnear $90^\\circ$ and even $180^\\circ$ pitch angles.", "AI": {"tldr": "基于多旋翼的空中操作器只能在小角度操作，本文提出了一种全向空中操作器的几何稳定控制和全身运动规划框架，能够在任意6D姿态空中想停并执行复杂操作任务。", "motivation": "传统多旋翼基础的空中操作器因为基底的不充分驱动性，只能在小角度的滚转和俯仰角度下进行操作，限制了工作空间和任务能力。如果能够在任意方位空中想停，将大大扩展操作能力。", "method": "首先提出了一种基于浮动基底的几何稳定控制器，能够应对机械手臂运动和交互力的影响。然后设计了一个两步优化的全身运动规划器，统筹考虑浮动基底的姿态和机械手关节角度，以利用整个配置空间。", "result": "该方法能够使基底在任意6D姿态下稳定停泊，并在避免碰撞的情况下自主执行复杂操作。通过实验验证，空中操作器能够在近90度甚至180度俯仰角度的场景中成功执行抓取和拉勘任务。", "conclusion": "本文提出的全向空中操作器控制和规划框架有效扩展了空中操作的工作空间和能力，能够在极端姿态下完成之前无法实现的操作任务，为空中操作领域提供了新的解决方案。"}}
{"id": "2508.19684", "categories": ["cs.RO", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2508.19684", "abs": "https://arxiv.org/abs/2508.19684", "authors": ["Ghadeer Elmkaiel", "Syn Schmitt", "Michael Muehlebach"], "title": "Embodied Intelligence for Sustainable Flight: A Soaring Robot with Active Morphological Control", "comment": null, "summary": "Achieving both agile maneuverability and high energy efficiency in aerial\nrobots, particularly in dynamic wind environments, remains challenging.\nConventional thruster-powered systems offer agility but suffer from high energy\nconsumption, while fixed-wing designs are efficient but lack hovering and\nmaneuvering capabilities. We present Floaty, a shape-changing robot that\novercomes these limitations by passively soaring, harnessing wind energy\nthrough intelligent morphological control inspired by birds. Floaty's design is\noptimized for passive stability, and its control policy is derived from an\nexperimentally learned aerodynamic model, enabling precise attitude and\nposition control without active propulsion. Wind tunnel experiments demonstrate\nFloaty's ability to hover, maneuver, and reject disturbances in vertical\nairflows up to 10 m/s. Crucially, Floaty achieves this with a specific power\nconsumption of 10 W/kg, an order of magnitude lower than thruster-powered\nsystems. This introduces a paradigm for energy-efficient aerial robotics,\nleveraging morphological intelligence and control to operate sustainably in\nchallenging wind conditions.", "AI": {"tldr": "Floaty是一种形状可变机器人，通过模仿鸟类的智能形态控制被动利用风能，在10m/s垂直气流中实现悬停和机动，能耗比推进器系统低一个数量级。", "motivation": "解决空中机器人同时实现敏捷机动性和高能效的挑战，特别是在动态风环境中。传统推进器系统能耗高，固定翼设计缺乏悬停能力。", "method": "采用形状变化设计，通过实验学习的气动模型进行智能形态控制，实现被动稳定性和精确姿态位置控制，无需主动推进。", "result": "风洞实验显示Floaty能在10m/s垂直气流中悬停、机动和抗干扰，比功率消耗仅为10W/kg，比推进器系统低一个数量级。", "conclusion": "Floaty引入了能效空中机器人的新范式，利用形态智能和控制技术在挑战性风条件下可持续运行。"}}
{"id": "2508.19731", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19731", "abs": "https://arxiv.org/abs/2508.19731", "authors": ["Maryam Kazemi Eskeri", "Ville Kyrki", "Dominik Baumann", "Tomasz Piotr Kucner"], "title": "Efficient Human-Aware Task Allocation for Multi-Robot Systems in Shared Environments", "comment": "7 Pages, 4 Figures, Accepted in IROS2025", "summary": "Multi-robot systems are increasingly deployed in applications, such as\nintralogistics or autonomous delivery, where multiple robots collaborate to\ncomplete tasks efficiently. One of the key factors enabling their efficient\ncooperation is Multi-Robot Task Allocation (MRTA). Algorithms solving this\nproblem optimize task distribution among robots to minimize the overall\nexecution time. In shared environments, apart from the relative distance\nbetween the robots and the tasks, the execution time is also significantly\nimpacted by the delay caused by navigating around moving people. However, most\nexisting MRTA approaches are dynamics-agnostic, relying on static maps and\nneglecting human motion patterns, leading to inefficiencies and delays. In this\npaper, we introduce \\acrfull{method name}. This method leverages Maps of\nDynamics (MoDs), spatio-temporal queryable models designed to capture\nhistorical human movement patterns, to estimate the impact of humans on the\ntask execution time during deployment. \\acrshort{method name} utilizes a\nstochastic cost function that includes MoDs. Experimental results show that\nintegrating MoDs enhances task allocation performance, resulting in reduced\nmission completion times by up to $26\\%$ compared to the dynamics-agnostic\nmethod and up to $19\\%$ compared to the baseline. This work underscores the\nimportance of considering human dynamics in MRTA within shared environments and\npresents an efficient framework for deploying multi-robot systems in\nenvironments populated by humans.", "AI": {"tldr": "提出了一种考虑人类动态的多机器人任务分配方法，利用动态地图(MoDs)来预测人类移动对任务执行时间的影响，显著提高了多机器人系统在共享环境中的效率。", "motivation": "现有的多机器人任务分配(MRTA)方法大多忽略人类动态，仅依赖静态地图，导致在共享环境中效率低下和延迟。人类移动模式对任务执行时间有显著影响，需要动态感知的分配策略。", "method": "提出了基于动态地图(MoDs)的方法，MoDs是可查询时空历史人类移动模式的模型。使用包含MoDs的随机成本函数来估计人类对任务执行时间的影响，从而优化任务分配。", "result": "实验结果显示，集成MoDs的方法相比动态无关方法减少了高达26%的任务完成时间，相比基线方法减少了高达19%的任务完成时间。", "conclusion": "这项工作强调了在共享环境的多机器人任务分配中考虑人类动态的重要性，为在人类密集环境中部署多机器人系统提供了高效框架。"}}
{"id": "2508.19771", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19771", "abs": "https://arxiv.org/abs/2508.19771", "authors": ["Liding Zhang", "Zhenshan Bing", "Yu Zhang", "Kuanqi Cai", "Lingyun Chen", "Fan Wu", "Sami Haddadin", "Alois Knoll"], "title": "Elliptical K-Nearest Neighbors -- Path Optimization via Coulomb's Law and Invalid Vertices in C-space Obstacles", "comment": "2024 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS)", "summary": "Path planning has long been an important and active research area in\nrobotics. To address challenges in high-dimensional motion planning, this study\nintroduces the Force Direction Informed Trees (FDIT*), a sampling-based planner\ndesigned to enhance speed and cost-effectiveness in pathfinding. FDIT* builds\nupon the state-of-the-art informed sampling planner, the Effort Informed Trees\n(EIT*), by capitalizing on often-overlooked information in invalid vertices. It\nincorporates principles of physical force, particularly Coulomb's law. This\napproach proposes the elliptical $k$-nearest neighbors search method, enabling\nfast convergence navigation and avoiding high solution cost or infeasible paths\nby exploring more problem-specific search-worthy areas. It demonstrates\nbenefits in search efficiency and cost reduction, particularly in confined,\nhigh-dimensional environments. It can be viewed as an extension of nearest\nneighbors search techniques. Fusing invalid vertex data with physical dynamics\nfacilitates force-direction-based search regions, resulting in an improved\nconvergence rate to the optimum. FDIT* outperforms existing single-query,\nsampling-based planners on the tested problems in R^4 to R^16 and has been\ndemonstrated on a real-world mobile manipulation task.", "AI": {"tldr": "FDIT*是一种基于采样的路径规划算法，通过利用无效顶点信息和库仑定律物理原理，在EIT*基础上改进搜索效率和解成本，在高维空间中表现优异。", "motivation": "解决高维运动规划中的挑战，利用传统规划器中常被忽视的无效顶点信息，结合物理力原理来提高路径规划的效率和成本效益。", "method": "基于EIT*算法，引入库仑定律物理原理，提出椭圆k近邻搜索方法，通过力方向引导搜索区域，利用无效顶点数据改进搜索策略。", "result": "在R^4到R^16的高维环境中，FDIT*在搜索效率和路径成本方面优于现有的单查询采样规划器，并在真实移动操作任务中得到验证。", "conclusion": "FDIT*通过融合无效顶点信息和物理动力学原理，实现了更快的收敛速度和更优的路径成本，特别适用于受限高维环境中的路径规划问题。"}}
{"id": "2508.19776", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19776", "abs": "https://arxiv.org/abs/2508.19776", "authors": ["Liding Zhang", "Yao Ling", "Zhenshan Bing", "Fan Wu", "Sami Haddadin", "Alois Knoll"], "title": "Tree-Based Grafting Approach for Bidirectional Motion Planning with Local Subsets Optimization", "comment": "IEEE Robotics and Automation Letters (also presented at IEEE-IROS\n  2025)", "summary": "Bidirectional motion planning often reduces planning time compared to its\nunidirectional counterparts. It requires connecting the forward and reverse\nsearch trees to form a continuous path. However, this process could fail and\nrestart the asymmetric bidirectional search due to the limitations of\nlazy-reverse search. To address this challenge, we propose Greedy GuILD\nGrafting Trees (G3T*), a novel path planner that grafts invalid edge\nconnections at both ends to re-establish tree-based connectivity, enabling\nrapid path convergence. G3T* employs a greedy approach using the minimum\nLebesgue measure of guided incremental local densification (GuILD) subsets to\noptimize paths efficiently. Furthermore, G3T* dynamically adjusts the sampling\ndistribution between the informed set and GuILD subsets based on historical and\ncurrent cost improvements, ensuring asymptotic optimality. These features\nenhance the forward search's growth towards the reverse tree, achieving faster\nconvergence and lower solution costs. Benchmark experiments across dimensions\nfrom R^2 to R^8 and real-world robotic evaluations demonstrate G3T*'s superior\nperformance compared to existing single-query sampling-based planners. A video\nshowcasing our experimental results is available at:\nhttps://youtu.be/3mfCRL5SQIU", "AI": {"tldr": "G3T*是一种新颖的双向运动规划算法，通过贪婪嫁接无效边连接来重建树连接性，实现快速路径收敛和渐近最优性", "motivation": "传统双向运动规划中，前向和反向搜索树的连接可能失败，导致需要重启非对称双向搜索，限制了规划效率", "method": "采用贪婪方法，使用GuILD子集的最小Lebesgue测度来优化路径，动态调整采样分布，嫁接无效边连接以重建树连接性", "result": "在R^2到R^8维度的基准实验和真实机器人评估中，G3T*相比现有单查询采样规划器表现出更优越的性能", "conclusion": "G3T*通过创新的嫁接机制和动态采样策略，显著提高了双向运动规划的收敛速度和解决方案质量"}}
{"id": "2508.19788", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.19788", "abs": "https://arxiv.org/abs/2508.19788", "authors": ["Sena Ishii", "Akash Chikhalikar", "Ankit A. Ravankar", "Jose Victorio Salazar Luces", "Yasuhisa Hirata"], "title": "Context-Aware Risk Estimation in Home Environments: A Probabilistic Framework for Service Robots", "comment": "8 pages, Accepted for IEEE RO-MAN 2025 Conference", "summary": "We present a novel framework for estimating accident-prone regions in\neveryday indoor scenes, aimed at improving real-time risk awareness in service\nrobots operating in human-centric environments. As robots become integrated\ninto daily life, particularly in homes, the ability to anticipate and respond\nto environmental hazards is crucial for ensuring user safety, trust, and\neffective human-robot interaction. Our approach models object-level risk and\ncontext through a semantic graph-based propagation algorithm. Each object is\nrepresented as a node with an associated risk score, and risk propagates\nasymmetrically from high-risk to low-risk objects based on spatial proximity\nand accident relationship. This enables the robot to infer potential hazards\neven when they are not explicitly visible or labeled. Designed for\ninterpretability and lightweight onboard deployment, our method is validated on\na dataset with human-annotated risk regions, achieving a binary risk detection\naccuracy of 75%. The system demonstrates strong alignment with human\nperception, particularly in scenes involving sharp or unstable objects. These\nresults underline the potential of context-aware risk reasoning to enhance\nrobotic scene understanding and proactive safety behaviors in shared\nhuman-robot spaces. This framework could serve as a foundation for future\nsystems that make context-driven safety decisions, provide real-time alerts, or\nautonomously assist users in avoiding or mitigating hazards within home\nenvironments.", "AI": {"tldr": "提出了一种基于语义图传播算法的室内场景事故风险区域估计框架，通过对象级风险评估和上下文传播来提升服务机器人的风险感知能力", "motivation": "随着机器人融入日常生活，特别是在家庭环境中，预测和应对环境风险对于确保用户安全、信任和有效人机交互至关重要", "method": "采用语义图传播算法，将每个对象表示为带有风险分数的节点，基于空间邻近性和事故关系进行不对称风险传播", "result": "在人工标注风险区域数据集上验证，二元风险检测准确率达到75%，在涉及尖锐或不稳定物体的场景中与人类感知高度一致", "conclusion": "该框架展示了上下文感知风险推理在增强机器人场景理解和主动安全行为方面的潜力，可为未来实时警报和自主避险系统奠定基础"}}
{"id": "2508.19790", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19790", "abs": "https://arxiv.org/abs/2508.19790", "authors": ["Liding Zhang", "Sicheng Wang", "Kuanqi Cai", "Zhenshan Bing", "Fan Wu", "Chaoqun Wang", "Sami Haddadin", "Alois Knoll"], "title": "APT*: Asymptotically Optimal Motion Planning via Adaptively Prolated Elliptical R-Nearest Neighbors", "comment": null, "summary": "Optimal path planning aims to determine a sequence of states from a start to\na goal while accounting for planning objectives. Popular methods often\nintegrate fixed batch sizes and neglect information on obstacles, which is not\nproblem-specific. This study introduces Adaptively Prolated Trees (APT*), a\nnovel sampling-based motion planner that extends based on Force Direction\nInformed Trees (FDIT*), integrating adaptive batch-sizing and elliptical\n$r$-nearest neighbor modules to dynamically modulate the path searching process\nbased on environmental feedback. APT* adjusts batch sizes based on the\nhypervolume of the informed sets and considers vertices as electric charges\nthat obey Coulomb's law to define virtual forces via neighbor samples, thereby\nrefining the prolate nearest neighbor selection. These modules employ\nnon-linear prolate methods to adaptively adjust the electric charges of\nvertices for force definition, thereby improving the convergence rate with\nlower solution costs. Comparative analyses show that APT* outperforms existing\nsingle-query sampling-based planners in dimensions from $\\mathbb{R}^4$ to\n$\\mathbb{R}^{16}$, and it was further validated through a real-world robot\nmanipulation task. A video showcasing our experimental results is available at:\nhttps://youtu.be/gCcUr8LiEw4", "AI": {"tldr": "APT*是一种新型采样运动规划器，通过自适应批量大小和椭圆最近邻模块动态调整路径搜索过程，在4-16维空间中优于现有单查询采样规划器", "motivation": "现有路径规划方法通常使用固定批量大小且忽略障碍物信息，缺乏问题特异性，需要更智能的自适应规划方法", "method": "扩展FDIT*算法，集成自适应批量调整和椭圆r最近邻模块，将顶点视为遵循库仑定律的电荷来定义虚拟力，使用非线性方法自适应调整电荷", "result": "APT*在R4到R16维度空间中优于现有单查询采样规划器，收敛速度更快且解成本更低，并在真实机器人操作任务中得到验证", "conclusion": "APT*通过自适应机制和环境反馈显著提升了路径规划性能，为高维运动规划提供了有效解决方案"}}
{"id": "2508.19816", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19816", "abs": "https://arxiv.org/abs/2508.19816", "authors": ["Ricardo J. Manríquez-Cisterna", "Ankit A. Ravankar", "Jose V. Salazar Luces", "Takuro Hatsukari", "Yasuhisa Hirata"], "title": "A Standing Support Mobility Robot for Enhancing Independence in Elderly Daily Living", "comment": "7 pages, accepted work for IEEE RO-MAN2025", "summary": "This paper presents a standing support mobility robot \"Moby\" developed to\nenhance independence and safety for elderly individuals during daily activities\nsuch as toilet transfers. Unlike conventional seated mobility aids, the robot\nmaintains users in an upright posture, reducing physical strain, supporting\nnatural social interaction at eye level, and fostering a greater sense of\nself-efficacy. Moby offers a novel alternative by functioning both passively\nand with mobility support, enabling users to perform daily tasks more\nindependently. Its main advantages include ease of use, lightweight design,\ncomfort, versatility, and effective sit-to-stand assistance. The robot\nleverages the Robot Operating System (ROS) for seamless control, featuring\nmanual and autonomous operation modes. A custom control system enables safe and\nintuitive interaction, while the integration with NAV2 and LiDAR allows for\nrobust navigation capabilities. This paper reviews existing mobility solutions\nand compares them to Moby, details the robot's design, and presents objective\nand subjective experimental results using the NASA-TLX method and time\ncomparisons to other methods to validate our design criteria and demonstrate\nthe advantages of our contribution.", "AI": {"tldr": "开发了一款名为Moby的站立式移动辅助机器人，旨在帮助老年人保持直立姿势进行日常活动，减少身体负担并增强独立性。", "motivation": "传统坐式移动辅助工具无法让使用者保持直立姿势，导致身体负担增加、社交互动受限和自主性降低。需要一种新型辅助设备来提升老年人的生活质量和独立性。", "method": "采用机器人操作系统(ROS)进行控制，具备手动和自主操作模式。集成NAV2和LiDAR实现稳健导航，配备定制控制系统确保安全直观的交互。通过NASA-TLX方法和时间对比实验进行验证。", "result": "Moby机器人展现出易用性、轻量化设计、舒适性、多功能性和有效的坐立转换辅助等优势。实验结果表明相比传统方法具有明显优势。", "conclusion": "Moby站立式移动机器人成功解决了传统辅助设备的局限性，为老年人提供了更自然、安全和独立的日常活动支持，显著提升了用户体验和生活质量。"}}
{"id": "2508.19926", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19926", "abs": "https://arxiv.org/abs/2508.19926", "authors": ["Tan Jing", "Shiting Chen", "Yangfan Li", "Weisheng Xu", "Renjing Xu"], "title": "FARM: Frame-Accelerated Augmentation and Residual Mixture-of-Experts for Physics-Based High-Dynamic Humanoid Control", "comment": null, "summary": "Unified physics-based humanoid controllers are pivotal for robotics and\ncharacter animation, yet models that excel on gentle, everyday motions still\nstumble on explosive actions, hampering real-world deployment. We bridge this\ngap with FARM (Frame-Accelerated Augmentation and Residual Mixture-of-Experts),\nan end-to-end framework composed of frame-accelerated augmentation, a robust\nbase controller, and a residual mixture-of-experts (MoE). Frame-accelerated\naugmentation exposes the model to high-velocity pose changes by widening\ninter-frame gaps. The base controller reliably tracks everyday low-dynamic\nmotions, while the residual MoE adaptively allocates additional network\ncapacity to handle challenging high-dynamic actions, significantly enhancing\ntracking accuracy. In the absence of a public benchmark, we curate the\nHigh-Dynamic Humanoid Motion (HDHM) dataset, comprising 3593 physically\nplausible clips. On HDHM, FARM reduces the tracking failure rate by 42.8\\% and\nlowers global mean per-joint position error by 14.6\\% relative to the baseline,\nwhile preserving near-perfect accuracy on low-dynamic motions. These results\nestablish FARM as a new baseline for high-dynamic humanoid control and\nintroduce the first open benchmark dedicated to this challenge. The code and\ndataset will be released at https://github.com/Colin-Jing/FARM.", "AI": {"tldr": "FARM框架通过帧加速增强和残差专家混合方法，显著提升了人形控制器在爆炸性动作上的表现，同时保持日常动作的精确跟踪。", "motivation": "现有的人形控制器在温和的日常动作上表现良好，但在爆炸性动作上容易失败，这限制了实际应用。需要一种能够统一处理不同动态范围动作的解决方案。", "method": "FARM框架包含三个核心组件：1) 帧加速增强 - 通过扩大帧间间隔让模型接触高速姿态变化；2) 鲁棒基础控制器 - 可靠跟踪日常低动态动作；3) 残差专家混合(MoE) - 自适应分配额外网络容量处理高动态挑战性动作。", "result": "在HDHM数据集上，FARM将跟踪失败率降低了42.8%，全局平均关节位置误差降低了14.6%，同时在低动态动作上保持了近乎完美的准确性。", "conclusion": "FARM为高动态人形控制设立了新的基准，并首次提供了专门针对这一挑战的开放基准测试，代码和数据集将开源发布。"}}
{"id": "2508.19953", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19953", "abs": "https://arxiv.org/abs/2508.19953", "authors": ["Rafael Cathomen", "Mayank Mittal", "Marin Vlastelica", "Marco Hutter"], "title": "Divide, Discover, Deploy: Factorized Skill Learning with Symmetry and Style Priors", "comment": "Accepted to CoRL 2025. For code and videos, please check:\n  https://leggedrobotics.github.io/d3-skill-discovery/", "summary": "Unsupervised Skill Discovery (USD) allows agents to autonomously learn\ndiverse behaviors without task-specific rewards. While recent USD methods have\nshown promise, their application to real-world robotics remains underexplored.\nIn this paper, we propose a modular USD framework to address the challenges in\nthe safety, interpretability, and deployability of the learned skills. Our\napproach employs user-defined factorization of the state space to learn\ndisentangled skill representations. It assigns different skill discovery\nalgorithms to each factor based on the desired intrinsic reward function. To\nencourage structured morphology-aware skills, we introduce symmetry-based\ninductive biases tailored to individual factors. We also incorporate a style\nfactor and regularization penalties to promote safe and robust behaviors. We\nevaluate our framework in simulation using a quadrupedal robot and demonstrate\nzero-shot transfer of the learned skills to real hardware. Our results show\nthat factorization and symmetry lead to the discovery of structured\nhuman-interpretable behaviors, while the style factor and penalties enhance\nsafety and diversity. Additionally, we show that the learned skills can be used\nfor downstream tasks and perform on par with oracle policies trained with\nhand-crafted rewards.", "AI": {"tldr": "提出模块化无监督技能发现框架，通过状态空间分解和对称性偏置学习结构化、可解释的技能，实现零样本迁移到真实机器人", "motivation": "解决无监督技能发现在真实机器人应用中的安全性、可解释性和部署性问题", "method": "用户定义状态空间分解，为不同因子分配技能发现算法，引入对称性归纳偏置和风格因子，加入正则化惩罚", "result": "在四足机器人仿真中学习到结构化、人类可解释的行为，零样本迁移到真实硬件，性能与手工奖励训练的策略相当", "conclusion": "因子分解和对称性偏置有助于发现结构化技能，风格因子和惩罚项提升安全性和多样性，学习到的技能可用于下游任务"}}
{"id": "2508.19958", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.19958", "abs": "https://arxiv.org/abs/2508.19958", "authors": ["Yiguo Fan", "Pengxiang Ding", "Shuanghao Bai", "Xinyang Tong", "Yuyang Zhu", "Hongchao Lu", "Fengqi Dai", "Wei Zhao", "Yang Liu", "Siteng Huang", "Zhaoxin Fan", "Badong Chen", "Donglin Wang"], "title": "Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation", "comment": "Accepted to CoRL 2025; Github Page: https://long-vla.github.io", "summary": "Vision-Language-Action (VLA) models have become a cornerstone in robotic\npolicy learning, leveraging large-scale multimodal data for robust and scalable\ncontrol. However, existing VLA frameworks primarily address short-horizon\ntasks, and their effectiveness on long-horizon, multi-step robotic manipulation\nremains limited due to challenges in skill chaining and subtask dependencies.\nIn this work, we introduce Long-VLA, the first end-to-end VLA model\nspecifically designed for long-horizon robotic tasks. Our approach features a\nnovel phase-aware input masking strategy that adaptively segments each subtask\ninto moving and interaction phases, enabling the model to focus on\nphase-relevant sensory cues and enhancing subtask compatibility. This unified\nstrategy preserves the scalability and data efficiency of VLA training, and our\narchitecture-agnostic module can be seamlessly integrated into existing VLA\nmodels. We further propose the L-CALVIN benchmark to systematically evaluate\nlong-horizon manipulation. Extensive experiments on both simulated and\nreal-world tasks demonstrate that Long-VLA significantly outperforms prior\nstate-of-the-art methods, establishing a new baseline for long-horizon robotic\ncontrol.", "AI": {"tldr": "Long-VLA是首个专为长时程机器人任务设计的端到端VLA模型，通过相位感知输入掩码策略将子任务分为移动和交互阶段，在L-CALVIN基准测试中显著优于现有方法", "motivation": "现有VLA框架主要处理短时程任务，在长时程多步操作中由于技能链和子任务依赖性的挑战而效果有限", "method": "采用相位感知输入掩码策略，自适应地将每个子任务分割为移动和交互阶段，使模型能够专注于阶段相关的感官线索，增强子任务兼容性", "result": "在仿真和真实世界任务上的大量实验表明，Long-VLA显著优于先前的最先进方法", "conclusion": "Long-VLA为长时程机器人控制建立了新的基准，其架构无关模块可无缝集成到现有VLA模型中"}}
{"id": "2508.20037", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.20037", "abs": "https://arxiv.org/abs/2508.20037", "authors": ["Henk H. A. Jekel", "Alejandro Díaz Rosales", "Luka Peternel"], "title": "Visio-Verbal Teleimpedance Interface: Enabling Semi-Autonomous Control of Physical Interaction via Eye Tracking and Speech", "comment": null, "summary": "The paper presents a visio-verbal teleimpedance interface for commanding 3D\nstiffness ellipsoids to the remote robot with a combination of the operator's\ngaze and verbal interaction. The gaze is detected by an eye-tracker, allowing\nthe system to understand the context in terms of what the operator is currently\nlooking at in the scene. Along with verbal interaction, a Visual Language Model\n(VLM) processes this information, enabling the operator to communicate their\nintended action or provide corrections. Based on these inputs, the interface\ncan then generate appropriate stiffness matrices for different physical\ninteraction actions. To validate the proposed visio-verbal teleimpedance\ninterface, we conducted a series of experiments on a setup including a Force\nDimension Sigma.7 haptic device to control the motion of the remote Kuka LBR\niiwa robotic arm. The human operator's gaze is tracked by Tobii Pro Glasses 2,\nwhile human verbal commands are processed by a VLM using GPT-4o. The first\nexperiment explored the optimal prompt configuration for the interface. The\nsecond and third experiments demonstrated different functionalities of the\ninterface on a slide-in-the-groove task.", "AI": {"tldr": "通过视觉-语音交互接口，结合眼动跟踪和语音呼呼来控制远程机器人的3D刚度掩圆体", "motivation": "为了实现更自然和直观的远程机器人控制，充分利用人类视觉和语音交互能力来理解操作者意图和上下文", "method": "使用Tobii Pro Glasses 2跟踪眼动，通过GPT-4o处理语音呼呼，视觉语言模型结合两者信息生成适当的刚度矩阵，在Force Dimension Sigma.7和Kuka LBR iiwa平台上进行验证", "result": "设计了最优提示配置，并在滑槽任务中展示了接口的多种功能性，验证了视觉-语音远程阻抗控制的可行性", "conclusion": "视觉-语音交互接口能够有效地通过眼动和语音呼呼来命令3D刚度掩圆体，为远程机器人控制提供了更自然的人机交互方式"}}
{"id": "2508.20085", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.20085", "abs": "https://arxiv.org/abs/2508.20085", "authors": ["Zhecheng Yuan", "Tianming Wei", "Langzhe Gu", "Pu Hua", "Tianhai Liang", "Yuanpei Chen", "Huazhe Xu"], "title": "HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation", "comment": null, "summary": "Leveraging human motion data to impart robots with versatile manipulation\nskills has emerged as a promising paradigm in robotic manipulation.\nNevertheless, translating multi-source human hand motions into feasible robot\nbehaviors remains challenging, particularly for robots equipped with\nmulti-fingered dexterous hands characterized by complex, high-dimensional\naction spaces. Moreover, existing approaches often struggle to produce policies\ncapable of adapting to diverse environmental conditions. In this paper, we\nintroduce HERMES, a human-to-robot learning framework for mobile bimanual\ndexterous manipulation. First, HERMES formulates a unified reinforcement\nlearning approach capable of seamlessly transforming heterogeneous human hand\nmotions from multiple sources into physically plausible robotic behaviors.\nSubsequently, to mitigate the sim2real gap, we devise an end-to-end, depth\nimage-based sim2real transfer method for improved generalization to real-world\nscenarios. Furthermore, to enable autonomous operation in varied and\nunstructured environments, we augment the navigation foundation model with a\nclosed-loop Perspective-n-Point (PnP) localization mechanism, ensuring precise\nalignment of visual goals and effectively bridging autonomous navigation and\ndexterous manipulation. Extensive experimental results demonstrate that HERMES\nconsistently exhibits generalizable behaviors across diverse, in-the-wild\nscenarios, successfully performing numerous complex mobile bimanual dexterous\nmanipulation tasks. Project Page:https:/gemcollector.github.io/HERMES/.", "AI": {"tldr": "HERMES是一个人类到机器人的学习框架，用于移动双手灵巧操作，通过统一强化学习方法将多源人手运动转化为机器人行为，并解决了sim2real差距和环境适应性问题。", "motivation": "将多源人手运动转化为可行的机器人行为具有挑战性，特别是对于具有复杂高维动作空间的多指灵巧手机器人。现有方法难以产生适应不同环境条件的策略。", "method": "1) 统一的强化学习方法转换异构人手运动；2) 基于深度图像的端到端sim2real迁移方法；3) 增强导航基础模型，加入闭环PnP定位机制", "result": "实验结果表明HERMES在各种野外场景中表现出可泛化的行为，成功执行了众多复杂的移动双手灵巧操作任务", "conclusion": "HERMES框架能够有效解决人手运动到机器人行为的转换问题，并在真实世界中展现出良好的泛化能力和适应性"}}
{"id": "2508.20095", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.20095", "abs": "https://arxiv.org/abs/2508.20095", "authors": ["Jinhao Liang", "Sven Koenig", "Ferdinando Fioretto"], "title": "Discrete-Guided Diffusion for Scalable and Safe Multi-Robot Motion Planning", "comment": null, "summary": "Multi-Robot Motion Planning (MRMP) involves generating collision-free\ntrajectories for multiple robots operating in a shared continuous workspace.\nWhile discrete multi-agent path finding (MAPF) methods are broadly adopted due\nto their scalability, their coarse discretization severely limits trajectory\nquality. In contrast, continuous optimization-based planners offer\nhigher-quality paths but suffer from the curse of dimensionality, resulting in\npoor scalability with respect to the number of robots. This paper tackles the\nlimitations of these two approaches by introducing a novel framework that\nintegrates discrete MAPF solvers with constrained generative diffusion models.\nThe resulting framework, called Discrete-Guided Diffusion (DGD), has three key\ncharacteristics: (1) it decomposes the original nonconvex MRMP problem into\ntractable subproblems with convex configuration spaces, (2) it combines\ndiscrete MAPF solutions with constrained optimization techniques to guide\ndiffusion models capture complex spatiotemporal dependencies among robots, and\n(3) it incorporates a lightweight constraint repair mechanism to ensure\ntrajectory feasibility. The proposed method sets a new state-of-the-art\nperformance in large-scale, complex environments, scaling to 100 robots while\nachieving planning efficiency and high success rates.", "AI": {"tldr": "通过结合离散MAPF解算器与生成式涵渋模型，提出了一种可扩展到100台机器人的高质量轨迹规划方法", "motivation": "解决离散MAPF方法轨迹质量低和连续优化方法维度灾难的问题，寻找一种既可扩展又能保证轨迹质量的多机器人运动规划方案", "method": "提出DGD框架，将非凸问题分解为可解的子问题，结合离散MAPF解决方案和约束优化技术来导向涵渋模型，并包含轻量约束修复机制", "result": "在大规模复杂环境中达到新的最高性能标准，可扩展到100台机器人，具有高规划效率和成功率", "conclusion": "DGD框架成功结合了离散和连续规划方法的优势，为大规模多机器人运动规划提供了一种高效、高质量的解决方案"}}
