{"id": "2506.21627", "categories": ["cs.RO", "cs.AI", "F.4.3; I.2.9"], "pdf": "https://arxiv.org/pdf/2506.21627", "abs": "https://arxiv.org/abs/2506.21627", "authors": ["Shiyi Wang", "Wenbo Li", "Yiteng Chen", "Qingyao Wu", "Huiping Zhuang"], "title": "FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models", "comment": "15 pages, 4 figures, under review of NeurIPS", "summary": "Developing a general robot manipulation system capable of performing a wide\nrange of tasks in complex, dynamic, and unstructured real-world environments\nhas long been a challenging task. It is widely recognized that achieving\nhuman-like efficiency and robustness manipulation requires the robotic brain to\nintegrate a comprehensive set of functions, such as task planning, policy\ngeneration, anomaly monitoring and handling, and long-term memory, achieving\nhigh-efficiency operation across all functions. Vision-Language Models (VLMs),\npretrained on massive multimodal data, have acquired rich world knowledge,\nexhibiting exceptional scene understanding and multimodal reasoning\ncapabilities. However, existing methods typically focus on realizing only a\nsingle function or a subset of functions within the robotic brain, without\nintegrating them into a unified cognitive architecture. Inspired by a\ndivide-and-conquer strategy and the architecture of the human brain, we propose\nFrankenBot, a VLM-driven, brain-morphic robotic manipulation framework that\nachieves both comprehensive functionality and high operational efficiency. Our\nframework includes a suite of components, decoupling a part of key functions\nfrom frequent VLM calls, striking an optimal balance between functional\ncompleteness and system efficiency. Specifically, we map task planning, policy\ngeneration, memory management, and low-level interfacing to the cortex,\ncerebellum, temporal lobe-hippocampus complex, and brainstem, respectively, and\ndesign efficient coordination mechanisms for the modules. We conducted\ncomprehensive experiments in both simulation and real-world robotic\nenvironments, demonstrating that our method offers significant advantages in\nanomaly detection and handling, long-term memory, operational efficiency, and\nstability -- all without requiring any fine-tuning or retraining.", "AI": {"tldr": "FrankenBot是一个基于视觉语言模型（VLM）的机器人操作框架，通过模拟人脑结构实现多功能集成与高效操作。", "motivation": "开发一个能在复杂动态环境中执行多样化任务的通用机器人系统，需整合任务规划、策略生成等功能，但现有方法多为单一功能实现。", "method": "采用分治策略和人脑结构启发，设计FrankenBot框架，将不同功能映射到类似人脑的模块（如皮层、小脑等），并优化协调机制。", "result": "实验表明，FrankenBot在异常检测、长期记忆、操作效率和稳定性方面表现优异，无需微调或重新训练。", "conclusion": "FrankenBot通过统一认知架构实现了功能全面与高效操作的平衡，为机器人系统设计提供了新思路。"}}
{"id": "2506.21628", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21628", "abs": "https://arxiv.org/abs/2506.21628", "authors": ["Magnus Dierking", "Christopher E. Mower", "Sarthak Das", "Huang Helong", "Jiacheng Qiu", "Cody Reading", "Wei Chen", "Huidong Liang", "Huang Guowei", "Jan Peters", "Quan Xingyue", "Jun Wang", "Haitham Bou-Ammar"], "title": "Ark: An Open-source Python-based Framework for Robot Learning", "comment": null, "summary": "Robotics has made remarkable hardware strides-from DARPA's Urban and Robotics\nChallenges to the first humanoid-robot kickboxing tournament-yet commercial\nautonomy still lags behind progress in machine learning. A major bottleneck is\nsoftware: current robot stacks demand steep learning curves, low-level C/C++\nexpertise, fragmented tooling, and intricate hardware integration, in stark\ncontrast to the Python-centric, well-documented ecosystems that propelled\nmodern AI. We introduce ARK, an open-source, Python-first robotics framework\ndesigned to close that gap. ARK presents a Gym-style environment interface that\nallows users to collect data, preprocess it, and train policies using\nstate-of-the-art imitation-learning algorithms (e.g., ACT, Diffusion Policy)\nwhile seamlessly toggling between high-fidelity simulation and physical robots.\nA lightweight client-server architecture provides networked\npublisher-subscriber communication, and optional C/C++ bindings ensure\nreal-time performance when needed. ARK ships with reusable modules for control,\nSLAM, motion planning, system identification, and visualization, along with\nnative ROS interoperability. Comprehensive documentation and case studies-from\nmanipulation to mobile navigation-demonstrate rapid prototyping, effortless\nhardware swapping, and end-to-end pipelines that rival the convenience of\nmainstream machine-learning workflows. By unifying robotics and AI practices\nunder a common Python umbrella, ARK lowers entry barriers and accelerates\nresearch and commercial deployment of autonomous robots.", "AI": {"tldr": "ARK是一个开源的、以Python为核心的机器人框架，旨在简化机器人软件开发，降低学习门槛，并加速自主机器人的研究和商业部署。", "motivation": "当前机器人软件栈复杂且分散，需要低级的C/C++专业知识，与Python主导的现代AI生态系统形成鲜明对比。ARK旨在填补这一差距，提供更便捷的开发体验。", "method": "ARK提供Gym风格的环境接口，支持数据收集、预处理和策略训练，使用模仿学习算法（如ACT、Diffusion Policy）。它采用轻量级客户端-服务器架构，支持ROS互操作性，并提供可重用模块。", "result": "ARK展示了从操作到移动导航的快速原型设计、硬件无缝切换以及端到端流水线，其便利性可与主流机器学习工作流媲美。", "conclusion": "ARK通过统一机器人学和AI实践，降低了入门门槛，加速了自主机器人的研究和商业部署。"}}
{"id": "2506.21630", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.21630", "abs": "https://arxiv.org/abs/2506.21630", "authors": ["Yixin Sun", "Li Li", "Wenke E", "Amir Atapour-Abarghouei", "Toby P. Breckon"], "title": "TOMD: A Trail-based Off-road Multimodal Dataset for Traversable Pathway Segmentation under Challenging Illumination Conditions", "comment": "8 pages, 9 figures, 2025 IJCNN", "summary": "Detecting traversable pathways in unstructured outdoor environments remains a\nsignificant challenge for autonomous robots, especially in critical\napplications such as wide-area search and rescue, as well as incident\nmanagement scenarios like forest fires. Existing datasets and models primarily\ntarget urban settings or wide, vehicle-traversable off-road tracks, leaving a\nsubstantial gap in addressing the complexity of narrow, trail-like off-road\nscenarios. To address this, we introduce the Trail-based Off-road Multimodal\nDataset (TOMD), a comprehensive dataset specifically designed for such\nenvironments. TOMD features high-fidelity multimodal sensor data -- including\n128-channel LiDAR, stereo imagery, GNSS, IMU, and illumination measurements --\ncollected through repeated traversals under diverse conditions. We also propose\na dynamic multiscale data fusion model for accurate traversable pathway\nprediction. The study analyzes the performance of early, cross, and mixed\nfusion strategies under varying illumination levels. Results demonstrate the\neffectiveness of our approach and the relevance of illumination in segmentation\nperformance. We publicly release TOMD at https://github.com/yyyxs1125/TMOD to\nsupport future research in trail-based off-road navigation.", "AI": {"tldr": "论文介绍了TOMD数据集和动态多尺度数据融合模型，用于解决非结构化户外环境中可通行路径检测的挑战。", "motivation": "现有数据集和模型主要针对城市环境或宽阔的越野路径，而忽视了狭窄的小径场景，因此需要专门的数据集和方法来填补这一空白。", "method": "提出了TOMD数据集，包含多模态传感器数据，并开发了动态多尺度数据融合模型，比较了早期、交叉和混合融合策略在不同光照条件下的表现。", "result": "结果表明，该方法在可通行路径预测上有效，且光照条件对分割性能有显著影响。", "conclusion": "TOMD数据集和提出的模型为非结构化户外环境中的路径检测提供了有效工具，并公开数据集以支持未来研究。"}}
{"id": "2506.21631", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.21631", "abs": "https://arxiv.org/abs/2506.21631", "authors": ["Tianliang Yao", "Bingrui Li", "Bo Lu", "Zhiqiang Pei", "Yixuan Yuan", "Peng Qi"], "title": "Real-Time 3D Guidewire Reconstruction from Intraoperative DSA Images for Robot-Assisted Endovascular Interventions", "comment": "This paper has been accepted by IEEE/RSJ IROS 2025", "summary": "Accurate three-dimensional (3D) reconstruction of guidewire shapes is crucial\nfor precise navigation in robot-assisted endovascular interventions.\nConventional 2D Digital Subtraction Angiography (DSA) is limited by the absence\nof depth information, leading to spatial ambiguities that hinder reliable\nguidewire shape sensing. This paper introduces a novel multimodal framework for\nreal-time 3D guidewire reconstruction, combining preoperative 3D Computed\nTomography Angiography (CTA) with intraoperative 2D DSA images. The method\nutilizes robust feature extraction to address noise and distortion in 2D DSA\ndata, followed by deformable image registration to align the 2D projections\nwith the 3D CTA model. Subsequently, the inverse projection algorithm\nreconstructs the 3D guidewire shape, providing real-time, accurate spatial\ninformation. This framework significantly enhances spatial awareness for\nrobotic-assisted endovascular procedures, effectively bridging the gap between\npreoperative planning and intraoperative execution. The system demonstrates\nnotable improvements in real-time processing speed, reconstruction accuracy,\nand computational efficiency. The proposed method achieves a projection error\nof 1.76$\\pm$0.08 pixels and a length deviation of 2.93$\\pm$0.15\\%, with a frame\nrate of 39.3$\\pm$1.5 frames per second (FPS). These advancements have the\npotential to optimize robotic performance and increase the precision of complex\nendovascular interventions, ultimately contributing to better clinical\noutcomes.", "AI": {"tldr": "提出了一种结合术前3D CTA和术中2D DSA的多模态框架，用于实时3D导丝重建，显著提升了机器人辅助血管内手术的空间感知能力。", "motivation": "传统2D DSA缺乏深度信息，导致空间模糊性，限制了导丝形状感知的可靠性。", "method": "通过鲁棒特征提取处理2D DSA数据噪声，利用可变形图像配准对齐2D投影与3D CTA模型，再通过逆投影算法重建3D导丝形状。", "result": "投影误差为1.76±0.08像素，长度偏差为2.93±0.15%，帧率为39.3±1.5 FPS。", "conclusion": "该方法优化了机器人性能，提高了复杂血管内手术的精确性，有望改善临床结果。"}}
{"id": "2506.21732", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.21732", "abs": "https://arxiv.org/abs/2506.21732", "authors": ["Ameya Salvi", "Venkat Krovi"], "title": "Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation", "comment": null, "summary": "Vision-based lane keeping is a topic of significant interest in the robotics\nand autonomous ground vehicles communities in various on-road and off-road\napplications. The skid-steered vehicle architecture has served as a useful\nvehicle platform for human controlled operations. However, systematic modeling,\nespecially of the skid-slip wheel terrain interactions (primarily in off-road\nsettings) has created bottlenecks for automation deployment. End-to-end\nlearning based methods such as imitation learning and deep reinforcement\nlearning, have gained prominence as a viable deployment option to counter the\nlack of accurate analytical models. However, the systematic formulation and\nsubsequent verification/validation in dynamic operation regimes (particularly\nfor skid-steered vehicles) remains a work in progress. To this end, a novel\napproach for structured formulation for learning visual navigation is proposed\nand investigated in this work. Extensive software simulations, hardware\nevaluations and ablation studies now highlight the significantly improved\nperformance of the proposed approach against contemporary literature.", "AI": {"tldr": "本文提出了一种基于学习的视觉导航方法，解决了滑移转向车辆在动态操作中的建模和验证问题。", "motivation": "滑移转向车辆在自动化部署中因缺乏准确的解析模型而受限，端到端学习方法成为替代方案，但动态操作中的验证仍不完善。", "method": "提出了一种结构化学习视觉导航的方法，并通过软件模拟、硬件评估和消融研究进行验证。", "result": "所提方法在性能上显著优于现有文献。", "conclusion": "该方法为滑移转向车辆的视觉导航提供了有效的解决方案。"}}
{"id": "2506.21635", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.21635", "abs": "https://arxiv.org/abs/2506.21635", "authors": ["Haiping Yang", "Huaxing Liu", "Wei Wu", "Zuohui Chen", "Ning Wu"], "title": "AeroLite-MDNet: Lightweight Multi-task Deviation Detection Network for UAV Landing", "comment": null, "summary": "Unmanned aerial vehicles (UAVs) are increasingly employed in diverse\napplications such as land surveying, material transport, and environmental\nmonitoring. Following missions like data collection or inspection, UAVs must\nland safely at docking stations for storage or recharging, which is an\nessential requirement for ensuring operational continuity. However, accurate\nlanding remains challenging due to factors like GPS signal interference. To\naddress this issue, we propose a deviation warning system for UAV landings,\npowered by a novel vision-based model called AeroLite-MDNet. This model\nintegrates a multiscale fusion module for robust cross-scale object detection\nand incorporates a segmentation branch for efficient orientation estimation. We\nintroduce a new evaluation metric, Average Warning Delay (AWD), to quantify the\nsystem's sensitivity to landing deviations. Furthermore, we contribute a new\ndataset, UAVLandData, which captures real-world landing deviation scenarios to\nsupport training and evaluation. Experimental results show that our system\nachieves an AWD of 0.7 seconds with a deviation detection accuracy of 98.6\\%,\ndemonstrating its effectiveness in enhancing UAV landing reliability. Code will\nbe available at https://github.com/ITTTTTI/Maskyolo.git", "AI": {"tldr": "论文提出了一种基于视觉的无人机着陆偏差预警系统AeroLite-MDNet，通过多尺度融合模块和分割分支提高检测精度，并引入新指标AWD和新数据集UAVLandData。实验显示系统性能优越。", "motivation": "无人机着陆时因GPS信号干扰等问题难以精准着陆，影响操作连续性，需解决这一问题。", "method": "提出AeroLite-MDNet模型，结合多尺度融合模块和分割分支，用于偏差检测和方向估计，并引入AWD指标和新数据集UAVLandData。", "result": "系统AWD为0.7秒，偏差检测准确率达98.6%，显著提升着陆可靠性。", "conclusion": "AeroLite-MDNet系统能有效解决无人机着陆偏差问题，提升操作安全性。"}}
{"id": "2506.21982", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.21982", "abs": "https://arxiv.org/abs/2506.21982", "authors": ["Akshay Jaitly", "Jack Cline", "Siavash Farzan"], "title": "A MILP-Based Solution to Multi-Agent Motion Planning and Collision Avoidance in Constrained Environments", "comment": "Accepted to 2025 IEEE International Conference on Automation Science\n  and Engineering (CASE 2025)", "summary": "We propose a mixed-integer linear program (MILP) for multi-agent motion\nplanning that embeds Polytopic Action-based Motion Planning (PAAMP) into a\nsequence-then-solve pipeline. Region sequences confine each agent to adjacent\nconvex polytopes, while a big-M hyperplane model enforces inter-agent\nseparation. Collision constraints are applied only to agents sharing or\nneighboring a region, which reduces binary variables exponentially compared\nwith naive formulations. An L1 path-length-plus-acceleration cost yields smooth\ntrajectories. We prove finite-time convergence and demonstrate on\nrepresentative multi-agent scenarios with obstacles that our formulation\nproduces collision-free trajectories an order of magnitude faster than an\nunstructured MILP baseline.", "AI": {"tldr": "提出一种混合整数线性规划（MILP）方法，用于多智能体运动规划，通过嵌入PAAMP到序列-求解流程中，显著减少计算复杂度。", "motivation": "解决多智能体运动规划中高计算复杂度的问题，特别是避免碰撞和优化轨迹。", "method": "采用PAAMP方法，结合序列-求解流程，使用凸多面体约束和L1路径长度加加速度成本函数。", "result": "在代表性多智能体场景中，比非结构化MILP基线快一个数量级，且生成无碰撞轨迹。", "conclusion": "该方法高效且收敛性有保证，适用于复杂多智能体运动规划。"}}
{"id": "2506.21689", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.21689", "abs": "https://arxiv.org/abs/2506.21689", "authors": ["Jason Lim", "Florian Richter", "Zih-Yun Chiu", "Jaeyon Lee", "Ethan Quist", "Nathan Fisher", "Jonathan Chambers", "Steven Hong", "Michael C. Yip"], "title": "Optimal Motion Scaling for Delayed Telesurgery", "comment": "Accepted to IROS 2025", "summary": "Robotic teleoperation over long communication distances poses challenges due\nto delays in commands and feedback from network latency. One simple yet\neffective strategy to reduce errors and increase performance under delay is to\ndownscale the relative motion between the operating surgeon and the robot. The\nquestion remains as to what is the optimal scaling factor, and how this value\nchanges depending on the level of latency as well as operator tendencies. We\npresent user studies investigating the relationship between latency, scaling\nfactor, and performance. The results of our studies demonstrate a statistically\nsignificant difference in performance between users and across scaling factors\nfor certain levels of delay. These findings indicate that the optimal scaling\nfactor for a given level of delay is specific to each user, motivating the need\nfor personalized models for optimal performance. We present techniques to model\nthe user-specific mapping of latency level to scaling factor for optimal\nperformance, leading to an efficient and effective solution to optimizing\nperformance of robotic teleoperation and specifically telesurgery under large\ncommunication delay.", "AI": {"tldr": "研究探讨了在长距离通信延迟下，通过调整运动缩放因子优化机器人远程操作的性能，发现个性化模型能显著提升效果。", "motivation": "解决因网络延迟导致的机器人远程操作性能下降问题，尤其是医疗远程手术中的挑战。", "method": "通过用户研究分析延迟、缩放因子与性能的关系，并开发个性化模型。", "result": "研究发现缩放因子的最优值因用户和延迟水平而异，个性化模型能显著提升性能。", "conclusion": "个性化缩放因子模型是优化远程操作性能的有效解决方案，尤其适用于高延迟环境。"}}
{"id": "2506.21853", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.21853", "abs": "https://arxiv.org/abs/2506.21853", "authors": ["Dewei Wang", "Chenjia Ba", "Chenhui Li", "Jiyuan Shi", "Yan Ding", "Chi Zhang", "Bin Zhao"], "title": "Skill-Nav: Enhanced Navigation with Versatile Quadrupedal Locomotion via Waypoint Interface", "comment": "17pages, 6 figures", "summary": "Quadrupedal robots have demonstrated exceptional locomotion capabilities\nthrough Reinforcement Learning (RL), including extreme parkour maneuvers.\nHowever, integrating locomotion skills with navigation in quadrupedal robots\nhas not been fully investigated, which holds promise for enhancing\nlong-distance movement capabilities. In this paper, we propose Skill-Nav, a\nmethod that incorporates quadrupedal locomotion skills into a hierarchical\nnavigation framework using waypoints as an interface. Specifically, we train a\nwaypoint-guided locomotion policy using deep RL, enabling the robot to\nautonomously adjust its locomotion skills to reach targeted positions while\navoiding obstacles. Compared with direct velocity commands, waypoints offer a\nsimpler yet more flexible interface for high-level planning and low-level\ncontrol. Utilizing waypoints as the interface allows for the application of\nvarious general planning tools, such as large language models (LLMs) and path\nplanning algorithms, to guide our locomotion policy in traversing terrains with\ndiverse obstacles. Extensive experiments conducted in both simulated and\nreal-world scenarios demonstrate that Skill-Nav can effectively traverse\ncomplex terrains and complete challenging navigation tasks.", "AI": {"tldr": "Skill-Nav结合强化学习与分层导航框架，通过路径点接口整合四足机器人的运动技能，实现复杂地形导航。", "motivation": "探索如何将四足机器人的运动技能与导航能力结合，以提升长距离移动能力。", "method": "使用深度强化学习训练路径点引导的运动策略，通过路径点接口连接高层规划与底层控制。", "result": "实验表明Skill-Nav能在模拟和现实场景中有效穿越复杂地形并完成导航任务。", "conclusion": "Skill-Nav为四足机器人导航提供了一种灵活且高效的解决方案。"}}
{"id": "2506.21860", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.21860", "abs": "https://arxiv.org/abs/2506.21860", "authors": ["Xiangyu Shi", "Yanyuan Qiao", "Lingqiao Liu", "Feras Dayoub"], "title": "Embodied Domain Adaptation for Object Detection", "comment": "Accepted by IROS 2025", "summary": "Mobile robots rely on object detectors for perception and object localization\nin indoor environments. However, standard closed-set methods struggle to handle\nthe diverse objects and dynamic conditions encountered in real homes and labs.\nOpen-vocabulary object detection (OVOD), driven by Vision Language Models\n(VLMs), extends beyond fixed labels but still struggles with domain shifts in\nindoor environments. We introduce a Source-Free Domain Adaptation (SFDA)\napproach that adapts a pre-trained model without accessing source data. We\nrefine pseudo labels via temporal clustering, employ multi-scale threshold\nfusion, and apply a Mean Teacher framework with contrastive learning. Our\nEmbodied Domain Adaptation for Object Detection (EDAOD) benchmark evaluates\nadaptation under sequential changes in lighting, layout, and object diversity.\nOur experiments show significant gains in zero-shot detection performance and\nflexible adaptation to dynamic indoor conditions.", "AI": {"tldr": "论文提出了一种无需源数据的领域自适应方法（SFDA），通过时间聚类和多尺度阈值融合改进伪标签，结合对比学习的Mean Teacher框架，显著提升了开放词汇目标检测（OVOD）在动态室内环境中的性能。", "motivation": "解决标准封闭集方法和现有开放词汇目标检测在动态室内环境中因领域偏移导致的性能不足问题。", "method": "采用源数据无关的领域自适应（SFDA），结合时间聚类、多尺度阈值融合和Mean Teacher框架的对比学习。", "result": "在EDAOD基准测试中，零样本检测性能显著提升，能够灵活适应动态室内条件。", "conclusion": "提出的方法有效解决了开放词汇目标检测在动态室内环境中的领域适应问题，具有实际应用潜力。"}}
{"id": "2506.22028", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.22028", "abs": "https://arxiv.org/abs/2506.22028", "authors": ["Ossi Parikka", "Roel Pieters"], "title": "LMPVC and Policy Bank: Adaptive voice control for industrial robots with code generating LLMs and reusable Pythonic policies", "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and\n  Human Interactive Communication (RO-MAN). For further information, videos and\n  code, see https://github.com/ozzyuni/LMPVC", "summary": "Modern industry is increasingly moving away from mass manufacturing, towards\nmore specialized and personalized products. As manufacturing tasks become more\ncomplex, full automation is not always an option, human involvement may be\nrequired. This has increased the need for advanced human robot collaboration\n(HRC), and with it, improved methods for interaction, such as voice control.\nRecent advances in natural language processing, driven by artificial\nintelligence (AI), have the potential to answer this demand. Large language\nmodels (LLMs) have rapidly developed very impressive general reasoning\ncapabilities, and many methods of applying this to robotics have been proposed,\nincluding through the use of code generation. This paper presents Language\nModel Program Voice Control (LMPVC), an LLM-based prototype voice control\narchitecture with integrated policy programming and teaching capabilities,\nbuilt for use with Robot Operating System 2 (ROS2) compatible robots. The\narchitecture builds on prior works using code generation for voice control by\nimplementing an additional programming and teaching system, the Policy Bank. We\nfind this system can compensate for the limitations of the underlying LLM, and\nallow LMPVC to adapt to different downstream tasks without a slow and costly\ntraining process. The architecture and additional results are released on\nGitHub (https://github.com/ozzyuni/LMPVC).", "AI": {"tldr": "论文提出了一种基于大型语言模型（LLM）的语音控制架构LMPVC，用于ROS2兼容机器人，通过集成策略编程和教学功能提升人机协作。", "motivation": "现代制造业向个性化和专业化转型，复杂任务需要人机协作，语音控制成为关键需求。", "method": "LMPVC架构结合代码生成和策略银行（Policy Bank）系统，实现语音控制与任务适应性。", "result": "LMPVC通过策略银行弥补LLM的局限性，无需昂贵训练即可适应不同任务。", "conclusion": "LMPVC为复杂人机协作任务提供了高效、灵活的解决方案。"}}
{"id": "2506.22034", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.22034", "abs": "https://arxiv.org/abs/2506.22034", "authors": ["Kejia Chen", "Celina Dettmering", "Florian Pachler", "Zhuo Liu", "Yue Zhang", "Tailai Cheng", "Jonas Dirr", "Zhenshan Bing", "Alois Knoll", "Rüdiger Daub"], "title": "Multi-Robot Assembly of Deformable Linear Objects Using Multi-Modal Perception", "comment": null, "summary": "Industrial assembly of deformable linear objects (DLOs) such as cables offers\ngreat potential for many industries. However, DLOs pose several challenges for\nrobot-based automation due to the inherent complexity of deformation and,\nconsequentially, the difficulties in anticipating the behavior of DLOs in\ndynamic situations. Although existing studies have addressed isolated\nsubproblems like shape tracking, grasping, and shape control, there has been\nlimited exploration of integrated workflows that combine these individual\nprocesses. To address this gap, we propose an object-centric perception and\nplanning framework to achieve a comprehensive DLO assembly process throughout\nthe industrial value chain. The framework utilizes visual and tactile\ninformation to track the DLO's shape as well as contact state across different\nstages, which facilitates effective planning of robot actions. Our approach\nencompasses robot-based bin picking of DLOs from cluttered environments,\nfollowed by a coordinated handover to two additional robots that mount the DLOs\nonto designated fixtures. Real-world experiments employing a setup with\nmultiple robots demonstrate the effectiveness of the approach and its relevance\nto industrial scenarios.", "AI": {"tldr": "提出了一种基于对象感知和规划的框架，用于实现工业价值链中全面的可变形线性物体（DLO）组装过程。", "motivation": "工业中DLO（如电缆）的组装潜力巨大，但由于其变形复杂性和动态行为难以预测，机器人自动化面临挑战。现有研究仅解决孤立子问题，缺乏集成工作流。", "method": "结合视觉和触觉信息跟踪DLO的形状和接触状态，规划机器人动作。包括从杂乱环境中拾取DLO，并协调多机器人完成装配。", "result": "通过多机器人实验验证了方法的有效性及其工业适用性。", "conclusion": "提出的框架为DLO的工业组装提供了集成解决方案，展示了实际应用的潜力。"}}
{"id": "2506.22087", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.22087", "abs": "https://arxiv.org/abs/2506.22087", "authors": ["Armand Jordana", "Jianghan Zhang", "Joseph Amigo", "Ludovic Righetti"], "title": "An Introduction to Zero-Order Optimization Techniques for Robotics", "comment": null, "summary": "Zero-order optimization techniques are becoming increasingly popular in\nrobotics due to their ability to handle non-differentiable functions and escape\nlocal minima. These advantages make them particularly useful for trajectory\noptimization and policy optimization. In this work, we propose a mathematical\ntutorial on random search. It offers a simple and unifying perspective for\nunderstanding a wide range of algorithms commonly used in robotics. Leveraging\nthis viewpoint, we classify many trajectory optimization methods under a common\nframework and derive novel competitive RL algorithms.", "AI": {"tldr": "本文介绍了零阶优化技术在机器人学中的应用，并提出了一种随机搜索的数学教程，用于统一理解多种算法。", "motivation": "零阶优化技术因其能处理不可微函数和逃离局部极小值的优势，在机器人学中越来越受欢迎，尤其是在轨迹优化和策略优化中。", "method": "提出了一种随机搜索的数学教程，为理解机器人学中常用的多种算法提供了简单且统一的视角。", "result": "基于这一视角，将多种轨迹优化方法分类到一个共同框架下，并推导出新颖且具有竞争力的强化学习算法。", "conclusion": "随机搜索的数学教程为机器人学中的优化问题提供了统一且实用的解决方案。"}}
{"id": "2506.22116", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.22116", "abs": "https://arxiv.org/abs/2506.22116", "authors": ["Noora Sassali", "Roel Pieters"], "title": "Evaluating Pointing Gestures for Target Selection in Human-Robot Collaboration", "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and\n  Human Interactive Communication (RO-MAN). Preprint", "summary": "Pointing gestures are a common interaction method used in Human-Robot\nCollaboration for various tasks, ranging from selecting targets to guiding\nindustrial processes. This study introduces a method for localizing pointed\ntargets within a planar workspace. The approach employs pose estimation, and a\nsimple geometric model based on shoulder-wrist extension to extract gesturing\ndata from an RGB-D stream. The study proposes a rigorous methodology and\ncomprehensive analysis for evaluating pointing gestures and target selection in\ntypical robotic tasks. In addition to evaluating tool accuracy, the tool is\nintegrated into a proof-of-concept robotic system, which includes object\ndetection, speech transcription, and speech synthesis to demonstrate the\nintegration of multiple modalities in a collaborative application. Finally, a\ndiscussion over tool limitations and performance is provided to understand its\nrole in multimodal robotic systems. All developments are available at:\nhttps://github.com/NMKsas/gesture_pointer.git.", "AI": {"tldr": "该研究提出了一种基于姿态估计和几何模型的方法，用于定位平面工作空间中的指向目标，并评估其在机器人任务中的表现。", "motivation": "指向手势是人机协作中常用的交互方式，但需要一种准确的方法来定位目标并评估其性能。", "method": "采用姿态估计和基于肩-腕伸展的几何模型，从RGB-D流中提取手势数据，并集成到多模态机器人系统中。", "result": "研究提出了一种严格的评估方法，并通过概念验证系统展示了多模态集成的可行性。", "conclusion": "讨论了工具的局限性和性能，强调了其在多模态机器人系统中的潜在作用。"}}
{"id": "2506.22170", "categories": ["cs.RO", "math.OC", "00A69, 93C85, 14H55", "I.2.9"], "pdf": "https://arxiv.org/pdf/2506.22170", "abs": "https://arxiv.org/abs/2506.22170", "authors": ["Yu Zhang", "Xiao-Song Yang"], "title": "RM-Dijkstra: A surface optimal path planning algorithm based on Riemannian metric", "comment": "7 pages", "summary": "The Dijkstra algorithm is a classic path planning method, which operates in a\ndiscrete graph space to determine the shortest path from a specified source\npoint to a target node or all other nodes based on non-negative edge weights.\nNumerous studies have focused on the Dijkstra algorithm due to its potential\napplication. However, its application in surface path planning for mobile\nrobots remains largely unexplored. In this letter, a surface optimal path\nplanning algorithm called RM-Dijkstra is proposed, which is based on Riemannian\nmetric model. By constructing a new Riemannian metric on the 2D projection\nplane, the surface optimal path planning problem is therefore transformed into\na geometric problem on the 2D plane with new Riemannian metric. Induced by the\nstandard Euclidean metric on surface, the constructed new metric reflects\nenvironmental information of the robot and ensures that the projection map is\nan isometric immersion. By conducting a series of simulation tests, the\nexperimental results demonstrate that the RM-Dijkstra algorithm not only\neffectively solves the optimal path planning problem on surfaces, but also\noutperforms traditional path planning algorithms in terms of path accuracy and\nsmoothness, particularly in complex scenarios.", "AI": {"tldr": "提出了一种基于黎曼度量的RM-Dijkstra算法，用于解决移动机器人表面最优路径规划问题，优于传统算法。", "motivation": "Dijkstra算法在离散图空间中表现优异，但其在移动机器人表面路径规划中的应用尚未充分探索。", "method": "通过构建新的黎曼度量，将表面最优路径规划问题转化为二维平面上的几何问题。", "result": "实验表明，RM-Dijkstra算法在路径精度和平滑度上优于传统算法，尤其在复杂场景中。", "conclusion": "RM-Dijkstra算法为表面路径规划提供了一种有效且优越的解决方案。"}}
{"id": "2506.22174", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22174", "abs": "https://arxiv.org/abs/2506.22174", "authors": ["Bavo Lesy", "Siemen Herremans", "Robin Kerstens", "Jan Steckel", "Walter Daems", "Siegfried Mercelis", "Ali Anwar"], "title": "ASVSim (AirSim for Surface Vehicles): A High-Fidelity Simulation Framework for Autonomous Surface Vehicle Research", "comment": "14 Pages, 11 Figures", "summary": "The transport industry has recently shown significant interest in unmanned\nsurface vehicles (USVs), specifically for port and inland waterway transport.\nThese systems can improve operational efficiency and safety, which is\nespecially relevant in the European Union, where initiatives such as the Green\nDeal are driving a shift towards increased use of inland waterways. At the same\ntime, a shortage of qualified personnel is accelerating the adoption of\nautonomous solutions. However, there is a notable lack of open-source,\nhigh-fidelity simulation frameworks and datasets for developing and evaluating\nsuch solutions. To address these challenges, we introduce AirSim For Surface\nVehicles (ASVSim), an open-source simulation framework specifically designed\nfor autonomous shipping research in inland and port environments. The framework\ncombines simulated vessel dynamics with marine sensor simulation capabilities,\nincluding radar and camera systems and supports the generation of synthetic\ndatasets for training computer vision models and reinforcement learning agents.\nBuilt upon Cosys-AirSim, ASVSim provides a comprehensive platform for\ndeveloping autonomous navigation algorithms and generating synthetic datasets.\nThe simulator supports research of both traditional control methods and deep\nlearning-based approaches. Through limited experiments, we demonstrate the\npotential of the simulator in these research areas. ASVSim is provided as an\nopen-source project under the MIT license, making autonomous navigation\nresearch accessible to a larger part of the ocean engineering community.", "AI": {"tldr": "ASVSim是一个开源仿真框架，专为内河和港口环境中的自主航运研究设计，结合了船舶动力学和海洋传感器模拟能力。", "motivation": "运输行业对无人水面车辆（USVs）的兴趣增加，但缺乏开源高保真仿真框架和数据集，阻碍了自主解决方案的开发。", "method": "基于Cosys-AirSim开发ASVSim，支持船舶动力学模拟、海洋传感器（如雷达和摄像头）仿真，并生成合成数据集。", "result": "ASVSim为自主导航算法开发和合成数据集生成提供了全面平台，支持传统控制方法和深度学习研究。", "conclusion": "ASVSim作为开源项目，有望推动海洋工程领域的自主导航研究。"}}
{"id": "2506.22176", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.22176", "abs": "https://arxiv.org/abs/2506.22176", "authors": ["Holly Dinkel", "Raghavendra Navaratna", "Jingyi Xiang", "Brian Coltin", "Trey Smith", "Timothy Bretl"], "title": "KnotDLO: Toward Interpretable Knot Tying", "comment": "4 pages, 5 figures, presented at the Workshop on 3D Visual\n  Representations for Manipulation at the 2023 IEEE International Conference on\n  Robotics and Automation in Yokohama, Japan. Video presentation\n  [https://youtu.be/mg30uCUtpOk]. Poster\n  [https://hollydinkel.github.io/assets/pdf/ICRA20243DVRM_poster.pdf] 3DVRM\n  Workshop [https://3d-manipulation-workshop.github.io/]", "summary": "This work presents KnotDLO, a method for one-handed Deformable Linear Object\n(DLO) knot tying that is robust to occlusion, repeatable for varying rope\ninitial configurations, interpretable for generating motion policies, and\nrequires no human demonstrations or training. Grasp and target waypoints for\nfuture DLO states are planned from the current DLO shape. Grasp poses are\ncomputed from indexing the tracked piecewise linear curve representing the DLO\nstate based on the current curve shape and are piecewise continuous. KnotDLO\ncomputes intermediate waypoints from the geometry of the current DLO state and\nthe desired next state. The system decouples visual reasoning from control. In\n16 trials of knot tying, KnotDLO achieves a 50% success rate in tying an\noverhand knot from previously unseen configurations.", "AI": {"tldr": "KnotDLO是一种无需人类演示或训练的单手可变形线性物体（DLO）打结方法，具有抗遮挡性、可重复性和可解释性。", "motivation": "解决DLO打结中的遮挡问题，并实现无需人类干预的自动化打结。", "method": "通过当前DLO形状规划抓取和目标路径点，利用分段线性曲线跟踪和几何计算生成中间路径点。", "result": "在16次实验中，KnotDLO成功率为50%，能够从未见过的配置中打结。", "conclusion": "KnotDLO展示了无需人类干预的DLO自动化打结潜力，但成功率有待提高。"}}
{"id": "2506.22364", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.22364", "abs": "https://arxiv.org/abs/2506.22364", "authors": ["Joe Johnson", "Phanender Chalasani", "Arnav Shah", "Ram L. Ray", "Muthukumar Bagavathiannan"], "title": "Robotic Multimodal Data Acquisition for In-Field Deep Learning Estimation of Cover Crop Biomass", "comment": "Accepted in the Extended Abstract, The 22nd International Conference\n  on Ubiquitous Robots (UR 2025), Texas, USA", "summary": "Accurate weed management is essential for mitigating significant crop yield\nlosses, necessitating effective weed suppression strategies in agricultural\nsystems. Integrating cover crops (CC) offers multiple benefits, including soil\nerosion reduction, weed suppression, decreased nitrogen requirements, and\nenhanced carbon sequestration, all of which are closely tied to the aboveground\nbiomass (AGB) they produce. However, biomass production varies significantly\ndue to microsite variability, making accurate estimation and mapping essential\nfor identifying zones of poor weed suppression and optimizing targeted\nmanagement strategies. To address this challenge, developing a comprehensive CC\nmap, including its AGB distribution, will enable informed decision-making\nregarding weed control methods and optimal application rates. Manual visual\ninspection is impractical and labor-intensive, especially given the extensive\nfield size and the wide diversity and variation of weed species and sizes. In\nthis context, optical imagery and Light Detection and Ranging (LiDAR) data are\ntwo prominent sources with unique characteristics that enhance AGB estimation.\nThis study introduces a ground robot-mounted multimodal sensor system designed\nfor agricultural field mapping. The system integrates optical and LiDAR data,\nleveraging machine learning (ML) methods for data fusion to improve biomass\npredictions. The best ML-based model for dry AGB estimation achieved a\ncoefficient of determination value of 0.88, demonstrating robust performance in\ndiverse field conditions. This approach offers valuable insights for\nsite-specific management, enabling precise weed suppression strategies and\npromoting sustainable farming practices.", "AI": {"tldr": "研究提出了一种结合光学和LiDAR数据的多模态传感器系统，通过机器学习方法提升生物量预测精度，以优化杂草管理策略。", "motivation": "杂草管理对减少作物产量损失至关重要，而覆盖作物的生物量分布直接影响其抑制杂草的效果。准确估计和绘制生物量分布是优化管理策略的关键。", "method": "开发了一种地面机器人搭载的多模态传感器系统，结合光学和LiDAR数据，利用机器学习方法进行数据融合，以提高生物量预测。", "result": "最佳机器学习模型在干燥生物量估计中达到了0.88的决定系数，表现优异。", "conclusion": "该方法为精准杂草抑制策略提供了有效工具，有助于推动可持续农业实践。"}}
