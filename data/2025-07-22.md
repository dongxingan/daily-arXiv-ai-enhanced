<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 43]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach](https://arxiv.org/abs/2507.14249)
*Yuejiao Xie,Maonan Wang,Di Zhou,Man-On Pun,Zhu Han*

Main category: cs.RO

TL;DR: 本文提出了一种基于无线电地图和混合注意力强化学习的UAM路径规划方法，以应对动态乘客需求和通信质量挑战。


<details>
  <summary>Details</summary>
Motivation: UAM系统需解决动态乘客需求和通信质量问题，传统路径规划方法缺乏灵活性。

Method: 构建无线电地图评估通信质量，提出MSHA-RL框架，通过混合注意力平衡全局与局部信息。

Result: 实验表明该方法能减少旅行时间并提高效率，同时确保通信合规性和乘客安全。

Conclusion: MSHA-RL框架为UAM系统提供了实时、自适应的路径规划解决方案。

Abstract: Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions
to alleviate urban congestion, with path planning becoming a key focus area.
Unlike ground transportation, UAM trajectory planning has to prioritize
communication quality for accurate location tracking in constantly changing
environments to ensure safety. Meanwhile, a UAM system, serving as an air taxi,
requires adaptive planning to respond to real-time passenger requests,
especially in ride-sharing scenarios where passenger demands are unpredictable
and dynamic. However, conventional trajectory planning strategies based on
predefined routes lack the flexibility to meet varied passenger ride demands.
To address these challenges, this work first proposes constructing a radio map
to evaluate the communication quality of urban airspace. Building on this, we
introduce a novel Multi-Source Hybrid Attention Reinforcement Learning
(MSHA-RL) framework for the challenge of effectively focusing on passengers and
UAM locations, which arises from the significant dimensional disparity between
the representations. This model first generates the alignment among diverse
data sources with large gap dimensions before employing hybrid attention to
balance global and local insights, thereby facilitating responsive, real-time
path planning. Extensive experimental results demonstrate that the approach
enables communication-compliant trajectory planning, reducing travel time and
enhancing operational efficiency while prioritizing passenger safety.

</details>


### [2] [A Recursive Lie-Group Formulation for the Second-Order Time Derivatives of the Inverse Dynamics of parallel Kinematic Manipulators](https://arxiv.org/abs/2507.14274)
*Andreas Mueller,Shivesh Kumar,Thomas Kordik*

Main category: cs.RO

TL;DR: 本文首次提出了用于并联运动学机械臂（PKM）的系列弹性执行器（SEA）的轨迹控制方法，重点解决了逆动力学解的二阶时间导数的高效计算问题。


<details>
  <summary>Details</summary>
Motivation: 并联运动学机械臂（PKM）配备系列弹性执行器（SEA）的轨迹控制尚未实现，关键挑战在于高效计算逆动力学解的二阶时间导数。

Method: 利用PKM的特殊拓扑结构，复用串联机器人逆动力学的递归算法，并采用李群框架推导所有关系。

Result: 数值结果展示了在6自由度Gough-Stewart平台（外骨骼的一部分）和平面PKM上应用平坦性控制方案的效果。

Conclusion: 本文首次解决了PKM配备SEA的轨迹控制问题，为相关应用提供了高效的计算方法。

Abstract: Series elastic actuators (SEA) were introduced for serial robotic arms. Their
model-based trajectory tracking control requires the second time derivatives of
the inverse dynamics solution, for which algorithms were proposed. Trajectory
control of parallel kinematics manipulators (PKM) equipped with SEAs has not
yet been pursued. Key element for this is the computationally efficient
evaluation of the second time derivative of the inverse dynamics solution. This
has not been presented in the literature, and is addressed in the present paper
for the first time. The special topology of PKM is exploited reusing the
recursive algorithms for evaluating the inverse dynamics of serial robots. A
Lie group formulation is used and all relations are derived within this
framework. Numerical results are presented for a 6-DOF Gough-Stewart platform
(as part of an exoskeleton), and for a planar PKM when a flatness-based control
scheme is applied.

</details>


### [3] [Personalized Socially Assistive Robots With End-to-End Speech-Language Models For Well-Being Support](https://arxiv.org/abs/2507.14412)
*Mengxue Fu,Zhonghao Shi,Minyu Huang,Siqi Liu,Mina Kian,Yirui Song,Maja J. Matarić*

Main category: cs.RO

TL;DR: 本文提出使用端到端语音语言模型（SLM）改进社交辅助机器人（SAR）的对话系统，并通过用户研究验证其效果，发现其在共情反馈和自然对话方面表现良好，但仍需改进非语言行为和个性化反馈。


<details>
  <summary>Details</summary>
Motivation: 现有SAR对话系统在实时延迟、反馈机制和个性化对话方面存在不足，需通过SLM技术提升其性能。

Method: 采用端到端SLM技术，并通过小规模用户研究（N=11）评估系统效果。

Result: 用户认为SLM-SAR系统在共情反馈和自然对话方面表现良好，但非语言行为和反馈的个性化仍需改进。

Conclusion: 未来需优化机器人动作同步、提示生成和语音表达，以进一步提升SAR系统的实用性。

Abstract: Socially assistive robots (SARs) have shown great potential for supplementing
well-being support. However, prior studies have found that existing dialogue
pipelines for SARs remain limited in real-time latency, back-channeling, and
personalized speech dialogue. Toward addressing these limitations, we propose
using integrated end-to-end speech-language models (SLMs) with SARs. This work
1) evaluated the usability of an SLM-enabled SAR dialogue system through a
small user study, and 2) identified remaining limitations through study user
feedback to inform future improvements. We conducted a small within-participant
user study with university students (N = 11) whose results showed that
participants perceived an SLM-enabled SAR system as capable of providing
empathetic feedback, natural turn-taking, back-channeling, and adaptive
responses. We also found that participants reported the robot's nonverbal
behaviors as lacking variability and synchronization with conversation, and the
SLM's verbal feedback as generic and repetitive. These findings highlighted the
need for real-time robot movement synchronized with conversation, improved
prompting or fine-tuning to generate outputs better aligned with mental health
practices, and more expressive, adaptive vocal generation.

</details>


### [4] [Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking](https://arxiv.org/abs/2507.14455)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 将时间延迟嵌入技术扩展到周期性非光滑或混合系统，构建线性状态空间模型，并提出一种新的状态历史增强LQR控制方法。


<details>
  <summary>Details</summary>
Motivation: 研究周期性非光滑或混合系统是否可以通过时间延迟嵌入技术建模为线性状态空间系统。

Method: 扩展时间延迟嵌入技术，应用于弹跳摆和简化步行者两个周期性混合系统，并构建状态历史增强的LQR控制器。

Result: 成功构建了线性状态空间模型，并验证了状态历史增强LQR的有效性。

Conclusion: 时间延迟嵌入技术适用于周期性非光滑或混合系统，状态历史增强LQR是一种有效的控制方法。

Abstract: Time-delay embedding is a technique that uses snapshots of state history over
time to build a linear state space model of a nonlinear smooth system. We
demonstrate that periodic non-smooth or hybrid system can also be modeled as a
linear state space system using this approach as long as its behavior is
consistent in modes and timings. We extended time-delay embeddings to generate
a linear model of two periodic hybrid systems: the bouncing pendulum and the
simplest walker with control inputs. This leads to a novel state history
augmented linear quadratic regulator (LQR) which uses current and past state
history for feedback control.

</details>


### [5] [Corridor-based Adaptive Control Barrier and Lyapunov Functions for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.14700)
*Nicholas Mohammad,Nicola Bezzo*

Main category: cs.RO

TL;DR: 提出了一种结合CLF和CBF的MPCC框架，用于在未知杂乱环境中安全导航，并通过SAC动态调整CBF参数。


<details>
  <summary>Details</summary>
Motivation: 现有MPCC方法缺乏形式化安全保证，无法在未知杂乱环境中确保安全导航。

Method: 结合CLF和CBF的MPCC框架，动态调整CBF参数以增强可行性。

Result: 通过仿真和移动机器人实验验证了方法的有效性。

Conclusion: 该方法在未知杂乱环境中实现了安全导航，并具有动态适应性。

Abstract: Safe navigation in unknown and cluttered environments remains a challenging
problem in robotics. Model Predictive Contour Control (MPCC) has shown promise
for performant obstacle avoidance by enabling precise and agile trajectory
tracking, however, existing methods lack formal safety assurances. To address
this issue, we propose a general Control Lyapunov Function (CLF) and Control
Barrier Function (CBF) enabled MPCC framework that enforces safety constraints
derived from a free-space corridor around the planned trajectory. To enhance
feasibility, we dynamically adapt the CBF parameters at runtime using a Soft
Actor-Critic (SAC) policy. The approach is validated with extensive simulations
and an experiment on mobile robot navigation in unknown cluttered environments.

</details>


### [6] [A 21-DOF Humanoid Dexterous Hand with Hybrid SMA-Motor Actuation: CYJ Hand-0](https://arxiv.org/abs/2507.14538)
*Jin Chai,Xiang Yao,Mengfan Hou,Yanghong Li,Erbao Dong*

Main category: cs.RO

TL;DR: CYJ Hand-0是一种21自由度的仿人灵巧手，采用混合肌腱驱动系统（结合形状记忆合金和直流电机），通过3D打印金属框架和人工肌腱实现仿生设计。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够模拟人手骨骼和肌腱肌肉结构的仿生灵巧手，以提升机器手的灵活性和功能性。

Method: 使用高强度的钓鱼线作为人工肌腱，结合3D打印的AlSi10Mg金属框架，采用线性电机驱动模块控制手指弯曲，形状记忆合金模块控制手指伸展和侧向外展。

Result: 机械和运动学实验验证了设计的有效性，展示了其仿生灵巧性。

Conclusion: CYJ Hand-0的设计成功实现了仿生灵巧手的性能，为未来机器人手的发展提供了新思路。

Abstract: CYJ Hand-0 is a 21-DOF humanoid dexterous hand featuring a hybrid
tendon-driven actuation system that combines shape memory alloys (SMAs) and DC
motors. The hand employs high-strength fishing line as artificial tendons and
uses a fully 3D-printed AlSi10Mg metal frame designed to replicate the skeletal
and tendon-muscle structure of the human hand. A linear motor-driven module
controls finger flexion, while an SMA-based module enables finger extension and
lateral abduction. These modules are integrated into a compact hybrid actuation
unit mounted on a custom rear support structure. Mechanical and kinematic
experiments, conducted under an Arduino Mega 2560-based control system,
validate the effectiveness of the design and demonstrate its biomimetic
dexterity.

</details>


### [7] [CPED-NCBFs: A Conformal Prediction for Expert Demonstration-based Neural Control Barrier Functions](https://arxiv.org/abs/2507.15022)
*Sumeadh MS,Kevin Dsouza,Ravi Prakash*

Main category: cs.RO

TL;DR: 本文提出了一种基于分形共形预测的验证策略（CPED-NCBFs），用于验证从专家演示中学习的神经控制屏障函数（NCBFs），以确保其在整个状态空间中的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有验证方法（如SMT求解器、MIP和区间传播方法）往往产生宽松且保守的边界，无法有效验证NCBFs的安全性。

Method: 采用分形共形预测策略（CPED-NCBFs）验证NCBFs，并在点质量系统和非完整模型上进行实验验证。

Result: 实验结果表明，CPED-NCBFs方法能有效验证NCBFs的安全性。

Conclusion: CPED-NCBFs提供了一种更精确的验证方法，克服了现有技术的局限性。

Abstract: Among the promising approaches to enforce safety in control systems, learning
Control Barrier Functions (CBFs) from expert demonstrations has emerged as an
effective strategy. However, a critical challenge remains: verifying that the
learned CBFs truly enforce safety across the entire state space. This is
especially difficult when CBF is represented using neural networks (NCBFs).
Several existing verification techniques attempt to address this problem
including SMT-based solvers, mixed-integer programming (MIP), and interval or
bound-propagation methods but these approaches often introduce loose,
conservative bounds. To overcome these limitations, in this work we use
CPED-NCBFs a split-conformal prediction based verification strategy to verify
the learned NCBF from the expert demonstrations. We further validate our method
on point mass systems and unicycle models to demonstrate the effectiveness of
the proposed theory.

</details>


### [8] [BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives](https://arxiv.org/abs/2507.14582)
*Zezhi Liu,Shizhen Wu,Hanqian Luo,Deyun Qin,Yongchun Fang*

Main category: cs.RO

TL;DR: 论文提出了一种名为BT-TL-DMPs的分层框架，结合行为树、时序逻辑和动态运动原语，以解决机器人从演示中学习技能并适应新场景的挑战。


<details>
  <summary>Details</summary>
Motivation: 在演示学习（LfD）中，机器人难以将学到的技能推广到具有不同任务和运动需求的新环境，尤其是在长期、多阶段且约束复杂的场景中。

Method: 框架使用信号时序逻辑（STL）规范任务需求，并将其转化为行为树用于高层决策，同时提出STL约束的DMP优化方法以调整运动原语。

Result: 仿真和实际实验验证了框架在多种STL约束下的泛化能力，成功应用于长期机器人操作任务。

Conclusion: 该框架有效弥合了符号与运动之间的鸿沟，提升了复杂任务中自主操作的可靠性和泛化能力。

Abstract: In the field of Learning from Demonstration (LfD), enabling robots to
generalize learned manipulation skills to novel scenarios for long-horizon
tasks remains challenging. Specifically, it is still difficult for robots to
adapt the learned skills to new environments with different task and motion
requirements, especially in long-horizon, multi-stage scenarios with intricate
constraints. This paper proposes a novel hierarchical framework, called
BT-TL-DMPs, that integrates Behavior Tree (BT), Temporal Logic (TL), and
Dynamical Movement Primitives (DMPs) to address this problem. Within this
framework, Signal Temporal Logic (STL) is employed to formally specify complex,
long-horizon task requirements and constraints. These STL specifications are
systematically transformed to generate reactive and modular BTs for high-level
decision-making task structure. An STL-constrained DMP optimization method is
proposed to optimize the DMP forcing term, allowing the learned motion
primitives to adapt flexibly while satisfying intricate spatiotemporal
requirements and, crucially, preserving the essential dynamics learned from
demonstrations. The framework is validated through simulations demonstrating
generalization capabilities under various STL constraints and real-world
experiments on several long-horizon robotic manipulation tasks. The results
demonstrate that the proposed framework effectively bridges the symbolic-motion
gap, enabling more reliable and generalizable autonomous manipulation for
complex robotic tasks.

</details>


### [9] [VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving](https://arxiv.org/abs/2507.15266)
*Haichao Liu,Haoren Guo,Pei Liu,Benshan Ma,Yuxiang Zhang,Jun Ma,Tong Heng Lee*

Main category: cs.RO

TL;DR: 提出了一种基于视觉语言模型（VLM）的统一决策与运动控制框架VLM-UDMC，用于提升自动驾驶的场景理解和风险感知能力。


<details>
  <summary>Details</summary>
Motivation: 模仿人类驾驶员的认知能力，确保自动驾驶的透明性和可解释性。

Method: 采用两级系统：上层慢系统通过RAG技术生成风险感知洞察，下层快系统实时调整运动规划。

Result: 通过仿真和实际测试验证了框架的有效性，提升了城市驾驶性能。

Conclusion: VLM-UDMC成功结合场景理解和注意力分解，优化了自动驾驶决策。

Abstract: Scene understanding and risk-aware attentions are crucial for human drivers
to make safe and effective driving decisions. To imitate this cognitive ability
in urban autonomous driving while ensuring the transparency and
interpretability, we propose a vision-language model (VLM)-enhanced unified
decision-making and motion control framework, named VLM-UDMC. This framework
incorporates scene reasoning and risk-aware insights into an upper-level slow
system, which dynamically reconfigures the optimal motion planning for the
downstream fast system. The reconfiguration is based on real-time environmental
changes, which are encoded through context-aware potential functions. More
specifically, the upper-level slow system employs a two-step reasoning policy
with Retrieval-Augmented Generation (RAG), leveraging foundation models to
process multimodal inputs and retrieve contextual knowledge, thereby generating
risk-aware insights. Meanwhile, a lightweight multi-kernel decomposed LSTM
provides real-time trajectory predictions for heterogeneous traffic
participants by extracting smoother trend representations for short-horizon
trajectory prediction. The effectiveness of the proposed VLM-UDMC framework is
verified via both simulations and real-world experiments with a full-size
autonomous vehicle. It is demonstrated that the presented VLM-UDMC effectively
leverages scene understanding and attention decomposition for rational driving
decisions, thus improving the overall urban driving performance. Our
open-source project is available at https://github.com/henryhcliu/vlmudmc.git.

</details>


### [10] [Koopman Operator Based Linear Model Predictive Control for 2D Quadruped Trotting, Bounding, and Gait Transition](https://arxiv.org/abs/2507.14605)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 论文提出了一种基于Koopman算子理论和EDMD的四足机器人运动控制方法，通过高维线性模型保留非线性动力学特性，并利用LMPC实现多种步态和步态转换的在线生成。


<details>
  <summary>Details</summary>
Motivation: 在线控制四足机器人在新场景中的运动需要高质量的控制方法，而传统的LMPC因线性化动力学方程可能导致解的质量不佳。

Method: 结合Koopman算子理论和EDMD构建高维线性模型，分别建模空中和地面接触阶段，并应用LMPC进行实时控制。

Result: 在平坦和崎岖地形上实现了跳跃、小跑以及步态转换（如跳跃到小跑和小跑到跳跃）。

Conclusion: 通过Koopman算子理论构建混合模型，成功实现了四足机器人多种步态的在线生成和转换，展示了方法的创新性和实用性。

Abstract: Online optimal control of quadrupedal robots would enable them to plan their
movement in novel scenarios. Linear Model Predictive Control (LMPC) has emerged
as a practical approach for real-time control. In LMPC, an optimization problem
with a quadratic cost and linear constraints is formulated over a finite
horizon and solved on the fly. However, LMPC relies on linearizing the
equations of motion (EOM), which may lead to poor solution quality. In this
paper, we use Koopman operator theory and the Extended Dynamic Mode
Decomposition (EDMD) to create a linear model of the system in high dimensional
space, thus retaining the nonlinearity of the EOM. We model the aerial phase
and ground contact phases using different linear models. Then, using LMPC, we
demonstrate bounding, trotting, and bound-to-trot and trot-to-bound gait
transitions in level and rough terrains. The main novelty is the use of Koopman
operator theory to create hybrid models of a quadrupedal system and demonstrate
the online generation of multiple gaits and gaits transitions.

</details>


### [11] [Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks](https://arxiv.org/abs/2507.14694)
*Yue Ma,Kanglei Zhou,Fuyang Yu,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.RO

TL;DR: ProbHMI提出了一种基于可逆网络的方法，用于3D人体运动预测中的不确定性量化，适用于安全关键场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法在不确定性量化方面表现不足，而安全关键场景（如人机协作）需要准确的风险评估。

Method: 使用可逆网络将姿态参数化解耦到潜在空间，并通过预测模块显式建模未来潜在分布。

Result: 在基准测试中，ProbHMI在确定性和多样性预测方面表现优异，同时验证了不确定性校准的有效性。

Conclusion: ProbHMI为风险感知决策提供了可靠的不确定性量化方法。

Abstract: 3D human motion forecasting aims to enable autonomous applications.
Estimating uncertainty for each prediction (i.e., confidence based on
probability density or quantile) is essential for safety-critical contexts like
human-robot collaboration to minimize risks. However, existing diverse motion
forecasting approaches struggle with uncertainty quantification due to implicit
probabilistic representations hindering uncertainty modeling. We propose
ProbHMI, which introduces invertible networks to parameterize poses in a
disentangled latent space, enabling probabilistic dynamics modeling. A
forecasting module then explicitly predicts future latent distributions,
allowing effective uncertainty quantification. Evaluated on benchmarks, ProbHMI
achieves strong performance for both deterministic and diverse prediction while
validating uncertainty calibration, critical for risk-aware decision making.

</details>


### [12] [Leveraging Extrinsic Dexterity for Occluded Grasping on Grasp Constraining Walls](https://arxiv.org/abs/2507.14721)
*Keita Kobashi,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 提出了一种分层强化学习框架，结合Q学习和CVAE，解决机器人因遮挡无法抓取物体的问题，并在仿真和现实中验证了方法的通用性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决因环境遮挡导致机器人无法抓取物体的问题，尤其是当可用环境特征（如墙壁）不符合假设时。

Method: 采用分层强化学习框架，高层策略选择动作类型，低层技能在连续空间中执行具体动作，并使用CVAE推断适合的执行位置。

Result: 在仿真和现实实验中验证了方法的通用性和鲁棒性，取得了较高的成功率。

Conclusion: 提出的方法能有效解决遮挡抓取问题，并展示了良好的仿真到现实的迁移能力。

Abstract: This study addresses the problem of occluded grasping, where primary grasp
configurations of an object are not available due to occlusion with
environment. Simple parallel grippers often struggle with such tasks due to
limited dexterity and actuation constraints. Prior works have explored object
pose reorientation such as pivoting by utilizing extrinsic contacts between an
object and an environment feature like a wall, to make the object graspable.
However, such works often assume the presence of a short wall, and this
assumption may not always hold in real-world scenarios. If the wall available
for interaction is too large or too tall, the robot may still fail to grasp the
object even after pivoting, and the robot must combine different types of
actions to grasp. To address this, we propose a hierarchical reinforcement
learning (RL) framework. We use Q-learning to train a high-level policy that
selects the type of action expected to yield the highest reward. The selected
low-level skill then samples a specific robot action in continuous space. To
guide the robot to an appropriate location for executing the selected action,
we adopt a Conditional Variational Autoencoder (CVAE). We condition the CVAE on
the object point cloud and the skill ID, enabling it to infer a suitable
location based on the object geometry and the selected skill. To promote
generalization, we apply domain randomization during the training of low-level
skills. The RL policy is trained entirely in simulation with a box-like object
and deployed to six objects in real world. We conduct experiments to evaluate
our method and demonstrate both its generalizability and robust sim-to-real
transfer performance with promising success rates.

</details>


### [13] [X-Nav: Learning End-to-End Cross-Embodiment Navigation for Mobile Robots](https://arxiv.org/abs/2507.14731)
*Haitong Wang,Aaron Hao Tan,Angus Fung,Goldie Nejat*

Main category: cs.RO

TL;DR: X-Nav是一个跨机器人平台导航的统一框架，通过两阶段学习实现通用策略，支持零样本迁移到新平台。


<details>
  <summary>Details</summary>
Motivation: 现有导航方法局限于特定机器人平台，缺乏通用性。

Method: 1) 训练多个专家策略；2) 通过Nav-ACT蒸馏为通用策略。

Result: 在模拟和真实环境中验证了零样本迁移能力和可扩展性。

Conclusion: X-Nav展示了跨平台导航的潜力，设计选择有效。

Abstract: Existing navigation methods are primarily designed for specific robot
embodiments, limiting their generalizability across diverse robot platforms. In
this paper, we introduce X-Nav, a novel framework for end-to-end
cross-embodiment navigation where a single unified policy can be deployed
across various embodiments for both wheeled and quadrupedal robots. X-Nav
consists of two learning stages: 1) multiple expert policies are trained using
deep reinforcement learning with privileged observations on a wide range of
randomly generated robot embodiments; and 2) a single general policy is
distilled from the expert policies via navigation action chunking with
transformer (Nav-ACT). The general policy directly maps visual and
proprioceptive observations to low-level control commands, enabling
generalization to novel robot embodiments. Simulated experiments demonstrated
that X-Nav achieved zero-shot transfer to both unseen embodiments and
photorealistic environments. A scalability study showed that the performance of
X-Nav improves when trained with an increasing number of randomly generated
embodiments. An ablation study confirmed the design choices of X-Nav.
Furthermore, real-world experiments were conducted to validate the
generalizability of X-Nav in real-world environments.

</details>


### [14] [KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning](https://arxiv.org/abs/2507.14820)
*Bingran Chen,Baorun Li,Jian Yang,Yong Liu,Guangyao Zhai*

Main category: cs.RO

TL;DR: KGN-Pro是一种新型抓取网络，通过概率PnP层直接优化3D信息，提升6-DoF抓取性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在6-DoF抓取估计中存在小物体和传感器噪声问题，或依赖昂贵的3D标注。KGN-Pro旨在结合2D效率与3D信息优化。

Method: KGN-Pro通过RGB-D图像生成关键点图和2D置信图，利用概率PnP层进行3D优化，实现端到端学习。

Result: 实验表明，KGN-Pro在抓取覆盖率和成功率上优于现有方法。

Conclusion: KGN-Pro通过3D优化显著提升了抓取性能，适用于仿真和真实场景。

Abstract: High-level robotic manipulation tasks demand flexible 6-DoF grasp estimation
to serve as a basic function. Previous approaches either directly generate
grasps from point-cloud data, suffering from challenges with small objects and
sensor noise, or infer 3D information from RGB images, which introduces
expensive annotation requirements and discretization issues. Recent methods
mitigate some challenges by retaining a 2D representation to estimate grasp
keypoints and applying Perspective-n-Point (PnP) algorithms to compute 6-DoF
poses. However, these methods are limited by their non-differentiable nature
and reliance solely on 2D supervision, which hinders the full exploitation of
rich 3D information. In this work, we present KGN-Pro, a novel grasping network
that preserves the efficiency and fine-grained object grasping of previous KGNs
while integrating direct 3D optimization through probabilistic PnP layers.
KGN-Pro encodes paired RGB-D images to generate Keypoint Map, and further
outputs a 2D confidence map to weight keypoint contributions during
re-projection error minimization. By modeling the weighted sum of squared
re-projection errors probabilistically, the network effectively transmits 3D
supervision to its 2D keypoint predictions, enabling end-to-end learning.
Experiments on both simulated and real-world platforms demonstrate that KGN-Pro
outperforms existing methods in terms of grasp cover rate and success rate.

</details>


### [15] [CoMoCAVs: Cohesive Decision-Guided Motion Planning for Connected and Autonomous Vehicles with Multi-Policy Reinforcement Learning](https://arxiv.org/abs/2507.14903)
*Pan Hu*

Main category: cs.RO

TL;DR: 本文提出了一种名为CDGMP的框架，通过混合专家架构和多策略强化学习，将决策制定和运动规划紧密结合，以提高自动驾驶的灵活性和安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要可靠且高效的决策制定和运动规划解决方案，尤其是在高速公路车道选择和精确轨迹执行方面。

Method: 采用混合专家（MoE）架构和多策略强化学习，通过门控机制协调多个专用子网络，将复杂驾驶任务分解为模块化组件。

Result: 仿真结果表明，CDGMP在车道选择和运动规划中表现出可靠的性能。

Conclusion: CDGMP不仅提升了自动驾驶的适应性和鲁棒性，还为其他高维决策和控制任务提供了基础。

Abstract: Autonomous driving demands reliable and efficient solutions to closely
related problems such as decision-making and motion planning. In this work,
decision-making refers specifically to highway lane selection, while motion
planning involves generating control commands (such as speed and steering) to
reach the chosen lane. In the context of Connected Autonomous Vehicles (CAVs),
achieving both flexible and safe lane selection alongside precise trajectory
execution remains a significant challenge. This paper proposes a framework
called Cohesive Decision-Guided Motion Planning (CDGMP), which tightly
integrates decision-making and motion planning using a Mixture of Experts (MoE)
inspired architecture combined with multi-policy reinforcement learning. By
coordinating multiple specialized sub-networks through a gating mechanism, the
method decomposes the complex driving task into modular components. Each
sub-network focuses on a specific aspect of driving, improving efficiency by
activating only the most relevant modules during inference. This design also
enhances safety through modular specialization. CDGMP improves the adaptability
and robustness of CAVs across diverse traffic scenarios, offering a scalable
solution to real-world autonomy challenges. The architectural principles behind
CDGMP, especially the use of MoE, also provide a strong foundation for other
high-dimensional decision and control tasks. Simulation results (available at
https://youtu.be/_-4OXNHV0UY) demonstrate reliable performance in both lane
selection and motion planning.

</details>


### [16] [One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner](https://arxiv.org/abs/2507.14914)
*Zhexuan Xu,Jie Wang,Siyuan Xu,Zijie Geng,Mingxuan Yuan,Feng Wu*

Main category: cs.RO

TL;DR: Flora是一种三阶段、考虑馈通和布局的矩形平面规划器，通过分阶段优化HPWL、馈通和组件布局，显著提升芯片PPA指标。


<details>
  <summary>Details</summary>
Motivation: 现有平面规划方法难以与后续物理设计阶段集成，导致模块内组件布局不优和模块间馈通过多。

Method: Flora分三阶段：1) 使用线掩模和位置掩模技术进行粗粒度优化；2) 在固定轮廓下通过局部调整模块形状实现零空白布局；3) 基于树搜索快速放置组件并调整模块边界。

Result: 实验显示，Flora平均减少HPWL 6%、FTpin 5.16%、FTmod 29.15%，组件布局性能提升14%。

Conclusion: Flora通过跨阶段优化，显著优于现有平面规划方法。

Abstract: Floorplanning determines the shapes and locations of modules on a chip canvas
and plays a critical role in optimizing the chip's Power, Performance, and Area
(PPA) metrics. However, existing floorplanning approaches often fail to
integrate with subsequent physical design stages, leading to suboptimal
in-module component placement and excessive inter-module feedthrough. To tackle
this challenge, we propose Flora, a three-stage feedthrough and placement aware
rectilinear floorplanner. In the first stage, Flora employs wiremask and
position mask techniques to achieve coarse-grained optimization of HPWL and
feedthrough. In the second stage, under the constraint of a fixed outline,
Flora achieves a zero-whitespace layout by locally resizing module shapes,
thereby performing fine-grained optimization of feedthrough and improving
component placement. In the third stage, Flora utilizes a fast tree
search-based method to efficiently place components-including macros and
standard cells-within each module, subsequently adjusting module boundaries
based on the placement results to enable cross-stage optimization. Experimental
results show that Flora outperforms recent state-of-the-art floorplanning
approaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin,
29.15% in FTmod, and a 14% improvement in component placement performance.

</details>


### [17] [Digital twin and extended reality for teleoperation of the electric vehicle battery disassembly](https://arxiv.org/abs/2507.14929)
*Tero Kaarlela,Sami Salo,Jose Outeiro*

Main category: cs.RO

TL;DR: 提出了一种用于电动汽车电池（EVB）安全拆卸和分类的远程操作系统，结合人机协作与自动化，提高安全性、适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 手动拆卸EVB存在安全隐患（如触电和有毒化学品），需开发更安全、高效的方法支持可持续电动汽车转型。

Method: 采用远程操作系统，结合人类操作员创建拆卸序列，利用RGB相机对齐物理与数字孪生，基于ROS中间件实现机器人数字孪生。

Result: 在线试点研究表明该方法具有用户友好性，能减少劳动力依赖并提高电池回收效率。

Conclusion: 该混合方法为EVB拆卸和分类提供了安全、适应性强且高效的解决方案，支持可持续供应链。

Abstract: Disassembling and sorting Electric Vehicle Batteries (EVBs) supports a
sustainable transition to electric vehicles by enabling a closed-loop supply
chain. Currently, the manual disassembly process exposes workers to hazards,
including electrocution and toxic chemicals. We propose a teleoperated system
for the safe disassembly and sorting of EVBs. A human-in-the-loop can create
and save disassembly sequences for unknown EVB types, enabling future
automation. An RGB camera aligns the physical and digital twins of the EVB, and
the digital twin of the robot is based on the Robot Operating System (ROS)
middleware. This hybrid approach combines teleoperation and automation to
improve safety, adaptability, and efficiency in EVB disassembly and sorting.
The economic contribution is realized by reducing labor dependency and
increasing throughput in battery recycling. An online pilot study was set up to
evaluate the usability of the presented approach, and the results demonstrate
the potential as a user-friendly solution.

</details>


### [18] [Designing Robots with, not for: A Co-Design Framework for Empowering Interactions in Forensic Psychiatry](https://arxiv.org/abs/2507.14931)
*Qiaoqiao Ren,Remko Proesmans,Arend Pissens,Lara Dehandschutter,William Denecker,Lotte Rouckhout,Joke Carrette,Peter Vanhopplinus,Tony Belpaeme,Francis wyffels*

Main category: cs.RO

TL;DR: 研究探讨了在法医心理健康护理中，通过共同设计开发陪伴机器人以监测和调节患者压力，同时跟踪其互动行为。


<details>
  <summary>Details</summary>
Motivation: 法医心理健康护理环境官僚化、风险规避且自主性受限，患者常感到失控，导致心理压力加剧。研究旨在通过共同设计改善这一状况。

Method: 在法医精神病诊所进行了四场共同设计工作坊，参与者包括患者、护理人员和治疗师，通过原型展示、创意构思和功能定义等步骤推进设计。

Result: 研究发现，患者在设计中赋权及根据其情绪状态调整提案至关重要，确保每位患者的声音被听到。

Conclusion: 共同设计方法能有效提升患者在设计过程中的参与感，为长期干预提供支持。

Abstract: Forensic mental health care involves the treatment of individuals with severe
mental disorders who have committed violent offences. These settings are often
characterized by high levels of bureaucracy, risk avoidance, and restricted
autonomy. Patients frequently experience a profound loss of control over their
lives, leading to heightened psychological stress-sometimes resulting in
isolation as a safety measure. In this study, we explore how co-design can be
used to collaboratively develop a companion robot that helps monitor and
regulate stress while maintaining tracking of the patients' interaction
behaviours for long-term intervention. We conducted four co-design workshops in
a forensic psychiatric clinic with patients, caregivers, and therapists. Our
process began with the presentation of an initial speculative prototype to
therapists, enabling reflection on shared concerns, ethical risks, and
desirable features. This was followed by a creative ideation session with
patients, a third workshop focused on defining desired functions and emotional
responses, and we are planning a final prototype demo to gather direct patient
feedback. Our findings emphasize the importance of empowering patients in the
design process and adapting proposals based on their current emotional state.
The goal was to empower the patient in the design process and ensure each
patient's voice was heard.

</details>


### [19] [Heterogeneous object manipulation on nonlinear soft surface through linear controller](https://arxiv.org/abs/2507.14967)
*Pratik Ingle,Kasper Støy,Andres Faiña*

Main category: cs.RO

TL;DR: 该论文提出了一种基于PID的闭环反馈控制策略，用于在MANTA-RAY平台上实现异构物体的精确操控，避免了传统高密度执行器阵列的复杂性和训练需求。


<details>
  <summary>Details</summary>
Motivation: 高密度执行器阵列虽然能动态变形操控物体，但其高自由度带来复杂控制问题，且学习型方法需要大量训练样本且泛化能力有限。

Method: 采用几何变换驱动的PID控制器，直接将倾斜角度控制输出映射到执行器命令，无需黑盒训练。

Result: 通过仿真和物理实验验证，成功操控了多种几何、重量和纹理的物体，包括易碎品如鸡蛋和苹果。

Conclusion: 该方法具有高度泛化性，为软机器人操控提供了实用可靠的解决方案，适合实际应用。

Abstract: Manipulation surfaces indirectly control and reposition objects by actively
modifying their shape or properties rather than directly gripping objects.
These surfaces, equipped with dense actuator arrays, generate dynamic
deformations. However, a high-density actuator array introduces considerable
complexity due to increased degrees of freedom (DOF), complicating control
tasks. High DOF restrict the implementation and utilization of manipulation
surfaces in real-world applications as the maintenance and control of such
systems exponentially increase with array/surface size. Learning-based control
approaches may ease the control complexity, but they require extensive training
samples and struggle to generalize for heterogeneous objects. In this study, we
introduce a simple, precise and robust PID-based linear close-loop feedback
control strategy for heterogeneous object manipulation on MANTA-RAY
(Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation
density). Our approach employs a geometric transformation-driven PID
controller, directly mapping tilt angle control outputs(1D/2D) to actuator
commands to eliminate the need for extensive black-box training. We validate
the proposed method through simulations and experiments on a physical system,
successfully manipulating objects with diverse geometries, weights and
textures, including fragile objects like eggs and apples. The outcomes
demonstrate that our approach is highly generalized and offers a practical and
reliable solution for object manipulation on soft robotic manipulation,
facilitating real-world implementation without prohibitive training demands.

</details>


### [20] [FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models](https://arxiv.org/abs/2507.14975)
*Yufan Song,Jiatao Zhang,Zeng Gu,Qingmiao Liang,Tuocheng Hu,Wei Song,Shiqiang Zhu*

Main category: cs.RO

TL;DR: 提出了一种名为FCRF的新型框架，通过灵活的自我反思机制提升家用机器人在复杂任务中的错误纠正能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）自我反思机制缺乏灵活性，限制了其在任务规划错误纠正中的效果。

Method: 提出了FCRF框架，采用Mentor-Actor架构，根据任务难度灵活调整自我反思，并结合历史经验与失败教训。

Result: 在AlfWorld模拟和真实环境中测试，FCRF显著提升了复杂任务的性能和反思灵活性。

Conclusion: FCRF通过灵活的自我反思机制，有效提高了家用机器人在复杂任务中的可靠性和适应性。

Abstract: Autonomous error correction is critical for domestic robots to achieve
reliable execution of complex long-horizon tasks. Prior work has explored
self-reflection in Large Language Models (LLMs) for task planning error
correction; however, existing methods are constrained by inflexible
self-reflection mechanisms that limit their effectiveness. Motivated by these
limitations and inspired by human cognitive adaptation, we propose the Flexible
Constructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture
that enables LLMs to perform flexible self-reflection based on task difficulty,
while constructively integrating historical valuable experience with failure
lessons. We evaluated FCRF on diverse domestic tasks through simulation in
AlfWorld and physical deployment in the real-world environment. Experimental
results demonstrate that FCRF significantly improves overall performance and
self-reflection flexibility in complex long-horizon robotic tasks.

</details>


### [21] [Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper](https://arxiv.org/abs/2507.15062)
*Xinyue Zhu,Binghao Huang,Yunzhu Li*

Main category: cs.RO

TL;DR: 提出了一种集成触觉传感器的便携式夹持器，用于同步收集视觉和触觉数据，并通过跨模态表示学习框架提升机器人操作的精确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有夹持器缺乏触觉传感，而触觉反馈在精确操作中至关重要。

Method: 开发便携式夹持器并设计跨模态表示学习框架，整合视觉与触觉信号。

Result: 在精细任务（如试管插入和移液操作）中表现出更高的准确性和鲁棒性。

Conclusion: 集成触觉传感和跨模态学习显著提升了机器人操作的效率和精确性。

Abstract: Handheld grippers are increasingly used to collect human demonstrations due
to their ease of deployment and versatility. However, most existing designs
lack tactile sensing, despite the critical role of tactile feedback in precise
manipulation. We present a portable, lightweight gripper with integrated
tactile sensors that enables synchronized collection of visual and tactile data
in diverse, real-world, and in-the-wild settings. Building on this hardware, we
propose a cross-modal representation learning framework that integrates visual
and tactile signals while preserving their distinct characteristics. The
learning procedure allows the emergence of interpretable representations that
consistently focus on contacting regions relevant for physical interactions.
When used for downstream manipulation tasks, these representations enable more
efficient and effective policy learning, supporting precise robotic
manipulation based on multimodal feedback. We validate our approach on
fine-grained tasks such as test tube insertion and pipette-based fluid
transfer, demonstrating improved accuracy and robustness under external
disturbances. Our project page is available at
https://binghao-huang.github.io/touch_in_the_wild/ .

</details>


### [22] [Search-Based Autonomous Vehicle Motion Planning Using Game Theory](https://arxiv.org/abs/2507.15088)
*Pouya Panahandeh,Mohammad Pirani,Baris Fidan,Amir Khajepour*

Main category: cs.RO

TL;DR: 提出了一种基于搜索和博弈论的自动驾驶车辆运动规划方案，考虑了其他道路使用者的智能行为，实现了实时应用。


<details>
  <summary>Details</summary>
Motivation: 传统搜索方法将其他道路用户视为静态障碍，缺乏现实性。新方法通过博弈论将其视为智能体，提升路径规划的真实性。

Method: 采用基于搜索和博弈论的方法，动态考虑其他道路用户的行为，优化路径规划。

Result: 方案计算时间短，适用于实时应用，实验验证了其优于现有技术。

Conclusion: 新方法显著提升了自动驾驶车辆运动规划的现实性和实时性。

Abstract: In this paper, we propose a search-based interactive motion planning scheme
for autonomous vehicles (AVs), using a game-theoretic approach. In contrast to
traditional search-based approaches, the newly developed approach considers
other road users (e.g. drivers and pedestrians) as intelligent agents rather
than static obstacles. This leads to the generation of a more realistic path
for the AV. Due to the low computational time, the proposed motion planning
scheme is implementable in real-time applications. The performance of the
developed motion planning scheme is compared with existing motion planning
techniques and validated through experiments using WATonoBus, an electrical
all-weather autonomous shuttle bus.

</details>


### [23] [Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions](https://arxiv.org/abs/2507.15155)
*Majid Roshanfar,Alex Zhang,Changyan He,Amir Hooshiar,Dale J. Podolsky,Thomas Looi,Eric Diller*

Main category: cs.RO

TL;DR: 提出了一种基于学习的磁控软吸引装置建模框架，用于内窥镜鼻内脑肿瘤切除，实现了亚毫米级的形状预测精度。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够精确建模和控制磁控软机器人变形的框架，以支持微创神经外科手术。

Method: 使用3D打印生物相容材料制造设备，集成FBG传感器实时反馈形状，通过Bezier控制点建模变形，并基于实验数据训练NN和RF模型。

Result: RF模型在所有指标上优于NN，控制点预测均方根误差为0.087 mm，形状重建误差为0.064 mm。

Conclusion: 该框架无需简化物理假设即可建模超弹性软机器人的非线性行为，为磁控软机器人在微创手术中的智能控制提供了进展。

Abstract: This letter introduces a novel learning-based modeling framework for a
magnetically steerable soft suction device designed for endoscopic endonasal
brain tumor resection. The device is miniaturized (4 mm outer diameter, 2 mm
inner diameter, 40 mm length), 3D printed using biocompatible SIL 30 material,
and integrates embedded Fiber Bragg Grating (FBG) sensors for real-time shape
feedback. Shape reconstruction is represented using four Bezier control points,
enabling a compact and smooth model of the device's deformation. A data-driven
model was trained on 5,097 experimental samples covering a range of magnetic
field magnitudes (0-14 mT), actuation frequencies (0.2-1.0 Hz), and vertical
tip distances (90-100 mm), using both Neural Network (NN) and Random Forest
(RF) architectures. The RF model outperformed the NN across all metrics,
achieving a mean root mean square error of 0.087 mm in control point prediction
and a mean shape reconstruction error of 0.064 mm. Feature importance analysis
further revealed that magnetic field components predominantly influence distal
control points, while frequency and distance affect the base configuration.
This learning-based approach effectively models the complex nonlinear behavior
of hyperelastic soft robots under magnetic actuation without relying on
simplified physical assumptions. By enabling sub-millimeter shape prediction
accuracy and real-time inference, this work represents an advancement toward
the intelligent control of magnetically actuated soft robotic tools in
minimally invasive neurosurgery.

</details>


### [24] [CHADET: Cross-Hierarchical-Attention for Depth-Completion Using Unsupervised Lightweight Transformer](https://arxiv.org/abs/2507.15189)
*Kevin Christiansen Marsim,Jinwoo Jeon,Yeeun Kim,Myeongwoo Jeong,Hyun Myung*

Main category: cs.RO

TL;DR: CHADET是一种轻量级深度补全网络，通过RGB图像和稀疏深度点生成准确的密集深度图，解决了现有方法在计算效率和准确性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 深度信息对机器人任务至关重要，但现有深度补全方法在计算效率和准确性之间存在显著权衡，无法满足实时应用需求。

Method: 提出CHADET网络，采用深度块提取特征，并通过轻量级基于Transformer的解码器和跨层次注意力模块优化特征。

Result: 在KITTI、NYUv2和VOID数据集上验证了CHADET在提高深度图质量和减少内存使用方面的有效性。

Conclusion: CHADET通过轻量级设计和跨层次注意力模块，显著提升了深度补全的效率和准确性，适用于实时机器人任务。

Abstract: Depth information which specifies the distance between objects and current
position of the robot is essential for many robot tasks such as navigation.
Recently, researchers have proposed depth completion frameworks to provide
dense depth maps that offer comprehensive information about the surrounding
environment. However, existing methods show significant trade-offs between
computational efficiency and accuracy during inference. The substantial memory
and computational requirements make them unsuitable for real-time applications,
highlighting the need to improve the completeness and accuracy of depth
information while improving processing speed to enhance robot performance in
various tasks. To address these challenges, in this paper, we propose
CHADET(cross-hierarchical-attention depth-completion transformer), a
lightweight depth-completion network that can generate accurate dense depth
maps from RGB images and sparse depth points. For each pair, its feature is
extracted from the depthwise blocks and passed to the equally lightweight
transformer-based decoder. In the decoder, we utilize the novel
cross-hierarchical-attention module that refines the image features from the
depth information. Our approach improves the quality and reduces memory usage
of the depth map prediction, as validated in both KITTI, NYUv2, and VOID
datasets.

</details>


### [25] [RepILN: Reparameterized Inertial Localization Network](https://arxiv.org/abs/2507.15293)
*Shanshan Zhang,Tianshui Wen,Siyue Wang,Qi Zhang,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出了一种重参数化惯性定位网络，通过多分支训练增强特征提取，推理时转为单路径架构以提高效率，结合稀疏注意力机制和门控卷积单元，实现精度与模型紧凑性的平衡。


<details>
  <summary>Details</summary>
Motivation: 惯性定位因其成本效益和独立性在IoT设备中具有潜力，但现有方法依赖复杂网络架构且忽略长期依赖建模，限制了性能。

Method: 采用多分支训练转为单路径推理的架构，引入时间尺度稀疏注意力机制和门控卷积单元，以捕捉长期依赖并整合局部特征。

Result: 在RoNIN数据集上，绝对轨迹误差降低2.59%，参数数量减少3.86%。

Conclusion: 该方法在精度和模型紧凑性之间取得了良好平衡，适用于资源受限的IoT设备。

Abstract: Inertial localization is regarded as a promising positioning solution for
consumer-grade IoT devices due to its cost-effectiveness and independence from
external infrastructure. However, data-driven inertial localization methods
often rely on increasingly complex network architectures to improve accuracy,
which challenges the limited computational resources of IoT devices. Moreover,
these methods frequently overlook the importance of modeling long-term
dependencies in inertial measurements - a critical factor for accurate
trajectory reconstruction - thereby limiting localization performance. To
address these challenges, we propose a reparameterized inertial localization
network that uses a multi-branch structure during training to enhance feature
extraction. At inference time, this structure is transformed into an equivalent
single-path architecture to improve parameter efficiency. To further capture
long-term dependencies in motion trajectories, we introduce a temporal-scale
sparse attention mechanism that selectively emphasizes key trajectory segments
while suppressing noise. Additionally, a gated convolutional unit is
incorporated to effectively integrate long-range dependencies with local
fine-grained features. Extensive experiments on public benchmarks demonstrate
that our method achieves a favorable trade-off between accuracy and model
compactness. For example, on the RoNIN dataset, our approach reduces the
Absolute Trajectory Error (ATE) by 2.59% compared to RoNIN-ResNet while
reducing the number of parameters by 3.86%.

</details>


### [26] [Low-Latency Event-Based Velocimetry for Quadrotor Control in a Narrow Pipe](https://arxiv.org/abs/2507.15444)
*Leonard Bauersfeld,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 提出了一种基于实时流场测量的四旋翼无人机闭环控制系统，用于在狭窄管道中悬停，解决了气流扰动问题。


<details>
  <summary>Details</summary>
Motivation: 在狭窄管道等封闭空间中，四旋翼无人机飞行面临气流扰动挑战，现有方法依赖持续运动或稳定性不足。

Method: 开发了低延迟事件型烟雾测速法，结合循环卷积神经网络的扰动估计器和强化学习控制器。

Result: 系统在管道横截面横向移动时表现优异，能有效抵消瞬态气动效应，避免碰撞。

Conclusion: 首次展示了基于实时流场测量的无人机闭环控制，为复杂气动环境飞行研究开辟新方向。

Abstract: Autonomous quadrotor flight in confined spaces such as pipes and tunnels
presents significant challenges due to unsteady, self-induced aerodynamic
disturbances. Very recent advances have enabled flight in such conditions, but
they either rely on constant motion through the pipe to mitigate airflow
recirculation effects or suffer from limited stability during hovering. In this
work, we present the first closed-loop control system for quadrotors for
hovering in narrow pipes that leverages real-time flow field measurements. We
develop a low-latency, event-based smoke velocimetry method that estimates
local airflow at high temporal resolution. This flow information is used by a
disturbance estimator based on a recurrent convolutional neural network, which
infers force and torque disturbances in real time. The estimated disturbances
are integrated into a learning-based controller trained via reinforcement
learning. The flow-feedback control proves particularly effective during
lateral translation maneuvers in the pipe cross-section. There, the real-time
disturbance information enables the controller to effectively counteract
transient aerodynamic effects, thereby preventing collisions with the pipe
wall. To the best of our knowledge, this work represents the first
demonstration of an aerial robot with closed-loop control informed by real-time
flow field measurements. This opens new directions for research on flight in
aerodynamically complex environments. In addition, our work also sheds light on
the characteristic flow structures that emerge during flight in narrow,
circular pipes, providing new insights at the intersection of robotics and
fluid dynamics.

</details>


### [27] [The Emergence of Deep Reinforcement Learning for Path Planning](https://arxiv.org/abs/2507.15469)
*Thanh Thi Nguyen,Saeid Nahavandi,Imran Razzak,Dung Nguyen,Nhat Truong Pham,Quoc Viet Hung Nguyen*

Main category: cs.RO

TL;DR: 综述探讨了智能路径规划的传统方法与深度强化学习（DRL）的最新进展，重点分析了算法优缺点及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 复杂动态环境中自主系统需求的增长推动了智能路径规划方法的研究，尤其是DRL的应用潜力。

Method: 分类比较了传统图搜索、线性规划、进化计算及DRL算法，并探讨了混合方法的优势。

Result: 总结了各类算法在计算效率、可扩展性、适应性和鲁棒性方面的表现。

Conclusion: 未来研究应关注DRL与传统方法的结合，以实现更稳健的自主导航。

Abstract: The increasing demand for autonomous systems in complex and dynamic
environments has driven significant research into intelligent path planning
methodologies. For decades, graph-based search algorithms, linear programming
techniques, and evolutionary computation methods have served as foundational
approaches in this domain. Recently, deep reinforcement learning (DRL) has
emerged as a powerful method for enabling autonomous agents to learn optimal
navigation strategies through interaction with their environments. This survey
provides a comprehensive overview of traditional approaches as well as the
recent advancements in DRL applied to path planning tasks, focusing on
autonomous vehicles, drones, and robotic platforms. Key algorithms across both
conventional and learning-based paradigms are categorized, with their
innovations and practical implementations highlighted. This is followed by a
thorough discussion of their respective strengths and limitations in terms of
computational efficiency, scalability, adaptability, and robustness. The survey
concludes by identifying key open challenges and outlining promising avenues
for future research. Special attention is given to hybrid approaches that
integrate DRL with classical planning techniques to leverage the benefits of
both learning-based adaptability and deterministic reliability, offering
promising directions for robust and resilient autonomous navigation.

</details>


### [28] [All-UWB SLAM Using UWB Radar and UWB AOA](https://arxiv.org/abs/2507.15474)
*Charith Premachandra,Achala Athukorala,U-Xuan Tan*

Main category: cs.RO

TL;DR: 提出了一种结合UWB AOA测量的新方法，用于在特征缺失的环境中提升SLAM的准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在恶劣环境（如烟雾、灰尘）中，光学传感器易失效，UWB雷达因其穿透能力成为SLAM的潜在技术，但现有方法受限于环境特征数量。

Method: 通过动态部署UWB锚点-标签单元获取AOA测量，将其整合到UWB雷达SLAM系统中。

Result: 实验表明，结合UWB AOA单元可在特征缺失的视觉受限环境中实现SLAM。

Conclusion: UWB AOA测量显著提升了SLAM在特征缺失环境中的性能。

Abstract: There has been a growing interest in autonomous systems designed to operate
in adverse conditions (e.g. smoke, dust), where the visible light spectrum
fails. In this context, Ultra-wideband (UWB) radar is capable of penetrating
through such challenging environmental conditions due to the lower frequency
components within its broad bandwidth. Therefore, UWB radar has emerged as a
potential sensing technology for Simultaneous Localization and Mapping (SLAM)
in vision-denied environments where optical sensors (e.g. LiDAR, Camera) are
prone to failure. Existing approaches involving UWB radar as the primary
exteroceptive sensor generally extract features in the environment, which are
later initialized as landmarks in a map. However, these methods are constrained
by the number of distinguishable features in the environment. Hence, this paper
proposes a novel method incorporating UWB Angle of Arrival (AOA) measurements
into UWB radar-based SLAM systems to improve the accuracy and scalability of
SLAM in feature-deficient environments. The AOA measurements are obtained using
UWB anchor-tag units which are dynamically deployed by the robot in featureless
areas during mapping of the environment. This paper thoroughly discusses
prevailing constraints associated with UWB AOA measurement units and presents
solutions to overcome them. Our experimental results show that integrating UWB
AOA units with UWB radar enables SLAM in vision-denied feature-deficient
environments.

</details>


### [29] [The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents](https://arxiv.org/abs/2507.15478)
*Simon Kohaut,Felix Divo,Navid Hamid,Benedict Flade,Julian Eggert,Devendra Singh Dhami,Kristian Kersting*

Main category: cs.RO

TL;DR: 论文提出了一种结合神经符号系统的框架CoCo，通过深度概率逻辑程序增强自主代理的安全性和可靠性，并在真实空中交通研究中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决自主代理在不确定环境中可靠且合规行为的挑战。

Method: 结合概率符号推理与深度学习的神经符号系统，提出Constitutional Controller (CoCo)框架，引入自怀疑概念。

Result: 在真实空中交通研究中，CoCo能有效学习适当怀疑并安全导航复杂环境。

Conclusion: 神经符号系统为自主代理在不确定环境中的安全合规行为提供了有力解决方案。

Abstract: Ensuring reliable and rule-compliant behavior of autonomous agents in
uncertain environments remains a fundamental challenge in modern robotics. Our
work shows how neuro-symbolic systems, which integrate probabilistic, symbolic
white-box reasoning models with deep learning methods, offer a powerful
solution to this challenge. This enables the simultaneous consideration of
explicit rules and neural models trained on noisy data, combining the strength
of structured reasoning with flexible representations. To this end, we
introduce the Constitutional Controller (CoCo), a novel framework designed to
enhance the safety and reliability of agents by reasoning over deep
probabilistic logic programs representing constraints such as those found in
shared traffic spaces. Furthermore, we propose the concept of self-doubt,
implemented as a probability density conditioned on doubt features such as
travel velocity, employed sensors, or health factors. In a real-world aerial
mobility study, we demonstrate CoCo's advantages for intelligent autonomous
systems to learn appropriate doubts and navigate complex and uncertain
environments safely and compliantly.

</details>


### [30] [Robots for Kiwifruit Harvesting and Pollination](https://arxiv.org/abs/2507.15484)
*Jamie Bell*

Main category: cs.RO

TL;DR: 研究开发了用于猕猴桃果园的移动机器人，实现了定向花粉喷洒和自动化采摘，改进了果实采摘机制和导航系统。


<details>
  <summary>Details</summary>
Motivation: 提高猕猴桃果园的自动化水平，解决传统采摘和花粉喷洒效率低的问题。

Method: 设计了多种果实采摘机制，测试了3D激光雷达导航系统和计算机视觉算法。

Result: 采摘机制覆盖率达80%，花粉喷洒速度达1.4米/秒，导航系统在30公里测试中表现良好。

Conclusion: 移动机器人和导航系统显著提升了猕猴桃果园的自动化效率。

Abstract: This research was a part of a project that developed mobile robots that
performed targeted pollen spraying and automated harvesting in pergola
structured kiwifruit orchards. Multiple kiwifruit detachment mechanisms were
designed and field testing of one of the concepts showed that the mechanism
could reliably pick kiwifruit. Furthermore, this kiwifruit detachment mechanism
was able to reach over 80 percent of fruit in the cluttered kiwifruit canopy,
whereas the previous state of the art mechanism was only able to reach less
than 70 percent of the fruit. Artificial pollination was performed by detecting
flowers and then spraying pollen in solution onto the detected flowers from a
line of sprayers on a boom, while driving at up to 1.4 ms-1. In addition, the
height of the canopy was measured and the spray boom was moved up and down to
keep the boom close enough to the flowers for the spray to reach the flowers,
while minimising collisions with the canopy. Mobile robot navigation was
performed using a 2D lidar in apple orchards and vineyards. Lidar navigation in
kiwifruit orchards was more challenging because the pergola structure only
provides a small amount of data for the direction of rows, compared to the
amount of data from the overhead canopy, the undulating ground and other
objects in the orchards. Multiple methods are presented here for extracting
structure defining features from 3D lidar data in kiwifruit orchards. In
addition, a 3D lidar navigation system -- which performed row following, row
end detection and row end turns -- was tested for over 30 km of autonomous
driving in kiwifruit orchards. Computer vision algorithms for row detection and
row following were also tested. The computer vision algorithm worked as well as
the 3D lidar row following method in testing.

</details>


### [31] [GR-3 Technical Report](https://arxiv.org/abs/2507.15493)
*Chilam Cheang,Sijin Chen,Zhongren Cui,Yingdong Hu,Liqun Huang,Tao Kong,Hang Li,Yifeng Li,Yuxiao Liu,Xiao Ma,Hao Niu,Wenxuan Ou,Wanli Peng,Zeyu Ren,Haixin Shi,Jiawen Tian,Hongtao Wu,Xin Xiao,Yuyang Xiao,Jiafeng Xu,Yichu Yang*

Main category: cs.RO

TL;DR: GR-3是一个大规模视觉-语言-动作模型，展示了在新对象、环境和抽象指令上的强大泛化能力，并能高效微调。结合ByteMini机器人，GR-3在多种任务中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 开发通用机器人策略，以辅助人类日常生活。

Method: 多模态训练方法，包括网络规模视觉-语言数据联合训练、VR设备收集的人类轨迹数据微调，以及机器人轨迹数据的模仿学习。

Result: GR-3在长时程和灵巧任务中表现优异，超越基线方法π0。

Conclusion: GR-3是迈向通用机器人技术的重要一步。

Abstract: We report our recent progress towards building generalist robot policies, the
development of GR-3. GR-3 is a large-scale vision-language-action (VLA) model.
It showcases exceptional capabilities in generalizing to novel objects,
environments, and instructions involving abstract concepts. Furthermore, it can
be efficiently fine-tuned with minimal human trajectory data, enabling rapid
and cost-effective adaptation to new settings. GR-3 also excels in handling
long-horizon and dexterous tasks, including those requiring bi-manual
manipulation and mobile movement, showcasing robust and reliable performance.
These capabilities are achieved through a multi-faceted training recipe that
includes co-training with web-scale vision-language data, efficient fine-tuning
from human trajectory data collected via VR devices, and effective imitation
learning with robot trajectory data. In addition, we introduce ByteMini, a
versatile bi-manual mobile robot designed with exceptional flexibility and
reliability, capable of accomplishing a wide range of tasks when integrated
with GR-3. Through extensive real-world experiments, we show GR-3 surpasses the
state-of-the-art baseline method, $\pi_0$, on a wide variety of challenging
tasks. We hope GR-3 can serve as a step towards building generalist robots
capable of assisting humans in daily life.

</details>


### [32] [CLEVER: Stream-based Active Learning for Robust Semantic Perception from Human Instructions](https://arxiv.org/abs/2507.15499)
*Jongseok Lee,Timo Birr,Rudolph Triebel,Tamim Asfour*

Main category: cs.RO

TL;DR: CLEVER是一个基于深度神经网络（DNN）的主动学习系统，通过在线适应人类指令来提升语义感知的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决数据流中DNN语义感知的失败问题，通过人类干预和在线适应提高系统鲁棒性。

Method: 设计了一个基于贝叶斯框架的系统，利用先验知识编码领域知识，并通过用户验证和实验验证其能力。

Result: 在真实机器人上实现了流式主动学习，证明了DNN语义感知的鲁棒性可以实际提升。

Conclusion: CLEVER系统通过结合人类指导和在线适应，显著提升了语义感知任务的鲁棒性。

Abstract: We propose CLEVER, an active learning system for robust semantic perception
with Deep Neural Networks (DNNs). For data arriving in streams, our system
seeks human support when encountering failures and adapts DNNs online based on
human instructions. In this way, CLEVER can eventually accomplish the given
semantic perception tasks. Our main contribution is the design of a system that
meets several desiderata of realizing the aforementioned capabilities. The key
enabler herein is our Bayesian formulation that encodes domain knowledge
through priors. Empirically, we not only motivate CLEVER's design but further
demonstrate its capabilities with a user validation study as well as
experiments on humanoid and deformable objects. To our knowledge, we are the
first to realize stream-based active learning on a real robot, providing
evidence that the robustness of the DNN-based semantic perception can be
improved in practice. The project website can be accessed at
https://sites.google.com/view/thecleversystem.

</details>


### [33] [Estimation of Payload Inertial Parameters from Human Demonstrations by Hand Guiding](https://arxiv.org/abs/2507.15604)
*Johannes Hartwig,Philipp Lienhardt,Dominik Henrich*

Main category: cs.RO

TL;DR: 论文提出了一种无需专用负载惯性参数（PIP）校准的方法，通过非接触运动部分估计PIP，使非专家用户能更高效地编程接触运动。


<details>
  <summary>Details</summary>
Motivation: 随着协作机器人（cobot）的普及，需要为非编程背景用户提供高效操作方式，尤其是编程接触运动时避免复杂的PIP校准。

Method: 利用任务中的非接触运动部分，结合现有估计技术，自动计算PIP，从而支持灵活的机器人工具更换。

Result: 实验表明，负载质量估计准确，但质心和惯性张量受噪声和激励不足影响。

Conclusion: 该方法在手动引导中估计PIP可行，但需足够负载加速度以提高估计精度。

Abstract: As the availability of cobots increases, it is essential to address the needs
of users with little to no programming knowledge to operate such systems
efficiently. Programming concepts often use intuitive interaction modalities,
such as hand guiding, to address this. When programming in-contact motions,
such frameworks require knowledge of the robot tool's payload inertial
parameters (PIP) in addition to the demonstrated velocities and forces to
ensure effective hybrid motion-force control. This paper aims to enable
non-expert users to program in-contact motions more efficiently by eliminating
the need for a dedicated PIP calibration, thereby enabling flexible robot tool
changes. Since demonstrated tasks generally also contain motions with
non-contact, our approach uses these parts to estimate the robot's PIP using
established estimation techniques. The results show that the estimation of the
payload's mass is accurate, whereas the center of mass and the inertia tensor
are affected by noise and a lack of excitation. Overall, these findings show
the feasibility of PIP estimation during hand guiding but also highlight the
need for sufficient payload accelerations for an accurate estimation.

</details>


### [34] [A Universal Vehicle-Trailer Navigation System with Neural Kinematics and Online Residual Learning](https://arxiv.org/abs/2507.15607)
*Yanbo Chen,Yunzhe Tan,Yaojia Wang,Zhengzhe Xu,Junbo Tan,Xueqian Wang*

Main category: cs.RO

TL;DR: 提出了一种新型通用车辆-拖车导航系统，结合混合运动学模型和在线残差学习模块，通过模型预测控制框架实现高精度长时预测和安全运动规划。


<details>
  <summary>Details</summary>
Motivation: 车辆-拖车系统在机场、超市等环境中的自主导航需求迫切，但准确建模（尤其是带脚轮拖车）仍具挑战性。

Method: 采用混合名义运动学模型（车辆非完整约束+神经网络拖车运动学）和轻量级在线残差学习模块，结合加权模型组合策略的模型预测控制框架。

Result: 通过多类型拖车和不同负载条件的真实实验验证，无需手动调整或拖车特定校准即可实现鲁棒性能。

Conclusion: 该系统在复杂环境中表现出色，为车辆-拖车导航提供了通用解决方案。

Abstract: Autonomous navigation of vehicle-trailer systems is crucial in environments
like airports, supermarkets, and concert venues, where various types of
trailers are needed to navigate with different payloads and conditions.
However, accurately modeling such systems remains challenging, especially for
trailers with castor wheels. In this work, we propose a novel universal
vehicle-trailer navigation system that integrates a hybrid nominal kinematic
model--combining classical nonholonomic constraints for vehicles and neural
network-based trailer kinematics--with a lightweight online residual learning
module to correct real-time modeling discrepancies and disturbances.
Additionally, we develop a model predictive control framework with a weighted
model combination strategy that improves long-horizon prediction accuracy and
ensures safer motion planning. Our approach is validated through extensive
real-world experiments involving multiple trailer types and varying payload
conditions, demonstrating robust performance without manual tuning or
trailer-specific calibration.

</details>


### [35] [Optimizing Force Signals from Human Demonstrations of In-Contact Motions](https://arxiv.org/abs/2507.15608)
*Johannes Hartwig,Fabian Viessmann,Dominik Henrich*

Main category: cs.RO

TL;DR: 论文探讨了优化力信号以更好反映人类意图的方法，比较了不同信号滤波方法，并提出了一种峰值检测方法，提高了机器人编程的可用性。


<details>
  <summary>Details</summary>
Motivation: 非专家用户通过运动引导编程机器人时，输入信号不精确且噪声大，影响运动再现或机器学习输入。

Method: 比较不同信号滤波方法，提出峰值检测方法处理首次接触偏差，并分析关键参数对滤波方法的影响。

Result: 单个运动的误差标准可提高达20%，优化了机器人编程的可用性和人机交互。

Conclusion: 提出的方法显著改善了力信号对人类意图的反映，提升了机器人编程的效率和用户体验。

Abstract: For non-robot-programming experts, kinesthetic guiding can be an intuitive
input method, as robot programming of in-contact tasks is becoming more
prominent. However, imprecise and noisy input signals from human demonstrations
pose problems when reproducing motions directly or using the signal as input
for machine learning methods. This paper explores optimizing force signals to
correspond better to the human intention of the demonstrated signal. We compare
different signal filtering methods and propose a peak detection method for
dealing with first-contact deviations in the signal. The evaluation of these
methods considers a specialized error criterion between the input and the
human-intended signal. In addition, we analyze the critical parameters'
influence on the filtering methods. The quality for an individual motion could
be increased by up to \SI{20}{\percent} concerning the error criterion. The
proposed contribution can improve the usability of robot programming and the
interaction between humans and robots.

</details>


### [36] [EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation](https://arxiv.org/abs/2507.15649)
*Haocheng Xu,Haodong Zhang,Zhenghan Chen,Rong Xiong*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的框架，使人形机器人模仿人类上半身动作同时保持整体稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究人形机器人在站立时如何稳定执行上半身动作，解决其可控范围有限的问题。

Method: 设计了一个重定向网络生成大规模动作数据集，训练强化学习策略，并引入可执行运动先验模块调整输入动作以确保稳定性。

Result: 通过仿真和实际测试验证了框架的实用性。

Conclusion: 该框架有效提升了人形机器人在站立时的稳定性和动作模仿能力。

Abstract: To support humanoid robots in performing manipulation tasks, it is essential
to study stable standing while accommodating upper-body motions. However, the
limited controllable range of humanoid robots in a standing position affects
the stability of the entire body. Thus we introduce a reinforcement learning
based framework for humanoid robots to imitate human upper-body motions while
maintaining overall stability. Our approach begins with designing a retargeting
network that generates a large-scale upper-body motion dataset for training the
reinforcement learning (RL) policy, which enables the humanoid robot to track
upper-body motion targets, employing domain randomization for enhanced
robustness. To avoid exceeding the robot's execution capability and ensure
safety and stability, we propose an Executable Motion Prior (EMP) module, which
adjusts the input target movements based on the robot's current state. This
adjustment improves standing stability while minimizing changes to motion
amplitude. We evaluate our framework through simulation and real-world tests,
demonstrating its practical applicability.

</details>


### [37] [Data-Driven MPC with Data Selection for Flexible Cable-Driven Robotic Arms](https://arxiv.org/abs/2507.15677)
*Huayue Liang,Yanbo Chen,Hongyang Cheng,Yanzhao Yu,Shoujie Li,Junbo Tan,Xueqian Wang,Long Zeng*

Main category: cs.RO

TL;DR: 本文提出了一种基于输入输出数据的模型预测控制（MPC）方法，用于提高柔性电缆驱动机械臂（FCRAs）的控制精度，无需物理模型。通过数据选择算法（DSA）优化计算效率，并在实验中验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 柔性电缆驱动机械臂（FCRAs）因其灵活性和适应性而具有广泛应用，但电缆的弹性、迟滞和摩擦等特性使其建模和控制面临挑战。本文旨在通过数据驱动的方法解决这些问题。

Method: 1. 基于输入输出数据构建隐式模型，并集成到MPC优化框架中。2. 引入数据选择算法（DSA）筛选最能表征系统的数据，显著减少计算时间。3. 通过仿真研究超参数对跟踪误差的影响。

Result: 实验验证表明，该方法在五点定位精度测试中平均精度为2.070毫米，跟踪误差为0.541度，优于PID方法的1.418度。计算时间缩短近80%，每步仅需4毫秒。

Conclusion: 提出的数据驱动MPC方法显著提高了FCRAs的控制精度和计算效率，为无需物理模型的高性能控制提供了可行方案。

Abstract: Flexible cable-driven robotic arms (FCRAs) offer dexterous and compliant
motion. Still, the inherent properties of cables, such as resilience,
hysteresis, and friction, often lead to particular difficulties in modeling and
control. This paper proposes a model predictive control (MPC) method that
relies exclusively on input-output data, without a physical model, to improve
the control accuracy of FCRAs. First, we develop an implicit model based on
input-output data and integrate it into an MPC optimization framework. Second,
a data selection algorithm (DSA) is introduced to filter the data that best
characterize the system, thereby reducing the solution time per step to
approximately 4 ms, which is an improvement of nearly 80%. Lastly, the
influence of hyperparameters on tracking error is investigated through
simulation. The proposed method has been validated on a real FCRA platform,
including five-point positioning accuracy tests, a five-point response tracking
test, and trajectory tracking for letter drawing. The results demonstrate that
the average positioning accuracy is approximately 2.070 mm. Moreover, compared
to the PID method with an average tracking error of 1.418{\deg}, the proposed
method achieves an average tracking error of 0.541{\deg}.

</details>


### [38] [Strong, Accurate, and Low-Cost Robot Manipulator](https://arxiv.org/abs/2507.15693)
*Georges Chebly,Spencer Little,Nisal Perera,Aliya Abedeen,Ken Suzuki,Donghyun Kim*

Main category: cs.RO

TL;DR: Forte是一款全3D打印的6自由度机械臂，性能接近工业级，成本低于215美元，适用于教育和AI实验。


<details>
  <summary>Details</summary>
Motivation: 突破现有低成本教育机械臂的性能限制，提供高性价比的机器人平台。

Method: 采用基于capstan的电缆驱动、同步带、简单张紧机构和轻量化3D打印结构，结合拓扑优化提升刚度。

Result: 实验验证显示，Forte具有高重复性和负载能力（0.63 kg负载，0.467 m范围，亚毫米级重复精度）。

Conclusion: Forte为课堂教学和高级机器人研究提供了一个高性能、低成本的解决方案。

Abstract: This paper presents Forte, a fully 3D-printable, 6-DoF robotic arm designed
to achieve near industrial-grade performance - 0.63 kg payload, 0.467 m reach,
and sub-millimeter repeatability - at a material cost under $215. As an
accessible robot for broad applications across classroom education to AI
experiments, Forte pushes forward the performance limitations of existing
low-cost educational arms. We introduce a cost-effective mechanical design that
combines capstan-based cable drives, timing belts, simple tensioning
mechanisms, and lightweight 3D-printed structures, along with topology
optimization for structural stiffness. Through careful drivetrain engineering,
we minimize backlash and maintain control fidelity without relying on
high-power electronics or expensive manufacturing processes. Experimental
validation demonstrates that Forte achieves high repeatability and load
capacity, offering a compelling robotic platform for both classroom instruction
and advanced robotics research.

</details>


### [39] [Selective Densification for Rapid Motion Planning in High Dimensions with Narrow Passages](https://arxiv.org/abs/2507.15710)
*Lu Huang,Lingxiao Meng,Jiankun Wang,Xingjian Jing*

Main category: cs.RO

TL;DR: 提出了一种高效的多分辨率采样规划框架，通过动态调整采样密度解决复杂配置空间中的规划问题。


<details>
  <summary>Details</summary>
Motivation: 现有采样规划算法在复杂配置空间中效率低，且启发式方法缺乏通用性或需要大量训练。

Method: 结合不同规划粒度，动态调整稀疏与密集采样，优化导航效率。

Result: 在多种配置空间和机器人实验中，性能优于现有方法。

Conclusion: 该方法高效、通用，适用于复杂环境中的运动规划。

Abstract: Sampling-based algorithms are widely used for motion planning in
high-dimensional configuration spaces. However, due to low sampling efficiency,
their performance often diminishes in complex configuration spaces with narrow
corridors. Existing approaches address this issue using handcrafted or learned
heuristics to guide sampling toward useful regions. Unfortunately, these
strategies often lack generalizability to various problems or require extensive
prior training. In this paper, we propose a simple yet efficient sampling-based
planning framework along with its bidirectional version that overcomes these
issues by integrating different levels of planning granularity. Our approach
probes configuration spaces with uniform random samples at varying resolutions
and explores these multi-resolution samples online with a bias towards sparse
samples when traveling large free configuration spaces. By seamlessly
transitioning between sparse and dense samples, our approach can navigate
complex configuration spaces while maintaining planning speed and completeness.
The simulation results demonstrate that our approach outperforms several
state-of-the-art sampling-based planners in $\mathbb{SE}(2)$, $\mathbb{SE}(3)$,
and $\mathbb{R}^{14}$ with challenging terrains. Furthermore, experiments
conducted with the Franka Emika Panda robot operating in a constrained
workspace provide additional evidence of the superiority of the proposed
method.

</details>


### [40] [DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models](https://arxiv.org/abs/2507.15716)
*Ziyu Wan,Lin Zhao*

Main category: cs.RO

TL;DR: DiffPF是一种可微分粒子滤波器，利用扩散模型进行动态系统状态估计，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统可微分粒子滤波器依赖预定义或低容量提案分布，限制了性能。DiffPF旨在通过扩散模型学习灵活的后验采样器。

Method: DiffPF通过将扩散模型条件化于预测粒子和当前观测，实现高维、多模态分布的高质量采样。

Result: 在模拟和真实任务中表现优异，如多模态全局定位任务精度提升82.8%，KITTI视觉测距任务提升26%。

Conclusion: DiffPF首次将条件扩散模型与粒子滤波结合，显著提升状态估计性能。

Abstract: This paper proposes DiffPF, a differentiable particle filter that leverages
diffusion models for state estimation in dynamic systems. Unlike conventional
differentiable particle filters, which require importance weighting and
typically rely on predefined or low-capacity proposal distributions. DiffPF
learns a flexible posterior sampler by conditioning a diffusion model on
predicted particles and the current observation. This enables accurate,
equally-weighted sampling from complex, high-dimensional, and multimodal
filtering distributions. We evaluate DiffPF across a range of scenarios,
including both unimodal and highly multimodal distributions, and test it on
simulated as well as real-world tasks, where it consistently outperforms
existing filtering baselines. In particular, DiffPF achieves an 82.8%
improvement in estimation accuracy on a highly multimodal global localization
benchmark, and a 26% improvement on the real-world KITTI visual odometry
benchmark, compared to state-of-the-art differentiable filters. To the best of
our knowledge, DiffPF is the first method to integrate conditional diffusion
models into particle filtering, enabling high-quality posterior sampling that
produces more informative particles and significantly improves state
estimation.

</details>


### [41] [Gaze-supported Large Language Model Framework for Bi-directional Human-Robot Interaction](https://arxiv.org/abs/2507.15729)
*Jens V. Rüppel,Andrey Rudenko,Tim Schreiter,Martin Magnusson,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: 论文提出了一种基于大语言模型（LLM）的辅助机器人交互系统，通过多模态输入（如视线和语音）支持动态用户任务，并与传统脚本化系统进行了对比。


<details>
  <summary>Details</summary>
Motivation: 现有的人机交互（HRI）系统在用户指令解析和任务执行方面已有显著进展，但在双向、多模态和上下文感知的协作任务支持方面仍存在挑战。

Method: 设计了一个模块化、可迁移的系统，支持实时语言交互和多视觉输入感知，并通过公开活动和实验室研究验证其性能。

Result: 基于LLM的系统在适应性和用户参与度上略有提升，但可能产生冗余输出；脚本化系统更适合简单任务。

Conclusion: LLM方法增强了适应性，但需优化冗余问题；脚本化系统在简单任务中表现更优。

Abstract: The rapid development of Large Language Models (LLMs) creates an exciting
potential for flexible, general knowledge-driven Human-Robot Interaction (HRI)
systems for assistive robots. Existing HRI systems demonstrate great progress
in interpreting and following user instructions, action generation, and robot
task solving. On the other hand, bi-directional, multi-modal, and context-aware
support of the user in collaborative tasks still remains an open challenge. In
this paper, we present a gaze- and speech-informed interface to the assistive
robot, which is able to perceive the working environment from multiple vision
inputs and support the dynamic user in their tasks. Our system is designed to
be modular and transferable to adapt to diverse tasks and robots, and it is
capable of real-time use of language-based interaction state representation and
fast on board perception modules. Its development was supported by multiple
public dissemination events, contributing important considerations for improved
robustness and user experience. Furthermore, in two lab studies, we compare the
performance and user ratings of our system with those of a traditional scripted
HRI pipeline. Our findings indicate that an LLM-based approach enhances
adaptability and marginally improves user engagement and task execution metrics
but may produce redundant output, while a scripted pipeline is well suited for
more straightforward tasks.

</details>


### [42] [Interleaved LLM and Motion Planning for Generalized Multi-Object Collection in Large Scene Graphs](https://arxiv.org/abs/2507.15782)
*Ruochu Yang,Yu Zhou,Fumin Zhang,Mengxue Hou*

Main category: cs.RO

TL;DR: 论文提出了一种名为Inter-LLM的新型算法，用于解决家庭机器人在多目标收集任务中的长时程规划问题，通过结合LLM和运动规划，显著提升了任务性能。


<details>
  <summary>Details</summary>
Motivation: 家庭机器人在处理开放集对象和大型环境导航时缺乏人类智能，多目标收集任务在长时程规划中面临巨大挑战。

Method: 提出Inter-LLM算法，结合多模态动作成本相似性函数，优化历史与未来规划，平衡质量与效率。

Result: 仿真实验显示，Inter-LLM比现有方法提升了30%的任务完成率、成功率和成本效益。

Conclusion: Inter-LLM为家庭机器人的长时程规划问题提供了高效解决方案，显著提升了任务性能。

Abstract: Household robots have been a longstanding research topic, but they still lack
human-like intelligence, particularly in manipulating open-set objects and
navigating large environments efficiently and accurately. To push this
boundary, we consider a generalized multi-object collection problem in large
scene graphs, where the robot needs to pick up and place multiple objects
across multiple locations in a long mission of multiple human commands. This
problem is extremely challenging since it requires long-horizon planning in a
vast action-state space under high uncertainties. To this end, we propose a
novel interleaved LLM and motion planning algorithm Inter-LLM. By designing a
multimodal action cost similarity function, our algorithm can both reflect the
history and look into the future to optimize plans, striking a good balance of
quality and efficiency. Simulation experiments demonstrate that compared with
latest works, our algorithm improves the overall mission performance by 30% in
terms of fulfilling human commands, maximizing mission success rates, and
minimizing mission costs.

</details>


### [43] [Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers](https://arxiv.org/abs/2507.15833)
*Ian Chuang,Andrew Lee,Dechen Gao,Jinyu Zou,Iman Soltani*

Main category: cs.RO

TL;DR: 论文探讨了将人类主动注视机制融入机器人视觉系统，以提高效率和性能。通过模拟人类头部和眼球运动，结合注视数据，提出了一种基于ViT的注视引导视觉处理框架，显著降低了计算开销并提升了任务表现。


<details>
  <summary>Details</summary>
Motivation: 人类视觉通过注视主动引导注意力，而机器人通常被动处理图像。研究旨在探索如何通过模拟人类注视机制提升机器人视觉系统的效率和性能。

Method: 结合注视数据和机器人演示，提出了一种注视引导的视觉处理框架，包括注视预测和端到端注视-动作联合预测两种方法。采用ViT的注视引导分块标记化方案减少计算量。

Result: 方法显著降低了计算开销，提升了高精度任务的性能，并增强了对未知干扰的鲁棒性。

Conclusion: 人类视觉机制为机器人视觉系统提供了有效的归纳偏置，未来可进一步探索其应用。

Abstract: Human vision is a highly active process driven by gaze, which directs
attention and fixation to task-relevant regions and dramatically reduces visual
processing. In contrast, robot learning systems typically rely on passive,
uniform processing of raw camera images. In this work, we explore how
incorporating human-like active gaze into robotic policies can enhance both
efficiency and performance. We build on recent advances in foveated image
processing and apply them to an Active Vision robot system that emulates both
human head movement and eye tracking. Extending prior work on the AV-ALOHA
robot simulation platform, we introduce a framework for simultaneously
collecting eye-tracking data and robot demonstrations from a human operator as
well as a simulation benchmark and dataset for training robot policies that
incorporate human gaze. Given the widespread use of Vision Transformers (ViTs)
in robot learning, we integrate gaze information into ViTs using a foveated
patch tokenization scheme inspired by recent work in image segmentation.
Compared to uniform patch tokenization, this significantly reduces the number
of tokens-and thus computation-without sacrificing visual fidelity near regions
of interest. We also explore two approaches to gaze imitation and prediction
from human data. The first is a two-stage model that predicts gaze to guide
foveation and action; the second integrates gaze into the action space,
allowing the policy to jointly predict gaze and actions end-to-end. Our results
show that our method for foveated robot vision not only drastically reduces
computational overhead, but also improves performance for high precision tasks
and robustness to unseen distractors. Together, these findings suggest that
human-inspired visual processing offers a useful inductive bias for robotic
vision systems. https://ian-chuang.github.io/gaze-av-aloha/

</details>
