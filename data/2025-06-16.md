<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 21]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving](https://arxiv.org/abs/2506.11234)
*Luke Rowe,Rodrigue de Schaetzen,Roger Girgis,Christopher Pal,Liam Paull*

Main category: cs.RO

TL;DR: Poutine是一个3B参数的视觉语言模型，专为长尾驾驶场景的端到端自动驾驶设计，通过两阶段训练实现高性能。


<details>
  <summary>Details</summary>
Motivation: 解决长尾驾驶场景中的自动驾驶问题，提升模型在复杂环境中的鲁棒性和泛化能力。

Method: 1. 自监督视觉-语言-轨迹（VLT）预训练；2. 使用GRPO进行轻量级强化学习微调。

Result: Poutine-Base验证集RFS为8.12，接近专家水平；最终模型在Waymo测试集RFS为7.99，排名第一。

Conclusion: VLT预训练和轻量级RL微调是实现鲁棒自动驾驶的有效方法。

Abstract: We present Poutine, a 3B-parameter vision-language model (VLM) tailored for
end-to-end autonomous driving in long-tail driving scenarios. Poutine is
trained in two stages. To obtain strong base driving capabilities, we train
Poutine-Base in a self-supervised vision-language-trajectory (VLT) next-token
prediction fashion on 83 hours of CoVLA nominal driving and 11 hours of Waymo
long-tail driving. Accompanying language annotations are auto-generated with a
72B-parameter VLM. Poutine is obtained by fine-tuning Poutine-Base with Group
Relative Policy Optimization (GRPO) using less than 500 preference-labeled
frames from the Waymo validation set. We show that both VLT pretraining and RL
fine-tuning are critical to attain strong driving performance in the long-tail.
Poutine-Base achieves a rater-feedback score (RFS) of 8.12 on the validation
set, nearly matching Waymo's expert ground-truth RFS. The final Poutine model
achieves an RFS of 7.99 on the official Waymo test set, placing 1st in the 2025
Waymo Vision-Based End-to-End Driving Challenge by a significant margin. These
results highlight the promise of scalable VLT pre-training and lightweight RL
fine-tuning to enable robust and generalizable autonomy.

</details>


### [2] [Gondola: Grounded Vision Language Planning for Generalizable Robotic Manipulation](https://arxiv.org/abs/2506.11261)
*Shizhe Chen,Ricardo Garcia,Paul Pacaud,Cordelia Schmid*

Main category: cs.RO

TL;DR: Gondola是一种基于LLM的视觉语言规划模型，通过多视角图像和历史计划生成动作计划，提升机器人在未见对象、环境和任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人操作在泛化到未见对象、环境和多样化语言指令任务时面临挑战，现有基于LLM的方法在视觉环境中生成接地计划的能力不足。

Method: 提出Gondola模型，利用多视角图像和历史计划生成包含文本和目标对象分割掩码的动作计划，并通过RLBench模拟器构建三类数据集进行训练。

Result: Gondola在GemBench数据集的四个泛化级别（新放置、刚性对象、铰接对象和长时任务）上均优于现有LLM方法。

Conclusion: Gondola通过多视角输入和接地规划显著提升了机器人操作的泛化能力。

Abstract: Robotic manipulation faces a significant challenge in generalizing across
unseen objects, environments and tasks specified by diverse language
instructions. To improve generalization capabilities, recent research has
incorporated large language models (LLMs) for planning and action execution.
While promising, these methods often fall short in generating grounded plans in
visual environments. Although efforts have been made to perform visual
instructional tuning on LLMs for robotic manipulation, existing methods are
typically constrained by single-view image input and struggle with precise
object grounding. In this work, we introduce Gondola, a novel grounded
vision-language planning model based on LLMs for generalizable robotic
manipulation. Gondola takes multi-view images and history plans to produce the
next action plan with interleaved texts and segmentation masks of target
objects and locations. To support the training of Gondola, we construct three
types of datasets using the RLBench simulator, namely robot grounded planning,
multi-view referring expression and pseudo long-horizon task datasets. Gondola
outperforms the state-of-the-art LLM-based method across all four
generalization levels of the GemBench dataset, including novel placements,
rigid objects, articulated objects and long-horizon tasks.

</details>


### [3] [Demonstration Sidetracks: Categorizing Systematic Non-Optimality in Human Demonstrations](https://arxiv.org/abs/2506.11262)
*Shijie Fang,Hang Yu,Qidi Fang,Reuben M. Aronson,Elaine S. Short*

Main category: cs.RO

TL;DR: 论文研究了非专家演示中的非最优行为，发现这些行为是系统性的，称为“演示偏离”。通过实验识别了四种偏离类型，并指出其对LfD算法改进的重要性。


<details>
  <summary>Details</summary>
Motivation: 人类演示中的非最优行为通常被视为随机噪声，但本文发现这些行为是系统性的，需要更好的模型来改进LfD算法。

Method: 通过40名参与者的公共空间研究，在仿真中重现任务并标注演示，识别了四种偏离类型和一种控制模式。

Result: 发现偏离行为频繁出现且与任务上下文相关，控制模式依赖于控制接口。

Conclusion: 研究强调了改进非最优演示模型的必要性，以缩小实验室训练与实际部署之间的差距。

Abstract: Learning from Demonstration (LfD) is a popular approach for robots to acquire
new skills, but most LfD methods suffer from imperfections in human
demonstrations. Prior work typically treats these suboptimalities as random
noise. In this paper we study non-optimal behaviors in non-expert
demonstrations and show that they are systematic, forming what we call
demonstration sidetracks. Using a public space study with 40 participants
performing a long-horizon robot task, we recreated the setup in simulation and
annotated all demonstrations. We identify four types of sidetracks
(Exploration, Mistake, Alignment, Pause) and one control pattern (one-dimension
control). Sidetracks appear frequently across participants, and their temporal
and spatial distribution is tied to task context. We also find that users'
control patterns depend on the control interface. These insights point to the
need for better models of suboptimal demonstrations to improve LfD algorithms
and bridge the gap between lab training and real-world deployment. All
demonstrations, infrastructure, and annotations are available at
https://github.com/AABL-Lab/Human-Demonstration-Sidetracks.

</details>


### [4] [Sensor Model Identification via Simultaneous Model Selection and State Variable Determination](https://arxiv.org/abs/2506.11263)
*Christian Brommer,Alessandro Fornasier,Jan Steinbrener,Stephan Weiss*

Main category: cs.RO

TL;DR: 提出了一种用于机器人定位中传感器模型的无人值守灰盒识别方法，旨在从未知测量数据中确定最可能的传感器模型，并支持传感器校准和参考帧的评估。


<details>
  <summary>Details</summary>
Motivation: 简化传感器模态的集成，避免定位方法开发和使用的常见问题，特别适用于模块化多智能体场景和运行时扩展的机器人平台。

Method: 通过预定义传感器模型目录识别未知测量数据的传感器模型，引入健康指标验证选择结果，生成校准状态的初始猜测，并评估传感器世界参考帧的必要性。

Result: 识别出的传感器模型及其参数信息可用于状态估计应用，提高新传感器集成的准确性和鲁棒性。

Conclusion: 该方法为不熟悉传感器类型和校准的用户提供了便利，同时支持模块化机器人平台的传感器扩展，简化了下游应用的传感器集成。

Abstract: We present a method for the unattended gray-box identification of sensor
models commonly used by localization algorithms in the field of robotics. The
objective is to determine the most likely sensor model for a time series of
unknown measurement data, given an extendable catalog of predefined sensor
models. Sensor model definitions may require states for rigid-body calibrations
and dedicated reference frames to replicate a measurement based on the robot's
localization state. A health metric is introduced, which verifies the outcome
of the selection process in order to detect false positives and facilitate
reliable decision-making. In a second stage, an initial guess for identified
calibration states is generated, and the necessity of sensor world reference
frames is evaluated. The identified sensor model with its parameter information
is then used to parameterize and initialize a state estimation application,
thus ensuring a more accurate and robust integration of new sensor elements.
This method is helpful for inexperienced users who want to identify the source
and type of a measurement, sensor calibrations, or sensor reference frames. It
will also be important in the field of modular multi-agent scenarios and
modularized robotic platforms that are augmented by sensor modalities during
runtime. Overall, this work aims to provide a simplified integration of sensor
modalities to downstream applications and circumvent common pitfalls in the
usage and development of localization approaches.

</details>


### [5] [Robust Optimal Task Planning to Maximize Battery Life](https://arxiv.org/abs/2506.11264)
*Jiachen Li,Chu Jian,Feiyang Zhao,Shihao Li,Wei Li,Dongmei Chen*

Main category: cs.RO

TL;DR: 提出了一种面向控制的优化平台，旨在延长自主移动机器人（AMR）的电池寿命，同时确保任务完成。通过McCormick包络技术线性化双线性项，并开发了带松弛约束的新型规划算法以高效处理参数不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决AMR在快速任务规划中如何保持最低电量状态以延长电池寿命的双线性优化问题。

Method: 采用McCormick包络技术线性化双线性项，并开发带松弛约束的规划算法以应对参数不确定性。

Result: 仿真结果表明，所提方法在减少电池退化的同时满足任务完成需求。

Conclusion: 该平台有效延长了AMR电池寿命，同时确保了任务的高效完成。

Abstract: This paper proposes a control-oriented optimization platform for autonomous
mobile robots (AMRs), focusing on extending battery life while ensuring task
completion. The requirement of fast AMR task planning while maintaining minimum
battery state of charge, thus maximizing the battery life, renders a bilinear
optimization problem. McCormick envelop technique is proposed to linearize the
bilinear term. A novel planning algorithm with relaxed constraints is also
developed to handle parameter uncertainties robustly with high efficiency
ensured. Simulation results are provided to demonstrate the utility of the
proposed methods in reducing battery degradation while satisfying task
completion requirements.

</details>


### [6] [Measuring and Minimizing Disturbance of Marine Animals to Underwater Vehicles](https://arxiv.org/abs/2506.11335)
*Levi Cai,Youenn Jézéquel,T. Aran Mooney,Yogesh Girdhar*

Main category: cs.RO

TL;DR: 研究探讨鱼类是否对水下车辆存在反应，并提出测量和减少这种偏差的理论与实践框架。


<details>
  <summary>Details</summary>
Motivation: 了解鱼类对水下车辆的反应是否会影响行为估计，并寻求减少偏差的方法。

Method: 提出理论框架，并通过珊瑚礁环境的实地研究进行验证。

Result: 提供了初步的实地研究结果，支持鱼类对水下车辆存在反应的可能性。

Conclusion: 研究为减少水下车辆观测中的行为偏差提供了理论和实践基础。

Abstract: Do fish respond to the presence of underwater vehicles, potentially biasing
our estimates about them? If so, are there strategies to measure and mitigate
this response? This work provides a theoretical and practical framework towards
bias-free estimation of animal behavior from underwater vehicle observations.
We also provide preliminary results from the field in coral reef environments
to address these questions.

</details>


### [7] [Control Architecture and Design for a Multi-robotic Visual Servoing System in Automated Manufacturing Environment](https://arxiv.org/abs/2506.11387)
*Rongfei Li*

Main category: cs.RO

TL;DR: 论文探讨了在微尺度制造中，通过多机器人控制系统模拟定位过程以减少不确定性，并提出了一种优化相机位置的算法以最小化图像噪声。


<details>
  <summary>Details</summary>
Motivation: 人类在微尺度制造中仍优于机器人，主要依赖感官线索补偿环境不确定性。现有技术虽能部分解决机器人定位误差，但控制算法仍是一种经济有效的替代方案。此外，相机位置对视觉伺服质量影响显著，但相关研究较少。

Method: 提出多机器人控制系统模拟定位过程以减少不确定性，并设计算法优化相机位置以最小化图像噪声。

Result: 多机器人控制系统能显著减少制造过程中的不确定性，相机位置优化算法能有效降低图像噪声。

Conclusion: 多机器人控制系统和相机位置优化算法为自动化制造提供了高效且经济的解决方案，提升了制造精度和稳定性。

Abstract: The use of robotic technology has drastically increased in manufacturing in
the 21st century. But by utilizing their sensory cues, humans still outperform
machines, especially in micro scale manufacturing, which requires
high-precision robot manipulators. These sensory cues naturally compensate for
high levels of uncertainties that exist in the manufacturing environment.
Uncertainties in performing manufacturing tasks may come from measurement
noise, model inaccuracy, joint compliance (e.g., elasticity), etc. Although
advanced metrology sensors and high precision microprocessors, which are
utilized in modern robots, have compensated for many structural and dynamic
errors in robot positioning, a well-designed control algorithm still works as a
comparable and cheaper alternative to reduce uncertainties in automated
manufacturing. Our work illustrates that a multi-robot control system that
simulates the positioning process for fastening and unfastening applications
can reduce various uncertainties, which may occur in this process, to a great
extent. In addition, most research papers in visual servoing mainly focus on
developing control and observation architectures in various scenarios, but few
have discussed the importance of the camera's location in the configuration. In
a manufacturing environment, the quality of camera estimations may vary
significantly from one observation location to another, as the combined effects
of environmental conditions result in different noise levels of a single image
shot at different locations. Therefore, in this paper, we also propose a novel
algorithm for the camera's moving policy so that it explores the camera
workspace and searches for the optimal location where the image noise level is
minimized.

</details>


### [8] [Robotic System for Chemical Experiment Automation with Dual Demonstration of End-effector and Jig Operations](https://arxiv.org/abs/2506.11384)
*Hikaru Sasaki,Naoto Komeno,Takumi Hachimine,Kei Takahashi,Yu-ya Ohnishi,Tetsunori Sugawara,Araki Wakiuchi,Miho Hatanaka,Tomoyuki Miyao,Hiroharu Ajiro,Mikiya Fujii,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 提出了一种通过化学家演示机器人动作和夹具操作来实现实验自动化的概念，验证了其高效性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人编程与实验夹具同步的挑战，简化化学实验自动化过程。

Method: 开发了包含辅助夹具、动作演示界面、夹具控制界面和移动机械臂的化学实验自动化系统。

Result: 在聚合物合成实验中验证了高重复性和任务成功率。

Conclusion: 该概念简化了机器人编程，为化学实验自动化提供了灵活高效的解决方案。

Abstract: While robotic automation has demonstrated remarkable performance, such as
executing hundreds of experiments continuously over several days, it is
challenging to design a program that synchronizes the robot's movements with
the experimental jigs to conduct an experiment. We propose a concept that
enables the automation of experiments by utilizing dual demonstrations of robot
motions and jig operations by chemists in an experimental environment
constructed to be controlled by a robot. To verify this concept, we developed a
chemical-experiment-automation system consisting of jigs to assist the robot in
experiments, a motion-demonstration interface, a jig-control interface, and a
mobile manipulator. We validate the concept through polymer-synthesis
experiments, focusing on critical liquid-handling tasks such as pipetting and
dilution. The experimental results indicate high reproducibility of the
demonstrated motions and robust task-success rates. This comprehensive concept
not only simplifies the robot programming process for chemists but also
provides a flexible and efficient solution to accommodate a wide range of
experimental conditions, contributing significantly to the field of chemical
experiment automation.

</details>


### [9] [Multi-Loco: Unifying Multi-Embodiment Legged Locomotion via Reinforcement Learning Augmented Diffusion](https://arxiv.org/abs/2506.11470)
*Shunpeng Yang,Zhen Fu,Zhefeng Cao,Guo Junde,Patrick Wensing,Wei Zhang,Hua Chen*

Main category: cs.RO

TL;DR: Multi-Loco框架通过结合扩散模型和残差策略，提升了多足机器人的运动泛化能力，平均性能提升10.35%。


<details>
  <summary>Details</summary>
Motivation: 解决不同形态机器人运动策略泛化问题，因观测/动作维度和系统动力学差异而具有挑战性。

Method: 提出Multi-Loco框架，结合形态无关的扩散模型和轻量级残差策略，扩散模型捕捉跨形态运动模式，残差策略优化动作。

Result: 在仿真和实验中，相比标准PPO框架，性能平均提升10.35%，轮式双足任务提升13.57%。

Conclusion: 跨形态数据和生成架构有助于学习鲁棒、泛化的运动技能。

Abstract: Generalizing locomotion policies across diverse legged robots with varying
morphologies is a key challenge due to differences in observation/action
dimensions and system dynamics. In this work, we propose Multi-Loco, a novel
unified framework combining a morphology-agnostic generative diffusion model
with a lightweight residual policy optimized via reinforcement learning (RL).
The diffusion model captures morphology-invariant locomotion patterns from
diverse cross-embodiment datasets, improving generalization and robustness. The
residual policy is shared across all embodiments and refines the actions
generated by the diffusion model, enhancing task-aware performance and
robustness for real-world deployment. We evaluated our method with a rich
library of four legged robots in both simulation and real-world experiments.
Compared to a standard RL framework with PPO, our approach -- replacing the
Gaussian policy with a diffusion model and residual term -- achieves a 10.35%
average return improvement, with gains up to 13.57% in wheeled-biped locomotion
tasks. These results highlight the benefits of cross-embodiment data and
composite generative architectures in learning robust, generalized locomotion
skills.

</details>


### [10] [Foundation Models in Autonomous Driving: A Survey on Scenario Generation and Scenario Analysis](https://arxiv.org/abs/2506.11526)
*Yuan Gao,Mattia Piccinini,Yuchen Zhang,Dingrui Wang,Korbinian Moller,Roberto Brusnicki,Baha Zarrouki,Alessio Gambi,Jan Frederik Totz,Kai Storms,Steven Peters,Andrea Stocco,Bassam Alrifaee,Marco Pavone,Johannes Betz*

Main category: cs.RO

TL;DR: 本文综述了基础模型在自动驾驶场景生成与分析中的应用，包括分类、方法、数据集、平台及挑战，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶在复杂环境中的安全导航需要处理多样且罕见的驾驶场景，传统方法生成场景的多样性和真实性有限，基础模型提供了新的解决方案。

Method: 通过统一分类法（如大语言模型、视觉语言模型等）综述基础模型在场景生成与分析中的应用，并回顾相关方法、数据集和评估指标。

Result: 提出了一个全面的分类框架，总结了现有方法、工具和挑战，并提供了开源资源库。

Conclusion: 基础模型在自动驾驶场景生成与分析中具有潜力，但仍面临开放挑战，未来研究需进一步探索。

Abstract: For autonomous vehicles, safe navigation in complex environments depends on
handling a broad range of diverse and rare driving scenarios. Simulation- and
scenario-based testing have emerged as key approaches to development and
validation of autonomous driving systems. Traditional scenario generation
relies on rule-based systems, knowledge-driven models, and data-driven
synthesis, often producing limited diversity and unrealistic safety-critical
cases. With the emergence of foundation models, which represent a new
generation of pre-trained, general-purpose AI models, developers can process
heterogeneous inputs (e.g., natural language, sensor data, HD maps, and control
actions), enabling the synthesis and interpretation of complex driving
scenarios. In this paper, we conduct a survey about the application of
foundation models for scenario generation and scenario analysis in autonomous
driving (as of May 2025). Our survey presents a unified taxonomy that includes
large language models, vision-language models, multimodal large language
models, diffusion models, and world models for the generation and analysis of
autonomous driving scenarios. In addition, we review the methodologies,
open-source datasets, simulation platforms, and benchmark challenges, and we
examine the evaluation metrics tailored explicitly to scenario generation and
analysis. Finally, the survey concludes by highlighting the open challenges and
research questions, and outlining promising future research directions. All
reviewed papers are listed in a continuously maintained repository, which
contains supplementary materials and is available at
https://github.com/TUM-AVS/FM-for-Scenario-Generation-Analysis.

</details>


### [11] [Construction of a Multiple-DOF Under-actuated Gripper with Force-Sensing via Deep Learning](https://arxiv.org/abs/2506.11570)
*Jihao Li,Keqi Zhu,Guodong Lu,I-Ming Chen,Huixu Dong*

Main category: cs.RO

TL;DR: 提出了一种新型欠驱动夹持器，采用双3关节手指和LSTM模型实现无传感器力反馈控制，具有低成本、高适应性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 设计一种低成本、高适应性的欠驱动夹持器，无需力传感器即可实现力反馈控制，提升抓取性能。

Method: 1. 设计五连杆机构实现平行和包络抓取模式切换；2. 建立运动学和动力传输理论模型；3. 使用LSTM模型实现力控制。

Result: 实验验证了夹持器的负载能力、抓取力、力感知、稳定性及对大尺寸范围物体的适应性。

Conclusion: 该夹持器具有高通用性和鲁棒性，适用于多种抓取任务。

Abstract: We present a novel under-actuated gripper with two 3-joint fingers, which
realizes force feedback control by the deep learning technique- Long Short-Term
Memory (LSTM) model, without any force sensor. First, a five-linkage mechanism
stacked by double four-linkages is designed as a finger to automatically
achieve the transformation between parallel and enveloping grasping modes. This
enables the creation of a low-cost under-actuated gripper comprising a single
actuator and two 3-phalange fingers. Second, we devise theoretical models of
kinematics and power transmission based on the proposed gripper, accurately
obtaining fingertip positions and contact forces. Through coupling and
decoupling of five-linkage mechanisms, the proposed gripper offers the expected
capabilities of grasping payload/force/stability and objects with large
dimension ranges. Third, to realize the force control, an LSTM model is
proposed to determine the grasping mode for synthesizing force-feedback control
policies that exploit contact sensing after outlining the uncertainty of
currents using a statistical method. Finally, a series of experiments are
implemented to measure quantitative indicators, such as the payload, grasping
force, force sensing, grasping stability and the dimension ranges of objects to
be grasped. Additionally, the grasping performance of the proposed gripper is
verified experimentally to guarantee the high versatility and robustness of the
proposed gripper.

</details>


### [12] [Robot Context Protocol (RCP): A Runtime-Agnostic Interface for Agent-Aware Robot Control](https://arxiv.org/abs/2506.11650)
*Lambert Lee,Joshua Lau*

Main category: cs.RO

TL;DR: RCP是一种轻量级、中间件无关的通信协议，旨在简化机器人系统的复杂性，支持机器人、用户和自主代理之间的无缝交互。


<details>
  <summary>Details</summary>
Motivation: 解决机器人系统中通信复杂性和异构性问题，提供统一接口。

Method: 基于HTTP和WebSocket，定义结构化消息格式（如读、写、执行、订阅），支持运行时自省、异步反馈等功能。

Result: 实现了鲁棒性、可扩展性和安全性，适用于多行业（如制造、物流、医疗）。

Conclusion: RCP为复杂多智能体生态系统提供了智能、弹性和安全的机器人操作解决方案。

Abstract: The Robot Context Protocol (RCP) is a lightweight, middleware-agnostic
communication protocol designed to simplify the complexity of robotic systems
and enable seamless interaction between robots, users, and autonomous agents.
RCP provides a unified and semantically meaningful interface that decouples
client-facing operations from backend implementations, supporting a wide range
of deployment environments including physical robots, cloud-based
orchestrators, and simulated platforms. Built on HTTP and WebSocket transport
layers, the protocol defines a schema-driven message format with structured
operations such as read, write, execute, and subscribe. It integrates features
such as runtime introspection, asynchronous feedback, multi-tenant namespace
isolation, and strict type validation to ensure robustness, scalability, and
security. The architecture, message structure, interface model, and
adapter-based backend integration strategy of RCP are described, along with
deployment practices and applicability across industries including
manufacturing, logistics, and healthcare. RCP enables intelligent, resilient,
and safe robotic operations in complex, multi-agent ecosystems.

</details>


### [13] [Dynamic Collaborative Material Distribution System for Intelligent Robots In Smart Manufacturing](https://arxiv.org/abs/2506.11723)
*Ziren Xiao,Ruxin Xiao,Chang Liu,Xinheng Wang*

Main category: cs.RO

TL;DR: 本文提出了一种轻量级深度强化学习（DRL）方法，用于解决智能制造中多机器人动态导航问题，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在解决动态多源单目标（DMS-SD）导航问题时，要么无法从历史经验中学习，要么仅利用有限信息，导致计算时间长，难以实时操作。

Method: 采用轻量级DRL方法，设计了目标导向的奖励函数，快速收敛至最优解。

Result: 实验表明，该方法将计算时间缩短至毫秒级，比枚举方法快100倍，且适用于轻量级设备。

Conclusion: 提出的DRL方法高效解决了DMS-SD问题，适用于智能制造的实时操作和资源受限设备。

Abstract: The collaboration and interaction of multiple robots have become integral
aspects of smart manufacturing. Effective planning and management play a
crucial role in achieving energy savings and minimising overall costs. This
paper addresses the real-time Dynamic Multiple Sources to Single Destination
(DMS-SD) navigation problem, particularly with a material distribution case for
multiple intelligent robots in smart manufacturing. Enumerated solutions, such
as in \cite{xiao2022efficient}, tackle the problem by generating as many
optimal or near-optimal solutions as possible but do not learn patterns from
the previous experience, whereas the method in \cite{xiao2023collaborative}
only uses limited information from the earlier trajectories. Consequently,
these methods may take a considerable amount of time to compute results on
large maps, rendering real-time operations impractical. To overcome this
challenge, we propose a lightweight Deep Reinforcement Learning (DRL) method to
address the DMS-SD problem. The proposed DRL method can be efficiently trained
and rapidly converges to the optimal solution using the designed target-guided
reward function. A well-trained DRL model significantly reduces the computation
time for the next movement to a millisecond level, which improves the time up
to 100 times in our experiments compared to the enumerated solutions. Moreover,
the trained DRL model can be easily deployed on lightweight devices in smart
manufacturing, such as Internet of Things devices and mobile phones, which only
require limited computational resources.

</details>


### [14] [CIRO7.2: A Material Network with Circularity of -7.2 and Reinforcement-Learning-Controlled Robotic Disassembler](https://arxiv.org/abs/2506.11748)
*Federico Zocco,Monica Malvezzi*

Main category: cs.RO

TL;DR: 论文提出基于热力学动态分区的循环经济模型，结合强化学习控制的机器人拆卸器，分析了材料关键性和数量对循环性的影响。


<details>
  <summary>Details</summary>
Motivation: 线性经济模式导致资源浪费和未解决的废弃物管理问题，转向循环经济可缓解这些问题。

Method: 基于热力学动态分区（λ）建模材料网络，使用强化学习算法设计机器人拆卸器，并评估其性能。

Result: 最高循环性为-2.1（拆卸2个1kg部件），最低为-7.2（拆卸4个1kg部件加3kg外壳）。RL控制器性能与材料关键性和数量正相关。

Conclusion: 研究为循环智能与机器人（CIRO）领域奠定基础，开源代码可供进一步研究。

Abstract: The competition over natural reserves of minerals is expected to increase in
part because of the linear-economy paradigm based on take-make-dispose.
Simultaneously, the linear economy considers end-of-use products as waste
rather than as a resource, which results in large volumes of waste whose
management remains an unsolved problem. Since a transition to a circular
economy can mitigate these open issues, in this paper we begin by enhancing the
notion of circularity based on compartmental dynamical thermodynamics, namely,
$\lambda$, and then, we model a thermodynamical material network processing a
batch of 2 solid materials of criticality coefficients of 0.1 and 0.95, with a
robotic disassembler compartment controlled via reinforcement learning (RL),
and processing 2-7 kg of materials. Subsequently, we focused on the design of
the robotic disassembler compartment using state-of-the-art RL algorithms and
assessing the algorithm performance with respect to $\lambda$ (Fig. 1). The
highest circularity is -2.1 achieved in the case of disassembling 2 parts of 1
kg each, whereas it reduces to -7.2 in the case of disassembling 4 parts of 1
kg each contained inside a chassis of 3 kg. Finally, a sensitivity analysis
highlighted that the impact on $\lambda$ of the performance of an RL controller
has a positive correlation with the quantity and the criticality of the
materials to be disassembled. This work also gives the principles of the
emerging research fields indicated as circular intelligence and robotics
(CIRO). Source code is publicly available.

</details>


### [15] [ExoStart: Efficient learning for dexterous manipulation with sensorized exoskeleton demonstrations](https://arxiv.org/abs/2506.11775)
*Zilin Si,Jose Enrique Chen,M. Emre Karagozler,Antonia Bronars,Jonathan Hutchinson,Thomas Lampe,Nimrod Gileadi,Taylor Howell,Stefano Saliceti,Lukasz Barczyk,Ilan Olivarez Correa,Tom Erez,Mohit Shridhar,Murilo Fernandes Martins,Konstantinos Bousmalis,Nicolas Heess,Francesco Nori,Maria Bauza Villalonga*

Main category: cs.RO

TL;DR: ExoStart是一个利用人类灵巧性改进机器人手控制的通用学习框架，通过低成本可穿戴外骨骼收集高质量数据，并结合仿真动态过滤器与强化学习，实现零样本迁移到真实机器人。


<details>
  <summary>Details</summary>
Motivation: 扩展机器人手的操作能力，尤其是实现类似人类手的灵巧性，但现有远程操作系统难以应对高自由度和复杂动态的挑战。

Method: 使用传感器化低成本可穿戴外骨骼收集直接演示数据，提出仿真动态过滤器生成动态可行轨迹，并通过稀疏奖励的自适应强化学习方法训练策略。

Result: ExoStart能生成灵巧的机器人手技能，在复杂任务（如打开AirPods盒或插入钥匙）中成功率超过50%。

Conclusion: ExoStart框架具有通用性和可扩展性，能有效提升机器人手的操作能力，并实现零样本迁移。

Abstract: Recent advancements in teleoperation systems have enabled high-quality data
collection for robotic manipulators, showing impressive results in learning
manipulation at scale. This progress suggests that extending these capabilities
to robotic hands could unlock an even broader range of manipulation skills,
especially if we could achieve the same level of dexterity that human hands
exhibit. However, teleoperating robotic hands is far from a solved problem, as
it presents a significant challenge due to the high degrees of freedom of
robotic hands and the complex dynamics occurring during contact-rich settings.
In this work, we present ExoStart, a general and scalable learning framework
that leverages human dexterity to improve robotic hand control. In particular,
we obtain high-quality data by collecting direct demonstrations without a robot
in the loop using a sensorized low-cost wearable exoskeleton, capturing the
rich behaviors that humans can demonstrate with their own hands. We also
propose a simulation-based dynamics filter that generates dynamically feasible
trajectories from the collected demonstrations and use the generated
trajectories to bootstrap an auto-curriculum reinforcement learning method that
relies only on simple sparse rewards. The ExoStart pipeline is generalizable
and yields robust policies that transfer zero-shot to the real robot. Our
results demonstrate that ExoStart can generate dexterous real-world hand
skills, achieving a success rate above 50% on a wide range of complex tasks
such as opening an AirPods case or inserting and turning a key in a lock. More
details and videos can be found in https://sites.google.com/view/exostart.

</details>


### [16] [Auditory-Tactile Congruence for Synthesis of Adaptive Pain Expressions in RoboPatients](https://arxiv.org/abs/2506.11827)
*Saitarun Nadipineni,Chapa Sirithunge,Yue Xie,Fumiya Iida,Thilina Dulantha Lalitharatne*

Main category: cs.RO

TL;DR: RoboPatient是一种医疗机器人模拟器，通过触觉和听觉反馈模拟疼痛表达，用于临床培训和诊断模拟。


<details>
  <summary>Details</summary>
Motivation: 减少因误诊导致的治疗延误和伤害，通过机器人患者提供可控的训练和评估方式。

Method: 利用腹部模型和触觉-疼痛映射模型，通过触觉输入生成多模态疼痛表达，并通过声音评估感知一致性。

Result: 振幅和音高显著影响对疼痛表达的认同，触觉力量与声音感知一致，音高是最关键的影响因素。

Conclusion: 该方法为临床教育和诊断模拟中高保真机器人患者奠定了基础。

Abstract: Misdiagnosis can lead to delayed treatments and harm. Robotic patients offer
a controlled way to train and evaluate clinicians in rare, subtle, or complex
cases, reducing diagnostic errors. We present RoboPatient, a medical robotic
simulator aimed at multimodal pain synthesis based on haptic and auditory
feedback during palpation-based training scenarios. The robopatient functions
as an adaptive intermediary, capable of synthesizing plausible pain expressions
vocal and facial in response to tactile stimuli generated during palpation.
Using an abdominal phantom, robopatient captures and processes haptic input via
an internal palpation-to-pain mapping model. To evaluate perceptual congruence
between palpation and the corresponding auditory output, we conducted a study
involving 7680 trials across 20 participants, where they evaluated pain
intensity through sound. Results show that amplitude and pitch significantly
influence agreement with the robot's pain expressions, irrespective of pain
sounds. Stronger palpation forces elicited stronger agreement, aligning with
psychophysical patterns. The study revealed two key dimensions: pitch and
amplitude are central to how people perceive pain sounds, with pitch being the
most influential cue. These acoustic features shape how well the sound matches
the applied force during palpation, impacting perceived realism. This approach
lays the groundwork for high-fidelity robotic patients in clinical education
and diagnostic simulation.

</details>


### [17] [The Space Between Us: A Methodological Framework for Researching Bonding and Proxemics in Situated Group-Agent Interactions](https://arxiv.org/abs/2506.11829)
*Ana Müller,Anja Richert*

Main category: cs.RO

TL;DR: 本文提出了一种多方法框架，用于研究现实世界中人与社交互动代理的空间和社交动态，结合了主观自我报告和客观空间追踪。


<details>
  <summary>Details</summary>
Motivation: 解决人类感知与行为一致性的挑战，并为未来研究提供工具。

Method: 结合近体学和联结理论，使用主观自我报告和客观空间追踪方法，在博物馆进行了两项实地研究。

Result: 开发了一个开源、可扩展且经过实地测试的工具包。

Conclusion: 该框架为未来研究提供了实用工具，并展示了其在现实场景中的应用潜力。

Abstract: This paper introduces a multimethod framework for studying spatial and social
dynamics in real-world group-agent interactions with socially interactive
agents. Drawing on proxemics and bonding theories, the method combines
subjective self-reports and objective spatial tracking. Applied in two field
studies in a museum (N = 187) with a robot and a virtual agent, the paper
addresses the challenges in aligning human perception and behavior. We focus on
presenting an open source, scalable, and field-tested toolkit for future
studies.

</details>


### [18] [Your Ride, Your Rules: Psychology and Cognition Enabled Automated Driving Systems](https://arxiv.org/abs/2506.11842)
*Zhipeng Bao,Qianwen Li*

Main category: cs.RO

TL;DR: PACE-ADS是一个基于心理学和认知的自动驾驶框架，通过三个智能体（驾驶员、心理学家和协调者）实现与乘员的双向交互，提升舒适度和信任感。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆缺乏与乘员的有效双向沟通，限制了个人化和故障恢复能力，影响舒适度和信任感，阻碍广泛采用。

Method: PACE-ADS包含三个基于基础模型的智能体：驾驶员智能体分析驾驶环境，心理学家智能体解读乘员心理信号和认知指令，协调者智能体整合输入并生成行为决策。

Result: 仿真结果显示，PACE-ADS能根据乘员状态调整驾驶风格，提升舒适度，并通过自主推理或人工指导安全恢复故障。

Conclusion: PACE-ADS展示了基于LLM的框架在弥合机器自主性和以人为本驾驶之间差距的潜力。

Abstract: Despite rapid advances in autonomous driving, current autonomous vehicles
(AVs) lack effective bidirectional communication with occupants, limiting
personalization and recovery from immobilization. This reduces comfort and
trust, potentially slowing broader AV adoption. We propose PACE-ADS (Psychology
and Cognition Enabled Automated Driving Systems), a human-centered autonomy
framework that enables AVs to sense, interpret, and respond to both external
traffic and internal occupant states. PACE-ADS comprises three foundation
model-based agents: a Driver Agent that analyzes the driving context, a
Psychologist Agent that interprets occupant psychological signals (e.g., EEG,
heart rate, facial expressions) and cognitive commands (e.g., speech), and a
Coordinator Agent that integrates these inputs to produce high-level behavior
decisions and operational parameters. Rather than replacing existing AV
modules, PACE-ADS complements them by operating at the behavioral level,
delegating low-level control to native AV systems. This separation enables
closed-loop adaptation and supports integration across diverse platforms. We
evaluate PACE-ADS in simulation across varied scenarios involving traffic
lights, pedestrians, work zones, and car following. Results show that PACE-ADS
adapts driving styles to occupant states, improves ride comfort, and enables
safe recovery from immobilization via autonomous reasoning or human guidance.
Our findings highlight the promise of LLM-based frameworks for bridging the gap
between machine autonomy and human-centered driving.

</details>


### [19] [Palpation Alters Auditory Pain Expressions with Gender-Specific Variations in Robopatients](https://arxiv.org/abs/2506.11906)
*Chapa Sirithunge,Yue Xie,Saitarun Nadipineni,Fumiya Iida,Thilina Dulantha Lalitharatne*

Main category: cs.RO

TL;DR: 论文提出了一种基于强化学习的机器人患者系统，通过动态生成听觉疼痛反馈来模拟真实患者的触诊训练，优化了疼痛声音与人类偏好的匹配。


<details>
  <summary>Details</summary>
Motivation: 诊断错误是导致可预防死亡的主要原因之一，尤其是在资源有限的地区。现有的医疗培训模拟器在生成多模态反馈（如听觉疼痛表达）方面存在挑战。

Method: 研究采用近端策略优化（PPO）强化学习技术，通过实时人类反馈迭代优化机器人患者的疼痛声音生成。

Result: 系统能够根据个体触诊力和声音偏好动态调整疼痛反馈，并捕捉从轻度不适到急性痛苦的广泛疼痛强度。

Conclusion: 该系统为腹部触诊训练提供了一个可控且沉浸式的模拟平台，具有显著的应用潜力。

Abstract: Diagnostic errors remain a major cause of preventable deaths, particularly in
resource-limited regions. Medical training simulators, including robopatients,
play a vital role in reducing these errors by mimicking real patients for
procedural training such as palpation. However, generating multimodal feedback,
especially auditory pain expressions, remains challenging due to the complex
relationship between palpation behavior and sound. The high-dimensional nature
of pain sounds makes exploration challenging with conventional methods. This
study introduces a novel experimental paradigm for pain expressivity in
robopatients where they dynamically generate auditory pain expressions in
response to palpation force, by co-optimizing human feedback using machine
learning. Using Proximal Policy Optimization (PPO), a reinforcement learning
(RL) technique optimized for continuous adaptation, our robot iteratively
refines pain sounds based on real-time human feedback. This robot initializes
randomized pain responses to palpation forces, and the RL agent learns to
adjust these sounds to align with human preferences. The results demonstrated
that the system adapts to an individual's palpation forces and sound
preferences and captures a broad spectrum of pain intensity, from mild
discomfort to acute distress, through RL-guided exploration of the auditory
pain space. The study further showed that pain sound perception exhibits
saturation at lower forces with gender specific thresholds. These findings
highlight the system's potential to enhance abdominal palpation training by
offering a controllable and immersive simulation platform.

</details>


### [20] [mimic-one: a Scalable Model Recipe for General Purpose Robot Dexterity](https://arxiv.org/abs/2506.11916)
*Elvis Nava,Victoriano Montesinos,Erik Bauer,Benedek Forrai,Jonas Pai,Stefan Weirich,Stephan-Daniel Gravert,Philipp Wand,Stephan Polinski,Benjamin F. Grewe,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 提出了一种基于扩散模型的高效学习方法，用于控制16自由度的人形机器人手，实现了93.3%的成功率和33.3%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决高自由度机器人手的实时控制和精细动作推断问题，提高样本效率和任务成功率。

Method: 设计了16自由度的肌腱驱动手，结合手腕摄像头和Franka Emika Panda机械臂，开发了多功能的远程操作和数据收集流程，利用高频生成控制训练端到端策略。

Result: 在复杂操作场景中实现了93.3%的成功率，性能提升33.3%，并展示了策略性能的扩展趋势。

Conclusion: 通过硬件、学习和实际部署的集成方法，推动了灵巧机器人操作的前沿技术。

Abstract: We present a diffusion-based model recipe for real-world control of a highly
dexterous humanoid robotic hand, designed for sample-efficient learning and
smooth fine-motor action inference. Our system features a newly designed 16-DoF
tendon-driven hand, equipped with wide angle wrist cameras and mounted on a
Franka Emika Panda arm. We develop a versatile teleoperation pipeline and data
collection protocol using both glove-based and VR interfaces, enabling
high-quality data collection across diverse tasks such as pick and place, item
sorting and assembly insertion. Leveraging high-frequency generative control,
we train end-to-end policies from raw sensory inputs, enabling smooth,
self-correcting motions in complex manipulation scenarios. Real-world
evaluations demonstrate up to 93.3% out of distribution success rates, with up
to a +33.3% performance boost due to emergent self-correcting behaviors, while
also revealing scaling trends in policy performance. Our results advance the
state-of-the-art in dexterous robotic manipulation through a fully integrated,
practical approach to hardware, learning, and real-world deployment.

</details>


### [21] [SAIL: Faster-than-Demonstration Execution of Imitation Learning Policies](https://arxiv.org/abs/2506.11948)
*Nadun Ranawaka Arachchige,Zhenyang Chen,Wonsuhk Jung,Woo Chul Shin,Rohan Bansal,Pierre Barroso,Yu Hang He,Yingyang Celine Lin,Benjamin Joffe,Shreyas Kousik,Danfei Xu*

Main category: cs.RO

TL;DR: SAIL系统通过一致性动作推断、高保真跟踪、自适应速度调节和动作调度，实现了离线模仿学习策略的快速执行，实验显示仿真中速度提升4倍，实际机器人中提升3.2倍。


<details>
  <summary>Details</summary>
Motivation: 现有离线模仿学习策略的执行速度受限于演示数据，限制了机器人系统的任务吞吐量，尤其在工业自动化等应用中。

Method: SAIL系统包含四个组件：一致性动作推断算法、高保真跟踪、自适应速度调节和动作调度。

Result: 在仿真和实际机器人平台上，SAIL实现了最高4倍和3.2倍的速度提升。

Conclusion: SAIL为离线模仿学习策略的快速执行提供了有效解决方案，提升了任务吞吐量。

Abstract: Offline Imitation Learning (IL) methods such as Behavior Cloning are
effective at acquiring complex robotic manipulation skills. However, existing
IL-trained policies are confined to executing the task at the same speed as
shown in demonstration data. This limits the task throughput of a robotic
system, a critical requirement for applications such as industrial automation.
In this paper, we introduce and formalize the novel problem of enabling
faster-than-demonstration execution of visuomotor policies and identify
fundamental challenges in robot dynamics and state-action distribution shifts.
We instantiate the key insights as SAIL (Speed Adaptation for Imitation
Learning), a full-stack system integrating four tightly-connected components:
(1) a consistency-preserving action inference algorithm for smooth motion at
high speed, (2) high-fidelity tracking of controller-invariant motion targets,
(3) adaptive speed modulation that dynamically adjusts execution speed based on
motion complexity, and (4) action scheduling to handle real-world system
latencies. Experiments on 12 tasks across simulation and two real, distinct
robot platforms show that SAIL achieves up to a 4x speedup over demonstration
speed in simulation and up to 3.2x speedup in the real world. Additional detail
is available at https://nadunranawaka1.github.io/sail-policy

</details>
