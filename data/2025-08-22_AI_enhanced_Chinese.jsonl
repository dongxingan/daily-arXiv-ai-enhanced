{"id": "2508.14994", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.14994", "abs": "https://arxiv.org/abs/2508.14994", "authors": ["Murilo Vinicius da Silva", "Matheus Hipolito Carvalho", "Juliano Negri", "Thiago Segreto", "Gustavo J. G. Lahr", "Ricardo V. Godoy", "Marcelo Becker"], "title": "A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot", "comment": null, "summary": "In hazardous and remote environments, robotic systems perform critical tasks\ndemanding improved safety and efficiency. Among these, quadruped robots with\nmanipulator arms offer mobility and versatility for complex operations.\nHowever, teleoperating quadruped robots is challenging due to the lack of\nintegrated obstacle detection and intuitive control methods for the robotic\narm, increasing collision risks in confined or dynamically changing workspaces.\nTeleoperation via joysticks or pads can be non-intuitive and demands a high\nlevel of expertise due to its complexity, culminating in a high cognitive load\non the operator. To address this challenge, a teleoperation approach that\ndirectly maps human arm movements to the robotic manipulator offers a simpler\nand more accessible solution. This work proposes an intuitive remote control by\nleveraging a vision-based pose estimation pipeline that utilizes an external\ncamera with a machine learning-based model to detect the operator's wrist\nposition. The system maps these wrist movements into robotic arm commands to\ncontrol the robot's arm in real-time. A trajectory planner ensures safe\nteleoperation by detecting and preventing collisions with both obstacles and\nthe robotic arm itself. The system was validated on the real robot,\ndemonstrating robust performance in real-time control. This teleoperation\napproach provides a cost-effective solution for industrial applications where\nsafety, precision, and ease of use are paramount, ensuring reliable and\nintuitive robotic control in high-risk environments.", "AI": {"tldr": "提出基于视觉姿态估计的直观四足机器人遥操作方法，通过外部摄像头检测操作者手腕位置，实时映射到机械臂控制，结合轨迹规划确保安全避障", "motivation": "在危险和远程环境中，四足机器人机械臂需要更安全和高效的遥操作。传统摇杆控制不直观且需要专业知识，认知负荷高，缺乏集成的障碍物检测功能", "method": "使用基于机器学习的外部摄像头视觉姿态估计管道检测操作者手腕位置，实时映射到机械臂命令，结合轨迹规划器检测和防止与障碍物及机械臂自身的碰撞", "result": "在真实机器人上验证，展示了实时控制的鲁棒性能，能够安全可靠地进行遥操作", "conclusion": "该遥操作方法为工业应用提供了成本效益高的解决方案，在安全性、精度和易用性至关重要的高风险环境中确保可靠直观的机器人控制"}}
{"id": "2508.15002", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15002", "abs": "https://arxiv.org/abs/2508.15002", "authors": ["René Zurbrügg", "Andrei Cramariuc", "Marco Hutter"], "title": "GraspQP: Differentiable Optimization of Force Closure for Diverse and Robust Dexterous Grasping", "comment": null, "summary": "Dexterous robotic hands enable versatile interactions due to the flexibility\nand adaptability of multi-fingered designs, allowing for a wide range of\ntask-specific grasp configurations in diverse environments. However, to fully\nexploit the capabilities of dexterous hands, access to diverse and high-quality\ngrasp data is essential -- whether for developing grasp prediction models from\npoint clouds, training manipulation policies, or supporting high-level task\nplanning with broader action options. Existing approaches for dataset\ngeneration typically rely on sampling-based algorithms or simplified\nforce-closure analysis, which tend to converge to power grasps and often\nexhibit limited diversity. In this work, we propose a method to synthesize\nlarge-scale, diverse, and physically feasible grasps that extend beyond simple\npower grasps to include refined manipulations, such as pinches and tri-finger\nprecision grasps. We introduce a rigorous, differentiable energy formulation of\nforce closure, implicitly defined through a Quadratic Program (QP).\nAdditionally, we present an adjusted optimization method (MALA*) that improves\nperformance by dynamically rejecting gradient steps based on the distribution\nof energy values across all samples. We extensively evaluate our approach and\ndemonstrate significant improvements in both grasp diversity and the stability\nof final grasp predictions. Finally, we provide a new, large-scale grasp\ndataset for 5,700 objects from DexGraspNet, comprising five different grippers\nand three distinct grasp types.\n  Dataset and Code:https://graspqp.github.io/", "AI": {"tldr": "提出了一种基于可微分能量公式和优化方法的大规模灵巧抓取数据集生成方法，显著提升了抓取多样性和稳定性", "motivation": "灵巧机械手需要多样化的高质量抓取数据来充分发挥其能力，但现有方法通常局限于强力抓取且多样性不足", "method": "引入基于二次规划的可微分力闭合能量公式，并提出动态拒绝梯度步长的优化方法MALA*", "result": "生成了包含5700个物体、5种夹爪和3种抓取类型的大规模数据集DexGraspNet，在抓取多样性和稳定性方面显著改进", "conclusion": "该方法能够合成超越简单强力抓取的多样化物理可行抓取，为灵巧抓取研究提供了重要的数据集基础"}}
{"id": "2508.15021", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15021", "abs": "https://arxiv.org/abs/2508.15021", "authors": ["Mark Van der Merwe", "Devesh Jha"], "title": "In-Context Iterative Policy Improvement for Dynamic Manipulation", "comment": "14 pages. Accepted at CoRL 2025", "summary": "Attention-based architectures trained on internet-scale language data have\ndemonstrated state of the art reasoning ability for various language-based\ntasks, such as logic problems and textual reasoning. Additionally, these Large\nLanguage Models (LLMs) have exhibited the ability to perform few-shot\nprediction via in-context learning, in which input-output examples provided in\nthe prompt are generalized to new inputs. This ability furthermore extends\nbeyond standard language tasks, enabling few-shot learning for general\npatterns. In this work, we consider the application of in-context learning with\npre-trained language models for dynamic manipulation. Dynamic manipulation\nintroduces several crucial challenges, including increased dimensionality,\ncomplex dynamics, and partial observability. To address this, we take an\niterative approach, and formulate our in-context learning problem to predict\nadjustments to a parametric policy based on previous interactions. We show\nacross several tasks in simulation and on a physical robot that utilizing\nin-context learning outperforms alternative methods in the low data regime.\nVideo summary of this work and experiments can be found\nhttps://youtu.be/2inxpdrq74U?si=dAdDYsUEr25nZvRn.", "AI": {"tldr": "该论文研究如何利用预训练大语言模型的上下文学习能力来解决动态操作任务，通过预测参数化策略的调整，在低数据情况下优于其他方法。", "motivation": "大语言模型在语言任务中展现出强大的推理和少样本学习能力，但将这些能力扩展到动态操作领域面临维度增加、复杂动态和部分可观测性等挑战。", "method": "采用迭代方法，将上下文学习问题表述为基于先前交互预测参数化策略的调整，通过在仿真和物理机器人上的多个任务进行验证。", "result": "实验表明，在低数据情况下，利用上下文学习的方法优于其他替代方法，在仿真和物理机器人任务中都取得了良好效果。", "conclusion": "大语言模型的上下文学习能力可以成功应用于动态操作任务，为解决复杂机器人控制问题提供了一种有效的少样本学习方法。"}}
{"id": "2508.15038", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.MA", "I.2.9"], "pdf": "https://arxiv.org/pdf/2508.15038", "abs": "https://arxiv.org/abs/2508.15038", "authors": ["Makram Chahine", "William Yang", "Alaa Maalouf", "Justin Siriska", "Ninad Jadhav", "Daniel Vogt", "Stephanie Gil", "Robert Wood", "Daniela Rus"], "title": "Decentralized Vision-Based Autonomous Aerial Wildlife Monitoring", "comment": null, "summary": "Wildlife field operations demand efficient parallel deployment methods to\nidentify and interact with specific individuals, enabling simultaneous\ncollective behavioral analysis, and health and safety interventions. Previous\nrobotics solutions approach the problem from the herd perspective, or are\nmanually operated and limited in scale. We propose a decentralized vision-based\nmulti-quadrotor system for wildlife monitoring that is scalable, low-bandwidth,\nand sensor-minimal (single onboard RGB camera). Our approach enables robust\nidentification and tracking of large species in their natural habitat. We\ndevelop novel vision-based coordination and tracking algorithms designed for\ndynamic, unstructured environments without reliance on centralized\ncommunication or control. We validate our system through real-world\nexperiments, demonstrating reliable deployment in diverse field conditions.", "AI": {"tldr": "一种基于视觉的多旋翼飞行器系统，用于野生动物监测，具有可扩展性、低带宽和最小传感器配置的特点。", "motivation": "野生动物田野操作需要高效的并行部署方法，以同时进行个体识别、集体行为分析以及健康安全干预，而现有方案或从群体角度出发或手动操作且规模有限。", "method": "发展了新颖的基于视觉的协调和跟踪算法，设计用于动态、非结构化环境，不依赖中央化通信或控制。系统仅需单个机载RGB摄像头。", "result": "通过实际环境实验验证，证明系统在多样化田野条件下能够可靠部署，实现了对大型物种在自然生境中的稳健识别和跟踪。", "conclusion": "该分布式视觉系统为野生动物监测提供了一种可扩展、低带宽需求的解决方案，充分利用了视觉技术在动态非结构环境中的优势。"}}
{"id": "2508.15160", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15160", "abs": "https://arxiv.org/abs/2508.15160", "authors": ["Hesam Azadjou", "Suraj Chakravarthi Raja", "Ali Marjaninejad", "Francisco J. Valero-Cuevas"], "title": "Hardware Implementation of a Zero-Prior-Knowledge Approach to Lifelong Learning in Kinematic Control of Tendon-Driven Quadrupeds", "comment": null, "summary": "Like mammals, robots must rapidly learn to control their bodies and interact\nwith their environment despite incomplete knowledge of their body structure and\nsurroundings. They must also adapt to continuous changes in both. This work\npresents a bio-inspired learning algorithm, General-to-Particular (G2P),\napplied to a tendon-driven quadruped robotic system developed and fabricated\nin-house. Our quadruped robot undergoes an initial five-minute phase of\ngeneralized motor babbling, followed by 15 refinement trials (each lasting 20\nseconds) to achieve specific cyclical movements. This process mirrors the\nexploration-exploitation paradigm observed in mammals. With each refinement,\nthe robot progressively improves upon its initial \"good enough\" solution. Our\nresults serve as a proof-of-concept, demonstrating the hardware-in-the-loop\nsystem's ability to learn the control of a tendon-driven quadruped with\nredundancies in just a few minutes to achieve functional and adaptive cyclical\nnon-convex movements. By advancing autonomous control in robotic locomotion,\nour approach paves the way for robots capable of dynamically adjusting to new\nenvironments, ensuring sustained adaptability and performance.", "AI": {"tldr": "提出G2P仿生学习算法，在肌腱驱动四足机器人上实现快速运动控制学习，通过5分钟通用运动探索和15次20秒的细化试验，实现功能性周期性运动控制", "motivation": "机器人需要像哺乳动物一样快速学习控制身体并与环境互动，尽管对自身结构和环境了解不完全，并且需要适应持续变化", "method": "采用通用到特定(G2P)仿生学习算法，先进行5分钟通用运动探索，然后进行15次20秒的细化试验，逐步改进初始解决方案", "result": "系统在几分钟内成功学习到肌腱驱动四足机器人的控制，实现功能性和自适应的周期性非凸运动", "conclusion": "该方法推进了机器人运动的自主控制，为能够动态适应新环境的机器人铺平道路，确保持续的适应性和性能"}}
{"id": "2508.15732", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.15732", "abs": "https://arxiv.org/abs/2508.15732", "authors": ["Gargi Das", "Daegyun Choi", "Donghoon Kim"], "title": "Understanding and Utilizing Dynamic Coupling in Free-Floating Space Manipulators for On-Orbit Servicing", "comment": "17 pages, 7 figures, 2025 AAS/AIAA Astrodynamics Specialist\n  Conference", "summary": "This study proposes a dynamic coupling-informed trajectory optimization\nalgorithm for free-floating space manipulator systems (SMSs). Dynamic coupling\nbetween the base and the manipulator arms plays a critical role in influencing\nthe system's behavior. While prior research has predominantly focused on\nminimizing this coupling, often overlooking its potential advantages, this work\ninvestigates how dynamic coupling can instead be leveraged to improve\ntrajectory planning. Singular value decomposition (SVD) of the dynamic coupling\nmatrix is employed to identify the dominant components governing coupling\nbehavior. A quantitative metric is then formulated to characterize the strength\nand directionality of the coupling and is incorporated into a trajectory\noptimization framework. To assess the feasibility of the optimized trajectory,\na sliding mode control-based tracking controller is designed to generate the\nrequired joint torque inputs. Simulation results demonstrate that explicitly\naccounting for dynamic coupling in trajectory planning enables more informed\nand potentially more efficient operation, offering new directions for the\ncontrol of free-floating SMSs.", "AI": {"tldr": "本研究提出了一种动态耦合信息的轨迹优化算法，用于自由浮动空间操纵器系统，利用动态耦合改善轨迹规划效果。", "motivation": "以往研究主要关注最小化动态耦合，而忽视了其潜在优势。本文研究如何利用动态耦合来改善轨迹规划。", "method": "采用动态耦合矩阵的奇异值分解(SVD)来识别主导耦合行为，形成定量指标来表征耦合强度和方向性，并将其整合到轨迹优化框架中。设计滑模控制跟踪控制器来验证优化轨迹的可行性。", "result": "模拟结果表明，在轨迹规划中明确考虑动态耦合可以实现更智能和更高效的操作，为自由浮动空间操纵器系统的控制提供了新方向。", "conclusion": "本研究证明了利用动态耦合而非小化它，可以提高空间操纵器系统轨迹规划的效果和效率，为该领域提供了新的研究思路。"}}
{"id": "2508.15201", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15201", "abs": "https://arxiv.org/abs/2508.15201", "authors": ["Haoran Li", "Yuhui Chen", "Wenbo Cui", "Weiheng Liu", "Kai Liu", "Mingcai Zhou", "Zhengtao Zhang", "Dongbin Zhao"], "title": "Survey of Vision-Language-Action Models for Embodied Manipulation", "comment": "in Chinese language", "summary": "Embodied intelligence systems, which enhance agent capabilities through\ncontinuous environment interactions, have garnered significant attention from\nboth academia and industry. Vision-Language-Action models, inspired by\nadvancements in large foundation models, serve as universal robotic control\nframeworks that substantially improve agent-environment interaction\ncapabilities in embodied intelligence systems. This expansion has broadened\napplication scenarios for embodied AI robots. This survey comprehensively\nreviews VLA models for embodied manipulation. Firstly, it chronicles the\ndevelopmental trajectory of VLA architectures. Subsequently, we conduct a\ndetailed analysis of current research across 5 critical dimensions: VLA model\nstructures, training datasets, pre-training methods, post-training methods, and\nmodel evaluation. Finally, we synthesize key challenges in VLA development and\nreal-world deployment, while outlining promising future research directions.", "AI": {"tldr": "这篇综述论文系统回顾了视觉-语言-动作(VLA)模型在具身智能系统中的发展，分析了模型架构、数据集、训练方法和评估等5个关键维度，并指出了未来研究方向。", "motivation": "随着大模型技术的发展，VLA模型作为通用机器人控制框架显著提升了具身智能系统的环境交互能力，扩展了应用场景，需要系统梳理该领域的发展现状和挑战。", "method": "通过全面调研VLA模型的发展历程，从模型结构、训练数据集、预训练方法、后训练方法和模型评估5个维度进行详细分析。", "result": "系统总结了VLA模型在具身操作任务中的技术发展路线，识别了当前研究的关键进展和存在的技术挑战。", "conclusion": "VLA模型是具身智能系统的重要技术方向，但仍面临实际部署的挑战，需要进一步研究来推动该领域的发展和应用落地。"}}
{"id": "2508.15300", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15300", "abs": "https://arxiv.org/abs/2508.15300", "authors": ["William McDonald", "Cedric Le Gentil", "Jennifer Wakulicz", "Teresa Vidal-Calleja"], "title": "Mag-Match: Magnetic Vector Field Features for Map Matching and Registration", "comment": "To be published in IROS: IEEE/RSJ International Conference on\n  Intelligent Robots and Systems, 2025", "summary": "Map matching and registration are essential tasks in robotics for\nlocalisation and integration of multi-session or multi-robot data. Traditional\nmethods rely on cameras or LiDARs to capture visual or geometric information\nbut struggle in challenging conditions like smoke or dust. Magnetometers, on\nthe other hand, detect magnetic fields, revealing features invisible to other\nsensors and remaining robust in such environments. In this paper, we introduce\nMag-Match, a novel method for extracting and describing features in 3D magnetic\nvector field maps to register different maps of the same area. Our feature\ndescriptor, based on higher-order derivatives of magnetic field maps, is\ninvariant to global orientation, eliminating the need for gravity-aligned\nmapping. To obtain these higher-order derivatives map-wide given point-wise\nmagnetometer data, we leverage a physics-informed Gaussian Process to perform\nefficient and recursive probabilistic inference of both the magnetic field and\nits derivatives. We evaluate Mag-Match in simulated and real-world experiments\nagainst a SIFT-based approach, demonstrating accurate map-to-map, robot-to-map,\nand robot-to-robot transformations - even without initial gravitational\nalignment.", "AI": {"tldr": "Mag-Match是一种基于磁场的3D地图匹配方法，利用高斯过程提取磁场高阶导数特征，无需重力对齐即可实现地图注册和机器人定位。", "motivation": "传统基于相机或LiDAR的地图匹配方法在烟雾、灰尘等恶劣环境中表现不佳，而磁力计能够检测其他传感器无法感知的磁场特征，并在这些挑战性条件下保持鲁棒性。", "method": "提出基于磁场高阶导数的特征描述子，利用物理信息高斯过程进行概率推理，递归计算磁场及其导数，实现全局方向不变的地图特征提取和匹配。", "result": "在仿真和真实实验中，Mag-Match相比基于SIFT的方法表现出色，能够准确实现地图到地图、机器人到地图以及机器人到机器人的变换，且无需初始重力对齐。", "conclusion": "Mag-Match为恶劣环境下的多会话或多机器人数据集成提供了有效的磁场地图匹配解决方案，具有方向不变性和环境鲁棒性的优势。"}}
{"id": "2508.15354", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15354", "abs": "https://arxiv.org/abs/2508.15354", "authors": ["Chaoran Xiong", "Yulong Huang", "Fangwen Yu", "Changhao Chen", "Yue Wang", "Songpengchen Xia", "Ling Pei"], "title": "Sensing, Social, and Motion Intelligence in Embodied Navigation: A Comprehensive Survey", "comment": null, "summary": "Embodied navigation (EN) advances traditional navigation by enabling robots\nto perform complex egocentric tasks through sensing, social, and motion\nintelligence. In contrast to classic methodologies that rely on explicit\nlocalization and pre-defined maps, EN leverages egocentric perception and\nhuman-like interaction strategies. This survey introduces a comprehensive EN\nformulation structured into five stages: Transition, Observation, Fusion,\nReward-policy construction, and Action (TOFRA). The TOFRA framework serves to\nsynthesize the current state of the art, provide a critical review of relevant\nplatforms and evaluation metrics, and identify critical open research\nchallenges. A list of studies is available at\nhttps://github.com/Franky-X/Awesome-Embodied-Navigation.", "AI": {"tldr": "本文提出了一个名为TOFRA的五阶段框架来系统化具身导航研究，包括转换、观察、融合、奖励策略构建和行动阶段，并对当前技术平台、评估指标进行了批判性评审。", "motivation": "传统导航方法依赖显式定位和预定义地图，而具身导航通过自我中心感知和类人交互策略，使机器人能够执行复杂的自我中心任务，需要新的系统化框架来整合这一领域的研究进展。", "method": "提出了TOFRA五阶段框架：转换(Transition)、观察(Observation)、融合(Fusion)、奖励策略构建(Reward-policy construction)和行动(Action)，用于分析和综合当前具身导航的最新技术。", "result": "建立了一个全面的具身导航系统化框架，对相关平台和评估指标进行了批判性评审，并识别了关键的开放研究挑战。", "conclusion": "TOFRA框架为具身导航研究提供了系统化的分析工具，有助于推动该领域的发展，同时指出了未来需要解决的关键研究方向。"}}
{"id": "2508.15427", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15427", "abs": "https://arxiv.org/abs/2508.15427", "authors": ["Huy Hoang Nguyen", "Johannes Huemer", "Markus Murschitz", "Tobias Glueck", "Minh Nhat Vu", "Andreas Kugi"], "title": "Lang2Lift: A Framework for Language-Guided Pallet Detection and Pose Estimation Integrated in Autonomous Outdoor Forklift Operation", "comment": "8 pages, 7 figures", "summary": "The logistics and construction industries face persistent challenges in\nautomating pallet handling, especially in outdoor environments with variable\npayloads, inconsistencies in pallet quality and dimensions, and unstructured\nsurroundings. In this paper, we tackle automation of a critical step in pallet\ntransport: the pallet pick-up operation. Our work is motivated by labor\nshortages, safety concerns, and inefficiencies in manually locating and\nretrieving pallets under such conditions. We present Lang2Lift, a framework\nthat leverages foundation models for natural language-guided pallet detection\nand 6D pose estimation, enabling operators to specify targets through intuitive\ncommands such as \"pick up the steel beam pallet near the crane.\" The perception\npipeline integrates Florence-2 and SAM-2 for language-grounded segmentation\nwith FoundationPose for robust pose estimation in cluttered, multi-pallet\noutdoor scenes under variable lighting. The resulting poses feed into a motion\nplanning module for fully autonomous forklift operation. We validate Lang2Lift\non the ADAPT autonomous forklift platform, achieving 0.76 mIoU pallet\nsegmentation accuracy on a real-world test dataset. Timing and error analysis\ndemonstrate the system's robustness and confirm its feasibility for deployment\nin operational logistics and construction environments. Video demonstrations\nare available at https://eric-nguyen1402.github.io/lang2lift.github.io/", "AI": {"tldr": "Lang2Lift是一个利用基础模型实现自然语言引导的托盘检测和6D姿态估计的框架，用于自动化室外环境中的托盘搬运操作", "motivation": "解决物流和建筑行业在室外环境中自动化托盘搬运的挑战，包括劳动力短缺、安全隐患以及在多变条件下手动定位和检索托盘的效率低下问题", "method": "集成Florence-2和SAM-2进行语言基础分割，使用FoundationPose进行杂乱多托盘室外场景的鲁棒姿态估计，最终通过运动规划模块实现全自主叉车操作", "result": "在真实世界测试数据集上达到0.76 mIoU的托盘分割精度，时间和误差分析证明了系统的鲁棒性和在物流和建筑环境中部署的可行性", "conclusion": "Lang2Lift框架通过自然语言交互和先进的感知技术，成功解决了室外环境中自动化托盘搬运的关键技术挑战，为实际部署提供了可行方案"}}
{"id": "2508.15501", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15501", "abs": "https://arxiv.org/abs/2508.15501", "authors": ["Deyu Zhang", "Xicheng Zhang", "Jiahao Li", "Tingting Long", "Xunhua Dai", "Yongjian Fu", "Jinrui Zhang", "Ju Ren", "Yaoxue Zhang"], "title": "LLM-Driven Self-Refinement for Embodied Drone Task Planning", "comment": "14pages", "summary": "We introduce SRDrone, a novel system designed for self-refinement task\nplanning in industrial-grade embodied drones. SRDrone incorporates two key\ntechnical contributions: First, it employs a continuous state evaluation\nmethodology to robustly and accurately determine task outcomes and provide\nexplanatory feedback. This approach supersedes conventional reliance on\nsingle-frame final-state assessment for continuous, dynamic drone operations.\nSecond, SRDrone implements a hierarchical Behavior Tree (BT) modification\nmodel. This model integrates multi-level BT plan analysis with a constrained\nstrategy space to enable structured reflective learning from experience.\nExperimental results demonstrate that SRDrone achieves a 44.87% improvement in\nSuccess Rate (SR) over baseline methods. Furthermore, real-world deployment\nutilizing an experience base optimized through iterative self-refinement\nattains a 96.25% SR. By embedding adaptive task refinement capabilities within\nan industrial-grade BT planning framework, SRDrone effectively integrates the\ngeneral reasoning intelligence of Large Language Models (LLMs) with the\nstringent physical execution constraints inherent to embodied drones. Code is\navailable at https://github.com/ZXiiiC/SRDrone.", "AI": {"tldr": "SRDrone是一个用于工业级无人机自我精化任务规划的新系统，通过连续状态评估和行为树分层修改，实现了44.87%的成功率提升，最终达到96.25%的实际部署成功率。", "motivation": "解决传统单帧最终状态评估方法在连续动态无人机操作中的局限性，将大型语言模型的通用推理能力与无人机严格物理执行约束相结合。", "method": "采用连续状态评估方法确定任务结果并提供解释性反馈，结合分层行为树修改模型，通过多级BT计划分析和约束策略空间实现结构化反思学习。", "result": "相比基线方法成功率提升44.87%，通过迭代自我精化优化的经验库在实际部署中达到96.25%的成功率。", "conclusion": "SRDrone成功将自适应任务精化能力嵌入工业级BT规划框架，有效整合了LLMs的通用推理智能和无人机的物理执行约束。"}}
{"id": "2508.15663", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15663", "abs": "https://arxiv.org/abs/2508.15663", "authors": ["Nikita Kachaev", "Andrei Spiridonov", "Andrey Gorodetsky", "Kirill Muravyev", "Nikita Oskolkov", "Aditya Narendra", "Vlad Shakhuro", "Dmitry Makarov", "Aleksandr I. Panov", "Polina Fedotova", "Alexey K. Kovalev"], "title": "Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation", "comment": null, "summary": "Benchmarks are crucial for evaluating progress in robotics and embodied AI.\nHowever, a significant gap exists between benchmarks designed for high-level\nlanguage instruction following, which often assume perfect low-level execution,\nand those for low-level robot control, which rely on simple, one-step commands.\nThis disconnect prevents a comprehensive evaluation of integrated systems where\nboth task planning and physical execution are critical. To address this, we\npropose Kitchen-R, a novel benchmark that unifies the evaluation of task\nplanning and low-level control within a simulated kitchen environment. Built as\na digital twin using the Isaac Sim simulator and featuring more than 500\ncomplex language instructions, Kitchen-R supports a mobile manipulator robot.\nWe provide baseline methods for our benchmark, including a task-planning\nstrategy based on a vision-language model and a low-level control policy based\non diffusion policy. We also provide a trajectory collection system. Our\nbenchmark offers a flexible framework for three evaluation modes: independent\nassessment of the planning module, independent assessment of the control\npolicy, and, crucially, an integrated evaluation of the whole system. Kitchen-R\nbridges a key gap in embodied AI research, enabling more holistic and realistic\nbenchmarking of language-guided robotic agents.", "AI": {"tldr": "Kitchen-R是一个新的机器人基准测试，在模拟厨房环境中统一评估任务规划和低级控制，填补了高级语言指令跟随和低级机器人控制之间的评估空白。", "motivation": "现有基准测试存在显著差距：高级语言指令跟随基准假设完美低级执行，而低级控制基准依赖简单单步命令，这阻碍了对任务规划和物理执行都至关重要的集成系统的全面评估。", "method": "基于Isaac Sim模拟器构建数字孪生厨房环境，包含500多个复杂语言指令，支持移动机械臂机器人。提供基于视觉语言模型的任务规划策略和基于扩散策略的低级控制策略基线方法，以及轨迹收集系统。", "result": "Kitchen-R基准提供了一个灵活的评估框架，支持三种评估模式：规划模块独立评估、控制策略独立评估以及关键的系统集成评估。", "conclusion": "Kitchen-R填补了具身AI研究中的关键空白，实现了对语言引导机器人代理更全面和现实的基准测试。"}}
{"id": "2508.15669", "categories": ["cs.RO", "cs.LG", "68T40", "I.2.9"], "pdf": "https://arxiv.org/pdf/2508.15669", "abs": "https://arxiv.org/abs/2508.15669", "authors": ["Annie S. Chen", "Philemon Brakel", "Antonia Bronars", "Annie Xie", "Sandy Huang", "Oliver Groth", "Maria Bauza", "Markus Wulfmeier", "Nicolas Heess", "Dushyant Rao"], "title": "Exploiting Policy Idling for Dexterous Manipulation", "comment": "A similar version to this paper was accepted at IROS 2025", "summary": "Learning-based methods for dexterous manipulation have made notable progress\nin recent years. However, learned policies often still lack reliability and\nexhibit limited robustness to important factors of variation. One failure\npattern that can be observed across many settings is that policies idle, i.e.\nthey cease to move beyond a small region of states when they reach certain\nstates. This policy idling is often a reflection of the training data. For\ninstance, it can occur when the data contains small actions in areas where the\nrobot needs to perform high-precision motions, e.g., when preparing to grasp an\nobject or object insertion. Prior works have tried to mitigate this phenomenon\ne.g. by filtering the training data or modifying the control frequency.\nHowever, these approaches can negatively impact policy performance in other\nways. As an alternative, we investigate how to leverage the detectability of\nidling behavior to inform exploration and policy improvement. Our approach,\nPause-Induced Perturbations (PIP), applies perturbations at detected idling\nstates, thus helping it to escape problematic basins of attraction. On a range\nof challenging simulated dual-arm tasks, we find that this simple approach can\nalready noticeably improve test-time performance, with no additional\nsupervision or training. Furthermore, since the robot tends to idle at critical\npoints in a movement, we also find that learning from the resulting episodes\nleads to better iterative policy improvement compared to prior approaches. Our\nperturbation strategy also leads to a 15-35% improvement in absolute success\nrate on a real-world insertion task that requires complex multi-finger\nmanipulation.", "AI": {"tldr": "提出Pause-Induced Perturbations (PIP)方法，通过在检测到的空闲状态施加扰动来帮助策略逃离问题吸引域，提高灵巧操作的鲁棒性和成功率", "motivation": "学习型灵巧操作策略经常出现空闲现象（停止运动），这反映了训练数据的局限性，特别是在需要高精度运动的区域。现有方法如数据过滤或控制频率调整可能会负面影响策略性能", "method": "PIP方法检测策略空闲状态，并在这些状态下施加扰动，帮助策略逃离问题吸引域。该方法无需额外监督或训练", "result": "在模拟双臂任务中显著改善测试性能，在真实世界插入任务中实现15-35%的绝对成功率提升，特别是在需要复杂多指操作的任务中表现优异", "conclusion": "PIP是一种简单有效的策略改进方法，通过利用空闲状态的可检测性来指导探索和策略改进，在关键运动点施加扰动能够带来更好的迭代策略改进效果"}}
{"id": "2508.15755", "categories": ["cs.RO", "cs.AI", "cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15755", "abs": "https://arxiv.org/abs/2508.15755", "authors": ["Jie Xu", "Eric Heiden", "Iretiayo Akinola", "Dieter Fox", "Miles Macklin", "Yashraj Narang"], "title": "Neural Robot Dynamics", "comment": null, "summary": "Accurate and efficient simulation of modern robots remains challenging due to\ntheir high degrees of freedom and intricate mechanisms. Neural simulators have\nemerged as a promising alternative to traditional analytical simulators,\ncapable of efficiently predicting complex dynamics and adapting to real-world\ndata; however, existing neural simulators typically require\napplication-specific training and fail to generalize to novel tasks and/or\nenvironments, primarily due to inadequate representations of the global state.\nIn this work, we address the problem of learning generalizable neural\nsimulators for robots that are structured as articulated rigid bodies. We\npropose NeRD (Neural Robot Dynamics), learned robot-specific dynamics models\nfor predicting future states for articulated rigid bodies under contact\nconstraints. NeRD uniquely replaces the low-level dynamics and contact solvers\nin an analytical simulator and employs a robot-centric and spatially-invariant\nsimulation state representation. We integrate the learned NeRD models as an\ninterchangeable backend solver within a state-of-the-art robotics simulator. We\nconduct extensive experiments to show that the NeRD simulators are stable and\naccurate over a thousand simulation steps; generalize across tasks and\nenvironment configurations; enable policy learning exclusively in a neural\nengine; and, unlike most classical simulators, can be fine-tuned from\nreal-world data to bridge the gap between simulation and reality.", "AI": {"tldr": "NeRD是一种神经机器人动力学模型，能够替代传统分析模拟器中的底层动力学和接触求解器，实现稳定准确的机器人仿真，并具有良好的泛化能力和从真实数据微调的能力。", "motivation": "现代机器人具有高自由度和复杂机构，传统分析模拟器仿真困难。现有神经模拟器需要针对特定应用训练，且无法泛化到新任务和环境，主要原因是全局状态表示不足。", "method": "提出NeRD模型，采用机器人中心和空间不变的仿真状态表示，替代传统模拟器中的底层动力学和接触求解器，并集成到先进的机器人模拟器中作为可互换的后端求解器。", "result": "实验表明NeRD模拟器在数千个仿真步骤中保持稳定准确；能够跨任务和环境配置泛化；支持在神经引擎中进行策略学习；可以从真实世界数据微调以缩小仿真与现实的差距。", "conclusion": "NeRD为关节刚体机器人提供了一种通用、可泛化的神经模拟器解决方案，克服了现有方法的局限性，在仿真准确性、泛化能力和现实适应性方面表现出色。"}}
