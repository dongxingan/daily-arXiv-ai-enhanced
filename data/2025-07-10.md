<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 21]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Evaluating Robots Like Human Infants: A Case Study of Learned Bipedal Locomotion](https://arxiv.org/abs/2507.06426)
*Devin Crowley,Whitney G. Cole,Christina M. Hospodar,Ruiting Shen,Karen E. Adolph,Alan Fern*

Main category: cs.RO

TL;DR: 论文提出了一种将发展心理学方法应用于机器人行为学习的研究，通过系统设计训练方案并模拟婴儿实验环境，揭示了训练方案对机器人行为的影响。


<details>
  <summary>Details</summary>
Motivation: 传统机器人控制器训练方法缺乏系统性且评估指标粗糙，无法深入理解训练方案对行为的影响。借鉴发展心理学的精细实验方法，可以弥补这一不足。

Method: 采用强化学习设计系统化的训练方案，并在模拟环境中测试机器人Cassie的行为，模拟婴儿行走实验。

Result: 研究揭示了不同训练方案对机器人行为的具体影响，并比较了Cassie与婴儿行走学习的行为发展。

Conclusion: 跨学科的婴儿-机器人研究方法为未来系统化研究复杂机器人行为学习提供了新思路。

Abstract: Typically, learned robot controllers are trained via relatively unsystematic
regimens and evaluated with coarse-grained outcome measures such as average
cumulative reward. The typical approach is useful to compare learning
algorithms but provides limited insight into the effects of different training
regimens and little understanding about the richness and complexity of learned
behaviors. Likewise, human infants and other animals are "trained" via
unsystematic regimens, but in contrast, developmental psychologists evaluate
their performance in highly-controlled experiments with fine-grained measures
such as success, speed of walking, and prospective adjustments. However, the
study of learned behavior in human infants is limited by the practical
constraints of training and testing babies. Here, we present a case study that
applies methods from developmental psychology to study the learned behavior of
the simulated bipedal robot Cassie. Following research on infant walking, we
systematically designed reinforcement learning training regimens and tested the
resulting controllers in simulated environments analogous to those used for
babies--but without the practical constraints. Results reveal new insights into
the behavioral impact of different training regimens and the development of
Cassie's learned behaviors relative to infants who are learning to walk. This
interdisciplinary baby-robot approach provides inspiration for future research
designed to systematically test effects of training on the development of
complex learned robot behaviors.

</details>


### [2] [SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments](https://arxiv.org/abs/2507.06564)
*Tianshun Li,Tianyi Huai,Zhen Li,Yichun Gao,Haoang Li,Xinhu Zheng*

Main category: cs.RO

TL;DR: SkyVLN框架结合视觉语言导航（VLN）和非线性模型预测控制（NMPC），提升无人机在复杂城市环境中的自主性。


<details>
  <summary>Details</summary>
Motivation: 传统导航方法在动态3D环境中表现不足，需要更智能的解决方案。

Method: 利用大型语言模型（LLMs）解析自然语言指令和视觉观察，结合NMPC模块实现动态避障。

Result: 实验表明SkyVLN显著提高了导航成功率和效率。

Conclusion: SkyVLN为无人机在复杂环境中的自主导航提供了有效解决方案。

Abstract: Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across
various sectors, driven by their mobility and adaptability. This paper
introduces SkyVLN, a novel framework integrating vision-and-language navigation
(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in
complex urban environments. Unlike traditional navigation methods, SkyVLN
leverages Large Language Models (LLMs) to interpret natural language
instructions and visual observations, enabling UAVs to navigate through dynamic
3D spaces with improved accuracy and robustness. We present a multimodal
navigation agent equipped with a fine-grained spatial verbalizer and a history
path memory mechanism. These components allow the UAV to disambiguate spatial
contexts, handle ambiguous instructions, and backtrack when necessary. The
framework also incorporates an NMPC module for dynamic obstacle avoidance,
ensuring precise trajectory tracking and collision prevention. To validate our
approach, we developed a high-fidelity 3D urban simulation environment using
AirSim, featuring realistic imagery and dynamic urban elements. Extensive
experiments demonstrate that SkyVLN significantly improves navigation success
rates and efficiency, particularly in new and unseen environments.

</details>


### [3] [Distributed Fault-Tolerant Multi-Robot Cooperative Localization in Adversarial Environments](https://arxiv.org/abs/2507.06750)
*Tohid Kargar Tasooji,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: 提出了一种分布式容错协同定位框架，通过自适应事件触发通信策略提升多机器人系统在对抗环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在GPS缺失或通信受限的环境中，对抗性攻击（如传感器操纵和通信干扰）对传统定位方法构成挑战，需要增强系统的容错能力。

Method: 采用自适应事件触发通信策略，动态调整通信阈值，结合实时感知和通信质量，确保性能最优。

Result: 实验证明，该算法在定位精度和通信效率上显著优于传统方法，尤其在对抗环境中表现突出。

Conclusion: 该方法提升了多机器人系统的可扩展性、可靠性和容错能力，适用于现实世界中的大规模部署。

Abstract: In multi-robot systems (MRS), cooperative localization is a crucial task for
enhancing system robustness and scalability, especially in GPS-denied or
communication-limited environments. However, adversarial attacks, such as
sensor manipulation, and communication jamming, pose significant challenges to
the performance of traditional localization methods. In this paper, we propose
a novel distributed fault-tolerant cooperative localization framework to
enhance resilience against sensor and communication disruptions in adversarial
environments. We introduce an adaptive event-triggered communication strategy
that dynamically adjusts communication thresholds based on real-time sensing
and communication quality. This strategy ensures optimal performance even in
the presence of sensor degradation or communication failure. Furthermore, we
conduct a rigorous analysis of the convergence and stability properties of the
proposed algorithm, demonstrating its resilience against bounded adversarial
zones and maintaining accurate state estimation. Robotarium-based experiment
results show that our proposed algorithm significantly outperforms traditional
methods in terms of localization accuracy and communication efficiency,
particularly in adversarial settings. Our approach offers improved scalability,
reliability, and fault tolerance for MRS, making it suitable for large-scale
deployments in real-world, challenging environments.

</details>


### [4] [Stream Function-Based Navigation for Complex Quadcopter Obstacle Avoidance](https://arxiv.org/abs/2507.06787)
*Sean Smith,Emmanuel Witrant,Ya-Jun Pan*

Main category: cs.RO

TL;DR: 提出了一种基于流函数的导航控制系统，用于避障，结合涡流面板法和模型预测控制，实现复杂环境中的实时导航。


<details>
  <summary>Details</summary>
Motivation: 解决在部分观测环境中避障的挑战，特别是在处理快速加速障碍物时的局限性。

Method: 结合涡流面板法（VPM）和基于高阶控制屏障函数（HOCBF）的模型预测控制器（MPC），利用最小包围椭圆（MBE）和自适应卡尔曼滤波器（AKF）处理障碍物动态。

Result: 在PX4驱动的Clover无人机Gazebo模拟器和实时实验中验证了系统的有效性。

Conclusion: 该系统能够有效处理复杂环境中的避障问题，特别是在动态障碍物场景下表现优异。

Abstract: This article presents a novel stream function-based navigational control
system for obstacle avoidance, where obstacles are represented as
two-dimensional (2D) rigid surfaces in inviscid, incompressible flows. The
approach leverages the vortex panel method (VPM) and incorporates safety
margins to control the stream function and flow properties around virtual
surfaces, enabling navigation in complex, partially observed environments using
real-time sensing. To address the limitations of the VPM in managing relative
distance and avoiding rapidly accelerating obstacles at close proximity, the
system integrates a model predictive controller (MPC) based on higher-order
control barrier functions (HOCBF). This integration incorporates VPM trajectory
generation, state estimation, and constraint handling into a receding-horizon
optimization problem. The 2D rigid surfaces are enclosed using minimum bounding
ellipses (MBEs), while an adaptive Kalman filter (AKF) captures and predicts
obstacle dynamics, propagating these estimates into the MPC-HOCBF for rapid
avoidance maneuvers. Evaluation is conducted using a PX4-powered Clover drone
Gazebo simulator and real-time experiments involving a COEX Clover quadcopter
equipped with a 360 degree LiDAR sensor.

</details>


### [5] [Solving the Constrained Random Disambiguation Path Problem via Lagrangian Relaxation and Graph Reduction](https://arxiv.org/abs/2507.06346)
*Li Zhou,Elvan Ceyhan*

Main category: cs.RO

TL;DR: 研究了资源受限的随机消歧路径（RDP）问题，提出了一种结合拉格朗日松弛和两阶段顶点消除（TPVE）的新算法框架COLOGR，解决了带权约束的最短路径问题（WCSPP），并在实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决在不确定障碍物环境中导航的资源受限路径规划问题，优化消歧成本与路径风险。

Method: 将问题建模为WCSPP，提出COLOGR框架，结合拉格朗日松弛和TPVE，修剪不可行和次优路径。

Result: COLOGR在实验中表现优于贪心基线，接近离线最优基准，且计算复杂度优于现有方法。

Conclusion: COLOGR框架适用于随机网络设计、移动规划和不确定性下的约束决策，具有广泛的应用潜力。

Abstract: We study a resource-constrained variant of the Random Disambiguation Path
(RDP) problem, a generalization of the Stochastic Obstacle Scene (SOS) problem,
in which a navigating agent must reach a target in a spatial environment
populated with uncertain obstacles. Each ambiguous obstacle may be
disambiguated at a (possibly) heterogeneous resource cost, subject to a global
disambiguation budget. We formulate this constrained planning problem as a
Weight-Constrained Shortest Path Problem (WCSPP) with risk-adjusted edge costs
that incorporate probabilistic blockage and traversal penalties. To solve it,
we propose a novel algorithmic framework-COLOGR-combining Lagrangian relaxation
with a two-phase vertex elimination (TPVE) procedure. The method prunes
infeasible and suboptimal paths while provably preserving the optimal solution,
and leverages dual bounds to guide efficient search. We establish correctness,
feasibility guarantees, and surrogate optimality under mild assumptions. Our
analysis also demonstrates that COLOGR frequently achieves zero duality gap and
offers improved computational complexity over prior constrained path-planning
methods. Extensive simulation experiments validate the algorithm's robustness
across varying obstacle densities, sensor accuracies, and risk models,
consistently outperforming greedy baselines and approaching offline-optimal
benchmarks. The proposed framework is broadly applicable to stochastic network
design, mobility planning, and constrained decision-making under uncertainty.

</details>


### [6] [Mapping the Catacombs: An Underwater Cave Segment of the Devil's Eye System](https://arxiv.org/abs/2507.06397)
*Michalis Chatzispyrou,Luke Horgan,Hyunkil Hwang,Harish Sathishchandra,Monika Roznere,Alberto Quattrini Li,Philippos Mordohai,Ioannis Rekleitis*

Main category: cs.RO

TL;DR: 本文提出了一种低成本的水下洞穴测绘框架，结合动作相机和潜水电脑生成稀疏点云和3D地图，并通过全局优化实现局部区域的密集重建。


<details>
  <summary>Details</summary>
Motivation: 水下洞穴对淡水资源管理、水下考古和水文地质学至关重要，但传统测绘方法成本高且复杂。本文旨在开发一种低成本、高效的测绘方法。

Method: 使用动作相机和潜水电脑估计相机轨迹和稀疏点云，结合SVIn2框架优化姿态，并通过COLMAP进行全局优化生成密集重建。

Result: 成功生成了洞穴的一维轨迹和边界，并通过手动测量验证了方法的准确性。动作相机结合全局优化可实现局部区域的3D密集重建。

Conclusion: 低成本的动作相机和潜水电脑结合优化框架，能够有效测绘水下洞穴，为洞穴研究提供了实用工具。

Abstract: This paper presents a framework for mapping underwater caves. Underwater
caves are crucial for fresh water resource management, underwater archaeology,
and hydrogeology. Mapping the cave's outline and dimensions, as well as
creating photorealistic 3D maps, is critical for enabling a better
understanding of this underwater domain. In this paper, we present the mapping
of an underwater cave segment (the catacombs) of the Devil's Eye cave system at
Ginnie Springs, FL. We utilized a set of inexpensive action cameras in
conjunction with a dive computer to estimate the trajectories of the cameras
together with a sparse point cloud. The resulting reconstructions are utilized
to produce a one-dimensional retract of the cave passages in the form of the
average trajectory together with the boundaries (top, bottom, left, and right).
The use of the dive computer enables the observability of the z-dimension in
addition to the roll and pitch in a visual/inertial framework (SVIn2). In
addition, the keyframes generated by SVIn2 together with the estimated camera
poses for select areas are used as input to a global optimization (bundle
adjustment) framework -- COLMAP -- in order to produce a dense reconstruction
of those areas. The same cave segment is manually surveyed using the MNemo V2
instrument, providing an additional set of measurements validating the proposed
approach. It is worth noting that with the use of action cameras, the primary
components of a cave map can be constructed. Furthermore, with the utilization
of a global optimization framework guided by the results of VI-SLAM package
SVIn2, photorealistic dense 3D representations of selected areas can be
reconstructed.

</details>


### [7] [Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction](https://arxiv.org/abs/2507.06404)
*Matteo Tiezzi,Tommaso Apicella,Carlos Cardenas-Perez,Giovanni Fregonese,Stefano Dafarra,Pietro Morerio,Daniele Pucci,Alessio Del Bue*

Main category: cs.RO

TL;DR: 提出了一种基于轨迹性能的通用评估框架NeME，用于比较人形机器人模仿学习方法的性能，无需人工参与。


<details>
  <summary>Details</summary>
Motivation: 评估人形机器人性能的挑战在于成功率指标难以复现且无法捕捉复杂运动轨迹，这在人机交互中至关重要。

Method: 设计了Neural Meta Evaluator (NeME)，一种深度学习模型，通过分类机器人关节轨迹来评估控制策略。

Result: 实验验证表明，该方法比基线更符合机器人实际成功率，提供了可复现且系统的评估手段。

Conclusion: NeME为复杂人机交互任务中的多模态模仿学习方法提供了有效的性能比较工具。

Abstract: Evaluating and comparing the performance of autonomous Humanoid Robots is
challenging, as success rate metrics are difficult to reproduce and fail to
capture the complexity of robot movement trajectories, critical in Human-Robot
Interaction and Collaboration (HRIC). To address these challenges, we propose a
general evaluation framework that measures the quality of Imitation Learning
(IL) methods by focusing on trajectory performance. We devise the Neural Meta
Evaluator (NeME), a deep learning model trained to classify actions from robot
joint trajectories. NeME serves as a meta-evaluator to compare the performance
of robot control policies, enabling policy evaluation without requiring human
involvement in the loop. We validate our framework on ergoCub, a humanoid
robot, using teleoperation data and comparing IL methods tailored to the
available platform. The experimental results indicate that our method is more
aligned with the success rate obtained on the robot than baselines, offering a
reproducible, systematic, and insightful means for comparing the performance of
multimodal imitation learning approaches in complex HRI tasks.

</details>


### [8] [Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies](https://arxiv.org/abs/2507.06519)
*Yuhan Liu,Xinyu Zhang,Haonan Chang,Abdeslam Boularias*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习和故障预测的sim-to-real框架，用于解决机器人高精度重复插入任务（RIT）的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决机器人执行高精度重复插入任务（如拧螺母）时面临的毫米级精度和长时间一致性问题。

Method: 结合强化学习的插入策略和故障预测模块，将工具姿态表示为螺母坐标系而非机器人坐标系，提升sim-to-real迁移能力。

Result: 在仿真和真实环境中均实现高一次性成功率，并能长期保持稳定性能。

Conclusion: 该方法有效解决了RIT任务中的精度和鲁棒性问题，具有实际应用潜力。

Abstract: This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where
a robot must repeatedly perform high-precision insertions, such as screwing a
nut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving
millimeter-level accuracy and maintaining consistent performance over multiple
repetitions, particularly when factors like nut rotation and friction introduce
additional complexity. We propose a sim-to-real framework that integrates a
reinforcement learning-based insertion policy with a failure forecasting
module. By representing the wrench's pose in the nut's coordinate frame rather
than the robot's frame, our approach significantly enhances sim-to-real
transferability. The insertion policy, trained in simulation, leverages
real-time 6D pose tracking to execute precise alignment, insertion, and
rotation maneuvers. Simultaneously, a neural network predicts potential
execution failures, triggering a simple recovery mechanism that lifts the
wrench and retries the insertion. Extensive experiments in both simulated and
real-world environments demonstrate that our method not only achieves a high
one-time success rate but also robustly maintains performance over long-horizon
repetitive tasks.

</details>


### [9] [KLEIYN : A Quadruped Robot with an Active Waist for Both Locomotion and Wall Climbing](https://arxiv.org/abs/2507.06562)
*Keita Yoneda,Kento Kawaharazuka,Temma Suzuki,Takahiro Hattori,Kei Okada*

Main category: cs.RO

TL;DR: 开发了具有腰部关节的四足机器人KLEIYN，通过强化学习实现垂直运动（如爬烟囱），并引入接触引导课程学习（CGCL）方法，显著提升了机器人在狭窄墙面的攀爬性能。


<details>
  <summary>Details</summary>
Motivation: 尽管硬件和强化学习控制使四足机器人具备高速运动能力，但在高度变化大的崎岖地形中稳定垂直运动的机器人及其控制方法尚未成熟。

Method: 开发了带腰部关节的机器人KLEIYN，采用强化学习和CGCL方法学习垂直运动。

Result: KLEIYN能以150 mm/s的速度攀爬800-1000 mm宽的墙面，速度是传统机器人的50倍，且腰部关节显著提升了在狭窄墙面的跟踪能力。

Conclusion: 通过腰部关节和CGCL方法，KLEIYN实现了高效的垂直运动，为四足机器人在复杂地形中的应用提供了新思路。

Abstract: In recent years, advancements in hardware have enabled quadruped robots to
operate with high power and speed, while robust locomotion control using
reinforcement learning (RL) has also been realized. As a result, expectations
are rising for the automation of tasks such as material transport and
exploration in unknown environments. However, autonomous locomotion in rough
terrains with significant height variations requires vertical movement, and
robots capable of performing such movements stably, along with their control
methods, have not yet been fully established. In this study, we developed the
quadruped robot KLEIYN, which features a waist joint, and aimed to expand
quadruped locomotion by enabling chimney climbing through RL. To facilitate the
learning of vertical motion, we introduced Contact-Guided Curriculum Learning
(CGCL). As a result, KLEIYN successfully climbed walls ranging from 800 mm to
1000 mm in width at an average speed of 150 mm/s, 50 times faster than
conventional robots. Furthermore, we demonstrated that the introduction of a
waist joint improves climbing performance, particularly enhancing tracking
ability on narrow walls.

</details>


### [10] [AI Space Cortex: An Experimental System for Future Era Space Exploration](https://arxiv.org/abs/2507.06574)
*Thomas Touma,Ersin Daş,Erica Tevere,Martin Feather,Ksenia Kolcio,Maurice Prather,Alberto Candela,Ashish Goel,Erik Kramer,Hari Nayar,Lorraine Fesq,Joel W. Burdick*

Main category: cs.RO

TL;DR: REASIMO项目旨在为NASA的COLDTech计划开发AI辅助的自主系统，以应对海洋世界任务中的通信延迟、能源限制和辐射等挑战，实现异常检测与恢复，并通过预训练行为执行任务。


<details>
  <summary>Details</summary>
Motivation: 海洋世界任务（如欧罗巴和恩塞拉多斯）面临通信延迟、能源限制和恶劣环境等挑战，传统安全模式无法满足任务需求，需要更高级的自主性。

Method: 结合AI技术和预训练行为，开发了一个智能框架，用于任务控制和异常恢复，并在NASA喷气推进实验室的测试平台上验证自主采样操作。

Result: 测试验证了框架在模拟海洋世界表面条件下的自主操作能力，展示了其异常处理和任务执行的潜力。

Conclusion: REASIMO框架为未来海洋世界任务提供了更高效、自主的解决方案，有望提升任务成功率和科学目标达成。

Abstract: Our Robust, Explainable Autonomy for Scientific Icy Moon Operations (REASIMO)
effort contributes to NASA's Concepts for Ocean worlds Life Detection
Technology (COLDTech) program, which explores science platform technologies for
ocean worlds such as Europa and Enceladus. Ocean world missions pose
significant operational challenges. These include long communication lags,
limited power, and lifetime limitations caused by radiation damage and hostile
conditions. Given these operational limitations, onboard autonomy will be vital
for future Ocean world missions. Besides the management of nominal lander
operations, onboard autonomy must react appropriately in the event of
anomalies. Traditional spacecraft rely on a transition into 'safe-mode' in
which non-essential components and subsystems are powered off to preserve
safety and maintain communication with Earth. For a severely time-limited Ocean
world mission, resolutions to these anomalies that can be executed without
Earth-in-the-loop communication and associated delays are paramount for
completion of the mission objectives and science goals. To address these
challenges, the REASIMO effort aims to demonstrate a robust level of
AI-assisted autonomy for such missions, including the ability to detect and
recover from anomalies, and to perform missions based on pre-trained behaviors
rather than hard-coded, predetermined logic like all prior space missions. We
developed an AI-assisted, personality-driven, intelligent framework for control
of an Ocean world mission by combining a mix of advanced technologies. To
demonstrate the capabilities of the framework, we perform tests of autonomous
sampling operations on a lander-manipulator testbed at the NASA Jet Propulsion
Laboratory, approximating possible surface conditions such a mission might
encounter.

</details>


### [11] [Growing Trees with an Agent: Accelerating RRTs with Learned, Multi-Step Episodic Exploration](https://arxiv.org/abs/2507.06605)
*Xinyu Wu*

Main category: cs.RO

TL;DR: 论文提出了一种名为Episodic RRT（ERRT）的新型混合规划框架，通过深度强化学习（DRL）生成多步探索片段，显著提升了经典RRT在复杂或高维空间中的效率。


<details>
  <summary>Details</summary>
Motivation: 经典RRT依赖随机采样，导致在高维或复杂环境中效率低下，需要一种更高效的探索方法。

Method: ERRT用DRL生成的多步探索片段替代随机点，将搜索过程从随机扩展转变为定向分支生长。

Result: 在2D、3D和6D环境中，ERRT及其变体显著优于经典RRT，6D机械臂场景中成功率从19%提升至98%，速度提升107倍，碰撞检测减少99.6%。

Conclusion: ERRT通过DRL驱动的定向探索，显著提升了运动规划的效率和质量，其变体ERRT*在优化性能上表现更优。

Abstract: Classical sampling-based motion planners like the RRTs suffer from
inefficiencies, particularly in cluttered or high-dimensional spaces, due to
their reliance on undirected, random sampling. This paper introduces the
Episodic RRT, a novel hybrid planning framework that replaces the primitive of
a random point with a learned, multi-step "exploratory episode" generated by a
Deep Reinforcement Learning agent. By making the DRL agent the engine of
exploration, ERRT transforms the search process from a diffuse, volumetric
expansion into a directed, branch-like growth. This paradigm shift yields key
advantages: it counters the curse of dimensionality with focused exploration,
minimizes expensive collision checks by proactively proposing locally valid
paths, and improves connectivity by generating inherently connected path
segments. We demonstrate through extensive empirical evaluation across 2D, 3D,
and 6D environments that ERRT and its variants consistently and significantly
outperform their classical counterparts. In a challenging 6D robotic arm
scenario, ERRT achieves a 98% success rate compared to 19% for RRT, is up to
107x faster, reduces collision checks by over 99.6%, and finds initial paths
that are nearly 50% shorter. Furthermore, its asymptotically optimal variant,
ERRT*, demonstrates vastly superior anytime performance, refining solutions to
near-optimality up to 29x faster than standard RRT* in 3D environments. Code:
https://xinyuwuu.github.io/Episodic_RRT/.

</details>


### [12] [Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic](https://arxiv.org/abs/2507.06625)
*Shizhe Cai,Jayadeep Jacob,Zeya Yin,Fabio Ramos*

Main category: cs.RO

TL;DR: Q-STAC框架结合贝叶斯MPC与演员-评论家强化学习，通过约束Stein变分梯度下降优化控制序列，提升样本效率与安全性。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习在连续控制任务中数据需求高、长时规划难、安全性不足的问题，同时弥补MPC局部最优和成本函数设计的局限性。

Method: 整合贝叶斯MPC与演员-评论家强化学习，利用约束SVGD优化控制序列，以Q值替代显式成本函数设计。

Result: 在2D导航和机器人操作任务中，Q-STAC在样本效率、鲁棒性和最优性上优于现有算法，同时保持策略分布的高表达能力。

Conclusion: Q-STAC成功结合了强化学习与MPC的优势，为复杂控制任务提供了高效、安全且可解释的解决方案。

Abstract: Deep reinforcement learning has shown remarkable success in continuous
control tasks, yet often requires extensive training data, struggles with
complex, long-horizon planning, and fails to maintain safety constraints during
operation. Meanwhile, Model Predictive Control (MPC) offers explainability and
constraint satisfaction, but typically yields only locally optimal solutions
and demands careful cost function design. This paper introduces the Q-guided
STein variational model predictive Actor-Critic (Q-STAC), a novel framework
that bridges these approaches by integrating Bayesian MPC with actor-critic
reinforcement learning through constrained Stein Variational Gradient Descent
(SVGD). Our method optimizes control sequences directly using learned Q-values
as objectives, eliminating the need for explicit cost function design while
leveraging known system dynamics to enhance sample efficiency and ensure
control signals remain within safe boundaries. Extensive experiments on 2D
navigation and robotic manipulation tasks demonstrate that Q-STAC achieves
superior sample efficiency, robustness, and optimality compared to
state-of-the-art algorithms, while maintaining the high expressiveness of
policy distributions. Experiment videos are available on our website:
https://sites.google.com/view/q-stac

</details>


### [13] [Multi-Task Multi-Agent Reinforcement Learning via Skill Graphs](https://arxiv.org/abs/2507.06690)
*Guobin Zhu,Rui Zhou,Wenkang Ji,Hongyin Zhang,Donglin Wang,Shiyu Zhao*

Main category: cs.RO

TL;DR: 提出了一种分层方法，通过技能图和高层模块解决多任务多智能体强化学习中的无关任务和知识转移问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理无关任务且知识转移能力有限，需要更高效的方法。

Method: 采用分层方法，高层模块使用技能图，低层模块采用标准MARL算法。

Result: 实验表明该方法优于最新的分层MAPPO算法。

Conclusion: 该方法扩展了MTRL的范围，有效处理无关任务并提升知识转移能力。

Abstract: Multi-task multi-agent reinforcement learning (MT-MARL) has recently gained
attention for its potential to enhance MARL's adaptability across multiple
tasks. However, it is challenging for existing multi-task learning methods to
handle complex problems, as they are unable to handle unrelated tasks and
possess limited knowledge transfer capabilities. In this paper, we propose a
hierarchical approach that efficiently addresses these challenges. The
high-level module utilizes a skill graph, while the low-level module employs a
standard MARL algorithm. Our approach offers two contributions. First, we
consider the MT-MARL problem in the context of unrelated tasks, expanding the
scope of MTRL. Second, the skill graph is used as the upper layer of the
standard hierarchical approach, with training independent of the lower layer,
effectively handling unrelated tasks and enhancing knowledge transfer
capabilities. Extensive experiments are conducted to validate these advantages
and demonstrate that the proposed method outperforms the latest hierarchical
MAPPO algorithms. Videos and code are available at
https://github.com/WindyLab/MT-MARL-SG

</details>


### [14] [Integrating Perceptions: A Human-Centered Physical Safety Model for Human-Robot Interaction](https://arxiv.org/abs/2507.06700)
*Pranav Pandey,Ramviyas Parasuraman,Prashant Doshi*

Main category: cs.RO

TL;DR: 本文提出了一种参数化通用安全模型，通过个性化参数ρ整合物理安全和感知安全，研究情感状态、信任和机器人行为对感知安全的影响。


<details>
  <summary>Details</summary>
Motivation: 传统安全模型仅依赖传感器数据，无法捕捉主观安全感知，因此需要结合个体差异和情境因素。

Method: 通过模拟救援场景的人体实验，研究情感、信任和机器人行为对安全感知的影响，并引入参数ρ量化个体差异。

Result: ρ能有效捕捉个体差异，机器人行为的可预测性和一致性以及积极情感状态显著提升感知安全。参与者角色和重复暴露也影响安全感知。

Conclusion: 研究强调了整合心理和行为维度的自适应、以人为本的安全模型的重要性，为安全关键领域的人机交互提供了更可信的路径。

Abstract: Ensuring safety in human-robot interaction (HRI) is essential to foster user
trust and enable the broader adoption of robotic systems. Traditional safety
models primarily rely on sensor-based measures, such as relative distance and
velocity, to assess physical safety. However, these models often fail to
capture subjective safety perceptions, which are shaped by individual traits
and contextual factors. In this paper, we introduce and analyze a parameterized
general safety model that bridges the gap between physical and perceived safety
by incorporating a personalization parameter, $\rho$, into the safety
measurement framework to account for individual differences in safety
perception. Through a series of hypothesis-driven human-subject studies in a
simulated rescue scenario, we investigate how emotional state, trust, and robot
behavior influence perceived safety. Our results show that $\rho$ effectively
captures meaningful individual differences, driven by affective responses,
trust in task consistency, and clustering into distinct user types.
Specifically, our findings confirm that predictable and consistent robot
behavior as well as the elicitation of positive emotional states, significantly
enhance perceived safety. Moreover, responses cluster into a small number of
user types, supporting adaptive personalization based on shared safety models.
Notably, participant role significantly shapes safety perception, and repeated
exposure reduces perceived safety for participants in the casualty role,
emphasizing the impact of physical interaction and experiential change. These
findings highlight the importance of adaptive, human-centered safety models
that integrate both psychological and behavioral dimensions, offering a pathway
toward more trustworthy and effective HRI in safety-critical domains.

</details>


### [15] [Spatial-Temporal Aware Visuomotor Diffusion Policy Learning](https://arxiv.org/abs/2507.06710)
*Zhenyang Liu,Yikai Wang,Kuanning Wang,Longfei Liang,Xiangyang Xue,Yanwei Fu*

Main category: cs.RO

TL;DR: 提出了一种名为4D Diffusion Policy (DP4)的新方法，通过动态高斯世界模型增强3D空间和4D时空感知，显著提升了视觉模仿学习的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模仿学习方法依赖历史轨迹的行为克隆，缺乏3D空间和4D时空感知能力，限制了实际应用效果。

Method: DP4利用动态高斯世界模型从交互环境中学习3D空间和4D时空感知，通过单视角RGB-D观测构建当前3D场景并预测未来3D场景，优化轨迹生成。

Result: 在17个仿真任务和3个真实机器人任务中，DP4平均成功率分别提升16.4%、14%、6.45%和8.6%，显著优于基线方法。

Conclusion: DP4通过引入时空感知能力，显著提升了视觉模仿学习的性能，适用于复杂现实场景。

Abstract: Visual imitation learning is effective for robots to learn versatile tasks.
However, many existing methods rely on behavior cloning with supervised
historical trajectories, limiting their 3D spatial and 4D spatiotemporal
awareness. Consequently, these methods struggle to capture the 3D structures
and 4D spatiotemporal relationships necessary for real-world deployment. In
this work, we propose 4D Diffusion Policy (DP4), a novel visual imitation
learning method that incorporates spatiotemporal awareness into diffusion-based
policies. Unlike traditional approaches that rely on trajectory cloning, DP4
leverages a dynamic Gaussian world model to guide the learning of 3D spatial
and 4D spatiotemporal perceptions from interactive environments. Our method
constructs the current 3D scene from a single-view RGB-D observation and
predicts the future 3D scene, optimizing trajectory generation by explicitly
modeling both spatial and temporal dependencies. Extensive experiments across
17 simulation tasks with 173 variants and 3 real-world robotic tasks
demonstrate that the 4D Diffusion Policy (DP4) outperforms baseline methods,
improving the average simulation task success rate by 16.4% (Adroit), 14%
(DexArt), and 6.45% (RLBench), and the average real-world robotic task success
rate by 8.6%.

</details>


### [16] [LOVON: Legged Open-Vocabulary Object Navigator](https://arxiv.org/abs/2507.06747)
*Daojie Peng,Jiahang Cao,Qiang Zhang,Jun Ma*

Main category: cs.RO

TL;DR: LOVON是一个结合大型语言模型（LLMs）和开放词汇视觉检测模型的新框架，用于动态非结构化环境中的长距离物体导航。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在复杂长距离导航任务中难以有效整合开放世界物体检测和高级任务规划的挑战。

Method: 集成LLMs进行分层任务规划，结合开放词汇视觉检测模型，并设计视觉稳定化（如拉普拉斯方差滤波）和功能执行逻辑。

Result: 实验表明LOVON能成功完成涉及实时检测、搜索和导航的长序列任务，并在不同机器人上展示兼容性。

Conclusion: LOVON为动态环境中的长距离物体导航提供了高效、兼容且鲁棒的解决方案。

Abstract: Object navigation in open-world environments remains a formidable and
pervasive challenge for robotic systems, particularly when it comes to
executing long-horizon tasks that require both open-world object detection and
high-level task planning. Traditional methods often struggle to integrate these
components effectively, and this limits their capability to deal with complex,
long-range navigation missions. In this paper, we propose LOVON, a novel
framework that integrates large language models (LLMs) for hierarchical task
planning with open-vocabulary visual detection models, tailored for effective
long-range object navigation in dynamic, unstructured environments. To tackle
real-world challenges including visual jittering, blind zones, and temporary
target loss, we design dedicated solutions such as Laplacian Variance Filtering
for visual stabilization. We also develop a functional execution logic for the
robot that guarantees LOVON's capabilities in autonomous navigation, task
adaptation, and robust task completion. Extensive evaluations demonstrate the
successful completion of long-sequence tasks involving real-time detection,
search, and navigation toward open-vocabulary dynamic targets. Furthermore,
real-world experiments across different legged robots (Unitree Go2, B2, and
H1-2) showcase the compatibility and appealing plug-and-play feature of LOVON.

</details>


### [17] [Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand](https://arxiv.org/abs/2507.06822)
*Wei Xu,Yanchao Zhao,Weichao Guo,Xinjun Sheng*

Main category: cs.RO

TL;DR: 提出了一种分层目标条件强化学习框架，用于提升仿人机器人手对铰接工具的操控能力，实验成功率达70.8%。


<details>
  <summary>Details</summary>
Motivation: 铰接工具的动态形状变化为机器人操控带来独特挑战，现有研究较少涉及。

Method: 采用分层策略：低层策略控制工具配置，高层策略定义目标状态并生成回放缓冲区。

Result: 机器人能有效操控类似镊子的工具抓取不同形状和大小的物体，成功率为70.8%。

Conclusion: 强化学习在铰接工具操控方面具有潜力。

Abstract: Manipulating articulated tools, such as tweezers or scissors, has rarely been
explored in previous research. Unlike rigid tools, articulated tools change
their shape dynamically, creating unique challenges for dexterous robotic
hands. In this work, we present a hierarchical, goal-conditioned reinforcement
learning (GCRL) framework to improve the manipulation capabilities of
anthropomorphic robotic hands using articulated tools. Our framework comprises
two policy layers: (1) a low-level policy that enables the dexterous hand to
manipulate the tool into various configurations for objects of different sizes,
and (2) a high-level policy that defines the tool's goal state and controls the
robotic arm for object-picking tasks. We employ an encoder, trained on
synthetic pointclouds, to estimate the tool's affordance states--specifically,
how different tool configurations (e.g., tweezer opening angles) enable
grasping of objects of varying sizes--from input point clouds, thereby enabling
precise tool manipulation. We also utilize a privilege-informed heuristic
policy to generate replay buffer, improving the training efficiency of the
high-level policy. We validate our approach through real-world experiments,
showing that the robot can effectively manipulate a tweezer-like tool to grasp
objects of diverse shapes and sizes with a 70.8 % success rate. This study
highlights the potential of RL to advance dexterous robotic manipulation of
articulated tools.

</details>


### [18] [Friction Estimation for In-Hand Planar Motion](https://arxiv.org/abs/2507.06824)
*Gabriel Arslan Waltersson,Yiannis Karayiannidis*

Main category: cs.RO

TL;DR: 提出了一种在线估计平行夹持器滑动操作中接触特性的方法，包括静摩擦、库仑摩擦和接触半径，并通过仿真和实验验证。


<details>
  <summary>Details</summary>
Motivation: 研究目的是为了在滑动操作中实时估计接触特性，以提升夹持器的操作精度和适应性。

Method: 通过触觉测量接触力和滑动速度，估计静态摩擦、库仑摩擦及接触半径，并提出启发式方法处理快速滑移-粘附动态。

Result: 方法在仿真和实际实验中均得到验证，能够有效估计接触特性。

Conclusion: 该方法为滑动操作中的接触特性估计提供了实用解决方案，并解决了快速滑移-粘附动态的干扰问题。

Abstract: This paper presents a method for online estimation of contact properties
during in-hand sliding manipulation with a parallel gripper. We estimate the
static and Coulomb friction as well as the contact radius from tactile
measurements of contact forces and sliding velocities. The method is validated
in both simulation and real-world experiments. Furthermore, we propose a
heuristic to deal with fast slip-stick dynamics which can adversely affect the
estimation.

</details>


### [19] [Toward a Full-Stack Co-Simulation Platform for Testing of Automated Driving Systems](https://arxiv.org/abs/2507.06884)
*Dong Bi,Yongqi Zhao,Zhengguo Gu,Tomislav Mihalj,Jia Hu,Arno Eichberger*

Main category: cs.RO

TL;DR: 提出了一种全栈工具链，用于从真实数据自动生成场景并通过CarMaker、ROS和Apollo的协同仿真平台高效验证自动驾驶系统。


<details>
  <summary>Details</summary>
Motivation: 现有仿真工具链难以整合快速自动场景生成与支持高级自动驾驶能力的仿真环境。

Method: 开发了基于CarMaker、ROS和Apollo的协同仿真平台，支持从真实数据自动生成场景。

Result: 仿真结果验证了该工具链的有效性。

Conclusion: 该工具链解决了现有仿真工具链的局限性，加速了自动驾驶系统的部署。

Abstract: Virtual testing has emerged as an effective approach to accelerate the
deployment of automated driving systems. Nevertheless, existing simulation
toolchains encounter difficulties in integrating rapid, automated scenario
generation with simulation environments supporting advanced automated driving
capabilities. To address this limitation, a full-stack toolchain is presented,
enabling automatic scenario generation from real-world datasets and efficient
validation through a co-simulation platform based on CarMaker, ROS, and Apollo.
The simulation results demonstrate the effectiveness of the proposed toolchain.
A demonstration video showcasing the toolchain is available at the provided
link: https://youtu.be/taJw_-CmSiY.

</details>


### [20] [ULC: A Unified and Fine-Grained Controller for Humanoid Loco-Manipulation](https://arxiv.org/abs/2507.06905)
*Wandong Sun,Luying Feng,Baoshi Cao,Yang Liu,Yaochu Jin,Zongwu Xie*

Main category: cs.RO

TL;DR: 论文提出了一种统一的人形机器人运动与操作控制策略（ULC），通过单一策略实现全身协调控制，优于传统分层方法。


<details>
  <summary>Details</summary>
Motivation: 现有分层控制方法限制了人形机器人上下肢的协调性，无法实现类似人类的全身统一控制。

Method: 采用单一策略框架（ULC），结合序列技能学习、残差动作建模、命令多项式插值等技术，实现端到端的全身控制。

Result: 在Unitree G1机器人上验证，ULC在跟踪精度、工作空间覆盖和抗干扰能力上优于传统方法。

Conclusion: 统一控制策略可行且高效，为复杂运动与操作任务提供了新思路。

Abstract: Loco-Manipulation for humanoid robots aims to enable robots to integrate
mobility with upper-body tracking capabilities. Most existing approaches adopt
hierarchical architectures that decompose control into isolated upper-body
(manipulation) and lower-body (locomotion) policies. While this decomposition
reduces training complexity, it inherently limits coordination between
subsystems and contradicts the unified whole-body control exhibited by humans.
We demonstrate that a single unified policy can achieve a combination of
tracking accuracy, large workspace, and robustness for humanoid
loco-manipulation. We propose the Unified Loco-Manipulation Controller (ULC), a
single-policy framework that simultaneously tracks root velocity, root height,
torso rotation, and dual-arm joint positions in an end-to-end manner, proving
the feasibility of unified control without sacrificing performance. We achieve
this unified control through key technologies: sequence skill acquisition for
progressive learning complexity, residual action modeling for fine-grained
control adjustments, command polynomial interpolation for smooth motion
transitions, random delay release for robustness to deploy variations, load
randomization for generalization to external disturbances, and
center-of-gravity tracking for providing explicit policy gradients to maintain
stability. We validate our method on the Unitree G1 humanoid robot with 3-DOF
(degrees-of-freedom) waist. Compared with strong baselines, ULC shows better
tracking performance to disentangled methods and demonstrating larger workspace
coverage. The unified dual-arm tracking enables precise manipulation under
external loads while maintaining coordinated whole-body control for complex
loco-manipulation tasks.

</details>


### [21] [Bounomodes: the grazing ox algorithm for exploration of clustered anomalies](https://arxiv.org/abs/2507.06960)
*Samuel Matloob,Ayan Dutta,O. Patrick Kreidl,Swapnonel Roy,Ladislau Bölöni*

Main category: cs.RO

TL;DR: 论文提出了一种名为“bounom=odes”的算法，结合均匀采样和异常区域针对性探索，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统IPP算法采用均匀覆盖模式，但在异常集群场景下效果不佳，需优先探索异常区域。

Method: 结合均匀的boustrophedon采样和基于深度强化学习的异常集群针对性探索。

Result: 实验表明，该方法优于多种基线算法。

Conclusion: bounom=odes算法在异常集群场景下表现更优，具有实际应用潜力。

Abstract: A common class of algorithms for informative path planning (IPP) follows
boustrophedon ("as the ox turns") patterns, which aim to achieve uniform area
coverage. However, IPP is often applied in scenarios where anomalies, such as
plant diseases, pollution, or hurricane damage, appear in clusters. In such
cases, prioritizing the exploration of anomalous regions over uniform coverage
is beneficial. This work introduces a class of algorithms referred to as
bounom\=odes ("as the ox grazes"), which alternates between uniform
boustrophedon sampling and targeted exploration of detected anomaly clusters.
While uniform sampling can be designed using geometric principles, close
exploration of clusters depends on the spatial distribution of anomalies and
must be learned. In our implementation, the close exploration behavior is
learned using deep reinforcement learning algorithms. Experimental evaluations
demonstrate that the proposed approach outperforms several established
baselines.

</details>
