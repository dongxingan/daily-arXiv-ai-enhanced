<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 28]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Evolutionary Gait Reconfiguration in Damaged Legged Robots](https://arxiv.org/abs/2506.19968)
*Sahand Farghdani,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出一种无需训练的快速损伤恢复算法，用于多足机器人部分或完全失去功能腿时的运动恢复。


<details>
  <summary>Details</summary>
Motivation: 多足机器人在复杂任务中容易腿部受损，影响任务完成和任务成功率。

Method: 首先生成新的步态序列稳定运动，随后通过差分进化算法优化步态配置，最大化前进并减少旋转和侧移。

Result: 算法在24自由度六足机器人上1小时内成功恢复运动，高效且鲁棒。

Conclusion: 该方法能快速恢复受损机器人的运动能力，适用于复杂任务。

Abstract: Multi-legged robots deployed in complex missions are susceptible to physical
damage in their legs, impairing task performance and potentially compromising
mission success. This letter presents a rapid, training-free damage recovery
algorithm for legged robots subject to partial or complete loss of functional
legs. The proposed method first stabilizes locomotion by generating a new gait
sequence and subsequently optimally reconfigures leg gaits via a developed
differential evolution algorithm to maximize forward progression while
minimizing body rotation and lateral drift. The algorithm successfully restores
locomotion in a 24-degree-of-freedom hexapod within one hour, demonstrating
both high efficiency and robustness to structural damage.

</details>


### [2] [Robust Embodied Self-Identification of Morphology in Damaged Multi-Legged Robots](https://arxiv.org/abs/2506.19984)
*Sahand Farghdani,Mili Patel,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了一种基于低成本IMU的自建模与损伤识别算法，帮助多足机器人自主适应腿部损伤。


<details>
  <summary>Details</summary>
Motivation: 多足机器人在复杂任务中易受腿部损伤影响性能，需自主适应能力。

Method: 引入FFT滤波器处理时间不一致信号，通过比较机器人与模型的身体方向检测损伤，更新模型并集成到控制系统。

Result: 在崎岖地形实验中验证了算法的鲁棒性和计算效率。

Conclusion: 该方法能有效识别损伤并自主适应，提升多足机器人的可靠性。

Abstract: Multi-legged robots (MLRs) are vulnerable to leg damage during complex
missions, which can impair their performance. This paper presents a
self-modeling and damage identification algorithm that enables autonomous
adaptation to partial or complete leg loss using only data from a low-cost IMU.
A novel FFT-based filter is introduced to address time-inconsistent signals,
improving damage detection by comparing body orientation between the robot and
its model. The proposed method identifies damaged legs and updates the robot's
model for integration into its control system. Experiments on uneven terrain
validate its robustness and computational efficiency.

</details>


### [3] [Hierarchical Reinforcement Learning and Value Optimization for Challenging Quadruped Locomotion](https://arxiv.org/abs/2506.20036)
*Jeremiah Coholich,Muhammad Ali Murtaza,Seth Hutchinson,Zsolt Kira*

Main category: cs.RO

TL;DR: 提出了一种新颖的分层强化学习框架，用于四足机器人在复杂地形上的运动。高层策略（HLP）选择目标，低层策略（LLP）执行。HLP无需额外训练，通过在线优化LLP的价值函数实现。相比端到端RL，该框架在奖励和碰撞减少方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人在复杂地形上的运动问题，提高其适应性和效率。

Method: 采用两层分层强化学习框架：HLP选择目标，LLP执行。LLP通过on-policy actor-critic RL算法训练，HLP通过在线优化LLP的价值函数实现。

Result: 相比端到端RL，该框架在奖励更高、碰撞更少方面表现更优，尤其在训练未涉及的地形上。

Conclusion: 分层强化学习框架显著提升了四足机器人在复杂地形上的运动性能。

Abstract: We propose a novel hierarchical reinforcement learning framework for
quadruped locomotion over challenging terrain. Our approach incorporates a
two-layer hierarchy in which a high-level policy (HLP) selects optimal goals
for a low-level policy (LLP). The LLP is trained using an on-policy
actor-critic RL algorithm and is given footstep placements as goals. We propose
an HLP that does not require any additional training or environment samples and
instead operates via an online optimization process over the learned value
function of the LLP. We demonstrate the benefits of this framework by comparing
it with an end-to-end reinforcement learning (RL) approach. We observe
improvements in its ability to achieve higher rewards with fewer collisions
across an array of different terrains, including terrains more difficult than
any encountered during training.

</details>


### [4] [Consensus-Driven Uncertainty for Robotic Grasping based on RGB Perception](https://arxiv.org/abs/2506.20045)
*Eric C. Joyce,Qianwen Zhao,Nathaniel Burgdorfer,Long Wang,Philippos Mordohai*

Main category: cs.RO

TL;DR: 提出了一种训练轻量级深度网络的方法，用于预测基于图像姿态估计的抓取是否成功。


<details>
  <summary>Details</summary>
Motivation: 现有深度物体姿态估计器过于自信，导致抓取任务失败。通过预测不确定性，可以避免高不确定性下的行动。

Method: 通过真实图像的物体姿态估计和模拟抓取生成训练数据，训练网络预测抓取成功率。

Result: 发现尽管抓取试验中物体差异大，但联合训练所有物体对网络有益，表明多样性物体有助于同一目标。

Conclusion: 提出的方法能有效预测抓取成功率，联合训练提升性能。

Abstract: Deep object pose estimators are notoriously overconfident. A grasping agent
that both estimates the 6-DoF pose of a target object and predicts the
uncertainty of its own estimate could avoid task failure by choosing not to act
under high uncertainty. Even though object pose estimation improves and
uncertainty quantification research continues to make strides, few studies have
connected them to the downstream task of robotic grasping. We propose a method
for training lightweight, deep networks to predict whether a grasp guided by an
image-based pose estimate will succeed before that grasp is attempted. We
generate training data for our networks via object pose estimation on real
images and simulated grasping. We also find that, despite high object
variability in grasping trials, networks benefit from training on all objects
jointly, suggesting that a diverse variety of objects can nevertheless
contribute to the same goal.

</details>


### [5] [Real-Time Obstacle Avoidance Algorithms for Unmanned Aerial and Ground Vehicles](https://arxiv.org/abs/2506.20311)
*Jingwen Wei*

Main category: cs.RO

TL;DR: 该论文探讨了无人机在复杂3D环境中的实时安全导航方法，特别是在森林火灾等灾害救援中的应用，提出了一种统一的控制方法，整合无人机和地面无人车进行协同救援。


<details>
  <summary>Details</summary>
Motivation: 无人机在灾害救援中的应用尚未充分探索，尤其是在自主导航方面。研究旨在通过改进导航算法，提高救援效率和安全性。

Method: 分阶段开发：首先探索2D融合导航策略，随后提出3D反应式导航策略，最后整合无人机和地面无人车进行协同控制。

Result: 通过数学和仿真验证，提出的方法能够实现无人机在复杂环境中的安全导航和协同救援。

Conclusion: 该研究为无人机在自然灾害救援中的实际应用提供了有价值的解决方案和学术见解。

Abstract: The growing use of mobile robots in sectors such as automotive, agriculture,
and rescue operations reflects progress in robotics and autonomy. In unmanned
aerial vehicles (UAVs), most research emphasizes visual SLAM, sensor fusion,
and path planning. However, applying UAVs to search and rescue missions in
disaster zones remains underexplored, especially for autonomous navigation.
  This report develops methods for real-time and secure UAV maneuvering in
complex 3D environments, crucial during forest fires. Building upon past
research, it focuses on designing navigation algorithms for unfamiliar and
hazardous environments, aiming to improve rescue efficiency and safety through
UAV-based early warning and rapid response.
  The work unfolds in phases. First, a 2D fusion navigation strategy is
explored, initially for mobile robots, enabling safe movement in dynamic
settings. This sets the stage for advanced features such as adaptive obstacle
handling and decision-making enhancements. Next, a novel 3D reactive navigation
strategy is introduced for collision-free movement in forest fire simulations,
addressing the unique challenges of UAV operations in such scenarios.
  Finally, the report proposes a unified control approach that integrates UAVs
and unmanned ground vehicles (UGVs) for coordinated rescue missions in forest
environments. Each phase presents challenges, proposes control models, and
validates them with mathematical and simulation-based evidence. The study
offers practical value and academic insights for improving the role of UAVs in
natural disaster rescue operations.

</details>


### [6] [Robust Robotic Exploration and Mapping Using Generative Occupancy Map Synthesis](https://arxiv.org/abs/2506.20049)
*Lorin Achey,Alec Reed,Brendan Crowe,Bradley Hayes,Christoffer Heckman*

Main category: cs.RO

TL;DR: 提出了一种基于生成占用映射的机器人探索新方法SceneSense，显著提升了地图质量和可通行性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人探索中部分观测导致的地图质量不足问题。

Method: 使用扩散模型SceneSense预测3D占用地图，并实时融合到运行地图中。

Result: 实验显示地图质量显著提升（FID改进24.44%和75.59%），探索稳健性和时间效率提高。

Conclusion: SceneSense增强的地图在探索任务中表现优于仅依赖传感器数据的地图。

Abstract: We present a novel approach for enhancing robotic exploration by using
generative occupancy mapping. We introduce SceneSense, a diffusion model
designed and trained for predicting 3D occupancy maps given partial
observations. Our proposed approach probabilistically fuses these predictions
into a running occupancy map in real-time, resulting in significant
improvements in map quality and traversability. We implement SceneSense onboard
a quadruped robot and validate its performance with real-world experiments to
demonstrate the effectiveness of the model. In these experiments, we show that
occupancy maps enhanced with SceneSense predictions better represent our fully
observed ground truth data (24.44% FID improvement around the robot and 75.59%
improvement at range). We additionally show that integrating
SceneSense-enhanced maps into our robotic exploration stack as a "drop-in" map
improvement, utilizing an existing off-the-shelf planner, results in
improvements in robustness and traversability time. Finally we show results of
full exploration evaluations with our proposed system in two dissimilar
environments and find that locally enhanced maps provide more consistent
exploration results than maps constructed only from direct sensor measurements.

</details>


### [7] [PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models](https://arxiv.org/abs/2506.20097)
*Wang Bill Zhu,Miaosen Chai,Ishika Singh,Robin Jia,Jesse Thomason*

Main category: cs.RO

TL;DR: PSALM-V是一种自主神经符号学习系统，通过交互在视觉环境中推导符号动作语义，无需专家定义，显著提升了规划成功率。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在文本领域或依赖不现实假设（如预定义问题文件或完全可观察性）的局限性，实现动态推断符号语义。

Method: 利用LLM生成启发式计划和候选符号语义，动态推断PDDL问题文件和动作语义，通过迭代执行和信念树优化。

Result: 在ALFRED任务中，规划成功率从37%提升至74%；在RTFM和Overcooked-AI中提升步骤效率；在机器人任务中成功推导PDDL条件。

Conclusion: PSALM-V在视觉环境和多智能体设置中有效，展示了神经符号学习的潜力。

Abstract: We propose PSALM-V, the first autonomous neuro-symbolic learning system able
to induce symbolic action semantics (i.e., pre- and post-conditions) in visual
environments through interaction. PSALM-V bootstraps reliable symbolic planning
without expert action definitions, using LLMs to generate heuristic plans and
candidate symbolic semantics. Previous work has explored using large language
models to generate action semantics for Planning Domain Definition Language
(PDDL)-based symbolic planners. However, these approaches have primarily
focused on text-based domains or relied on unrealistic assumptions, such as
access to a predefined problem file, full observability, or explicit error
messages. By contrast, PSALM-V dynamically infers PDDL problem files and domain
action semantics by analyzing execution outcomes and synthesizing possible
error explanations. The system iteratively generates and executes plans while
maintaining a tree-structured belief over possible action semantics for each
action, iteratively refining these beliefs until a goal state is reached.
Simulated experiments of task completion in ALFRED demonstrate that PSALM-V
increases the plan success rate from 37% (Claude-3.7) to 74% in partially
observed setups. Results on two 2D game environments, RTFM and Overcooked-AI,
show that PSALM-V improves step efficiency and succeeds in domain induction in
multi-agent settings. PSALM-V correctly induces PDDL pre- and post-conditions
for real-world robot BlocksWorld tasks, despite low-level manipulation failures
from the robot.

</details>


### [8] [Personalized Mental State Evaluation in Human-Robot Interaction using Federated Learning](https://arxiv.org/abs/2506.20212)
*Andrea Bussolan,Oliver Avram,Andrea Pignata,Gianvito Urgese,Stefano Baraldo,Anna Valente*

Main category: cs.RO

TL;DR: 论文提出了一种基于联邦学习的多模态框架，用于实时评估操作员的压力水平，并优化人机协作，同时保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 随着工业5.0的发展，制造商越来越重视工人福祉与大规模定制的结合。压力感知的人机协作（HRC）在此背景下至关重要，机器人需根据人类心理状态调整行为以提高协作流畅性和安全性。

Method: 论文提出了一种集成联邦学习（FL）的框架，利用EEG、ECG、EDA、EMG和呼吸等多模态生理信号预测操作员的压力水平，并通过分布式设备端训练保护数据隐私。

Result: 实验结果表明，FL方法的全局模型在压力预测准确性上与集中式训练方法相当，同时提升了个性化能力，优化了工业环境中的人机交互。

Conclusion: 该框架推动了隐私保护的适应性机器人技术，提升了智能制造中的劳动力福祉。

Abstract: With the advent of Industry 5.0, manufacturers are increasingly prioritizing
worker well-being alongside mass customization. Stress-aware Human-Robot
Collaboration (HRC) plays a crucial role in this paradigm, where robots must
adapt their behavior to human mental states to improve collaboration fluency
and safety. This paper presents a novel framework that integrates Federated
Learning (FL) to enable personalized mental state evaluation while preserving
user privacy. By leveraging physiological signals, including EEG, ECG, EDA,
EMG, and respiration, a multimodal model predicts an operator's stress level,
facilitating real-time robot adaptation. The FL-based approach allows
distributed on-device training, ensuring data confidentiality while improving
model generalization and individual customization. Results demonstrate that the
deployment of an FL approach results in a global model with performance in
stress prediction accuracy comparable to a centralized training approach.
Moreover, FL allows for enhancing personalization, thereby optimizing
human-robot interaction in industrial settings, while preserving data privacy.
The proposed framework advances privacy-preserving, adaptive robotics to
enhance workforce well-being in smart manufacturing.

</details>


### [9] [Generating and Customizing Robotic Arm Trajectories using Neural Networks](https://arxiv.org/abs/2506.20259)
*Andrej Lúčny,Matilde Antonj,Carlo Mazzola,Hana Hornáčková,Igor Farkaš*

Main category: cs.RO

TL;DR: 提出了一种神经网络方法，用于生成和定制机械臂的轨迹，确保精度和可重复性。


<details>
  <summary>Details</summary>
Motivation: 提高机械臂在认知机器人实验中的可预测性，特别是在与人类互动时。

Method: 结合神经网络计算机械臂的正向运动学，并通过生成关节角度的神经网络训练人工数据集。

Result: 成功生成精确且可定制的轨迹，适用于不同场景。

Conclusion: 该方法具有广泛适用性，能够生成高精度且可定制的机械臂轨迹。

Abstract: We introduce a neural network approach for generating and customizing the
trajectory of a robotic arm, that guarantees precision and repeatability. To
highlight the potential of this novel method, we describe the design and
implementation of the technique and show its application in an experimental
setting of cognitive robotics. In this scenario, the NICO robot was
characterized by the ability to point to specific points in space with precise
linear movements, increasing the predictability of the robotic action during
its interaction with humans. To achieve this goal, the neural network computes
the forward kinematics of the robot arm. By integrating it with a generator of
joint angles, another neural network was developed and trained on an artificial
dataset created from suitable start and end poses of the robotic arm. Through
the computation of angular velocities, the robot was characterized by its
ability to perform the movement, and the quality of its action was evaluated in
terms of shape and accuracy. Thanks to its broad applicability, our approach
successfully generates precise trajectories that could be customized in their
shape and adapted to different settings.

</details>


### [10] [Why Robots Are Bad at Detecting Their Mistakes: Limitations of Miscommunication Detection in Human-Robot Dialogue](https://arxiv.org/abs/2506.20268)
*Ruben Janssens,Jens De Bock,Sofie Labat,Eva Verhelst,Veronique Hoste,Tony Belpaeme*

Main category: cs.RO

TL;DR: 研究评估机器学习模型在检测人机对话中的沟通错误时的表现，发现即使使用先进模型，识别效果仅略优于随机猜测，且用户反馈不足是主要限制。


<details>
  <summary>Details</summary>
Motivation: 人机交互中检测沟通错误对维持用户信任至关重要，但机器人难以通过非语言反馈识别错误。

Method: 使用包含240段人机对话的多模态数据集，引入四种对话失败类型，评估计算机视觉模型的性能。

Result: 模型识别沟通错误的效果不佳，仅略优于随机猜测；在情感表达更丰富的数据集上表现较好。

Conclusion: 用户反馈不足是识别机器人沟通错误的根本限制，需设计更好的对话机制以主动获取反馈。

Abstract: Detecting miscommunication in human-robot interaction is a critical function
for maintaining user engagement and trust. While humans effortlessly detect
communication errors in conversations through both verbal and non-verbal cues,
robots face significant challenges in interpreting non-verbal feedback, despite
advances in computer vision for recognizing affective expressions. This
research evaluates the effectiveness of machine learning models in detecting
miscommunications in robot dialogue. Using a multi-modal dataset of 240
human-robot conversations, where four distinct types of conversational failures
were systematically introduced, we assess the performance of state-of-the-art
computer vision models. After each conversational turn, users provided feedback
on whether they perceived an error, enabling an analysis of the models' ability
to accurately detect robot mistakes. Despite using state-of-the-art models, the
performance barely exceeds random chance in identifying miscommunication, while
on a dataset with more expressive emotional content, they successfully
identified confused states. To explore the underlying cause, we asked human
raters to do the same. They could also only identify around half of the induced
miscommunications, similarly to our model. These results uncover a fundamental
limitation in identifying robot miscommunications in dialogue: even when users
perceive the induced miscommunication as such, they often do not communicate
this to their robotic conversation partner. This knowledge can shape
expectations of the performance of computer vision models and can help
researchers to design better human-robot conversations by deliberately
eliciting feedback where needed.

</details>


### [11] [Near Time-Optimal Hybrid Motion Planning for Timber Cranes](https://arxiv.org/abs/2506.20314)
*Marc-Philip Ecker,Bernhard Bischof,Minh Nhat Vu,Christoph Fröhlich,Tobias Glück,Wolfgang Kemmetmüller*

Main category: cs.RO

TL;DR: 提出了一种针对液压驱动木材起重机的时间最优、无碰撞混合运动规划方法，改进了VP-STO算法，并验证了其优于RRT*算法的性能。


<details>
  <summary>Details</summary>
Motivation: 大型机械臂（如木材起重机）的运动规划面临液压驱动约束和被动关节等独特挑战，现有方法未充分解决。

Method: 增强VP-STO算法以包含泵流量约束，并提出新的碰撞成本公式；结合梯度局部规划器形成混合规划。

Result: 改进的VP-STO作为全局规划器优于RRT*算法，混合规划有效考虑了被动关节动力学。

Conclusion: 该方法为液压驱动机械臂提供了高效、鲁棒的运动规划解决方案。

Abstract: Efficient, collision-free motion planning is essential for automating
large-scale manipulators like timber cranes. They come with unique challenges
such as hydraulic actuation constraints and passive joints-factors that are
seldom addressed by current motion planning methods. This paper introduces a
novel approach for time-optimal, collision-free hybrid motion planning for a
hydraulically actuated timber crane with passive joints. We enhance the
via-point-based stochastic trajectory optimization (VP-STO) algorithm to
include pump flow rate constraints and develop a novel collision cost
formulation to improve robustness. The effectiveness of the enhanced VP-STO as
an optimal single-query global planner is validated by comparison with an
informed RRT* algorithm using a time-optimal path parameterization (TOPP). The
overall hybrid motion planning is formed by combination with a gradient-based
local planner that is designed to follow the global planner's reference and to
systematically consider the passive joint dynamics for both collision avoidance
and sway damping.

</details>


### [12] [Building Forest Inventories with Autonomous Legged Robots -- System, Lessons, and Challenges Ahead](https://arxiv.org/abs/2506.20315)
*Matías Mattamala,Nived Chebrolu,Jonas Frey,Leonard Freißmuth,Haedam Oh,Benoit Casseau,Marco Hutter,Maurice Fallon*

Main category: cs.RO

TL;DR: 本文介绍了一种用于森林自主测绘的四足机器人系统，展示了其在自然环境中导航和测绘的能力，并总结了相关挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现代四足机器人在复杂自然环境中的鲁棒性和移动性激发了开发自主森林测绘系统的需求。

Method: 提出了一种完整的导航系统架构，包括状态估计、任务规划、树木检测和特征估计。

Result: ANYmal机器人在欧洲三国森林中测试，30分钟内可测绘1公顷区域，树木直径测量精度达2厘米。

Conclusion: 总结了硬件成熟度、状态估计限制等五方面挑战，为未来四足机器人和自然环境中导航系统研究提供了方向。

Abstract: Legged robots are increasingly being adopted in industries such as oil, gas,
mining, nuclear, and agriculture. However, new challenges exist when moving
into natural, less-structured environments, such as forestry applications. This
paper presents a prototype system for autonomous, under-canopy forest inventory
with legged platforms. Motivated by the robustness and mobility of modern
legged robots, we introduce a system architecture which enabled a quadruped
platform to autonomously navigate and map forest plots. Our solution involves a
complete navigation stack for state estimation, mission planning, and tree
detection and trait estimation. We report the performance of the system from
trials executed over one and a half years in forests in three European
countries. Our results with the ANYmal robot demonstrate that we can survey
plots up to 1 ha plot under 30 min, while also identifying trees with typical
DBH accuracy of 2cm. The findings of this project are presented as five lessons
and challenges. Particularly, we discuss the maturity of hardware development,
state estimation limitations, open problems in forest navigation, future
avenues for robotic forest inventory, and more general challenges to assess
autonomous systems. By sharing these lessons and challenges, we offer insight
and new directions for future research on legged robots, navigation systems,
and applications in natural environments. Additional videos can be found in
https://dynamic.robots.ox.ac.uk/projects/legged-robots

</details>


### [13] [Finding the Easy Way Through -- the Probabilistic Gap Planner for Social Robot Navigation](https://arxiv.org/abs/2506.20320)
*Malte Probst,Raphael Wenzel,Tim Puphal,Monica Dasi,Nico A. Steinhardt,Sango Matsuzaki,Misa Komuro*

Main category: cs.RO

TL;DR: 论文提出了一种分解轨迹规划的方法，结合冲突避免和协作碰撞避免，通过Probabilistic Gap Planner（PGP）提升社交机器人导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有规划器仅关注短期交互，难以处理复杂场景，如寻找人群中的空隙或通道。

Method: 将轨迹规划分解为冲突避免（宏观轨迹）和协作碰撞避免（微观交互），提出PGP作为冲突避免规划器。

Result: 在模拟实验中，PGP结合现有规划器显著提升了性能：减少碰撞、增加空间、降低紧张感，但路径略长。

Conclusion: PGP方法有效提升了社交机器人导航的长期规划能力，适用于实时应用。

Abstract: In Social Robot Navigation, autonomous agents need to resolve many sequential
interactions with other agents. State-of-the art planners can efficiently
resolve the next, imminent interaction cooperatively and do not focus on longer
planning horizons. This makes it hard to maneuver scenarios where the agent
needs to select a good strategy to find gaps or channels in the crowd. We
propose to decompose trajectory planning into two separate steps: Conflict
avoidance for finding good, macroscopic trajectories, and cooperative collision
avoidance (CCA) for resolving the next interaction optimally. We propose the
Probabilistic Gap Planner (PGP) as a conflict avoidance planner. PGP modifies
an established probabilistic collision risk model to include a general
assumption of cooperativity. PGP biases the short-term CCA planner to head
towards gaps in the crowd. In extensive simulations with crowds of varying
density, we show that using PGP in addition to state-of-the-art CCA planners
improves the agents' performance: On average, agents keep more space to others,
create less tension, and cause fewer collisions. This typically comes at the
expense of slightly longer paths. PGP runs in real-time on WaPOCHI mobile robot
by Honda R&D.

</details>


### [14] [PIMBS: Efficient Body Schema Learning for Musculoskeletal Humanoids with Physics-Informed Neural Networks](https://arxiv.org/abs/2506.20343)
*Kento Kawaharazuka,Takahiro Hattori,Keita Yoneda,Kei Okada*

Main category: cs.RO

TL;DR: 提出了一种基于物理信息神经网络（PINNs）的方法，用于学习肌肉骨骼人形机器人的身体模式，即使在数据有限的情况下也能实现高精度学习。


<details>
  <summary>Details</summary>
Motivation: 肌肉骨骼人形机器人的身体结构复杂，肌肉路径与几何模型偏差大，传统方法依赖大量实际数据且学习困难。

Method: 结合实际机器人数据和物理规律（扭矩与肌肉张力关系），应用PINNs进行高效学习。

Result: 在仿真和实际机器人上验证了方法的有效性和特点。

Conclusion: 该方法能够显著减少数据需求，提高学习效率，适用于肌肉骨骼人形机器人的身体模式学习。

Abstract: Musculoskeletal humanoids are robots that closely mimic the human
musculoskeletal system, offering various advantages such as variable stiffness
control, redundancy, and flexibility. However, their body structure is complex,
and muscle paths often significantly deviate from geometric models. To address
this, numerous studies have been conducted to learn body schema, particularly
the relationships among joint angles, muscle tension, and muscle length. These
studies typically rely solely on data collected from the actual robot, but this
data collection process is labor-intensive, and learning becomes difficult when
the amount of data is limited. Therefore, in this study, we propose a method
that applies the concept of Physics-Informed Neural Networks (PINNs) to the
learning of body schema in musculoskeletal humanoids, enabling high-accuracy
learning even with a small amount of data. By utilizing not only data obtained
from the actual robot but also the physical laws governing the relationship
between torque and muscle tension under the assumption of correct joint
structure, more efficient learning becomes possible. We apply the proposed
method to both simulation and an actual musculoskeletal humanoid and discuss
its effectiveness and characteristics.

</details>


### [15] [CARMA: Context-Aware Situational Grounding of Human-Robot Group Interactions by Combining Vision-Language Models with Object and Action Recognition](https://arxiv.org/abs/2506.20373)
*Joerg Deigmoeller,Stephan Hasler,Nakul Agarwal,Daniel Tanneberg,Anna Belardinelli,Reza Ghoddoosian,Chao Wang,Felix Ocker,Fan Zhang,Behzad Dariush,Michael Gienger*

Main category: cs.RO

TL;DR: CARMA系统通过情境感知和实例识别，支持人机群组交互中的协作。


<details>
  <summary>Details</summary>
Motivation: 在群组交互中，机器人需要情境感知和一致的实例识别以实现有效协作。

Method: CARMA通过唯一标识实体并组织为行动者-对象-动作三元组来实现情境感知。

Result: 实验表明，CARMA能可靠生成准确的三元组，支持时空推理和决策。

Conclusion: CARMA为协作场景提供了结构化且鲁棒的情境感知基础。

Abstract: We introduce CARMA, a system for situational grounding in human-robot group
interactions. Effective collaboration in such group settings requires
situational awareness based on a consistent representation of present persons
and objects coupled with an episodic abstraction of events regarding actors and
manipulated objects. This calls for a clear and consistent assignment of
instances, ensuring that robots correctly recognize and track actors, objects,
and their interactions over time. To achieve this, CARMA uniquely identifies
physical instances of such entities in the real world and organizes them into
grounded triplets of actors, objects, and actions.
  To validate our approach, we conducted three experiments, where multiple
humans and a robot interact: collaborative pouring, handovers, and sorting.
These scenarios allow the assessment of the system's capabilities as to role
distinction, multi-actor awareness, and consistent instance identification. Our
experiments demonstrate that the system can reliably generate accurate
actor-action-object triplets, providing a structured and robust foundation for
applications requiring spatiotemporal reasoning and situated decision-making in
collaborative settings.

</details>


### [16] [Enhanced Robotic Navigation in Deformable Environments using Learning from Demonstration and Dynamic Modulation](https://arxiv.org/abs/2506.20376)
*Lingyun Chen,Xinrui Zhao,Marcos P. S. Campanha,Alexander Wegener,Abdeldjallil Naceri,Abdalla Swikir,Sami Haddadin*

Main category: cs.RO

TL;DR: 提出了一种结合LfD和DS的机器人导航方法，用于在包含可变形障碍物的环境中实现自适应高效导航。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂环境中（包含软硬障碍物）机器人导航的灵活性和安全性问题。

Method: 在DS框架中引入动态调制矩阵，实时区分可穿越软区域与不可穿越硬区域，实现安全轨迹规划。

Result: 通过仿真和实验验证了方法在可变形环境中的导航能力，并实现了对轨迹和速度的控制。

Conclusion: 该方法能够动态适应障碍物，确保平滑可靠的导航，同时保持原始DS轨迹。

Abstract: This paper presents a novel approach for robot navigation in environments
containing deformable obstacles. By integrating Learning from Demonstration
(LfD) with Dynamical Systems (DS), we enable adaptive and efficient navigation
in complex environments where obstacles consist of both soft and hard regions.
We introduce a dynamic modulation matrix within the DS framework, allowing the
system to distinguish between traversable soft regions and impassable hard
areas in real-time, ensuring safe and flexible trajectory planning. We validate
our method through extensive simulations and robot experiments, demonstrating
its ability to navigate deformable environments. Additionally, the approach
provides control over both trajectory and velocity when interacting with
deformable objects, including at intersections, while maintaining adherence to
the original DS trajectory and dynamically adapting to obstacles for smooth and
reliable navigation.

</details>


### [17] [SPARK: Graph-Based Online Semantic Integration System for Robot Task Planning](https://arxiv.org/abs/2506.20394)
*Mimo Shirasaka,Yuya Ikeda,Tatsuya Matsushima,Yutaka Matsuo,Yusuke Iwasawa*

Main category: cs.RO

TL;DR: 论文提出SPARK框架，用于在线更新语义信息，提升机器人在动态环境中的任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 通用服务机器人需要在线更新几何和语义信息，但现有SLAM技术仅处理几何更新，语义信息的在线更新尚未解决。

Method: 基于离线场景图表示，提出SPARK框架，从环境线索中提取语义信息并更新场景图，用于任务规划。

Result: 实验表明，空间关系的图表示能增强机器人在动态环境中的任务执行能力，适应非常规空间线索（如手势）。

Conclusion: SPARK框架有效解决了语义信息在线更新的问题，提升了机器人在动态环境中的适应性。

Abstract: The ability to update information acquired through various means online
during task execution is crucial for a general-purpose service robot. This
information includes geometric and semantic data. While SLAM handles geometric
updates on 2D maps or 3D point clouds, online updates of semantic information
remain unexplored. We attribute the challenge to the online scene graph
representation, for its utility and scalability. Building on previous works
regarding offline scene graph representations, we study online graph
representations of semantic information in this work. We introduce SPARK:
Spatial Perception and Robot Knowledge Integration. This framework extracts
semantic information from environment-embedded cues and updates the scene graph
accordingly, which is then used for subsequent task planning. We demonstrate
that graph representations of spatial relationships enhance the robot system's
ability to perform tasks in dynamic environments and adapt to unconventional
spatial cues, like gestures.

</details>


### [18] [Multimodal Behaviour Trees for Robotic Laboratory Task Automation](https://arxiv.org/abs/2506.20399)
*Hatem Fakhruldeen,Arvind Raveendran Nambiar,Satheeshkumar Veeramani,Bonilkumar Vijaykumar Tailor,Hadi Beyzaee Juneghani,Gabriella Pizzuto,Andrew Ian Cooper*

Main category: cs.RO

TL;DR: 论文提出了一种基于行为树和多模态感知的新方法，用于提高实验室机器人在执行任务时的可靠性和安全性，实验结果显示高成功率和强错误检测能力。


<details>
  <summary>Details</summary>
Motivation: 实验室机器人虽能高效执行重复任务，但其可靠性不足可能导致安全隐患（如毒物泄漏），因此需要一种方法确保任务执行的准确性。

Method: 采用行为树结合多模态感知的方法，自动化任务执行并验证任务完成情况。

Result: 实验在样本瓶盖封和实验室架插入任务中分别达到88%和92%的成功率，并具备强错误检测能力。

Conclusion: 该方法证明了其鲁棒性和可靠性，为下一代机器人化学家的研发奠定了基础。

Abstract: Laboratory robotics offer the capability to conduct experiments with a high
degree of precision and reproducibility, with the potential to transform
scientific research. Trivial and repeatable tasks; e.g., sample transportation
for analysis and vial capping are well-suited for robots; if done successfully
and reliably, chemists could contribute their efforts towards more critical
research activities. Currently, robots can perform these tasks faster than
chemists, but how reliable are they? Improper capping could result in human
exposure to toxic chemicals which could be fatal. To ensure that robots perform
these tasks as accurately as humans, sensory feedback is required to assess the
progress of task execution. To address this, we propose a novel methodology
based on behaviour trees with multimodal perception. Along with automating
robotic tasks, this methodology also verifies the successful execution of the
task, a fundamental requirement in safety-critical environments. The
experimental evaluation was conducted on two lab tasks: sample vial capping and
laboratory rack insertion. The results show high success rate, i.e., 88% for
capping and 92% for insertion, along with strong error detection capabilities.
This ultimately proves the robustness and reliability of our approach and that
using multimodal behaviour trees should pave the way towards the next
generation of robotic chemists.

</details>


### [19] [Learn to Position -- A Novel Meta Method for Robotic Positioning](https://arxiv.org/abs/2506.20445)
*Dongkun Wang,Junkai Zhao,Yunfei Teng,Jieyang Peng,Wenjing Xue,Xiaoming Tao*

Main category: cs.RO

TL;DR: 提出了一种无视觉、模型无关的元方法，通过交互反馈补偿机器人位置误差，提高定位精度。


<details>
  <summary>Details</summary>
Motivation: 机器人绝对定位精度至关重要，但误差来源复杂且随机，视觉方法易受遮挡和光照影响。

Method: 基于交互反馈的无视觉元方法，具备学习和自适应能力，灵感来自人类在不确定条件下的抓取本能。

Result: 实证研究验证了方法的有效性，已在电子元件装配线中应用。

Conclusion: 该方法能自适应学习并加速定位过程，适用于复杂环境。

Abstract: Absolute positioning accuracy is a vital specification for robots. Achieving
high position precision can be challenging due to the presence of various
sources of errors. Meanwhile, accurately depicting these errors is difficult
due to their stochastic nature. Vision-based methods are commonly integrated to
guide robotic positioning, but their performance can be highly impacted by
inevitable occlusions or adverse lighting conditions. Drawing on the
aforementioned considerations, a vision-free, model-agnostic meta-method for
compensating robotic position errors is proposed, which maximizes the
probability of accurate robotic position via interactive feedback. Meanwhile,
the proposed method endows the robot with the capability to learn and adapt to
various position errors, which is inspired by the human's instinct for grasping
under uncertainties. Furthermore, it is a self-learning and self-adaptive
method able to accelerate the robotic positioning process as more examples are
incorporated and learned. Empirical studies validate the effectiveness of the
proposed method. As of the writing of this paper, the proposed meta search
method has already been implemented in a robotic-based assembly line for
odd-form electronic components.

</details>


### [20] [A Review of Personalisation in Human-Robot Collaboration and Future Perspectives Towards Industry 5.0](https://arxiv.org/abs/2506.20447)
*James Fant-Male,Roel Pieters*

Main category: cs.RO

TL;DR: 论文探讨了从工业4.0到工业5.0的转变，强调以人为中心的工作环境，并研究了人机协作（HRC）的个性化发展。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于工业5.0背景下，如何通过个性化的人机协作提升社会福祉和工作效率。

Method: 方法包括综述近期关于个性化HRC的研究，分析其适应性、交互设计和任务完成方式。

Result: 研究发现个性化HRC缺乏统一方法，但揭示了关键研究趋势和未来发展的伦理与监管问题。

Conclusion: 结论指出未来需关注个性化系统的伦理和监管发展，以实现更高效的人机协作。

Abstract: The shift in research focus from Industry 4.0 to Industry 5.0 (I5.0) promises
a human-centric workplace, with social and well-being values at the centre of
technological implementation. Human-Robot Collaboration (HRC) is a core aspect
of I5.0 development, with an increase in adaptive and personalised interactions
and behaviours. This review investigates recent advancements towards
personalised HRC, where user-centric adaption is key. There is a growing trend
for adaptable HRC research, however there lacks a consistent and unified
approach. The review highlights key research trends on which personal factors
are considered, workcell and interaction design, and adaptive task completion.
This raises various key considerations for future developments, particularly
around the ethical and regulatory development of personalised systems, which
are discussed in detail.

</details>


### [21] [EANS: Reducing Energy Consumption for UAV with an Environmental Adaptive Navigation Strategy](https://arxiv.org/abs/2506.20485)
*Tian Liu,Han Liu,Boyang Li,Long Chen,Kai Huang*

Main category: cs.RO

TL;DR: 本文提出一种动态调整无人机导航策略的方法，通过分析动态特性和时间特性，减少能耗，实验显示显著提升任务时间和能源效率。


<details>
  <summary>Details</summary>
Motivation: 无人机能源有限，现有静态导航策略在动态场景中效率低下，需解决任务管道依赖、环境-策略关联和参数选择等挑战。

Method: 动态调整导航策略，分析无人机动态特性和自主导航管道的时间特性。

Result: 硬件在环仿真和实际实验显示，任务时间提升3.2倍和2.6倍，能源效率提升2.4倍和1.6倍。

Conclusion: 动态导航策略能有效减少无人机能耗，适应环境变化，显著提升性能。

Abstract: Unmanned Aerial Vehicles (UAVS) are limited by the onboard energy. Refinement
of the navigation strategy directly affects both the flight velocity and the
trajectory based on the adjustment of key parameters in the UAVS pipeline, thus
reducing energy consumption. However, existing techniques tend to adopt static
and conservative strategies in dynamic scenarios, leading to inefficient energy
reduction. Dynamically adjusting the navigation strategy requires overcoming
the challenges including the task pipeline interdependencies, the
environmental-strategy correlations, and the selecting parameters. To solve the
aforementioned problems, this paper proposes a method to dynamically adjust the
navigation strategy of the UAVS by analyzing its dynamic characteristics and
the temporal characteristics of the autonomous navigation pipeline, thereby
reducing UAVS energy consumption in response to environmental changes. We
compare our method with the baseline through hardware-in-the-loop (HIL)
simulation and real-world experiments, showing our method 3.2X and 2.6X
improvements in mission time, 2.4X and 1.6X improvements in energy,
respectively.

</details>


### [22] [Behavior Foundation Model: Towards Next-Generation Whole-Body Control System of Humanoid Robots](https://arxiv.org/abs/2506.20487)
*Mingqi Yuan,Tao Yu,Wenqi Ge,Xiuyong Yao,Dapeng Li,Huijiang Wang,Jiayu Chen,Xin Jin,Bo Li,Hua Chen,Wei Zhang,Wenjun Zeng*

Main category: cs.RO

TL;DR: 本文综述了行为基础模型（BFMs）在人形机器人全身控制（WBC）中的应用，探讨了其发展、实际应用、局限性和未来机会。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在复杂运动控制和通用物理智能方面潜力巨大，但传统学习方法依赖高成本重训练，限制了实际应用。BFMs通过大规模预训练学习可重用技能，有望解决这一问题。

Method: BFMs利用大规模预训练学习原始技能和行为先验，支持零样本或快速适应下游任务。

Result: BFMs为可扩展和通用的人形智能提供了关键方法，但仍面临实际应用中的挑战。

Conclusion: BFMs是人形机器人WBC的重要研究方向，未来需解决其局限性以推动实际应用。

Abstract: Humanoid robots are drawing significant attention as versatile platforms for
complex motor control, human-robot interaction, and general-purpose physical
intelligence. However, achieving efficient whole-body control (WBC) in
humanoids remains a fundamental challenge due to sophisticated dynamics,
underactuation, and diverse task requirements. While learning-based controllers
have shown promise for complex tasks, their reliance on labor-intensive and
costly retraining for new scenarios limits real-world applicability. To address
these limitations, behavior(al) foundation models (BFMs) have emerged as a new
paradigm that leverages large-scale pretraining to learn reusable primitive
skills and behavioral priors, enabling zero-shot or rapid adaptation to a wide
range of downstream tasks. In this paper, we present a comprehensive overview
of BFMs for humanoid WBC, tracing their development across diverse pre-training
pipelines. Furthermore, we discuss real-world applications, current
limitations, urgent challenges, and future opportunities, positioning BFMs as a
key approach toward scalable and general-purpose humanoid intelligence.
Finally, we provide a curated and long-term list of BFM papers and projects to
facilitate more subsequent research, which is available at
https://github.com/yuanmingqi/awesome-bfm-papers.

</details>


### [23] [Critical Anatomy-Preserving & Terrain-Augmenting Navigation (CAPTAiN): Application to Laminectomy Surgical Education](https://arxiv.org/abs/2506.20496)
*Jonathan Wang,Hisashi Ishida,David Usevitch,Kesavan Venkatesh,Yi Wang,Mehran Armand,Rachel Bronheim,Amit Jain,Adnan Munawar*

Main category: cs.RO

TL;DR: CAPTAiN系统通过分层彩色体素引导，显著提高椎板切除术的完成率并降低认知负荷，缩小了不同经验水平外科医生的表现差距。


<details>
  <summary>Details</summary>
Motivation: 椎板切除术中意外撕裂硬膜的风险高达11.3%，且缺乏辅助工具；患者解剖结构差异增加了新手学习难度。

Method: 开发CAPTAiN系统，提供分层彩色体素引导，通过110次虚拟椎板切除术评估其效果。

Result: CAPTAiN显著提高了目标解剖结构的完成率（87.99% vs. 74.42%），降低了认知负荷，并使新手表现接近高级学员。

Conclusion: CAPTAiN有望优化手术执行并支持技能发展，适用于多种外科和钻孔手术。

Abstract: Surgical training remains a crucial milestone in modern medicine, with
procedures such as laminectomy exemplifying the high risks involved.
Laminectomy drilling requires precise manual control to mill bony tissue while
preserving spinal segment integrity and avoiding breaches in the dura: the
protective membrane surrounding the spinal cord. Despite unintended tears
occurring in up to 11.3% of cases, no assistive tools are currently utilized to
reduce this risk. Variability in patient anatomy further complicates learning
for novice surgeons. This study introduces CAPTAiN, a critical
anatomy-preserving and terrain-augmenting navigation system that provides
layered, color-coded voxel guidance to enhance anatomical awareness during
spinal drilling. CAPTAiN was evaluated against a standard non-navigated
approach through 110 virtual laminectomies performed by 11 orthopedic residents
and medical students. CAPTAiN significantly improved surgical completion rates
of target anatomy (87.99% vs. 74.42%) and reduced cognitive load across
multiple NASA-TLX domains. It also minimized performance gaps across experience
levels, enabling novices to perform on par with advanced trainees. These
findings highlight CAPTAiN's potential to optimize surgical execution and
support skill development across experience levels. Beyond laminectomy, it
demonstrates potential for broader applications across various surgical and
drilling procedures, including those in neurosurgery, otolaryngology, and other
medical fields.

</details>


### [24] [Leveraging Correlation Across Test Platforms for Variance-Reduced Metric Estimation](https://arxiv.org/abs/2506.20553)
*Rachel Luo,Heng Yang,Michael Watson,Apoorva Sharma,Sushant Veer,Edward Schmerling,Marco Pavone*

Main category: cs.RO

TL;DR: 提出一种利用配对数据（如仿真和现实观测）的控制变量方法，减少机器人系统验证所需的现实样本数量。


<details>
  <summary>Details</summary>
Motivation: 现实测试成本高且数据不足，需更高效验证方法。

Method: 利用控制变量法结合仿真数据，降低蒙特卡洛估计方差。

Result: 理论分析和实验表明，显著减少现实样本需求。

Conclusion: 该方法降低测试负担，提升机器人系统验证效率。

Abstract: Learning-based robotic systems demand rigorous validation to assure reliable
performance, but extensive real-world testing is often prohibitively expensive,
and if conducted may still yield insufficient data for high-confidence
guarantees. In this work, we introduce a general estimation framework that
leverages paired data across test platforms, e.g., paired simulation and
real-world observations, to achieve better estimates of real-world metrics via
the method of control variates. By incorporating cheap and abundant auxiliary
measurements (for example, simulator outputs) as control variates for costly
real-world samples, our method provably reduces the variance of Monte Carlo
estimates and thus requires significantly fewer real-world samples to attain a
specified confidence bound on the mean performance. We provide theoretical
analysis characterizing the variance and sample-efficiency improvement, and
demonstrate empirically in autonomous driving and quadruped robotics settings
that our approach achieves high-probability bounds with markedly improved
sample efficiency. Our technique can lower the real-world testing burden for
validating the performance of the stack, thereby enabling more efficient and
cost-effective experimental evaluation of robotic systems.

</details>


### [25] [HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction](https://arxiv.org/abs/2506.20566)
*Zhonghao Shi,Enyu Zhao,Nathaniel Dennler,Jingzhen Wang,Xinyang Xu,Kaleen Shrestha,Mengxue Fu,Daniel Seita,Maja Matarić*

Main category: cs.RO

TL;DR: HRIBench是一个用于评估视觉语言模型（VLMs）在人类感知任务中性能与延迟权衡的基准测试，涵盖五个关键领域，结果显示当前VLMs在实时人机交互（HRI）中仍存在不足。


<details>
  <summary>Details</summary>
Motivation: 研究VLMs在HRI中的人类感知能力及其性能与延迟的权衡，填补现有研究的空白。

Method: 构建HRIBench基准测试，包含1000个视觉问答（VQA）问题，覆盖五个HRI关键领域，并评估11种VLMs。

Result: 当前VLMs在核心感知能力上表现不足，且未能在性能与延迟之间达到满意的平衡。

Conclusion: 未来需开发更小、低延迟且具备更强人类感知能力的VLMs，HRIBench为此提供了评估工具。

Abstract: Real-time human perception is crucial for effective human-robot interaction
(HRI). Large vision-language models (VLMs) offer promising generalizable
perceptual capabilities but often suffer from high latency, which negatively
impacts user experience and limits VLM applicability in real-world scenarios.
To systematically study VLM capabilities in human perception for HRI and
performance-latency trade-offs, we introduce HRIBench, a visual
question-answering (VQA) benchmark designed to evaluate VLMs across a diverse
set of human perceptual tasks critical for HRI. HRIBench covers five key
domains: (1) non-verbal cue understanding, (2) verbal instruction
understanding, (3) human-robot object relationship understanding, (4) social
navigation, and (5) person identification. To construct HRIBench, we collected
data from real-world HRI environments to curate questions for non-verbal cue
understanding, and leveraged publicly available datasets for the remaining four
domains. We curated 200 VQA questions for each domain, resulting in a total of
1000 questions for HRIBench. We then conducted a comprehensive evaluation of
both state-of-the-art closed-source and open-source VLMs (N=11) on HRIBench.
Our results show that, despite their generalizability, current VLMs still
struggle with core perceptual capabilities essential for HRI. Moreover, none of
the models within our experiments demonstrated a satisfactory
performance-latency trade-off suitable for real-time deployment, underscoring
the need for future research on developing smaller, low-latency VLMs with
improved human perception capabilities. HRIBench and our results can be found
in this Github repository: https://github.com/interaction-lab/HRIBench.

</details>


### [26] [Communication-Aware Map Compression for Online Path-Planning: A Rate-Distortion Approach](https://arxiv.org/abs/2506.20579)
*Ali Reza Pedram,Evangelos Psomiadis,Dipankar Maity,Panagiotis Tsiotras*

Main category: cs.RO

TL;DR: 论文提出了一种在带宽限制下，支持者机器人通过压缩地图信息辅助寻求者机器人导航的方法，优化了通信成本和任务相关性。


<details>
  <summary>Details</summary>
Motivation: 解决在未知环境中，两机器人协作导航时的带宽限制问题，优化地图信息的压缩和传输。

Method: 引入基于二进制码字长度的比特率度量，将压缩设计问题建模为率失真优化问题，采用反向注水法求解。

Result: 仿真结果表明，该方法能在带宽限制下高效生成任务相关的地图压缩表示，指导寻求者机器人的路径规划。

Conclusion: 提出的方法在低计算量和实时性要求下，有效解决了协作导航中的通信优化问题。

Abstract: This paper addresses the problem of collaborative navigation in an unknown
environment, where two robots, referred to in the sequel as the Seeker and the
Supporter, traverse the space simultaneously. The Supporter assists the Seeker
by transmitting a compressed representation of its local map under bandwidth
constraints to support the Seeker's path-planning task. We introduce a bit-rate
metric based on the expected binary codeword length to quantify communication
cost. Using this metric, we formulate the compression design problem as a
rate-distortion optimization problem that determines when to communicate, which
regions of the map should be included in the compressed representation, and at
what resolution (i.e., quantization level) they should be encoded. Our
formulation allows different map regions to be encoded at varying quantization
levels based on their relevance to the Seeker's path-planning task. We
demonstrate that the resulting optimization problem is convex, and admits a
closed-form solution known in the information theory literature as reverse
water-filling, enabling efficient, low-computation, and real-time
implementation. Additionally, we show that the Seeker can infer the compression
decisions of the Supporter independently, requiring only the encoded map
content and not the encoding policy itself to be transmitted, thereby reducing
communication overhead. Simulation results indicate that our method effectively
constructs compressed, task-relevant map representations, both in content and
resolution, that guide the Seeker's planning decisions even under tight
bandwidth limitations.

</details>


### [27] [A Computationally Aware Multi Objective Framework for Camera LiDAR Calibration](https://arxiv.org/abs/2506.20636)
*Venkat Karramreddy,Rangarajan Ramanujam*

Main category: cs.RO

TL;DR: 提出一种多目标优化框架，用于联合优化LiDAR与相机的外参标定误差和计算成本，通过NSGA-II算法探索参数空间，并在KITTI数据集上验证性能。


<details>
  <summary>Details</summary>
Motivation: LiDAR与相机的外参标定对自动驾驶系统的可靠感知至关重要，但现有方法在计算成本和标定精度之间缺乏平衡。

Method: 采用多目标优化框架，结合几何对齐误差和计算成本作为优化目标，使用NSGA-II算法探索6-DoF变换和点采样率的参数空间。

Result: 在KITTI数据集上验证，相比现有方法，该方法在标定精度和资源效率之间提供了可调的性能，且部署开销更低。

Conclusion: 该框架为资源受限条件下的标定提供了可扩展且透明的方法，适用于长期自主运行的L3+车辆。

Abstract: Accurate extrinsic calibration between LiDAR and camera sensors is important
for reliable perception in autonomous systems. In this paper, we present a
novel multi-objective optimization framework that jointly minimizes the
geometric alignment error and computational cost associated with camera-LiDAR
calibration. We optimize two objectives: (1) error between projected LiDAR
points and ground-truth image edges, and (2) a composite metric for
computational cost reflecting runtime and resource usage. Using the NSGA-II
\cite{deb2002nsga2} evolutionary algorithm, we explore the parameter space
defined by 6-DoF transformations and point sampling rates, yielding a
well-characterized Pareto frontier that exposes trade-offs between calibration
fidelity and resource efficiency. Evaluations are conducted on the KITTI
dataset using its ground-truth extrinsic parameters for validation, with
results verified through both multi-objective and constrained single-objective
baselines. Compared to existing gradient-based and learned calibration methods,
our approach demonstrates interpretable, tunable performance with lower
deployment overhead. Pareto-optimal configurations are further analyzed for
parameter sensitivity and innovation insights. A preference-based
decision-making strategy selects solutions from the Pareto knee region to suit
the constraints of the embedded system. The robustness of calibration is tested
across variable edge-intensity weighting schemes, highlighting optimal balance
points. Although real-time deployment on embedded platforms is deferred to
future work, this framework establishes a scalable and transparent method for
calibration under realistic misalignment and resource-limited conditions,
critical for long-term autonomy, particularly in SAE L3+ vehicles receiving OTA
updates.

</details>


### [28] [DemoDiffusion: One-Shot Human Imitation using pre-trained Diffusion Policy](https://arxiv.org/abs/2506.20668)
*Sungjae Park,Homanga Bharadhwaj,Shubham Tulsiani*

Main category: cs.RO

TL;DR: DemoDiffusion是一种通过模仿单个人类演示使机器人在自然环境中执行操作任务的简单可扩展方法。


<details>
  <summary>Details</summary>
Motivation: 解决机器人通过单次人类演示学习任务的问题，避免在线强化学习或配对数据的需求。

Method: 结合人类手部运动的先验信息（通过运动学重定向）和预训练的扩散策略，生成符合机器人动作分布的轨迹。

Result: 在仿真和实际环境中，DemoDiffusion优于基础策略和重定向轨迹，能完成预训练策略失败的任务。

Conclusion: DemoDiffusion是一种高效且鲁棒的方法，适用于新任务和场景的快速适应。

Abstract: We propose DemoDiffusion, a simple and scalable method for enabling robots to
perform manipulation tasks in natural environments by imitating a single human
demonstration. Our approach is based on two key insights. First, the hand
motion in a human demonstration provides a useful prior for the robot's
end-effector trajectory, which we can convert into a rough open-loop robot
motion trajectory via kinematic retargeting. Second, while this retargeted
motion captures the overall structure of the task, it may not align well with
plausible robot actions in-context. To address this, we leverage a pre-trained
generalist diffusion policy to modify the trajectory, ensuring it both follows
the human motion and remains within the distribution of plausible robot
actions. Our approach avoids the need for online reinforcement learning or
paired human-robot data, enabling robust adaptation to new tasks and scenes
with minimal manual effort. Experiments in both simulation and real-world
settings show that DemoDiffusion outperforms both the base policy and the
retargeted trajectory, enabling the robot to succeed even on tasks where the
pre-trained generalist policy fails entirely. Project page:
https://demodiffusion.github.io/

</details>
