{"id": "2507.06426", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.06426", "abs": "https://arxiv.org/abs/2507.06426", "authors": ["Devin Crowley", "Whitney G. Cole", "Christina M. Hospodar", "Ruiting Shen", "Karen E. Adolph", "Alan Fern"], "title": "Evaluating Robots Like Human Infants: A Case Study of Learned Bipedal Locomotion", "comment": "7 pages, 4 figures, accepted into ICDL 2025 as a contributed paper", "summary": "Typically, learned robot controllers are trained via relatively unsystematic\nregimens and evaluated with coarse-grained outcome measures such as average\ncumulative reward. The typical approach is useful to compare learning\nalgorithms but provides limited insight into the effects of different training\nregimens and little understanding about the richness and complexity of learned\nbehaviors. Likewise, human infants and other animals are \"trained\" via\nunsystematic regimens, but in contrast, developmental psychologists evaluate\ntheir performance in highly-controlled experiments with fine-grained measures\nsuch as success, speed of walking, and prospective adjustments. However, the\nstudy of learned behavior in human infants is limited by the practical\nconstraints of training and testing babies. Here, we present a case study that\napplies methods from developmental psychology to study the learned behavior of\nthe simulated bipedal robot Cassie. Following research on infant walking, we\nsystematically designed reinforcement learning training regimens and tested the\nresulting controllers in simulated environments analogous to those used for\nbabies--but without the practical constraints. Results reveal new insights into\nthe behavioral impact of different training regimens and the development of\nCassie's learned behaviors relative to infants who are learning to walk. This\ninterdisciplinary baby-robot approach provides inspiration for future research\ndesigned to systematically test effects of training on the development of\ncomplex learned robot behaviors.", "AI": {"tldr": "论文提出了一种将发展心理学方法应用于机器人行为学习的研究，通过系统设计训练方案并模拟婴儿实验环境，揭示了训练方案对机器人行为的影响。", "motivation": "传统机器人控制器训练方法缺乏系统性且评估指标粗糙，无法深入理解训练方案对行为的影响。借鉴发展心理学的精细实验方法，可以弥补这一不足。", "method": "采用强化学习设计系统化的训练方案，并在模拟环境中测试机器人Cassie的行为，模拟婴儿行走实验。", "result": "研究揭示了不同训练方案对机器人行为的具体影响，并比较了Cassie与婴儿行走学习的行为发展。", "conclusion": "跨学科的婴儿-机器人研究方法为未来系统化研究复杂机器人行为学习提供了新思路。"}}
{"id": "2507.06564", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.06564", "abs": "https://arxiv.org/abs/2507.06564", "authors": ["Tianshun Li", "Tianyi Huai", "Zhen Li", "Yichun Gao", "Haoang Li", "Xinhu Zheng"], "title": "SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments", "comment": "8 pages, 9 figures, has been accepted by IROS 2025", "summary": "Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across\nvarious sectors, driven by their mobility and adaptability. This paper\nintroduces SkyVLN, a novel framework integrating vision-and-language navigation\n(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in\ncomplex urban environments. Unlike traditional navigation methods, SkyVLN\nleverages Large Language Models (LLMs) to interpret natural language\ninstructions and visual observations, enabling UAVs to navigate through dynamic\n3D spaces with improved accuracy and robustness. We present a multimodal\nnavigation agent equipped with a fine-grained spatial verbalizer and a history\npath memory mechanism. These components allow the UAV to disambiguate spatial\ncontexts, handle ambiguous instructions, and backtrack when necessary. The\nframework also incorporates an NMPC module for dynamic obstacle avoidance,\nensuring precise trajectory tracking and collision prevention. To validate our\napproach, we developed a high-fidelity 3D urban simulation environment using\nAirSim, featuring realistic imagery and dynamic urban elements. Extensive\nexperiments demonstrate that SkyVLN significantly improves navigation success\nrates and efficiency, particularly in new and unseen environments.", "AI": {"tldr": "SkyVLN框架结合视觉语言导航（VLN）和非线性模型预测控制（NMPC），提升无人机在复杂城市环境中的自主性。", "motivation": "传统导航方法在动态3D环境中表现不足，需要更智能的解决方案。", "method": "利用大型语言模型（LLMs）解析自然语言指令和视觉观察，结合NMPC模块实现动态避障。", "result": "实验表明SkyVLN显著提高了导航成功率和效率。", "conclusion": "SkyVLN为无人机在复杂环境中的自主导航提供了有效解决方案。"}}
{"id": "2507.06750", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.06750", "abs": "https://arxiv.org/abs/2507.06750", "authors": ["Tohid Kargar Tasooji", "Ramviyas Parasuraman"], "title": "Distributed Fault-Tolerant Multi-Robot Cooperative Localization in Adversarial Environments", "comment": "Accepted to IROS 2025 Conference", "summary": "In multi-robot systems (MRS), cooperative localization is a crucial task for\nenhancing system robustness and scalability, especially in GPS-denied or\ncommunication-limited environments. However, adversarial attacks, such as\nsensor manipulation, and communication jamming, pose significant challenges to\nthe performance of traditional localization methods. In this paper, we propose\na novel distributed fault-tolerant cooperative localization framework to\nenhance resilience against sensor and communication disruptions in adversarial\nenvironments. We introduce an adaptive event-triggered communication strategy\nthat dynamically adjusts communication thresholds based on real-time sensing\nand communication quality. This strategy ensures optimal performance even in\nthe presence of sensor degradation or communication failure. Furthermore, we\nconduct a rigorous analysis of the convergence and stability properties of the\nproposed algorithm, demonstrating its resilience against bounded adversarial\nzones and maintaining accurate state estimation. Robotarium-based experiment\nresults show that our proposed algorithm significantly outperforms traditional\nmethods in terms of localization accuracy and communication efficiency,\nparticularly in adversarial settings. Our approach offers improved scalability,\nreliability, and fault tolerance for MRS, making it suitable for large-scale\ndeployments in real-world, challenging environments.", "AI": {"tldr": "提出了一种分布式容错协同定位框架，通过自适应事件触发通信策略提升多机器人系统在对抗环境中的鲁棒性。", "motivation": "在GPS缺失或通信受限的环境中，对抗性攻击（如传感器操纵和通信干扰）对传统定位方法构成挑战，需要增强系统的容错能力。", "method": "采用自适应事件触发通信策略，动态调整通信阈值，结合实时感知和通信质量，确保性能最优。", "result": "实验证明，该算法在定位精度和通信效率上显著优于传统方法，尤其在对抗环境中表现突出。", "conclusion": "该方法提升了多机器人系统的可扩展性、可靠性和容错能力，适用于现实世界中的大规模部署。"}}
{"id": "2507.06787", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.06787", "abs": "https://arxiv.org/abs/2507.06787", "authors": ["Sean Smith", "Emmanuel Witrant", "Ya-Jun Pan"], "title": "Stream Function-Based Navigation for Complex Quadcopter Obstacle Avoidance", "comment": null, "summary": "This article presents a novel stream function-based navigational control\nsystem for obstacle avoidance, where obstacles are represented as\ntwo-dimensional (2D) rigid surfaces in inviscid, incompressible flows. The\napproach leverages the vortex panel method (VPM) and incorporates safety\nmargins to control the stream function and flow properties around virtual\nsurfaces, enabling navigation in complex, partially observed environments using\nreal-time sensing. To address the limitations of the VPM in managing relative\ndistance and avoiding rapidly accelerating obstacles at close proximity, the\nsystem integrates a model predictive controller (MPC) based on higher-order\ncontrol barrier functions (HOCBF). This integration incorporates VPM trajectory\ngeneration, state estimation, and constraint handling into a receding-horizon\noptimization problem. The 2D rigid surfaces are enclosed using minimum bounding\nellipses (MBEs), while an adaptive Kalman filter (AKF) captures and predicts\nobstacle dynamics, propagating these estimates into the MPC-HOCBF for rapid\navoidance maneuvers. Evaluation is conducted using a PX4-powered Clover drone\nGazebo simulator and real-time experiments involving a COEX Clover quadcopter\nequipped with a 360 degree LiDAR sensor.", "AI": {"tldr": "提出了一种基于流函数的导航控制系统，用于避障，结合涡流面板法和模型预测控制，实现复杂环境中的实时导航。", "motivation": "解决在部分观测环境中避障的挑战，特别是在处理快速加速障碍物时的局限性。", "method": "结合涡流面板法（VPM）和基于高阶控制屏障函数（HOCBF）的模型预测控制器（MPC），利用最小包围椭圆（MBE）和自适应卡尔曼滤波器（AKF）处理障碍物动态。", "result": "在PX4驱动的Clover无人机Gazebo模拟器和实时实验中验证了系统的有效性。", "conclusion": "该系统能够有效处理复杂环境中的避障问题，特别是在动态障碍物场景下表现优异。"}}
{"id": "2507.06346", "categories": ["cs.RO", "stat.CO"], "pdf": "https://arxiv.org/pdf/2507.06346", "abs": "https://arxiv.org/abs/2507.06346", "authors": ["Li Zhou", "Elvan Ceyhan"], "title": "Solving the Constrained Random Disambiguation Path Problem via Lagrangian Relaxation and Graph Reduction", "comment": null, "summary": "We study a resource-constrained variant of the Random Disambiguation Path\n(RDP) problem, a generalization of the Stochastic Obstacle Scene (SOS) problem,\nin which a navigating agent must reach a target in a spatial environment\npopulated with uncertain obstacles. Each ambiguous obstacle may be\ndisambiguated at a (possibly) heterogeneous resource cost, subject to a global\ndisambiguation budget. We formulate this constrained planning problem as a\nWeight-Constrained Shortest Path Problem (WCSPP) with risk-adjusted edge costs\nthat incorporate probabilistic blockage and traversal penalties. To solve it,\nwe propose a novel algorithmic framework-COLOGR-combining Lagrangian relaxation\nwith a two-phase vertex elimination (TPVE) procedure. The method prunes\ninfeasible and suboptimal paths while provably preserving the optimal solution,\nand leverages dual bounds to guide efficient search. We establish correctness,\nfeasibility guarantees, and surrogate optimality under mild assumptions. Our\nanalysis also demonstrates that COLOGR frequently achieves zero duality gap and\noffers improved computational complexity over prior constrained path-planning\nmethods. Extensive simulation experiments validate the algorithm's robustness\nacross varying obstacle densities, sensor accuracies, and risk models,\nconsistently outperforming greedy baselines and approaching offline-optimal\nbenchmarks. The proposed framework is broadly applicable to stochastic network\ndesign, mobility planning, and constrained decision-making under uncertainty.", "AI": {"tldr": "研究了资源受限的随机消歧路径（RDP）问题，提出了一种结合拉格朗日松弛和两阶段顶点消除（TPVE）的新算法框架COLOGR，解决了带权约束的最短路径问题（WCSPP），并在实验中验证了其优越性。", "motivation": "解决在不确定障碍物环境中导航的资源受限路径规划问题，优化消歧成本与路径风险。", "method": "将问题建模为WCSPP，提出COLOGR框架，结合拉格朗日松弛和TPVE，修剪不可行和次优路径。", "result": "COLOGR在实验中表现优于贪心基线，接近离线最优基准，且计算复杂度优于现有方法。", "conclusion": "COLOGR框架适用于随机网络设计、移动规划和不确定性下的约束决策，具有广泛的应用潜力。"}}
{"id": "2507.06397", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06397", "abs": "https://arxiv.org/abs/2507.06397", "authors": ["Michalis Chatzispyrou", "Luke Horgan", "Hyunkil Hwang", "Harish Sathishchandra", "Monika Roznere", "Alberto Quattrini Li", "Philippos Mordohai", "Ioannis Rekleitis"], "title": "Mapping the Catacombs: An Underwater Cave Segment of the Devil's Eye System", "comment": "Presented at the 2025 IEEE ICRA Workshop on Field Robotics", "summary": "This paper presents a framework for mapping underwater caves. Underwater\ncaves are crucial for fresh water resource management, underwater archaeology,\nand hydrogeology. Mapping the cave's outline and dimensions, as well as\ncreating photorealistic 3D maps, is critical for enabling a better\nunderstanding of this underwater domain. In this paper, we present the mapping\nof an underwater cave segment (the catacombs) of the Devil's Eye cave system at\nGinnie Springs, FL. We utilized a set of inexpensive action cameras in\nconjunction with a dive computer to estimate the trajectories of the cameras\ntogether with a sparse point cloud. The resulting reconstructions are utilized\nto produce a one-dimensional retract of the cave passages in the form of the\naverage trajectory together with the boundaries (top, bottom, left, and right).\nThe use of the dive computer enables the observability of the z-dimension in\naddition to the roll and pitch in a visual/inertial framework (SVIn2). In\naddition, the keyframes generated by SVIn2 together with the estimated camera\nposes for select areas are used as input to a global optimization (bundle\nadjustment) framework -- COLMAP -- in order to produce a dense reconstruction\nof those areas. The same cave segment is manually surveyed using the MNemo V2\ninstrument, providing an additional set of measurements validating the proposed\napproach. It is worth noting that with the use of action cameras, the primary\ncomponents of a cave map can be constructed. Furthermore, with the utilization\nof a global optimization framework guided by the results of VI-SLAM package\nSVIn2, photorealistic dense 3D representations of selected areas can be\nreconstructed.", "AI": {"tldr": "本文提出了一种低成本的水下洞穴测绘框架，结合动作相机和潜水电脑生成稀疏点云和3D地图，并通过全局优化实现局部区域的密集重建。", "motivation": "水下洞穴对淡水资源管理、水下考古和水文地质学至关重要，但传统测绘方法成本高且复杂。本文旨在开发一种低成本、高效的测绘方法。", "method": "使用动作相机和潜水电脑估计相机轨迹和稀疏点云，结合SVIn2框架优化姿态，并通过COLMAP进行全局优化生成密集重建。", "result": "成功生成了洞穴的一维轨迹和边界，并通过手动测量验证了方法的准确性。动作相机结合全局优化可实现局部区域的3D密集重建。", "conclusion": "低成本的动作相机和潜水电脑结合优化框架，能够有效测绘水下洞穴，为洞穴研究提供了实用工具。"}}
{"id": "2507.06404", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06404", "abs": "https://arxiv.org/abs/2507.06404", "authors": ["Matteo Tiezzi", "Tommaso Apicella", "Carlos Cardenas-Perez", "Giovanni Fregonese", "Stefano Dafarra", "Pietro Morerio", "Daniele Pucci", "Alessio Del Bue"], "title": "Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction", "comment": null, "summary": "Evaluating and comparing the performance of autonomous Humanoid Robots is\nchallenging, as success rate metrics are difficult to reproduce and fail to\ncapture the complexity of robot movement trajectories, critical in Human-Robot\nInteraction and Collaboration (HRIC). To address these challenges, we propose a\ngeneral evaluation framework that measures the quality of Imitation Learning\n(IL) methods by focusing on trajectory performance. We devise the Neural Meta\nEvaluator (NeME), a deep learning model trained to classify actions from robot\njoint trajectories. NeME serves as a meta-evaluator to compare the performance\nof robot control policies, enabling policy evaluation without requiring human\ninvolvement in the loop. We validate our framework on ergoCub, a humanoid\nrobot, using teleoperation data and comparing IL methods tailored to the\navailable platform. The experimental results indicate that our method is more\naligned with the success rate obtained on the robot than baselines, offering a\nreproducible, systematic, and insightful means for comparing the performance of\nmultimodal imitation learning approaches in complex HRI tasks.", "AI": {"tldr": "提出了一种基于轨迹性能的通用评估框架NeME，用于比较人形机器人模仿学习方法的性能，无需人工参与。", "motivation": "评估人形机器人性能的挑战在于成功率指标难以复现且无法捕捉复杂运动轨迹，这在人机交互中至关重要。", "method": "设计了Neural Meta Evaluator (NeME)，一种深度学习模型，通过分类机器人关节轨迹来评估控制策略。", "result": "实验验证表明，该方法比基线更符合机器人实际成功率，提供了可复现且系统的评估手段。", "conclusion": "NeME为复杂人机交互任务中的多模态模仿学习方法提供了有效的性能比较工具。"}}
{"id": "2507.06519", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.06519", "abs": "https://arxiv.org/abs/2507.06519", "authors": ["Yuhan Liu", "Xinyu Zhang", "Haonan Chang", "Abdeslam Boularias"], "title": "Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies", "comment": "Accepted at IROS2025. Project website:\n  https://jaysparrow.github.io/rit", "summary": "This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where\na robot must repeatedly perform high-precision insertions, such as screwing a\nnut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving\nmillimeter-level accuracy and maintaining consistent performance over multiple\nrepetitions, particularly when factors like nut rotation and friction introduce\nadditional complexity. We propose a sim-to-real framework that integrates a\nreinforcement learning-based insertion policy with a failure forecasting\nmodule. By representing the wrench's pose in the nut's coordinate frame rather\nthan the robot's frame, our approach significantly enhances sim-to-real\ntransferability. The insertion policy, trained in simulation, leverages\nreal-time 6D pose tracking to execute precise alignment, insertion, and\nrotation maneuvers. Simultaneously, a neural network predicts potential\nexecution failures, triggering a simple recovery mechanism that lifts the\nwrench and retries the insertion. Extensive experiments in both simulated and\nreal-world environments demonstrate that our method not only achieves a high\none-time success rate but also robustly maintains performance over long-horizon\nrepetitive tasks.", "AI": {"tldr": "提出了一种基于强化学习和故障预测的sim-to-real框架，用于解决机器人高精度重复插入任务（RIT）的挑战。", "motivation": "解决机器人执行高精度重复插入任务（如拧螺母）时面临的毫米级精度和长时间一致性问题。", "method": "结合强化学习的插入策略和故障预测模块，将工具姿态表示为螺母坐标系而非机器人坐标系，提升sim-to-real迁移能力。", "result": "在仿真和真实环境中均实现高一次性成功率，并能长期保持稳定性能。", "conclusion": "该方法有效解决了RIT任务中的精度和鲁棒性问题，具有实际应用潜力。"}}
{"id": "2507.06562", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06562", "abs": "https://arxiv.org/abs/2507.06562", "authors": ["Keita Yoneda", "Kento Kawaharazuka", "Temma Suzuki", "Takahiro Hattori", "Kei Okada"], "title": "KLEIYN : A Quadruped Robot with an Active Waist for Both Locomotion and Wall Climbing", "comment": "Accepted at IROS2025, website -\n  https://keitayoneda.github.io/kleiyn-chimney-climbing/, YouTube -\n  https://www.youtube.com/watch?v=vDmSfkazAvI", "summary": "In recent years, advancements in hardware have enabled quadruped robots to\noperate with high power and speed, while robust locomotion control using\nreinforcement learning (RL) has also been realized. As a result, expectations\nare rising for the automation of tasks such as material transport and\nexploration in unknown environments. However, autonomous locomotion in rough\nterrains with significant height variations requires vertical movement, and\nrobots capable of performing such movements stably, along with their control\nmethods, have not yet been fully established. In this study, we developed the\nquadruped robot KLEIYN, which features a waist joint, and aimed to expand\nquadruped locomotion by enabling chimney climbing through RL. To facilitate the\nlearning of vertical motion, we introduced Contact-Guided Curriculum Learning\n(CGCL). As a result, KLEIYN successfully climbed walls ranging from 800 mm to\n1000 mm in width at an average speed of 150 mm/s, 50 times faster than\nconventional robots. Furthermore, we demonstrated that the introduction of a\nwaist joint improves climbing performance, particularly enhancing tracking\nability on narrow walls.", "AI": {"tldr": "开发了具有腰部关节的四足机器人KLEIYN，通过强化学习实现垂直运动（如爬烟囱），并引入接触引导课程学习（CGCL）方法，显著提升了机器人在狭窄墙面的攀爬性能。", "motivation": "尽管硬件和强化学习控制使四足机器人具备高速运动能力，但在高度变化大的崎岖地形中稳定垂直运动的机器人及其控制方法尚未成熟。", "method": "开发了带腰部关节的机器人KLEIYN，采用强化学习和CGCL方法学习垂直运动。", "result": "KLEIYN能以150 mm/s的速度攀爬800-1000 mm宽的墙面，速度是传统机器人的50倍，且腰部关节显著提升了在狭窄墙面的跟踪能力。", "conclusion": "通过腰部关节和CGCL方法，KLEIYN实现了高效的垂直运动，为四足机器人在复杂地形中的应用提供了新思路。"}}
{"id": "2507.06574", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06574", "abs": "https://arxiv.org/abs/2507.06574", "authors": ["Thomas Touma", "Ersin Daş", "Erica Tevere", "Martin Feather", "Ksenia Kolcio", "Maurice Prather", "Alberto Candela", "Ashish Goel", "Erik Kramer", "Hari Nayar", "Lorraine Fesq", "Joel W. Burdick"], "title": "AI Space Cortex: An Experimental System for Future Era Space Exploration", "comment": null, "summary": "Our Robust, Explainable Autonomy for Scientific Icy Moon Operations (REASIMO)\neffort contributes to NASA's Concepts for Ocean worlds Life Detection\nTechnology (COLDTech) program, which explores science platform technologies for\nocean worlds such as Europa and Enceladus. Ocean world missions pose\nsignificant operational challenges. These include long communication lags,\nlimited power, and lifetime limitations caused by radiation damage and hostile\nconditions. Given these operational limitations, onboard autonomy will be vital\nfor future Ocean world missions. Besides the management of nominal lander\noperations, onboard autonomy must react appropriately in the event of\nanomalies. Traditional spacecraft rely on a transition into 'safe-mode' in\nwhich non-essential components and subsystems are powered off to preserve\nsafety and maintain communication with Earth. For a severely time-limited Ocean\nworld mission, resolutions to these anomalies that can be executed without\nEarth-in-the-loop communication and associated delays are paramount for\ncompletion of the mission objectives and science goals. To address these\nchallenges, the REASIMO effort aims to demonstrate a robust level of\nAI-assisted autonomy for such missions, including the ability to detect and\nrecover from anomalies, and to perform missions based on pre-trained behaviors\nrather than hard-coded, predetermined logic like all prior space missions. We\ndeveloped an AI-assisted, personality-driven, intelligent framework for control\nof an Ocean world mission by combining a mix of advanced technologies. To\ndemonstrate the capabilities of the framework, we perform tests of autonomous\nsampling operations on a lander-manipulator testbed at the NASA Jet Propulsion\nLaboratory, approximating possible surface conditions such a mission might\nencounter.", "AI": {"tldr": "REASIMO项目旨在为NASA的COLDTech计划开发AI辅助的自主系统，以应对海洋世界任务中的通信延迟、能源限制和辐射等挑战，实现异常检测与恢复，并通过预训练行为执行任务。", "motivation": "海洋世界任务（如欧罗巴和恩塞拉多斯）面临通信延迟、能源限制和恶劣环境等挑战，传统安全模式无法满足任务需求，需要更高级的自主性。", "method": "结合AI技术和预训练行为，开发了一个智能框架，用于任务控制和异常恢复，并在NASA喷气推进实验室的测试平台上验证自主采样操作。", "result": "测试验证了框架在模拟海洋世界表面条件下的自主操作能力，展示了其异常处理和任务执行的潜力。", "conclusion": "REASIMO框架为未来海洋世界任务提供了更高效、自主的解决方案，有望提升任务成功率和科学目标达成。"}}
{"id": "2507.06605", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06605", "abs": "https://arxiv.org/abs/2507.06605", "authors": ["Xinyu Wu"], "title": "Growing Trees with an Agent: Accelerating RRTs with Learned, Multi-Step Episodic Exploration", "comment": null, "summary": "Classical sampling-based motion planners like the RRTs suffer from\ninefficiencies, particularly in cluttered or high-dimensional spaces, due to\ntheir reliance on undirected, random sampling. This paper introduces the\nEpisodic RRT, a novel hybrid planning framework that replaces the primitive of\na random point with a learned, multi-step \"exploratory episode\" generated by a\nDeep Reinforcement Learning agent. By making the DRL agent the engine of\nexploration, ERRT transforms the search process from a diffuse, volumetric\nexpansion into a directed, branch-like growth. This paradigm shift yields key\nadvantages: it counters the curse of dimensionality with focused exploration,\nminimizes expensive collision checks by proactively proposing locally valid\npaths, and improves connectivity by generating inherently connected path\nsegments. We demonstrate through extensive empirical evaluation across 2D, 3D,\nand 6D environments that ERRT and its variants consistently and significantly\noutperform their classical counterparts. In a challenging 6D robotic arm\nscenario, ERRT achieves a 98% success rate compared to 19% for RRT, is up to\n107x faster, reduces collision checks by over 99.6%, and finds initial paths\nthat are nearly 50% shorter. Furthermore, its asymptotically optimal variant,\nERRT*, demonstrates vastly superior anytime performance, refining solutions to\nnear-optimality up to 29x faster than standard RRT* in 3D environments. Code:\nhttps://xinyuwuu.github.io/Episodic_RRT/.", "AI": {"tldr": "论文提出了一种名为Episodic RRT（ERRT）的新型混合规划框架，通过深度强化学习（DRL）生成多步探索片段，显著提升了经典RRT在复杂或高维空间中的效率。", "motivation": "经典RRT依赖随机采样，导致在高维或复杂环境中效率低下，需要一种更高效的探索方法。", "method": "ERRT用DRL生成的多步探索片段替代随机点，将搜索过程从随机扩展转变为定向分支生长。", "result": "在2D、3D和6D环境中，ERRT及其变体显著优于经典RRT，6D机械臂场景中成功率从19%提升至98%，速度提升107倍，碰撞检测减少99.6%。", "conclusion": "ERRT通过DRL驱动的定向探索，显著提升了运动规划的效率和质量，其变体ERRT*在优化性能上表现更优。"}}
{"id": "2507.06625", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.06625", "abs": "https://arxiv.org/abs/2507.06625", "authors": ["Shizhe Cai", "Jayadeep Jacob", "Zeya Yin", "Fabio Ramos"], "title": "Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic", "comment": "9 pages, 10 figures", "summary": "Deep reinforcement learning has shown remarkable success in continuous\ncontrol tasks, yet often requires extensive training data, struggles with\ncomplex, long-horizon planning, and fails to maintain safety constraints during\noperation. Meanwhile, Model Predictive Control (MPC) offers explainability and\nconstraint satisfaction, but typically yields only locally optimal solutions\nand demands careful cost function design. This paper introduces the Q-guided\nSTein variational model predictive Actor-Critic (Q-STAC), a novel framework\nthat bridges these approaches by integrating Bayesian MPC with actor-critic\nreinforcement learning through constrained Stein Variational Gradient Descent\n(SVGD). Our method optimizes control sequences directly using learned Q-values\nas objectives, eliminating the need for explicit cost function design while\nleveraging known system dynamics to enhance sample efficiency and ensure\ncontrol signals remain within safe boundaries. Extensive experiments on 2D\nnavigation and robotic manipulation tasks demonstrate that Q-STAC achieves\nsuperior sample efficiency, robustness, and optimality compared to\nstate-of-the-art algorithms, while maintaining the high expressiveness of\npolicy distributions. Experiment videos are available on our website:\nhttps://sites.google.com/view/q-stac", "AI": {"tldr": "Q-STAC框架结合贝叶斯MPC与演员-评论家强化学习，通过约束Stein变分梯度下降优化控制序列，提升样本效率与安全性。", "motivation": "解决深度强化学习在连续控制任务中数据需求高、长时规划难、安全性不足的问题，同时弥补MPC局部最优和成本函数设计的局限性。", "method": "整合贝叶斯MPC与演员-评论家强化学习，利用约束SVGD优化控制序列，以Q值替代显式成本函数设计。", "result": "在2D导航和机器人操作任务中，Q-STAC在样本效率、鲁棒性和最优性上优于现有算法，同时保持策略分布的高表达能力。", "conclusion": "Q-STAC成功结合了强化学习与MPC的优势，为复杂控制任务提供了高效、安全且可解释的解决方案。"}}
{"id": "2507.06690", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06690", "abs": "https://arxiv.org/abs/2507.06690", "authors": ["Guobin Zhu", "Rui Zhou", "Wenkang Ji", "Hongyin Zhang", "Donglin Wang", "Shiyu Zhao"], "title": "Multi-Task Multi-Agent Reinforcement Learning via Skill Graphs", "comment": "Conditionally accepted by IEEE Robotics and Automation Letters", "summary": "Multi-task multi-agent reinforcement learning (MT-MARL) has recently gained\nattention for its potential to enhance MARL's adaptability across multiple\ntasks. However, it is challenging for existing multi-task learning methods to\nhandle complex problems, as they are unable to handle unrelated tasks and\npossess limited knowledge transfer capabilities. In this paper, we propose a\nhierarchical approach that efficiently addresses these challenges. The\nhigh-level module utilizes a skill graph, while the low-level module employs a\nstandard MARL algorithm. Our approach offers two contributions. First, we\nconsider the MT-MARL problem in the context of unrelated tasks, expanding the\nscope of MTRL. Second, the skill graph is used as the upper layer of the\nstandard hierarchical approach, with training independent of the lower layer,\neffectively handling unrelated tasks and enhancing knowledge transfer\ncapabilities. Extensive experiments are conducted to validate these advantages\nand demonstrate that the proposed method outperforms the latest hierarchical\nMAPPO algorithms. Videos and code are available at\nhttps://github.com/WindyLab/MT-MARL-SG", "AI": {"tldr": "提出了一种分层方法，通过技能图和高层模块解决多任务多智能体强化学习中的无关任务和知识转移问题。", "motivation": "现有方法难以处理无关任务且知识转移能力有限，需要更高效的方法。", "method": "采用分层方法，高层模块使用技能图，低层模块采用标准MARL算法。", "result": "实验表明该方法优于最新的分层MAPPO算法。", "conclusion": "该方法扩展了MTRL的范围，有效处理无关任务并提升知识转移能力。"}}
{"id": "2507.06700", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.06700", "abs": "https://arxiv.org/abs/2507.06700", "authors": ["Pranav Pandey", "Ramviyas Parasuraman", "Prashant Doshi"], "title": "Integrating Perceptions: A Human-Centered Physical Safety Model for Human-Robot Interaction", "comment": "Accepted to IEEE RO-MAN 2025 Conference", "summary": "Ensuring safety in human-robot interaction (HRI) is essential to foster user\ntrust and enable the broader adoption of robotic systems. Traditional safety\nmodels primarily rely on sensor-based measures, such as relative distance and\nvelocity, to assess physical safety. However, these models often fail to\ncapture subjective safety perceptions, which are shaped by individual traits\nand contextual factors. In this paper, we introduce and analyze a parameterized\ngeneral safety model that bridges the gap between physical and perceived safety\nby incorporating a personalization parameter, $\\rho$, into the safety\nmeasurement framework to account for individual differences in safety\nperception. Through a series of hypothesis-driven human-subject studies in a\nsimulated rescue scenario, we investigate how emotional state, trust, and robot\nbehavior influence perceived safety. Our results show that $\\rho$ effectively\ncaptures meaningful individual differences, driven by affective responses,\ntrust in task consistency, and clustering into distinct user types.\nSpecifically, our findings confirm that predictable and consistent robot\nbehavior as well as the elicitation of positive emotional states, significantly\nenhance perceived safety. Moreover, responses cluster into a small number of\nuser types, supporting adaptive personalization based on shared safety models.\nNotably, participant role significantly shapes safety perception, and repeated\nexposure reduces perceived safety for participants in the casualty role,\nemphasizing the impact of physical interaction and experiential change. These\nfindings highlight the importance of adaptive, human-centered safety models\nthat integrate both psychological and behavioral dimensions, offering a pathway\ntoward more trustworthy and effective HRI in safety-critical domains.", "AI": {"tldr": "本文提出了一种参数化通用安全模型，通过个性化参数ρ整合物理安全和感知安全，研究情感状态、信任和机器人行为对感知安全的影响。", "motivation": "传统安全模型仅依赖传感器数据，无法捕捉主观安全感知，因此需要结合个体差异和情境因素。", "method": "通过模拟救援场景的人体实验，研究情感、信任和机器人行为对安全感知的影响，并引入参数ρ量化个体差异。", "result": "ρ能有效捕捉个体差异，机器人行为的可预测性和一致性以及积极情感状态显著提升感知安全。参与者角色和重复暴露也影响安全感知。", "conclusion": "研究强调了整合心理和行为维度的自适应、以人为本的安全模型的重要性，为安全关键领域的人机交互提供了更可信的路径。"}}
{"id": "2507.06710", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06710", "abs": "https://arxiv.org/abs/2507.06710", "authors": ["Zhenyang Liu", "Yikai Wang", "Kuanning Wang", "Longfei Liang", "Xiangyang Xue", "Yanwei Fu"], "title": "Spatial-Temporal Aware Visuomotor Diffusion Policy Learning", "comment": null, "summary": "Visual imitation learning is effective for robots to learn versatile tasks.\nHowever, many existing methods rely on behavior cloning with supervised\nhistorical trajectories, limiting their 3D spatial and 4D spatiotemporal\nawareness. Consequently, these methods struggle to capture the 3D structures\nand 4D spatiotemporal relationships necessary for real-world deployment. In\nthis work, we propose 4D Diffusion Policy (DP4), a novel visual imitation\nlearning method that incorporates spatiotemporal awareness into diffusion-based\npolicies. Unlike traditional approaches that rely on trajectory cloning, DP4\nleverages a dynamic Gaussian world model to guide the learning of 3D spatial\nand 4D spatiotemporal perceptions from interactive environments. Our method\nconstructs the current 3D scene from a single-view RGB-D observation and\npredicts the future 3D scene, optimizing trajectory generation by explicitly\nmodeling both spatial and temporal dependencies. Extensive experiments across\n17 simulation tasks with 173 variants and 3 real-world robotic tasks\ndemonstrate that the 4D Diffusion Policy (DP4) outperforms baseline methods,\nimproving the average simulation task success rate by 16.4% (Adroit), 14%\n(DexArt), and 6.45% (RLBench), and the average real-world robotic task success\nrate by 8.6%.", "AI": {"tldr": "提出了一种名为4D Diffusion Policy (DP4)的新方法，通过动态高斯世界模型增强3D空间和4D时空感知，显著提升了视觉模仿学习的性能。", "motivation": "现有视觉模仿学习方法依赖历史轨迹的行为克隆，缺乏3D空间和4D时空感知能力，限制了实际应用效果。", "method": "DP4利用动态高斯世界模型从交互环境中学习3D空间和4D时空感知，通过单视角RGB-D观测构建当前3D场景并预测未来3D场景，优化轨迹生成。", "result": "在17个仿真任务和3个真实机器人任务中，DP4平均成功率分别提升16.4%、14%、6.45%和8.6%，显著优于基线方法。", "conclusion": "DP4通过引入时空感知能力，显著提升了视觉模仿学习的性能，适用于复杂现实场景。"}}
{"id": "2507.06747", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.06747", "abs": "https://arxiv.org/abs/2507.06747", "authors": ["Daojie Peng", "Jiahang Cao", "Qiang Zhang", "Jun Ma"], "title": "LOVON: Legged Open-Vocabulary Object Navigator", "comment": "9 pages, 10 figures; Project Page:\n  https://daojiepeng.github.io/LOVON/", "summary": "Object navigation in open-world environments remains a formidable and\npervasive challenge for robotic systems, particularly when it comes to\nexecuting long-horizon tasks that require both open-world object detection and\nhigh-level task planning. Traditional methods often struggle to integrate these\ncomponents effectively, and this limits their capability to deal with complex,\nlong-range navigation missions. In this paper, we propose LOVON, a novel\nframework that integrates large language models (LLMs) for hierarchical task\nplanning with open-vocabulary visual detection models, tailored for effective\nlong-range object navigation in dynamic, unstructured environments. To tackle\nreal-world challenges including visual jittering, blind zones, and temporary\ntarget loss, we design dedicated solutions such as Laplacian Variance Filtering\nfor visual stabilization. We also develop a functional execution logic for the\nrobot that guarantees LOVON's capabilities in autonomous navigation, task\nadaptation, and robust task completion. Extensive evaluations demonstrate the\nsuccessful completion of long-sequence tasks involving real-time detection,\nsearch, and navigation toward open-vocabulary dynamic targets. Furthermore,\nreal-world experiments across different legged robots (Unitree Go2, B2, and\nH1-2) showcase the compatibility and appealing plug-and-play feature of LOVON.", "AI": {"tldr": "LOVON是一个结合大型语言模型（LLMs）和开放词汇视觉检测模型的新框架，用于动态非结构化环境中的长距离物体导航。", "motivation": "解决传统方法在复杂长距离导航任务中难以有效整合开放世界物体检测和高级任务规划的挑战。", "method": "集成LLMs进行分层任务规划，结合开放词汇视觉检测模型，并设计视觉稳定化（如拉普拉斯方差滤波）和功能执行逻辑。", "result": "实验表明LOVON能成功完成涉及实时检测、搜索和导航的长序列任务，并在不同机器人上展示兼容性。", "conclusion": "LOVON为动态环境中的长距离物体导航提供了高效、兼容且鲁棒的解决方案。"}}
{"id": "2507.06822", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06822", "abs": "https://arxiv.org/abs/2507.06822", "authors": ["Wei Xu", "Yanchao Zhao", "Weichao Guo", "Xinjun Sheng"], "title": "Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand", "comment": "Accepted by 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025). copyright 2025 IEEE. Final version to appear\n  in IEEE Xplore", "summary": "Manipulating articulated tools, such as tweezers or scissors, has rarely been\nexplored in previous research. Unlike rigid tools, articulated tools change\ntheir shape dynamically, creating unique challenges for dexterous robotic\nhands. In this work, we present a hierarchical, goal-conditioned reinforcement\nlearning (GCRL) framework to improve the manipulation capabilities of\nanthropomorphic robotic hands using articulated tools. Our framework comprises\ntwo policy layers: (1) a low-level policy that enables the dexterous hand to\nmanipulate the tool into various configurations for objects of different sizes,\nand (2) a high-level policy that defines the tool's goal state and controls the\nrobotic arm for object-picking tasks. We employ an encoder, trained on\nsynthetic pointclouds, to estimate the tool's affordance states--specifically,\nhow different tool configurations (e.g., tweezer opening angles) enable\ngrasping of objects of varying sizes--from input point clouds, thereby enabling\nprecise tool manipulation. We also utilize a privilege-informed heuristic\npolicy to generate replay buffer, improving the training efficiency of the\nhigh-level policy. We validate our approach through real-world experiments,\nshowing that the robot can effectively manipulate a tweezer-like tool to grasp\nobjects of diverse shapes and sizes with a 70.8 % success rate. This study\nhighlights the potential of RL to advance dexterous robotic manipulation of\narticulated tools.", "AI": {"tldr": "提出了一种分层目标条件强化学习框架，用于提升仿人机器人手对铰接工具的操控能力，实验成功率达70.8%。", "motivation": "铰接工具的动态形状变化为机器人操控带来独特挑战，现有研究较少涉及。", "method": "采用分层策略：低层策略控制工具配置，高层策略定义目标状态并生成回放缓冲区。", "result": "机器人能有效操控类似镊子的工具抓取不同形状和大小的物体，成功率为70.8%。", "conclusion": "强化学习在铰接工具操控方面具有潜力。"}}
{"id": "2507.06824", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06824", "abs": "https://arxiv.org/abs/2507.06824", "authors": ["Gabriel Arslan Waltersson", "Yiannis Karayiannidis"], "title": "Friction Estimation for In-Hand Planar Motion", "comment": null, "summary": "This paper presents a method for online estimation of contact properties\nduring in-hand sliding manipulation with a parallel gripper. We estimate the\nstatic and Coulomb friction as well as the contact radius from tactile\nmeasurements of contact forces and sliding velocities. The method is validated\nin both simulation and real-world experiments. Furthermore, we propose a\nheuristic to deal with fast slip-stick dynamics which can adversely affect the\nestimation.", "AI": {"tldr": "提出了一种在线估计平行夹持器滑动操作中接触特性的方法，包括静摩擦、库仑摩擦和接触半径，并通过仿真和实验验证。", "motivation": "研究目的是为了在滑动操作中实时估计接触特性，以提升夹持器的操作精度和适应性。", "method": "通过触觉测量接触力和滑动速度，估计静态摩擦、库仑摩擦及接触半径，并提出启发式方法处理快速滑移-粘附动态。", "result": "方法在仿真和实际实验中均得到验证，能够有效估计接触特性。", "conclusion": "该方法为滑动操作中的接触特性估计提供了实用解决方案，并解决了快速滑移-粘附动态的干扰问题。"}}
{"id": "2507.06884", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06884", "abs": "https://arxiv.org/abs/2507.06884", "authors": ["Dong Bi", "Yongqi Zhao", "Zhengguo Gu", "Tomislav Mihalj", "Jia Hu", "Arno Eichberger"], "title": "Toward a Full-Stack Co-Simulation Platform for Testing of Automated Driving Systems", "comment": "IEEE International Conference on Intelligent Transportation Systems\n  (ITSC) 2025", "summary": "Virtual testing has emerged as an effective approach to accelerate the\ndeployment of automated driving systems. Nevertheless, existing simulation\ntoolchains encounter difficulties in integrating rapid, automated scenario\ngeneration with simulation environments supporting advanced automated driving\ncapabilities. To address this limitation, a full-stack toolchain is presented,\nenabling automatic scenario generation from real-world datasets and efficient\nvalidation through a co-simulation platform based on CarMaker, ROS, and Apollo.\nThe simulation results demonstrate the effectiveness of the proposed toolchain.\nA demonstration video showcasing the toolchain is available at the provided\nlink: https://youtu.be/taJw_-CmSiY.", "AI": {"tldr": "提出了一种全栈工具链，用于从真实数据自动生成场景并通过CarMaker、ROS和Apollo的协同仿真平台高效验证自动驾驶系统。", "motivation": "现有仿真工具链难以整合快速自动场景生成与支持高级自动驾驶能力的仿真环境。", "method": "开发了基于CarMaker、ROS和Apollo的协同仿真平台，支持从真实数据自动生成场景。", "result": "仿真结果验证了该工具链的有效性。", "conclusion": "该工具链解决了现有仿真工具链的局限性，加速了自动驾驶系统的部署。"}}
{"id": "2507.06905", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06905", "abs": "https://arxiv.org/abs/2507.06905", "authors": ["Wandong Sun", "Luying Feng", "Baoshi Cao", "Yang Liu", "Yaochu Jin", "Zongwu Xie"], "title": "ULC: A Unified and Fine-Grained Controller for Humanoid Loco-Manipulation", "comment": null, "summary": "Loco-Manipulation for humanoid robots aims to enable robots to integrate\nmobility with upper-body tracking capabilities. Most existing approaches adopt\nhierarchical architectures that decompose control into isolated upper-body\n(manipulation) and lower-body (locomotion) policies. While this decomposition\nreduces training complexity, it inherently limits coordination between\nsubsystems and contradicts the unified whole-body control exhibited by humans.\nWe demonstrate that a single unified policy can achieve a combination of\ntracking accuracy, large workspace, and robustness for humanoid\nloco-manipulation. We propose the Unified Loco-Manipulation Controller (ULC), a\nsingle-policy framework that simultaneously tracks root velocity, root height,\ntorso rotation, and dual-arm joint positions in an end-to-end manner, proving\nthe feasibility of unified control without sacrificing performance. We achieve\nthis unified control through key technologies: sequence skill acquisition for\nprogressive learning complexity, residual action modeling for fine-grained\ncontrol adjustments, command polynomial interpolation for smooth motion\ntransitions, random delay release for robustness to deploy variations, load\nrandomization for generalization to external disturbances, and\ncenter-of-gravity tracking for providing explicit policy gradients to maintain\nstability. We validate our method on the Unitree G1 humanoid robot with 3-DOF\n(degrees-of-freedom) waist. Compared with strong baselines, ULC shows better\ntracking performance to disentangled methods and demonstrating larger workspace\ncoverage. The unified dual-arm tracking enables precise manipulation under\nexternal loads while maintaining coordinated whole-body control for complex\nloco-manipulation tasks.", "AI": {"tldr": "论文提出了一种统一的人形机器人运动与操作控制策略（ULC），通过单一策略实现全身协调控制，优于传统分层方法。", "motivation": "现有分层控制方法限制了人形机器人上下肢的协调性，无法实现类似人类的全身统一控制。", "method": "采用单一策略框架（ULC），结合序列技能学习、残差动作建模、命令多项式插值等技术，实现端到端的全身控制。", "result": "在Unitree G1机器人上验证，ULC在跟踪精度、工作空间覆盖和抗干扰能力上优于传统方法。", "conclusion": "统一控制策略可行且高效，为复杂运动与操作任务提供了新思路。"}}
{"id": "2507.06960", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.06960", "abs": "https://arxiv.org/abs/2507.06960", "authors": ["Samuel Matloob", "Ayan Dutta", "O. Patrick Kreidl", "Swapnonel Roy", "Ladislau Bölöni"], "title": "Bounomodes: the grazing ox algorithm for exploration of clustered anomalies", "comment": null, "summary": "A common class of algorithms for informative path planning (IPP) follows\nboustrophedon (\"as the ox turns\") patterns, which aim to achieve uniform area\ncoverage. However, IPP is often applied in scenarios where anomalies, such as\nplant diseases, pollution, or hurricane damage, appear in clusters. In such\ncases, prioritizing the exploration of anomalous regions over uniform coverage\nis beneficial. This work introduces a class of algorithms referred to as\nbounom\\=odes (\"as the ox grazes\"), which alternates between uniform\nboustrophedon sampling and targeted exploration of detected anomaly clusters.\nWhile uniform sampling can be designed using geometric principles, close\nexploration of clusters depends on the spatial distribution of anomalies and\nmust be learned. In our implementation, the close exploration behavior is\nlearned using deep reinforcement learning algorithms. Experimental evaluations\ndemonstrate that the proposed approach outperforms several established\nbaselines.", "AI": {"tldr": "论文提出了一种名为“bounom=odes”的算法，结合均匀采样和异常区域针对性探索，优于传统方法。", "motivation": "传统IPP算法采用均匀覆盖模式，但在异常集群场景下效果不佳，需优先探索异常区域。", "method": "结合均匀的boustrophedon采样和基于深度强化学习的异常集群针对性探索。", "result": "实验表明，该方法优于多种基线算法。", "conclusion": "bounom=odes算法在异常集群场景下表现更优，具有实际应用潜力。"}}
