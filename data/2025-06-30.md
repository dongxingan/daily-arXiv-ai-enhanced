<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 18]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models](https://arxiv.org/abs/2506.21627)
*Shiyi Wang,Wenbo Li,Yiteng Chen,Qingyao Wu,Huiping Zhuang*

Main category: cs.RO

TL;DR: FrankenBot是一个基于视觉语言模型（VLM）的机器人操作框架，通过模拟人脑结构实现多功能集成与高效操作。


<details>
  <summary>Details</summary>
Motivation: 开发一个能在复杂动态环境中执行多样化任务的通用机器人系统，需整合任务规划、策略生成等功能，但现有方法多为单一功能实现。

Method: 采用分治策略和人脑结构启发，设计FrankenBot框架，将不同功能映射到类似人脑的模块（如皮层、小脑等），并优化协调机制。

Result: 实验表明，FrankenBot在异常检测、长期记忆、操作效率和稳定性方面表现优异，无需微调或重新训练。

Conclusion: FrankenBot通过统一认知架构实现了功能全面与高效操作的平衡，为机器人系统设计提供了新思路。

Abstract: Developing a general robot manipulation system capable of performing a wide
range of tasks in complex, dynamic, and unstructured real-world environments
has long been a challenging task. It is widely recognized that achieving
human-like efficiency and robustness manipulation requires the robotic brain to
integrate a comprehensive set of functions, such as task planning, policy
generation, anomaly monitoring and handling, and long-term memory, achieving
high-efficiency operation across all functions. Vision-Language Models (VLMs),
pretrained on massive multimodal data, have acquired rich world knowledge,
exhibiting exceptional scene understanding and multimodal reasoning
capabilities. However, existing methods typically focus on realizing only a
single function or a subset of functions within the robotic brain, without
integrating them into a unified cognitive architecture. Inspired by a
divide-and-conquer strategy and the architecture of the human brain, we propose
FrankenBot, a VLM-driven, brain-morphic robotic manipulation framework that
achieves both comprehensive functionality and high operational efficiency. Our
framework includes a suite of components, decoupling a part of key functions
from frequent VLM calls, striking an optimal balance between functional
completeness and system efficiency. Specifically, we map task planning, policy
generation, memory management, and low-level interfacing to the cortex,
cerebellum, temporal lobe-hippocampus complex, and brainstem, respectively, and
design efficient coordination mechanisms for the modules. We conducted
comprehensive experiments in both simulation and real-world robotic
environments, demonstrating that our method offers significant advantages in
anomaly detection and handling, long-term memory, operational efficiency, and
stability -- all without requiring any fine-tuning or retraining.

</details>


### [2] [Ark: An Open-source Python-based Framework for Robot Learning](https://arxiv.org/abs/2506.21628)
*Magnus Dierking,Christopher E. Mower,Sarthak Das,Huang Helong,Jiacheng Qiu,Cody Reading,Wei Chen,Huidong Liang,Huang Guowei,Jan Peters,Quan Xingyue,Jun Wang,Haitham Bou-Ammar*

Main category: cs.RO

TL;DR: ARK是一个开源的、以Python为核心的机器人框架，旨在简化机器人软件开发，降低学习门槛，并加速自主机器人的研究和商业部署。


<details>
  <summary>Details</summary>
Motivation: 当前机器人软件栈复杂且分散，需要低级的C/C++专业知识，与Python主导的现代AI生态系统形成鲜明对比。ARK旨在填补这一差距，提供更便捷的开发体验。

Method: ARK提供Gym风格的环境接口，支持数据收集、预处理和策略训练，使用模仿学习算法（如ACT、Diffusion Policy）。它采用轻量级客户端-服务器架构，支持ROS互操作性，并提供可重用模块。

Result: ARK展示了从操作到移动导航的快速原型设计、硬件无缝切换以及端到端流水线，其便利性可与主流机器学习工作流媲美。

Conclusion: ARK通过统一机器人学和AI实践，降低了入门门槛，加速了自主机器人的研究和商业部署。

Abstract: Robotics has made remarkable hardware strides-from DARPA's Urban and Robotics
Challenges to the first humanoid-robot kickboxing tournament-yet commercial
autonomy still lags behind progress in machine learning. A major bottleneck is
software: current robot stacks demand steep learning curves, low-level C/C++
expertise, fragmented tooling, and intricate hardware integration, in stark
contrast to the Python-centric, well-documented ecosystems that propelled
modern AI. We introduce ARK, an open-source, Python-first robotics framework
designed to close that gap. ARK presents a Gym-style environment interface that
allows users to collect data, preprocess it, and train policies using
state-of-the-art imitation-learning algorithms (e.g., ACT, Diffusion Policy)
while seamlessly toggling between high-fidelity simulation and physical robots.
A lightweight client-server architecture provides networked
publisher-subscriber communication, and optional C/C++ bindings ensure
real-time performance when needed. ARK ships with reusable modules for control,
SLAM, motion planning, system identification, and visualization, along with
native ROS interoperability. Comprehensive documentation and case studies-from
manipulation to mobile navigation-demonstrate rapid prototyping, effortless
hardware swapping, and end-to-end pipelines that rival the convenience of
mainstream machine-learning workflows. By unifying robotics and AI practices
under a common Python umbrella, ARK lowers entry barriers and accelerates
research and commercial deployment of autonomous robots.

</details>


### [3] [TOMD: A Trail-based Off-road Multimodal Dataset for Traversable Pathway Segmentation under Challenging Illumination Conditions](https://arxiv.org/abs/2506.21630)
*Yixin Sun,Li Li,Wenke E,Amir Atapour-Abarghouei,Toby P. Breckon*

Main category: cs.RO

TL;DR: 论文介绍了TOMD数据集和动态多尺度数据融合模型，用于解决非结构化户外环境中可通行路径检测的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有数据集和模型主要针对城市环境或宽阔的越野路径，而忽视了狭窄的小径场景，因此需要专门的数据集和方法来填补这一空白。

Method: 提出了TOMD数据集，包含多模态传感器数据，并开发了动态多尺度数据融合模型，比较了早期、交叉和混合融合策略在不同光照条件下的表现。

Result: 结果表明，该方法在可通行路径预测上有效，且光照条件对分割性能有显著影响。

Conclusion: TOMD数据集和提出的模型为非结构化户外环境中的路径检测提供了有效工具，并公开数据集以支持未来研究。

Abstract: Detecting traversable pathways in unstructured outdoor environments remains a
significant challenge for autonomous robots, especially in critical
applications such as wide-area search and rescue, as well as incident
management scenarios like forest fires. Existing datasets and models primarily
target urban settings or wide, vehicle-traversable off-road tracks, leaving a
substantial gap in addressing the complexity of narrow, trail-like off-road
scenarios. To address this, we introduce the Trail-based Off-road Multimodal
Dataset (TOMD), a comprehensive dataset specifically designed for such
environments. TOMD features high-fidelity multimodal sensor data -- including
128-channel LiDAR, stereo imagery, GNSS, IMU, and illumination measurements --
collected through repeated traversals under diverse conditions. We also propose
a dynamic multiscale data fusion model for accurate traversable pathway
prediction. The study analyzes the performance of early, cross, and mixed
fusion strategies under varying illumination levels. Results demonstrate the
effectiveness of our approach and the relevance of illumination in segmentation
performance. We publicly release TOMD at https://github.com/yyyxs1125/TMOD to
support future research in trail-based off-road navigation.

</details>


### [4] [Real-Time 3D Guidewire Reconstruction from Intraoperative DSA Images for Robot-Assisted Endovascular Interventions](https://arxiv.org/abs/2506.21631)
*Tianliang Yao,Bingrui Li,Bo Lu,Zhiqiang Pei,Yixuan Yuan,Peng Qi*

Main category: cs.RO

TL;DR: 提出了一种结合术前3D CTA和术中2D DSA的多模态框架，用于实时3D导丝重建，显著提升了机器人辅助血管内手术的空间感知能力。


<details>
  <summary>Details</summary>
Motivation: 传统2D DSA缺乏深度信息，导致空间模糊性，限制了导丝形状感知的可靠性。

Method: 通过鲁棒特征提取处理2D DSA数据噪声，利用可变形图像配准对齐2D投影与3D CTA模型，再通过逆投影算法重建3D导丝形状。

Result: 投影误差为1.76±0.08像素，长度偏差为2.93±0.15%，帧率为39.3±1.5 FPS。

Conclusion: 该方法优化了机器人性能，提高了复杂血管内手术的精确性，有望改善临床结果。

Abstract: Accurate three-dimensional (3D) reconstruction of guidewire shapes is crucial
for precise navigation in robot-assisted endovascular interventions.
Conventional 2D Digital Subtraction Angiography (DSA) is limited by the absence
of depth information, leading to spatial ambiguities that hinder reliable
guidewire shape sensing. This paper introduces a novel multimodal framework for
real-time 3D guidewire reconstruction, combining preoperative 3D Computed
Tomography Angiography (CTA) with intraoperative 2D DSA images. The method
utilizes robust feature extraction to address noise and distortion in 2D DSA
data, followed by deformable image registration to align the 2D projections
with the 3D CTA model. Subsequently, the inverse projection algorithm
reconstructs the 3D guidewire shape, providing real-time, accurate spatial
information. This framework significantly enhances spatial awareness for
robotic-assisted endovascular procedures, effectively bridging the gap between
preoperative planning and intraoperative execution. The system demonstrates
notable improvements in real-time processing speed, reconstruction accuracy,
and computational efficiency. The proposed method achieves a projection error
of 1.76$\pm$0.08 pixels and a length deviation of 2.93$\pm$0.15\%, with a frame
rate of 39.3$\pm$1.5 frames per second (FPS). These advancements have the
potential to optimize robotic performance and increase the precision of complex
endovascular interventions, ultimately contributing to better clinical
outcomes.

</details>


### [5] [Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation](https://arxiv.org/abs/2506.21732)
*Ameya Salvi,Venkat Krovi*

Main category: cs.RO

TL;DR: 本文提出了一种基于学习的视觉导航方法，解决了滑移转向车辆在动态操作中的建模和验证问题。


<details>
  <summary>Details</summary>
Motivation: 滑移转向车辆在自动化部署中因缺乏准确的解析模型而受限，端到端学习方法成为替代方案，但动态操作中的验证仍不完善。

Method: 提出了一种结构化学习视觉导航的方法，并通过软件模拟、硬件评估和消融研究进行验证。

Result: 所提方法在性能上显著优于现有文献。

Conclusion: 该方法为滑移转向车辆的视觉导航提供了有效的解决方案。

Abstract: Vision-based lane keeping is a topic of significant interest in the robotics
and autonomous ground vehicles communities in various on-road and off-road
applications. The skid-steered vehicle architecture has served as a useful
vehicle platform for human controlled operations. However, systematic modeling,
especially of the skid-slip wheel terrain interactions (primarily in off-road
settings) has created bottlenecks for automation deployment. End-to-end
learning based methods such as imitation learning and deep reinforcement
learning, have gained prominence as a viable deployment option to counter the
lack of accurate analytical models. However, the systematic formulation and
subsequent verification/validation in dynamic operation regimes (particularly
for skid-steered vehicles) remains a work in progress. To this end, a novel
approach for structured formulation for learning visual navigation is proposed
and investigated in this work. Extensive software simulations, hardware
evaluations and ablation studies now highlight the significantly improved
performance of the proposed approach against contemporary literature.

</details>


### [6] [AeroLite-MDNet: Lightweight Multi-task Deviation Detection Network for UAV Landing](https://arxiv.org/abs/2506.21635)
*Haiping Yang,Huaxing Liu,Wei Wu,Zuohui Chen,Ning Wu*

Main category: cs.RO

TL;DR: 论文提出了一种基于视觉的无人机着陆偏差预警系统AeroLite-MDNet，通过多尺度融合模块和分割分支提高检测精度，并引入新指标AWD和新数据集UAVLandData。实验显示系统性能优越。


<details>
  <summary>Details</summary>
Motivation: 无人机着陆时因GPS信号干扰等问题难以精准着陆，影响操作连续性，需解决这一问题。

Method: 提出AeroLite-MDNet模型，结合多尺度融合模块和分割分支，用于偏差检测和方向估计，并引入AWD指标和新数据集UAVLandData。

Result: 系统AWD为0.7秒，偏差检测准确率达98.6%，显著提升着陆可靠性。

Conclusion: AeroLite-MDNet系统能有效解决无人机着陆偏差问题，提升操作安全性。

Abstract: Unmanned aerial vehicles (UAVs) are increasingly employed in diverse
applications such as land surveying, material transport, and environmental
monitoring. Following missions like data collection or inspection, UAVs must
land safely at docking stations for storage or recharging, which is an
essential requirement for ensuring operational continuity. However, accurate
landing remains challenging due to factors like GPS signal interference. To
address this issue, we propose a deviation warning system for UAV landings,
powered by a novel vision-based model called AeroLite-MDNet. This model
integrates a multiscale fusion module for robust cross-scale object detection
and incorporates a segmentation branch for efficient orientation estimation. We
introduce a new evaluation metric, Average Warning Delay (AWD), to quantify the
system's sensitivity to landing deviations. Furthermore, we contribute a new
dataset, UAVLandData, which captures real-world landing deviation scenarios to
support training and evaluation. Experimental results show that our system
achieves an AWD of 0.7 seconds with a deviation detection accuracy of 98.6\%,
demonstrating its effectiveness in enhancing UAV landing reliability. Code will
be available at https://github.com/ITTTTTI/Maskyolo.git

</details>


### [7] [A MILP-Based Solution to Multi-Agent Motion Planning and Collision Avoidance in Constrained Environments](https://arxiv.org/abs/2506.21982)
*Akshay Jaitly,Jack Cline,Siavash Farzan*

Main category: cs.RO

TL;DR: 提出一种混合整数线性规划（MILP）方法，用于多智能体运动规划，通过嵌入PAAMP到序列-求解流程中，显著减少计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体运动规划中高计算复杂度的问题，特别是避免碰撞和优化轨迹。

Method: 采用PAAMP方法，结合序列-求解流程，使用凸多面体约束和L1路径长度加加速度成本函数。

Result: 在代表性多智能体场景中，比非结构化MILP基线快一个数量级，且生成无碰撞轨迹。

Conclusion: 该方法高效且收敛性有保证，适用于复杂多智能体运动规划。

Abstract: We propose a mixed-integer linear program (MILP) for multi-agent motion
planning that embeds Polytopic Action-based Motion Planning (PAAMP) into a
sequence-then-solve pipeline. Region sequences confine each agent to adjacent
convex polytopes, while a big-M hyperplane model enforces inter-agent
separation. Collision constraints are applied only to agents sharing or
neighboring a region, which reduces binary variables exponentially compared
with naive formulations. An L1 path-length-plus-acceleration cost yields smooth
trajectories. We prove finite-time convergence and demonstrate on
representative multi-agent scenarios with obstacles that our formulation
produces collision-free trajectories an order of magnitude faster than an
unstructured MILP baseline.

</details>


### [8] [Optimal Motion Scaling for Delayed Telesurgery](https://arxiv.org/abs/2506.21689)
*Jason Lim,Florian Richter,Zih-Yun Chiu,Jaeyon Lee,Ethan Quist,Nathan Fisher,Jonathan Chambers,Steven Hong,Michael C. Yip*

Main category: cs.RO

TL;DR: 研究探讨了在长距离通信延迟下，通过调整运动缩放因子优化机器人远程操作的性能，发现个性化模型能显著提升效果。


<details>
  <summary>Details</summary>
Motivation: 解决因网络延迟导致的机器人远程操作性能下降问题，尤其是医疗远程手术中的挑战。

Method: 通过用户研究分析延迟、缩放因子与性能的关系，并开发个性化模型。

Result: 研究发现缩放因子的最优值因用户和延迟水平而异，个性化模型能显著提升性能。

Conclusion: 个性化缩放因子模型是优化远程操作性能的有效解决方案，尤其适用于高延迟环境。

Abstract: Robotic teleoperation over long communication distances poses challenges due
to delays in commands and feedback from network latency. One simple yet
effective strategy to reduce errors and increase performance under delay is to
downscale the relative motion between the operating surgeon and the robot. The
question remains as to what is the optimal scaling factor, and how this value
changes depending on the level of latency as well as operator tendencies. We
present user studies investigating the relationship between latency, scaling
factor, and performance. The results of our studies demonstrate a statistically
significant difference in performance between users and across scaling factors
for certain levels of delay. These findings indicate that the optimal scaling
factor for a given level of delay is specific to each user, motivating the need
for personalized models for optimal performance. We present techniques to model
the user-specific mapping of latency level to scaling factor for optimal
performance, leading to an efficient and effective solution to optimizing
performance of robotic teleoperation and specifically telesurgery under large
communication delay.

</details>


### [9] [Skill-Nav: Enhanced Navigation with Versatile Quadrupedal Locomotion via Waypoint Interface](https://arxiv.org/abs/2506.21853)
*Dewei Wang,Chenjia Ba,Chenhui Li,Jiyuan Shi,Yan Ding,Chi Zhang,Bin Zhao*

Main category: cs.RO

TL;DR: Skill-Nav结合强化学习与分层导航框架，通过路径点接口整合四足机器人的运动技能，实现复杂地形导航。


<details>
  <summary>Details</summary>
Motivation: 探索如何将四足机器人的运动技能与导航能力结合，以提升长距离移动能力。

Method: 使用深度强化学习训练路径点引导的运动策略，通过路径点接口连接高层规划与底层控制。

Result: 实验表明Skill-Nav能在模拟和现实场景中有效穿越复杂地形并完成导航任务。

Conclusion: Skill-Nav为四足机器人导航提供了一种灵活且高效的解决方案。

Abstract: Quadrupedal robots have demonstrated exceptional locomotion capabilities
through Reinforcement Learning (RL), including extreme parkour maneuvers.
However, integrating locomotion skills with navigation in quadrupedal robots
has not been fully investigated, which holds promise for enhancing
long-distance movement capabilities. In this paper, we propose Skill-Nav, a
method that incorporates quadrupedal locomotion skills into a hierarchical
navigation framework using waypoints as an interface. Specifically, we train a
waypoint-guided locomotion policy using deep RL, enabling the robot to
autonomously adjust its locomotion skills to reach targeted positions while
avoiding obstacles. Compared with direct velocity commands, waypoints offer a
simpler yet more flexible interface for high-level planning and low-level
control. Utilizing waypoints as the interface allows for the application of
various general planning tools, such as large language models (LLMs) and path
planning algorithms, to guide our locomotion policy in traversing terrains with
diverse obstacles. Extensive experiments conducted in both simulated and
real-world scenarios demonstrate that Skill-Nav can effectively traverse
complex terrains and complete challenging navigation tasks.

</details>


### [10] [Embodied Domain Adaptation for Object Detection](https://arxiv.org/abs/2506.21860)
*Xiangyu Shi,Yanyuan Qiao,Lingqiao Liu,Feras Dayoub*

Main category: cs.RO

TL;DR: 论文提出了一种无需源数据的领域自适应方法（SFDA），通过时间聚类和多尺度阈值融合改进伪标签，结合对比学习的Mean Teacher框架，显著提升了开放词汇目标检测（OVOD）在动态室内环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决标准封闭集方法和现有开放词汇目标检测在动态室内环境中因领域偏移导致的性能不足问题。

Method: 采用源数据无关的领域自适应（SFDA），结合时间聚类、多尺度阈值融合和Mean Teacher框架的对比学习。

Result: 在EDAOD基准测试中，零样本检测性能显著提升，能够灵活适应动态室内条件。

Conclusion: 提出的方法有效解决了开放词汇目标检测在动态室内环境中的领域适应问题，具有实际应用潜力。

Abstract: Mobile robots rely on object detectors for perception and object localization
in indoor environments. However, standard closed-set methods struggle to handle
the diverse objects and dynamic conditions encountered in real homes and labs.
Open-vocabulary object detection (OVOD), driven by Vision Language Models
(VLMs), extends beyond fixed labels but still struggles with domain shifts in
indoor environments. We introduce a Source-Free Domain Adaptation (SFDA)
approach that adapts a pre-trained model without accessing source data. We
refine pseudo labels via temporal clustering, employ multi-scale threshold
fusion, and apply a Mean Teacher framework with contrastive learning. Our
Embodied Domain Adaptation for Object Detection (EDAOD) benchmark evaluates
adaptation under sequential changes in lighting, layout, and object diversity.
Our experiments show significant gains in zero-shot detection performance and
flexible adaptation to dynamic indoor conditions.

</details>


### [11] [LMPVC and Policy Bank: Adaptive voice control for industrial robots with code generating LLMs and reusable Pythonic policies](https://arxiv.org/abs/2506.22028)
*Ossi Parikka,Roel Pieters*

Main category: cs.RO

TL;DR: 论文提出了一种基于大型语言模型（LLM）的语音控制架构LMPVC，用于ROS2兼容机器人，通过集成策略编程和教学功能提升人机协作。


<details>
  <summary>Details</summary>
Motivation: 现代制造业向个性化和专业化转型，复杂任务需要人机协作，语音控制成为关键需求。

Method: LMPVC架构结合代码生成和策略银行（Policy Bank）系统，实现语音控制与任务适应性。

Result: LMPVC通过策略银行弥补LLM的局限性，无需昂贵训练即可适应不同任务。

Conclusion: LMPVC为复杂人机协作任务提供了高效、灵活的解决方案。

Abstract: Modern industry is increasingly moving away from mass manufacturing, towards
more specialized and personalized products. As manufacturing tasks become more
complex, full automation is not always an option, human involvement may be
required. This has increased the need for advanced human robot collaboration
(HRC), and with it, improved methods for interaction, such as voice control.
Recent advances in natural language processing, driven by artificial
intelligence (AI), have the potential to answer this demand. Large language
models (LLMs) have rapidly developed very impressive general reasoning
capabilities, and many methods of applying this to robotics have been proposed,
including through the use of code generation. This paper presents Language
Model Program Voice Control (LMPVC), an LLM-based prototype voice control
architecture with integrated policy programming and teaching capabilities,
built for use with Robot Operating System 2 (ROS2) compatible robots. The
architecture builds on prior works using code generation for voice control by
implementing an additional programming and teaching system, the Policy Bank. We
find this system can compensate for the limitations of the underlying LLM, and
allow LMPVC to adapt to different downstream tasks without a slow and costly
training process. The architecture and additional results are released on
GitHub (https://github.com/ozzyuni/LMPVC).

</details>


### [12] [Multi-Robot Assembly of Deformable Linear Objects Using Multi-Modal Perception](https://arxiv.org/abs/2506.22034)
*Kejia Chen,Celina Dettmering,Florian Pachler,Zhuo Liu,Yue Zhang,Tailai Cheng,Jonas Dirr,Zhenshan Bing,Alois Knoll,Rüdiger Daub*

Main category: cs.RO

TL;DR: 提出了一种基于对象感知和规划的框架，用于实现工业价值链中全面的可变形线性物体（DLO）组装过程。


<details>
  <summary>Details</summary>
Motivation: 工业中DLO（如电缆）的组装潜力巨大，但由于其变形复杂性和动态行为难以预测，机器人自动化面临挑战。现有研究仅解决孤立子问题，缺乏集成工作流。

Method: 结合视觉和触觉信息跟踪DLO的形状和接触状态，规划机器人动作。包括从杂乱环境中拾取DLO，并协调多机器人完成装配。

Result: 通过多机器人实验验证了方法的有效性及其工业适用性。

Conclusion: 提出的框架为DLO的工业组装提供了集成解决方案，展示了实际应用的潜力。

Abstract: Industrial assembly of deformable linear objects (DLOs) such as cables offers
great potential for many industries. However, DLOs pose several challenges for
robot-based automation due to the inherent complexity of deformation and,
consequentially, the difficulties in anticipating the behavior of DLOs in
dynamic situations. Although existing studies have addressed isolated
subproblems like shape tracking, grasping, and shape control, there has been
limited exploration of integrated workflows that combine these individual
processes. To address this gap, we propose an object-centric perception and
planning framework to achieve a comprehensive DLO assembly process throughout
the industrial value chain. The framework utilizes visual and tactile
information to track the DLO's shape as well as contact state across different
stages, which facilitates effective planning of robot actions. Our approach
encompasses robot-based bin picking of DLOs from cluttered environments,
followed by a coordinated handover to two additional robots that mount the DLOs
onto designated fixtures. Real-world experiments employing a setup with
multiple robots demonstrate the effectiveness of the approach and its relevance
to industrial scenarios.

</details>


### [13] [An Introduction to Zero-Order Optimization Techniques for Robotics](https://arxiv.org/abs/2506.22087)
*Armand Jordana,Jianghan Zhang,Joseph Amigo,Ludovic Righetti*

Main category: cs.RO

TL;DR: 本文介绍了零阶优化技术在机器人学中的应用，并提出了一种随机搜索的数学教程，用于统一理解多种算法。


<details>
  <summary>Details</summary>
Motivation: 零阶优化技术因其能处理不可微函数和逃离局部极小值的优势，在机器人学中越来越受欢迎，尤其是在轨迹优化和策略优化中。

Method: 提出了一种随机搜索的数学教程，为理解机器人学中常用的多种算法提供了简单且统一的视角。

Result: 基于这一视角，将多种轨迹优化方法分类到一个共同框架下，并推导出新颖且具有竞争力的强化学习算法。

Conclusion: 随机搜索的数学教程为机器人学中的优化问题提供了统一且实用的解决方案。

Abstract: Zero-order optimization techniques are becoming increasingly popular in
robotics due to their ability to handle non-differentiable functions and escape
local minima. These advantages make them particularly useful for trajectory
optimization and policy optimization. In this work, we propose a mathematical
tutorial on random search. It offers a simple and unifying perspective for
understanding a wide range of algorithms commonly used in robotics. Leveraging
this viewpoint, we classify many trajectory optimization methods under a common
framework and derive novel competitive RL algorithms.

</details>


### [14] [Evaluating Pointing Gestures for Target Selection in Human-Robot Collaboration](https://arxiv.org/abs/2506.22116)
*Noora Sassali,Roel Pieters*

Main category: cs.RO

TL;DR: 该研究提出了一种基于姿态估计和几何模型的方法，用于定位平面工作空间中的指向目标，并评估其在机器人任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 指向手势是人机协作中常用的交互方式，但需要一种准确的方法来定位目标并评估其性能。

Method: 采用姿态估计和基于肩-腕伸展的几何模型，从RGB-D流中提取手势数据，并集成到多模态机器人系统中。

Result: 研究提出了一种严格的评估方法，并通过概念验证系统展示了多模态集成的可行性。

Conclusion: 讨论了工具的局限性和性能，强调了其在多模态机器人系统中的潜在作用。

Abstract: Pointing gestures are a common interaction method used in Human-Robot
Collaboration for various tasks, ranging from selecting targets to guiding
industrial processes. This study introduces a method for localizing pointed
targets within a planar workspace. The approach employs pose estimation, and a
simple geometric model based on shoulder-wrist extension to extract gesturing
data from an RGB-D stream. The study proposes a rigorous methodology and
comprehensive analysis for evaluating pointing gestures and target selection in
typical robotic tasks. In addition to evaluating tool accuracy, the tool is
integrated into a proof-of-concept robotic system, which includes object
detection, speech transcription, and speech synthesis to demonstrate the
integration of multiple modalities in a collaborative application. Finally, a
discussion over tool limitations and performance is provided to understand its
role in multimodal robotic systems. All developments are available at:
https://github.com/NMKsas/gesture_pointer.git.

</details>


### [15] [RM-Dijkstra: A surface optimal path planning algorithm based on Riemannian metric](https://arxiv.org/abs/2506.22170)
*Yu Zhang,Xiao-Song Yang*

Main category: cs.RO

TL;DR: 提出了一种基于黎曼度量的RM-Dijkstra算法，用于解决移动机器人表面最优路径规划问题，优于传统算法。


<details>
  <summary>Details</summary>
Motivation: Dijkstra算法在离散图空间中表现优异，但其在移动机器人表面路径规划中的应用尚未充分探索。

Method: 通过构建新的黎曼度量，将表面最优路径规划问题转化为二维平面上的几何问题。

Result: 实验表明，RM-Dijkstra算法在路径精度和平滑度上优于传统算法，尤其在复杂场景中。

Conclusion: RM-Dijkstra算法为表面路径规划提供了一种有效且优越的解决方案。

Abstract: The Dijkstra algorithm is a classic path planning method, which operates in a
discrete graph space to determine the shortest path from a specified source
point to a target node or all other nodes based on non-negative edge weights.
Numerous studies have focused on the Dijkstra algorithm due to its potential
application. However, its application in surface path planning for mobile
robots remains largely unexplored. In this letter, a surface optimal path
planning algorithm called RM-Dijkstra is proposed, which is based on Riemannian
metric model. By constructing a new Riemannian metric on the 2D projection
plane, the surface optimal path planning problem is therefore transformed into
a geometric problem on the 2D plane with new Riemannian metric. Induced by the
standard Euclidean metric on surface, the constructed new metric reflects
environmental information of the robot and ensures that the projection map is
an isometric immersion. By conducting a series of simulation tests, the
experimental results demonstrate that the RM-Dijkstra algorithm not only
effectively solves the optimal path planning problem on surfaces, but also
outperforms traditional path planning algorithms in terms of path accuracy and
smoothness, particularly in complex scenarios.

</details>


### [16] [ASVSim (AirSim for Surface Vehicles): A High-Fidelity Simulation Framework for Autonomous Surface Vehicle Research](https://arxiv.org/abs/2506.22174)
*Bavo Lesy,Siemen Herremans,Robin Kerstens,Jan Steckel,Walter Daems,Siegfried Mercelis,Ali Anwar*

Main category: cs.RO

TL;DR: ASVSim是一个开源仿真框架，专为内河和港口环境中的自主航运研究设计，结合了船舶动力学和海洋传感器模拟能力。


<details>
  <summary>Details</summary>
Motivation: 运输行业对无人水面车辆（USVs）的兴趣增加，但缺乏开源高保真仿真框架和数据集，阻碍了自主解决方案的开发。

Method: 基于Cosys-AirSim开发ASVSim，支持船舶动力学模拟、海洋传感器（如雷达和摄像头）仿真，并生成合成数据集。

Result: ASVSim为自主导航算法开发和合成数据集生成提供了全面平台，支持传统控制方法和深度学习研究。

Conclusion: ASVSim作为开源项目，有望推动海洋工程领域的自主导航研究。

Abstract: The transport industry has recently shown significant interest in unmanned
surface vehicles (USVs), specifically for port and inland waterway transport.
These systems can improve operational efficiency and safety, which is
especially relevant in the European Union, where initiatives such as the Green
Deal are driving a shift towards increased use of inland waterways. At the same
time, a shortage of qualified personnel is accelerating the adoption of
autonomous solutions. However, there is a notable lack of open-source,
high-fidelity simulation frameworks and datasets for developing and evaluating
such solutions. To address these challenges, we introduce AirSim For Surface
Vehicles (ASVSim), an open-source simulation framework specifically designed
for autonomous shipping research in inland and port environments. The framework
combines simulated vessel dynamics with marine sensor simulation capabilities,
including radar and camera systems and supports the generation of synthetic
datasets for training computer vision models and reinforcement learning agents.
Built upon Cosys-AirSim, ASVSim provides a comprehensive platform for
developing autonomous navigation algorithms and generating synthetic datasets.
The simulator supports research of both traditional control methods and deep
learning-based approaches. Through limited experiments, we demonstrate the
potential of the simulator in these research areas. ASVSim is provided as an
open-source project under the MIT license, making autonomous navigation
research accessible to a larger part of the ocean engineering community.

</details>


### [17] [KnotDLO: Toward Interpretable Knot Tying](https://arxiv.org/abs/2506.22176)
*Holly Dinkel,Raghavendra Navaratna,Jingyi Xiang,Brian Coltin,Trey Smith,Timothy Bretl*

Main category: cs.RO

TL;DR: KnotDLO是一种无需人类演示或训练的单手可变形线性物体（DLO）打结方法，具有抗遮挡性、可重复性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决DLO打结中的遮挡问题，并实现无需人类干预的自动化打结。

Method: 通过当前DLO形状规划抓取和目标路径点，利用分段线性曲线跟踪和几何计算生成中间路径点。

Result: 在16次实验中，KnotDLO成功率为50%，能够从未见过的配置中打结。

Conclusion: KnotDLO展示了无需人类干预的DLO自动化打结潜力，但成功率有待提高。

Abstract: This work presents KnotDLO, a method for one-handed Deformable Linear Object
(DLO) knot tying that is robust to occlusion, repeatable for varying rope
initial configurations, interpretable for generating motion policies, and
requires no human demonstrations or training. Grasp and target waypoints for
future DLO states are planned from the current DLO shape. Grasp poses are
computed from indexing the tracked piecewise linear curve representing the DLO
state based on the current curve shape and are piecewise continuous. KnotDLO
computes intermediate waypoints from the geometry of the current DLO state and
the desired next state. The system decouples visual reasoning from control. In
16 trials of knot tying, KnotDLO achieves a 50% success rate in tying an
overhand knot from previously unseen configurations.

</details>


### [18] [Robotic Multimodal Data Acquisition for In-Field Deep Learning Estimation of Cover Crop Biomass](https://arxiv.org/abs/2506.22364)
*Joe Johnson,Phanender Chalasani,Arnav Shah,Ram L. Ray,Muthukumar Bagavathiannan*

Main category: cs.RO

TL;DR: 研究提出了一种结合光学和LiDAR数据的多模态传感器系统，通过机器学习方法提升生物量预测精度，以优化杂草管理策略。


<details>
  <summary>Details</summary>
Motivation: 杂草管理对减少作物产量损失至关重要，而覆盖作物的生物量分布直接影响其抑制杂草的效果。准确估计和绘制生物量分布是优化管理策略的关键。

Method: 开发了一种地面机器人搭载的多模态传感器系统，结合光学和LiDAR数据，利用机器学习方法进行数据融合，以提高生物量预测。

Result: 最佳机器学习模型在干燥生物量估计中达到了0.88的决定系数，表现优异。

Conclusion: 该方法为精准杂草抑制策略提供了有效工具，有助于推动可持续农业实践。

Abstract: Accurate weed management is essential for mitigating significant crop yield
losses, necessitating effective weed suppression strategies in agricultural
systems. Integrating cover crops (CC) offers multiple benefits, including soil
erosion reduction, weed suppression, decreased nitrogen requirements, and
enhanced carbon sequestration, all of which are closely tied to the aboveground
biomass (AGB) they produce. However, biomass production varies significantly
due to microsite variability, making accurate estimation and mapping essential
for identifying zones of poor weed suppression and optimizing targeted
management strategies. To address this challenge, developing a comprehensive CC
map, including its AGB distribution, will enable informed decision-making
regarding weed control methods and optimal application rates. Manual visual
inspection is impractical and labor-intensive, especially given the extensive
field size and the wide diversity and variation of weed species and sizes. In
this context, optical imagery and Light Detection and Ranging (LiDAR) data are
two prominent sources with unique characteristics that enhance AGB estimation.
This study introduces a ground robot-mounted multimodal sensor system designed
for agricultural field mapping. The system integrates optical and LiDAR data,
leveraging machine learning (ML) methods for data fusion to improve biomass
predictions. The best ML-based model for dry AGB estimation achieved a
coefficient of determination value of 0.88, demonstrating robust performance in
diverse field conditions. This approach offers valuable insights for
site-specific management, enabling precise weed suppression strategies and
promoting sustainable farming practices.

</details>
