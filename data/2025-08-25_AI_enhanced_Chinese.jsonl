{"id": "2508.15874", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15874", "abs": "https://arxiv.org/abs/2508.15874", "authors": ["Yijun Liu", "Yuwei Liu", "Yuan Meng", "Jieheng Zhang", "Yuwei Zhou", "Ye Li", "Jiacheng Jiang", "Kangye Ji", "Shijia Ge", "Zhi Wang", "Wenwu Zhu"], "title": "Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning", "comment": null, "summary": "Vision-centric hierarchical embodied models have demonstrated strong\npotential for long-horizon robotic control. However, existing methods lack\nspatial awareness capabilities, limiting their effectiveness in bridging visual\nplans to actionable control in complex environments. To address this problem,\nwe propose Spatial Policy (SP), a unified spatial-aware visuomotor robotic\nmanipulation framework via explicit spatial modeling and reasoning.\nSpecifically, we first design a spatial-conditioned embodied video generation\nmodule to model spatially guided predictions through a spatial plan table.\nThen, we propose a spatial-based action prediction module to infer executable\nactions with coordination. Finally, we propose a spatial reasoning feedback\npolicy to refine the spatial plan table via dual-stage replanning. Extensive\nexperiments show that SP significantly outperforms state-of-the-art baselines,\nachieving a 33.0% average improvement over the best baseline. With an 86.7%\naverage success rate across 11 diverse tasks, SP substantially enhances the\npracticality of embodied models for robotic control applications. Code and\ncheckpoints are maintained at\nhttps://plantpotatoonmoon.github.io/SpatialPolicy/.", "AI": {"tldr": "提出了Spatial Policy (SP)框架，通过显式空间建模和推理来解决视觉中心层次化具身模型缺乏空间感知能力的问题，在11个多样化任务中达到86.7%的平均成功率。", "motivation": "现有视觉中心层次化具身模型缺乏空间感知能力，限制了其在复杂环境中将视觉计划转化为可执行控制的有效性。", "method": "设计了空间条件具身视频生成模块、基于空间的动作预测模块和空间推理反馈策略，通过空间计划表和双阶段重规划实现统一的空间感知视觉运动机器人操作框架。", "result": "SP显著优于最先进的基线方法，相比最佳基线平均提升33.0%，在11个多样化任务中达到86.7%的平均成功率。", "conclusion": "SP通过显式空间建模和推理，大幅提升了具身模型在机器人控制应用中的实用性。"}}
{"id": "2508.15972", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15972", "abs": "https://arxiv.org/abs/2508.15972", "authors": ["Zhaodong Jiang", "Ashish Sinha", "Tongtong Cao", "Yuan Ren", "Bingbing Liu", "Binbin Xu"], "title": "UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation", "comment": "Published at the Conference on Robot Learning (CoRL) 2025. For more\n  details please visit https://frankzhaodong.github.io/UnPose", "summary": "Estimating the 6D pose of novel objects is a fundamental yet challenging\nproblem in robotics, often relying on access to object CAD models. However,\nacquiring such models can be costly and impractical. Recent approaches aim to\nbypass this requirement by leveraging strong priors from foundation models to\nreconstruct objects from single or multi-view images, but typically require\nadditional training or produce hallucinated geometry. To this end, we propose\nUnPose, a novel framework for zero-shot, model-free 6D object pose estimation\nand reconstruction that exploits 3D priors and uncertainty estimates from a\npre-trained diffusion model. Specifically, starting from a single-view RGB-D\nframe, UnPose uses a multi-view diffusion model to estimate an initial 3D model\nusing 3D Gaussian Splatting (3DGS) representation, along with pixel-wise\nepistemic uncertainty estimates. As additional observations become available,\nwe incrementally refine the 3DGS model by fusing new views guided by the\ndiffusion model's uncertainty, thereby continuously improving the pose\nestimation accuracy and 3D reconstruction quality. To ensure global\nconsistency, the diffusion prior-generated views and subsequent observations\nare further integrated in a pose graph and jointly optimized into a coherent\n3DGS field. Extensive experiments demonstrate that UnPose significantly\noutperforms existing approaches in both 6D pose estimation accuracy and 3D\nreconstruction quality. We further showcase its practical applicability in\nreal-world robotic manipulation tasks.", "AI": {"tldr": "UnPose是一个零样本、无模型的6D物体姿态估计和重建框架，利用预训练扩散模型的3D先验和不确定性估计，通过3D高斯泼溅表示和增量优化实现高精度姿态估计和3D重建。", "motivation": "传统6D姿态估计需要物体CAD模型，但获取成本高且不实用。现有方法虽然尝试绕过这一要求，但通常需要额外训练或产生幻觉几何。", "method": "从单视角RGB-D帧开始，使用多视角扩散模型估计初始3D高斯泼溅模型和不确定性。随着新观测的加入，基于不确定性指导增量优化3D模型，并通过姿态图优化确保全局一致性。", "result": "大量实验表明，UnPose在6D姿态估计精度和3D重建质量上显著优于现有方法，并在真实机器人操作任务中展示了实用性。", "conclusion": "UnPose提供了一个有效的零样本解决方案，无需CAD模型或额外训练，通过扩散模型先验和不确定性指导的增量优化实现了高质量的6D姿态估计和3D重建。"}}
{"id": "2508.15990", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15990", "abs": "https://arxiv.org/abs/2508.15990", "authors": ["Hung-Jui Huang", "Mohammad Amin Mirzaee", "Michael Kaess", "Wenzhen Yuan"], "title": "GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System", "comment": "18 pages", "summary": "Accurately perceiving an object's pose and shape is essential for precise\ngrasping and manipulation. Compared to common vision-based methods, tactile\nsensing offers advantages in precision and immunity to occlusion when tracking\nand reconstructing objects in contact. This makes it particularly valuable for\nin-hand and other high-precision manipulation tasks. In this work, we present\nGelSLAM, a real-time 3D SLAM system that relies solely on tactile sensing to\nestimate object pose over long periods and reconstruct object shapes with high\nfidelity. Unlike traditional point cloud-based approaches, GelSLAM uses\ntactile-derived surface normals and curvatures for robust tracking and loop\nclosure. It can track object motion in real time with low error and minimal\ndrift, and reconstruct shapes with submillimeter accuracy, even for low-texture\nobjects such as wooden tools. GelSLAM extends tactile sensing beyond local\ncontact to enable global, long-horizon spatial perception, and we believe it\nwill serve as a foundation for many precise manipulation tasks involving\ninteraction with objects in hand. The video demo is available on our website:\nhttps://joehjhuang.github.io/gelslam.", "AI": {"tldr": "GelSLAM是一种基于触觉传感的实时3D SLAM系统，能够长时间估计物体姿态并以高保真度重建物体形状，无需视觉输入", "motivation": "精确感知物体姿态和形状对于精确抓取和操作至关重要。相比视觉方法，触觉传感在跟踪和重建接触物体时具有精度高、抗遮挡的优势，特别适合手内操作等高精度任务", "method": "使用触觉传感获取的表面法线和曲率进行鲁棒跟踪和闭环检测，而非传统的点云方法。系统能够实时跟踪物体运动并重建形状", "result": "能够以低误差和最小漂移实时跟踪物体运动，重建形状精度达到亚毫米级别，即使对于木质工具等低纹理物体也有效", "conclusion": "GelSLAM将触觉传感从局部接触扩展到全局、长时程的空间感知，为涉及手内物体交互的精确操作任务提供了基础"}}
{"id": "2508.16008", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.16008", "abs": "https://arxiv.org/abs/2508.16008", "authors": ["Bingchao Wang", "Adam A. Stokes"], "title": "Self-Aligning EPM Connector: A Versatile Solution for Adaptive and Multi-Modal Interfaces", "comment": null, "summary": "This paper presents a multifunctional connector based on electro-permanent\nmagnet (EPM) technology, integrating self-alignment, mechanical coupling, fluid\ntransfer, and data communication within a compact SLA-3D printed structure.\nExperimental results demonstrate reliable self-alignment, efficient fluid\ntransfer in single-loop and dual-channel modes, and robust data transmission\nvia integrated electronic control. The connector exhibits high flexibility in\naccommodating axial, angular, and lateral misalignments while maintaining low\nenergy consumption. These features make it highly suitable for modular\nrobotics, electric vehicle charging, household robotic platforms, and aerospace\ndocking applications.", "AI": {"tldr": "基于电永磁技术的多功能连接器，集成了自对准、机械耦合、流体传输和数据通信功能，适用于模块化机器人、电动汽车充电等多种应用场景", "motivation": "开发一种紧凑型多功能连接器，能够同时处理机械连接、流体传输和数据通信，解决传统连接器在复杂应用场景中的局限性", "method": "采用电永磁技术，通过SLA 3D打印制造紧凑结构，集成自对准机制、流体传输通道和数据通信电子控制系统", "result": "实验证明连接器具有可靠的自对准性能、高效的流体传输能力（单回路和双通道模式）、稳定的数据传输，并能适应轴向、角度和横向偏差，同时保持低能耗", "conclusion": "该电永磁多功能连接器技术成熟，具有高度灵活性和低能耗特点，非常适合模块化机器人、电动汽车充电、家用机器人平台和航空航天对接等应用领域"}}
{"id": "2508.16143", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16143", "abs": "https://arxiv.org/abs/2508.16143", "authors": ["Akira Oyama", "Shoichi Hasegawa", "Akira Taniguchi", "Yoshinobu Hagiwara", "Tadahiro Taniguchi"], "title": "Take That for Me: Multimodal Exophora Resolution with Interactive Questioning for Ambiguous Out-of-View Instructions", "comment": "See website at https://emergentsystemlabstudent.github.io/MIEL/.\n  Accepted at IEEE RO-MAN 2025", "summary": "Daily life support robots must interpret ambiguous verbal instructions\ninvolving demonstratives such as ``Bring me that cup,'' even when objects or\nusers are out of the robot's view. Existing approaches to exophora resolution\nprimarily rely on visual data and thus fail in real-world scenarios where the\nobject or user is not visible. We propose Multimodal Interactive Exophora\nresolution with user Localization (MIEL), which is a multimodal exophora\nresolution framework leveraging sound source localization (SSL), semantic\nmapping, visual-language models (VLMs), and interactive questioning with\nGPT-4o. Our approach first constructs a semantic map of the environment and\nestimates candidate objects from a linguistic query with the user's skeletal\ndata. SSL is utilized to orient the robot toward users who are initially\noutside its visual field, enabling accurate identification of user gestures and\npointing directions. When ambiguities remain, the robot proactively interacts\nwith the user, employing GPT-4o to formulate clarifying questions. Experiments\nin a real-world environment showed results that were approximately 1.3 times\nbetter when the user was visible to the robot and 2.0 times better when the\nuser was not visible to the robot, compared to the methods without SSL and\ninteractive questioning. The project website is\nhttps://emergentsystemlabstudent.github.io/MIEL/.", "AI": {"tldr": "MIEL是一个多模态外指消解框架，通过声音定位、语义地图和交互式提问来解决机器人视野外物体的指代问题，性能比现有方法提升1.3-2.0倍", "motivation": "现有外指消解方法主要依赖视觉数据，无法处理用户或物体不在机器人视野内的真实场景", "method": "结合声音源定位(SSL)确定用户位置，构建语义地图，使用视觉语言模型(VLMs)和GPT-4o进行交互式提问", "result": "实验显示，用户可见时性能提升约1.3倍，用户不可见时提升约2.0倍", "conclusion": "MIEL框架通过多模态融合和主动交互，有效解决了真实环境中视野外物体的指代消解问题"}}
{"id": "2508.16459", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.16459", "abs": "https://arxiv.org/abs/2508.16459", "authors": ["Ali Emre Balcı", "Erhan Ege Keyvan", "Emre Özkan"], "title": "GPL-SLAM: A Laser SLAM Framework with Gaussian Process Based Extended Landmarks", "comment": "Authors Ali Emre Balc{\\i} and Erhan Ege Keyvan contributed equally to\n  this work", "summary": "We present a novel Simultaneous Localization and Mapping (SLAM) method that\nemploys Gaussian Process (GP) based landmark (object) representations. Instead\nof conventional grid maps or point cloud registration, we model the environment\non a per object basis using GP based contour representations. These contours\nare updated online through a recursive scheme, enabling efficient memory usage.\nThe SLAM problem is formulated within a fully Bayesian framework, allowing\njoint inference over the robot pose and object based map. This representation\nprovides semantic information such as the number of objects and their areas,\nwhile also supporting probabilistic measurement to object associations.\nFurthermore, the GP based contours yield confidence bounds on object shapes,\noffering valuable information for downstream tasks like safe navigation and\nexploration. We validate our method on synthetic and real world experiments,\nand show that it delivers accurate localization and mapping performance across\ndiverse structured environments.", "AI": {"tldr": "提出了一种基于高斯过程的SLAM方法，使用GP轮廓表示物体地标，在贝叶斯框架下联合推断机器人位姿和物体地图，提供语义信息和形状置信度", "motivation": "传统SLAM方法使用网格地图或点云配准，缺乏语义信息和物体级别的环境表示，需要更高效的内存使用和更丰富的环境理解", "method": "采用高斯过程(GP)基于轮廓的物体表示方法，通过递归方案在线更新轮廓，在完全贝叶斯框架下制定SLAM问题，联合推断机器人位姿和基于物体的地图", "result": "在合成和真实世界实验中验证了方法，在不同结构化环境中实现了准确的定位和建图性能，提供了物体数量和面积等语义信息", "conclusion": "GP基于轮廓的表示方法为SLAM提供了语义丰富的环境模型，支持概率测量到物体的关联，为安全导航和探索等下游任务提供有价值的形状置信度信息"}}
{"id": "2508.16460", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.16460", "abs": "https://arxiv.org/abs/2508.16460", "authors": ["Jiri Horyna", "Roland Jung", "Stephan Weiss", "Eliseo Ferrante", "Martin Saska"], "title": "Swarming Without an Anchor (SWA): Robot Swarms Adapt Better to Localization Dropouts Then a Single Robot", "comment": "Accepted to IEEE RA-L on April 1, 2025", "summary": "In this paper, we present the Swarming Without an Anchor (SWA) approach to\nstate estimation in swarms of Unmanned Aerial Vehicles (UAVs) experiencing\nego-localization dropout, where individual agents are laterally stabilized\nusing relative information only. We propose to fuse decentralized state\nestimation with robust mutual perception and onboard sensor data to maintain\naccurate state awareness despite intermittent localization failures. Thus, the\nrelative information used to estimate the lateral state of UAVs enables the\nidentification of the unambiguous state of UAVs with respect to the local\nconstellation. The resulting behavior reaches velocity consensus, as this task\ncan be referred to as the double integrator synchronization problem. All\ndisturbances and performance degradations except a uniform translation drift of\nthe swarm as a whole is attenuated which is enabling new opportunities in using\ntight cooperation for increasing reliability and resilience of multi-UAV\nsystems. Simulations and real-world experiments validate the effectiveness of\nour approach, demonstrating its capability to sustain cohesive swarm behavior\nin challenging conditions of unreliable or unavailable primary localization.", "AI": {"tldr": "SWA方法通过融合分散状态估计、鲁棒相互感知和机载传感器数据，使无人机群在个体定位丢失时仅使用相对信息维持横向稳定和速度一致性", "motivation": "解决无人机群在个体定位系统间歇性失效时的状态估计问题，提高多无人机系统的可靠性和弹性", "method": "融合分散状态估计、鲁棒相互感知和机载传感器数据，利用相对信息估计无人机横向状态并识别相对于局部星座的无歧义状态", "result": "实现了速度一致性（双积分器同步问题），除了整个群集的均匀平移漂移外，所有干扰和性能下降都被衰减", "conclusion": "模拟和真实实验验证了该方法在主要定位不可靠或不可用的情况下维持凝聚群行为的有效性，为紧密合作提高多无人机系统可靠性提供了新机会"}}
{"id": "2508.16504", "categories": ["cs.RO", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.16504", "abs": "https://arxiv.org/abs/2508.16504", "authors": ["Sophie Villemure", "Jefferson Silveira", "Joshua A. Marshall"], "title": "Terrain Classification for the Spot Quadrupedal Mobile Robot Using Only Proprioceptive Sensing", "comment": null, "summary": "Quadrupedal mobile robots can traverse a wider range of terrain types than\ntheir wheeled counterparts but do not perform the same on all terrain types.\nThese robots are prone to undesirable behaviours like sinking and slipping on\nchallenging terrains. To combat this issue, we propose a terrain classifier\nthat provides information on terrain type that can be used in robotic systems\nto create a traversability map to plan safer paths for the robot to navigate.\nThe work presented here is a terrain classifier developed for a Boston Dynamics\nSpot robot. Spot provides over 100 measured proprioceptive signals describing\nthe motions of the robot and its four legs (e.g., foot penetration, forces,\njoint angles, etc.). The developed terrain classifier combines dimensionality\nreduction techniques to extract relevant information from the signals and then\napplies a classification technique to differentiate terrain based on\ntraversability. In representative field testing, the resulting terrain\nclassifier was able to identify three different terrain types with an accuracy\nof approximately 97%", "AI": {"tldr": "四足机器人地形分类器，利用自感信号识别不同地形类型，准确率达97%，为机器人安全航行提供支撑", "motivation": "四足机器人在挑战性地形上容易出现滑移和下沉等不良行为，需要地形识别技术来提升航行安全性", "method": "采用维度降屈技术处理Spot机器人提供的100多个自感信号，包括脚部突破、力量、关节角度等，然后进行分类识别", "result": "在代表性地面测试中，该地形分类器能够识别三种不同地形类型，准确率约为97%", "conclusion": "通过自感信号分析可以高效识别地形，为四足机器人的航行安全提供重要的地形可通行性信息"}}
{"id": "2508.16511", "categories": ["cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.16511", "abs": "https://arxiv.org/abs/2508.16511", "authors": ["Otobong Jerome", "Alexandr Klimchik", "Alexander Maloletov", "Geesara Kulathunga"], "title": "On Kinodynamic Global Planning in a Simplicial Complex Environment: A Mixed Integer Approach", "comment": null, "summary": "This work casts the kinodynamic planning problem for car-like vehicles as an\noptimization task to compute a minimum-time trajectory and its associated\nvelocity profile, subject to boundary conditions on velocity, acceleration, and\nsteering. The approach simultaneously optimizes both the spatial path and the\nsequence of acceleration and steering controls, ensuring continuous motion from\na specified initial position and velocity to a target end position and\nvelocity.The method analyzes the admissible control space and terrain to avoid\nlocal minima. The proposed method operates efficiently in simplicial complex\nenvironments, a preferred terrain representation for capturing intricate 3D\nlandscapes. The problem is initially posed as a mixed-integer fractional\nprogram with quadratic constraints, which is then reformulated into a\nmixed-integer bilinear objective through a variable transformation and\nsubsequently relaxed to a mixed-integer linear program using McCormick\nenvelopes. Comparative simulations against planners such as MPPI and log-MPPI\ndemonstrate that the proposed approach generates solutions 104 times faster\nwhile strictly adhering to the specified constraints", "AI": {"tldr": "该研究将类车车辆的动力学规划问题转化为优化任务，计算最小时间轨迹和速度曲线，同时满足速度、加速度和转向的边界条件约束。", "motivation": "为了解决类车车辆在复杂3D地形中的动力学规划问题，需要同时优化空间路径和控制序列，确保从初始状态到目标状态的连续运动，并避免局部最优解。", "method": "将问题建模为混合整数分数规划，通过变量变换转化为混合整数双线性目标，再使用McCormick包络松弛为混合整数线性规划，在单纯复形环境中高效运算。", "result": "与MPPI和log-MPPI等规划器相比，该方法生成解决方案的速度快104倍，且严格满足所有约束条件。", "conclusion": "该方法能够高效解决类车车辆的动力学规划问题，在复杂地形中快速生成满足约束的最优轨迹，具有显著的性能优势。"}}
{"id": "2508.16515", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16515", "abs": "https://arxiv.org/abs/2508.16515", "authors": ["Hichem Cheriet", "Khellat Kihel Badra", "Chouraqui Samira"], "title": "Comparative Analysis of UAV Path Planning Algorithms for Efficient Navigation in Urban 3D Environments", "comment": null, "summary": "The most crucial challenges for UAVs are planning paths and avoiding\nobstacles in their way. In recent years, a wide variety of path-planning\nalgorithms have been developed. These algorithms have successfully solved\npath-planning problems; however, they suffer from multiple challenges and\nlimitations. To test the effectiveness and efficiency of three widely used\nalgorithms, namely A*, RRT*, and Particle Swarm Optimization (PSO), this paper\nconducts extensive experiments in 3D urban city environments cluttered with\nobstacles. Three experiments were designed with two scenarios each to test the\naforementioned algorithms. These experiments consider different city map sizes,\ndifferent altitudes, and varying obstacle densities and sizes in the\nenvironment. According to the experimental results, the A* algorithm\noutperforms the others in both computation efficiency and path quality. PSO is\nespecially suitable for tight turns and dense environments, and RRT* offers a\nbalance and works well across all experiments due to its randomized approach to\nfinding solutions.", "AI": {"tldr": "本文通过三维城市环境实验比较A*、RRT*和PSO三种路径规划算法，发现A*在计算效率和路径质量方面表现最佳，PSO适合密集环境，RRT*在各种场景下表现均衡。", "motivation": "无人机路径规划面临诸多挑战，现有算法虽能解决问题但存在局限性，需要通过系统实验评估主流算法的性能表现。", "method": "在三维城市环境中设计三组实验，每组包含两种场景，测试不同地图尺寸、飞行高度、障碍物密度和大小条件下的算法性能。", "result": "A*算法在计算效率和路径质量方面表现最优；PSO算法特别适合密集环境和急转弯；RRT*算法因其随机搜索特性在所有实验中表现均衡。", "conclusion": "不同算法各有优势，A*综合性能最佳，PSO适合特定密集场景，RRT*具有较好的通用性，为无人机路径规划算法选择提供了实证依据。"}}
{"id": "2508.16574", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16574", "abs": "https://arxiv.org/abs/2508.16574", "authors": ["Yizhi Wang", "Degang Xu", "Yongfang Xie", "Shuzhong Tan", "Xianan Zhou", "Peng Chen"], "title": "Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems", "comment": null, "summary": "This paper presents a hierarchical decision-making framework for autonomous\nnavigation in four-wheel independent steering and driving (4WISD) systems. The\nproposed approach integrates deep reinforcement learning (DRL) for high-level\nnavigation with fuzzy logic for low-level control to ensure both task\nperformance and physical feasibility. The DRL agent generates global motion\ncommands, while the fuzzy logic controller enforces kinematic constraints to\nprevent mechanical strain and wheel slippage. Simulation experiments\ndemonstrate that the proposed framework outperforms traditional navigation\nmethods, offering enhanced training efficiency and stability and mitigating\nerratic behaviors compared to purely DRL-based solutions. Real-world\nvalidations further confirm the framework's ability to navigate safely and\neffectively in dynamic industrial settings. Overall, this work provides a\nscalable and reliable solution for deploying 4WISD mobile robots in complex,\nreal-world scenarios.", "AI": {"tldr": "本文提出了一种用于四轮独立转向驾驶系统的层次决策框架，结合深度强化学习和模糊逻辑控制，实现了更高效稳定的自主导航能力。", "motivation": "解决纯粹深度强化学习在四轮独立轮轮轮系统中导致的机械压力和轮胎滑移问题，提高导航的安全性和可靠性。", "method": "采用层次决策框架，高层使用深度强化学习生成全局运动指令，低层使用模糊逻辑控制器确保运动学约束和物理可行性。", "result": "模拟实验表明该框架在训练效率、稳定性和行为表现方面都超过传统方法，并在实际工业环境中验证了其安全有效导航能力。", "conclusion": "该工作为四轮独立轮轮轮系统提供了一种可扩展、可靠的解决方案，适用于复杂的实际应用场景。"}}
