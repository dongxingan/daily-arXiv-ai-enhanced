<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 42]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Safe and Performant Deployment of Autonomous Systems via Model Predictive Control and Hamilton-Jacobi Reachability Analysis](https://arxiv.org/abs/2506.23346)
*Hao Wang,Armand Jordana,Ludovic Righetti,Somil Bansal*

Main category: cs.RO

TL;DR: 提出了一种基于MPC和HJ可达性的框架，优化自主系统的任务性能同时满足安全约束。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在保证安全的同时高效完成任务，缺乏安全性保证或牺牲任务性能。

Method: 结合模型预测控制（MPC）和Hamilton-Jacobi（HJ）可达性理论，确保递归可行性并适用于高维系统。

Result: 在4D Dubins Car和6自由度Kuka iiwa机械臂的仿真实验中，框架显著提高了系统的安全性。

Conclusion: 该框架在保证安全性的同时优化了任务性能，适用于高维自主系统。

Abstract: While we have made significant algorithmic developments to enable autonomous
systems to perform sophisticated tasks, it remains difficult for them to
perform tasks effective and safely. Most existing approaches either fail to
provide any safety assurances or substantially compromise task performance for
safety. In this work, we develop a framework, based on model predictive control
(MPC) and Hamilton-Jacobi (HJ) reachability, to optimize task performance for
autonomous systems while respecting the safety constraints. Our framework
guarantees recursive feasibility for the MPC controller, and it is scalable to
high-dimensional systems. We demonstrate the effectiveness of our framework
with two simulation studies using a 4D Dubins Car and a 6 Dof Kuka iiwa
manipulator, and the experiments show that our framework significantly improves
the safety constraints satisfaction of the systems over the baselines.

</details>


### [2] [A Model Predictive Control Framework to Enhance Safety and Quality in Mobile Additive Manufacturing Systems](https://arxiv.org/abs/2506.23400)
*Yifei Li,Joshua A. Robbins,Guha Manogharan,Herschel C. Pangborn,Ilya Kovalenko*

Main category: cs.RO

TL;DR: 提出了一种结合移动机器人与增材制造（AM）的模型预测控制框架，以提高生产灵活性和打印质量。


<details>
  <summary>Details</summary>
Motivation: 传统AM系统因静态设置和依赖人工导致生产周期长、扩展性差，移动机器人可提升灵活性但忽视打印质量。

Method: 集成AM系统与移动机器人，采用模型预测控制框架，确保安全导航和高打印质量。

Result: 通过三个案例研究验证了系统的可行性和可靠性。

Conclusion: 该框架为动态环境中的高质量AM生产提供了有效解决方案。

Abstract: In recent years, the demand for customized, on-demand production has grown in
the manufacturing sector. Additive Manufacturing (AM) has emerged as a
promising technology to enhance customization capabilities, enabling greater
flexibility, reduced lead times, and more efficient material usage. However,
traditional AM systems remain constrained by static setups and human worker
dependencies, resulting in long lead times and limited scalability. Mobile
robots can improve the flexibility of production systems by transporting
products to designated locations in a dynamic environment. By integrating AM
systems with mobile robots, manufacturers can optimize travel time for
preparatory tasks and distributed printing operations. Mobile AM robots have
been deployed for on-site production of large-scale structures, but often
neglect critical print quality metrics like surface roughness. Additionally,
these systems do not have the precision necessary for producing small,
intricate components. We propose a model predictive control framework for a
mobile AM platform that ensures safe navigation on the plant floor while
maintaining high print quality in a dynamic environment. Three case studies are
used to test the feasibility and reliability of the proposed systems.

</details>


### [3] [Towards Universal Shared Control in Teleoperation Without Haptic Feedback](https://arxiv.org/abs/2506.23624)
*Max Grobbel,Tristan Schneider,Sören Hohmann*

Main category: cs.RO

TL;DR: 论文提出了一种通过多目标优化将用户输入转换为无碰撞UR5e关节轨迹的方法，以解决非触觉VR控制器缺乏运动反馈的问题，同时抑制玻璃中液体的晃动。


<details>
  <summary>Details</summary>
Motivation: 非触觉VR控制器缺乏关键的运动反馈，限制了操作效果。

Method: 嵌入多目标优化问题，将用户输入转换为无碰撞的UR5e关节轨迹，并主动抑制液体晃动。

Result: 控制器平均规划延迟为13毫秒，证实了实时性能。

Conclusion: 该方法适用于进一步扩展其他目标的远程操作。

Abstract: Teleoperation with non-haptic VR controllers deprives human operators of
critical motion feedback. We address this by embedding a multi-objective
optimization problem that converts user input into collision-free UR5e joint
trajectories while actively suppressing liquid slosh in a glass. The controller
maintains 13 ms average planning latency, confirming real-time performance and
motivating the augmentation of this teleoperation approach to further
objectives.

</details>


### [4] [Data-Driven Predictive Planning and Control for Aerial 3D Inspection with Back-face Elimination](https://arxiv.org/abs/2506.23781)
*Savvas Papaioannou,Panayiotis Kolios,Christos G. Panayiotou,Marios M. Polycarpou*

Main category: cs.RO

TL;DR: 提出了一种基于数据驱动预测控制的3D检测方法，统一了感知、规划与控制，适用于现成的黑盒无人机系统。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将感知、规划和控分离，且缺乏长时程规划能力，难以满足复杂检测任务的需求。

Method: 结合3D计算机图形学中的背面消除技术，在控制循环中在线生成长时程的3D检测轨迹。

Result: 方法无需已知无人机动态模型，仅需输入输出数据，适用于现成无人机。

Conclusion: 该方法为复杂检测任务提供了一种高效、统一的解决方案。

Abstract: Automated inspection with Unmanned Aerial Systems (UASs) is a transformative
capability set to revolutionize various application domains. However, this task
is inherently complex, as it demands the seamless integration of perception,
planning, and control which existing approaches often treat separately.
Moreover, it requires accurate long-horizon planning to predict action
sequences, in contrast to many current techniques, which tend to be myopic. To
overcome these limitations, we propose a 3D inspection approach that unifies
perception, planning, and control within a single data-driven predictive
control framework. Unlike traditional methods that rely on known UAS dynamic
models, our approach requires only input-output data, making it easily
applicable to off-the-shelf black-box UASs. Our method incorporates back-face
elimination, a visibility determination technique from 3D computer graphics,
directly into the control loop, thereby enabling the online generation of
accurate, long-horizon 3D inspection trajectories.

</details>


### [5] [Conversations with Andrea: Visitors' Opinions on Android Robots in a Museum](https://arxiv.org/abs/2506.22466)
*Marcel Heisler,Christian Becker-Asano*

Main category: cs.RO

TL;DR: Andrea机器人博物馆互动实验显示，访客对其总体评价积极，主要希望其提供展品信息，同时改进语言支持和响应速度。


<details>
  <summary>Details</summary>
Motivation: 研究公众对自主对话机器人的接受度及潜在应用场景。

Method: 在博物馆部署Andrea机器人，进行结构化访谈和系统日志分析。

Result: 访客对机器人总体评价积极，主要需求为展品信息和多语言支持。

Conclusion: 实验结果将用于改进机器人系统，以适应实际应用需求。

Abstract: The android robot Andrea was set up at a public museum in Germany for six
consecutive days to have conversations with visitors, fully autonomously. No
specific context was given, so visitors could state their opinions regarding
possible use-cases in structured interviews, without any bias. Additionally the
44 interviewees were asked for their general opinions of the robot, their
reasons (not) to interact with it and necessary improvements for future use.
The android's voice and wig were changed between different days of operation to
give varying cues regarding its gender. This did not have a significant impact
on the positive overall perception of the robot. Most visitors want the robot
to provide information about exhibits in the future, while opinions on other
roles, like a receptionist, were both wanted and explicitly not wanted by
different visitors. Speaking more languages (than only English) and faster
response times were the improvements most desired. These findings from the
interviews are in line with an analysis of the system logs, which revealed,
that after chitchat and personal questions, most of the 4436 collected requests
asked for information related to the museum and to converse in a different
language. The valuable insights gained from these real-world interactions are
now used to improve the system to become a useful real-world application.

</details>


### [6] [Unsupervised Discovery of Behavioral Primitives from Sensorimotor Dynamic Functional Connectivity](https://arxiv.org/abs/2506.22473)
*Fernando Diaz Ledezma,Valentin Marcel,Matej Hoffmann*

Main category: cs.RO

TL;DR: 提出了一种分析机器人多模态感知信号动态功能连接的框架，揭示其底层结构。


<details>
  <summary>Details</summary>
Motivation: 研究如何从高维传感器运动信息中提取有意义的结构，帮助机器人或新生儿理解其感知运动空间。

Method: 使用瞬时互信息捕捉动态功能连接，结合无限关系模型和非负矩阵分解识别传感器运动模块及其演化模式。

Result: 发现了感知运动模块及其动态连接模式，这些模式可视为运动基元，用于行为选择。

Conclusion: 该方法可应用于机器人学习和人类运动轨迹或脑信号分析。

Abstract: The movements of both animals and robots give rise to streams of
high-dimensional motor and sensory information. Imagine the brain of a newborn
or the controller of a baby humanoid robot trying to make sense of unprocessed
sensorimotor time series. Here, we present a framework for studying the dynamic
functional connectivity between the multimodal sensory signals of a robotic
agent to uncover an underlying structure. Using instantaneous mutual
information, we capture the time-varying functional connectivity (FC) between
proprioceptive, tactile, and visual signals, revealing the sensorimotor
relationships. Using an infinite relational model, we identified sensorimotor
modules and their evolving connectivity. To further interpret these dynamic
interactions, we employed non-negative matrix factorization, which decomposed
the connectivity patterns into additive factors and their corresponding
temporal coefficients. These factors can be considered the agent's motion
primitives or movement synergies that the agent can use to make sense of its
sensorimotor space and later for behavior selection. In the future, the method
can be deployed in robot learning as well as in the analysis of human movement
trajectories or brain signals.

</details>


### [7] [DriveBLIP2: Attention-Guided Explanation Generation for Complex Driving Scenarios](https://arxiv.org/abs/2506.22494)
*Shihong Ling,Yue Wan,Xiaowei Jia,Na Du*

Main category: cs.RO

TL;DR: DriveBLIP2框架基于BLIP2-OPT架构，通过注意力图生成器提升自动驾驶场景中的解释质量。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在复杂多目标环境中表现不佳，尤其在实时自动驾驶场景中难以快速识别关键对象。

Method: 提出注意力图生成器，突出关键帧中对驾驶决策重要的对象，以生成更清晰的解释。

Result: 在DRAMA数据集上评估，BLEU、ROUGE、CIDEr和SPICE分数显著优于基线模型。

Conclusion: 定向注意力机制可提升视觉语言模型在实时自动驾驶中的可解释性。

Abstract: This paper introduces a new framework, DriveBLIP2, built upon the BLIP2-OPT
architecture, to generate accurate and contextually relevant explanations for
emerging driving scenarios. While existing vision-language models perform well
in general tasks, they encounter difficulties in understanding complex,
multi-object environments, particularly in real-time applications such as
autonomous driving, where the rapid identification of key objects is crucial.
To address this limitation, an Attention Map Generator is proposed to highlight
significant objects relevant to driving decisions within critical video frames.
By directing the model's focus to these key regions, the generated attention
map helps produce clear and relevant explanations, enabling drivers to better
understand the vehicle's decision-making process in critical situations.
Evaluations on the DRAMA dataset reveal significant improvements in explanation
quality, as indicated by higher BLEU, ROUGE, CIDEr, and SPICE scores compared
to baseline models. These findings underscore the potential of targeted
attention mechanisms in vision-language models for enhancing explainability in
real-time autonomous driving.

</details>


### [8] [Directed Shape Morphing using Kirigami-enhanced Thermoplastics](https://arxiv.org/abs/2506.22572)
*Mrunmayi Mungekar,Sanjith Menon,M. Ravi Shankar,M. Khalid Jawed*

Main category: cs.RO

TL;DR: 提出了一种简单的方法，通过均匀加热和常见工具（如家用烤箱和剪刀）将平面塑料片自主转化为复杂三维结构。


<details>
  <summary>Details</summary>
Motivation: 探索一种无需复杂控制即可实现复杂三维形状的自变形方法，适用于自适应设计和规模化制造。

Method: 结合热收缩热塑性塑料和定制Kirigami图案，形成双层复合材料，通过均匀加热驱动变形。

Result: 成功制造出多种复杂结构（如碗、金字塔和鼠标盖），并通过有限元模拟验证了变形行为。

Conclusion: 该方法通过几何设计实现了低信息刺激下的高复杂度形状，为自适应设计和制造提供了通用平台。

Abstract: We present a simple, accessible method for autonomously transforming flat
plastic sheets into intricate three-dimensional structures using only uniform
heating and common tools such as household ovens and scissors. Our approach
combines heat-shrinkable thermoplastics with Kirigami patterns tailored to the
target 3D shape, creating bilayer composites that morph into a wide range of
complex structures, e.g., bowls, pyramids, and even custom ergonomic surfaces
like mouse covers. Critically, the transformation is driven by a
low-information stimulus (uniform heat) yet produces highly intricate shapes
through programmed geometric design. The morphing behavior, confirmed by finite
element simulations, arises from strain mismatch between the contracting
thermoplastic layer and the constraining Kirigami layer. By decoupling material
composition from mechanical response, this method avoids detailed process
control and enables a broad class of self-morphing structures, offering a
versatile platform for adaptive design and scalable manufacturing.

</details>


### [9] [Pixels-to-Graph: Real-time Integration of Building Information Models and Scene Graphs for Semantic-Geometric Human-Robot Understanding](https://arxiv.org/abs/2506.22593)
*Antonello Longo,Chanyoung Chung,Matteo Palieri,Sung-Kyun Kim,Ali Agha,Cataldo Guaragnella,Shehryar Khattak*

Main category: cs.RO

TL;DR: Pix2G方法通过实时生成结构化场景图，连接2D BIM与3D地图，支持资源受限机器人自主探索未知环境。


<details>
  <summary>Details</summary>
Motivation: 解决人类操作员与机器人在高风险任务中高效合作的需求，弥合2D BIM与3D地图之间的差距。

Method: 提出Pix2G，一种轻量级方法，从图像像素和LiDAR地图实时生成场景图，仅使用CPU。

Result: 生成去噪2D地图和结构分割的3D点云，通过多层图连接，实验验证了实时性能。

Conclusion: Pix2G在资源受限平台上实现了高效的环境探索与地图构建。

Abstract: Autonomous robots are increasingly playing key roles as support platforms for
human operators in high-risk, dangerous applications. To accomplish challenging
tasks, an efficient human-robot cooperation and understanding is required.
While typically robotic planning leverages 3D geometric information, human
operators are accustomed to a high-level compact representation of the
environment, like top-down 2D maps representing the Building Information Model
(BIM). 3D scene graphs have emerged as a powerful tool to bridge the gap
between human readable 2D BIM and the robot 3D maps. In this work, we introduce
Pixels-to-Graph (Pix2G), a novel lightweight method to generate structured
scene graphs from image pixels and LiDAR maps in real-time for the autonomous
exploration of unknown environments on resource-constrained robot platforms. To
satisfy onboard compute constraints, the framework is designed to perform all
operation on CPU only. The method output are a de-noised 2D top-down
environment map and a structure-segmented 3D pointcloud which are seamlessly
connected using a multi-layer graph abstracting information from object-level
up to the building-level. The proposed method is quantitatively and
qualitatively evaluated during real-world experiments performed using the NASA
JPL NeBula-Spot legged robot to autonomously explore and map cluttered garage
and urban office like environments in real-time.

</details>


### [10] [Robust Peg-in-Hole Assembly under Uncertainties via Compliant and Interactive Contact-Rich Manipulation](https://arxiv.org/abs/2506.22766)
*Yiting Chen,Kenneth Kimble,Howard H. Qian,Podshara Chanrungmaneekul,Robert Seney,Kaiyu Hang*

Main category: cs.RO

TL;DR: 提出了一种基于接触约束的鲁棒自适应机器人插孔装配方法，通过利用接触消除不确定性，无需精确感知即可完成装配。


<details>
  <summary>Details</summary>
Motivation: 解决紧密公差下机器人插孔装配中的感知和物理不确定性挑战。

Method: 利用接触约束规划碰撞包容的交互动作，通过漏斗化状态空间构建不确定性吸收范式。

Result: 系统在不同尺度、形状和材料的插孔场景中表现鲁棒，实验验证了其有效性。

Conclusion: 该方法为插孔装配提供了一种学习无关的鲁棒解决方案。

Abstract: Robust and adaptive robotic peg-in-hole assembly under tight tolerances is
critical to various industrial applications. However, it remains an open
challenge due to perceptual and physical uncertainties from contact-rich
interactions that easily exceed the allowed clearance. In this paper, we study
how to leverage contact between the peg and its matching hole to eliminate
uncertainties in the assembly process under unstructured settings. By examining
the role of compliance under contact constraints, we present a manipulation
system that plans collision-inclusive interactions for the peg to 1)
iteratively identify its task environment to localize the target hole and 2)
exploit environmental contact constraints to refine insertion motions into the
target hole without relying on precise perception, enabling a robust solution
to peg-in-hole assembly. By conceptualizing the above process as the
composition of funneling in different state spaces, we present a formal
approach to constructing manipulation funnels as an uncertainty-absorbing
paradigm for peg-in-hole assembly. The proposed system effectively generalizes
across diverse peg-in-hole scenarios across varying scales, shapes, and
materials in a learning-free manner. Extensive experiments on a NIST Assembly
Task Board (ATB) and additional challenging scenarios validate its robustness
in real-world applications.

</details>


### [11] [Learning Efficient Robotic Garment Manipulation with Standardization](https://arxiv.org/abs/2506.22769)
*Changshi Zhou,Feng Luan,Jiarui Hu,Shaoqiang Meng,Zhipeng Wang,Yanchao Dong,Yanmin Zhou,Bin He*

Main category: cs.RO

TL;DR: APS-Net提出了一种结合展开和标准化的统一框架，用于机器人衣物操作，通过动态抛掷和精确对齐实现高效展开和标准化。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了衣物展开后的标准化，而标准化能显著简化后续任务（如折叠、熨烫和包装）。

Method: 采用双臂多基元策略，结合动态抛掷和精确对齐，引入因子化奖励函数（覆盖率、关键点距离和IoU）和空间动作掩码。

Result: 在仿真中，APS-Net在长袖衣物上表现优于现有方法，覆盖率提高3.9%，IoU提高5.2%，关键点距离减少7.09%。

Conclusion: 标准化显著简化了折叠任务，APS-Net在衣物操作中表现出高效性和实用性。

Abstract: Garment manipulation is a significant challenge for robots due to the complex
dynamics and potential self-occlusion of garments. Most existing methods of
efficient garment unfolding overlook the crucial role of standardization of
flattened garments, which could significantly simplify downstream tasks like
folding, ironing, and packing. This paper presents APS-Net, a novel approach to
garment manipulation that combines unfolding and standardization in a unified
framework. APS-Net employs a dual-arm, multi-primitive policy with dynamic
fling to quickly unfold crumpled garments and pick-and-place (p and p) for
precise alignment. The purpose of garment standardization during unfolding
involves not only maximizing surface coverage but also aligning the garment's
shape and orientation to predefined requirements. To guide effective robot
learning, we introduce a novel factorized reward function for standardization,
which incorporates garment coverage (Cov), keypoint distance (KD), and
intersection-over-union (IoU) metrics. Additionally, we introduce a spatial
action mask and an Action Optimized Module to improve unfolding efficiency by
selecting actions and operation points effectively. In simulation, APS-Net
outperforms state-of-the-art methods for long sleeves, achieving 3.9 percent
better coverage, 5.2 percent higher IoU, and a 0.14 decrease in KD (7.09
percent relative reduction). Real-world folding tasks further demonstrate that
standardization simplifies the folding process. Project page: see
https://hellohaia.github.io/APS/

</details>


### [12] [SPI-BoTER: Error Compensation for Industrial Robots via Sparse Attention Masking and Hybrid Loss with Spatial-Physical Information](https://arxiv.org/abs/2506.22788)
*Xuao Hou,Yongquan Jia,Shijin Zhang,Yuqiang Wu*

Main category: cs.RO

TL;DR: 论文提出了一种结合物理模型与Transformer架构的SPI-BoTER方法，用于工业机器人末端执行器的高精度误差补偿，显著提升了小样本条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 工业机器人轨迹精度需求日益严格，现有误差补偿方法存在建模简化、物理一致性不足和数据需求大等问题，难以同时实现高精度与强泛化。

Method: 提出SPI-BoTER方法，融合机器人运动学方程与稀疏自注意力Transformer架构，采用参数自适应混合损失函数迭代优化网络，并通过梯度下降优化逆关节角补偿。

Result: 在UR5机械臂小样本数据集上，3D绝对定位误差降至0.2515 mm（标准差0.15 mm），比传统DNN方法误差减少35.16%；逆角度补偿算法平均147次迭代收敛至0.01 mm精度。

Conclusion: SPI-BoTER方法结合物理可解释性与数据适应性，为工业机器人高精度控制提供了有效解决方案，有望推动智能制造中精密任务的可靠执行。

Abstract: The widespread application of industrial robots in fields such as cutting and
welding has imposed increasingly stringent requirements on the trajectory
accuracy of end-effectors. However, current error compensation methods face
several critical challenges, including overly simplified mechanism modeling, a
lack of physical consistency in data-driven approaches, and substantial data
requirements. These issues make it difficult to achieve both high accuracy and
strong generalization simultaneously. To address these challenges, this paper
proposes a Spatial-Physical Informed Attention Residual Network (SPI-BoTER).
This method integrates the kinematic equations of the robotic manipulator with
a Transformer architecture enhanced by sparse self-attention masks. A
parameter-adaptive hybrid loss function incorporating spatial and physical
information is employed to iteratively optimize the network during training,
enabling high-precision error compensation under small-sample conditions.
Additionally, inverse joint angle compensation is performed using a gradient
descent-based optimization method. Experimental results on a small-sample
dataset from a UR5 robotic arm (724 samples, with a train:test:validation split
of 8:1:1) demonstrate the superior performance of the proposed method. It
achieves a 3D absolute positioning error of 0.2515 mm with a standard deviation
of 0.15 mm, representing a 35.16\% reduction in error compared to conventional
deep neural network (DNN) methods. Furthermore, the inverse angle compensation
algorithm converges to an accuracy of 0.01 mm within an average of 147
iterations. This study presents a solution that combines physical
interpretability with data adaptability for high-precision control of
industrial robots, offering promising potential for the reliable execution of
precision tasks in intelligent manufacturing.

</details>


### [13] [Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation](https://arxiv.org/abs/2506.22827)
*André Schakkal,Ben Zandonati,Zhutian Yang,Navid Azizan*

Main category: cs.RO

TL;DR: 提出了一种分层规划与控制框架，用于实现人形机器人可靠的多步操作任务。


<details>
  <summary>Details</summary>
Motivation: 为了在工业和家庭环境中有效部署人形机器人，需要确保其能够可靠执行复杂的多步操作任务。

Method: 系统分为三层：低层RL控制器跟踪全身运动目标；中层模仿学习技能策略生成任务各步的运动目标；高层视觉语言规划模块决定技能执行并实时监控。

Result: 在Unitree G1人形机器人上进行的实验中，系统在40次试验中实现了72.5%的成功率。

Conclusion: 分层系统可行，视觉语言模型在技能规划和监控中具有优势。

Abstract: Enabling humanoid robots to reliably execute complex multi-step manipulation
tasks is crucial for their effective deployment in industrial and household
environments. This paper presents a hierarchical planning and control framework
designed to achieve reliable multi-step humanoid manipulation. The proposed
system comprises three layers: (1) a low-level RL-based controller responsible
for tracking whole-body motion targets; (2) a mid-level set of skill policies
trained via imitation learning that produce motion targets for different steps
of a task; and (3) a high-level vision-language planning module that determines
which skills should be executed and also monitors their completion in real-time
using pretrained vision-language models (VLMs). Experimental validation is
performed on a Unitree G1 humanoid robot executing a non-prehensile
pick-and-place task. Over 40 real-world trials, the hierarchical system
achieved a 72.5% success rate in completing the full manipulation sequence.
These experiments confirm the feasibility of the proposed hierarchical system,
highlighting the benefits of VLM-based skill planning and monitoring for
multi-step manipulation scenarios. See https://vlp-humanoid.github.io/ for
video demonstrations of the policy rollout.

</details>


### [14] [Safe Reinforcement Learning with a Predictive Safety Filter for Motion Planning and Control: A Drifting Vehicle Example](https://arxiv.org/abs/2506.22894)
*Bei Zhou,Baha Zarrouki,Mattia Piccinini,Cheng Hu,Lei Xie,Johannes Betz*

Main category: cs.RO

TL;DR: 提出了一种基于安全强化学习的运动规划方法，用于自主漂移，结合模型漂移动力学和预测安全过滤器，确保安全高效的学习和操作。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法在高不稳定性漂移中表现不佳，现有学习方法的探索能力有限且安全性不足。

Method: 结合强化学习代理与模型漂移动力学，引入预测安全过滤器在线调整动作以防止不安全状态。

Result: 在Matlab-Carsim平台上验证，显著提升漂移性能、减少跟踪误差并提高计算效率。

Conclusion: 该方法有望提升自动驾驶车辆在安全关键场景中的能力。

Abstract: Autonomous drifting is a complex and crucial maneuver for safety-critical
scenarios like slippery roads and emergency collision avoidance, requiring
precise motion planning and control. Traditional motion planning methods often
struggle with the high instability and unpredictability of drifting,
particularly when operating at high speeds. Recent learning-based approaches
have attempted to tackle this issue but often rely on expert knowledge or have
limited exploration capabilities. Additionally, they do not effectively address
safety concerns during learning and deployment. To overcome these limitations,
we propose a novel Safe Reinforcement Learning (RL)-based motion planner for
autonomous drifting. Our approach integrates an RL agent with model-based drift
dynamics to determine desired drift motion states, while incorporating a
Predictive Safety Filter (PSF) that adjusts the agent's actions online to
prevent unsafe states. This ensures safe and efficient learning, and stable
drift operation. We validate the effectiveness of our method through
simulations on a Matlab-Carsim platform, demonstrating significant improvements
in drift performance, reduced tracking errors, and computational efficiency
compared to traditional methods. This strategy promises to extend the
capabilities of autonomous vehicles in safety-critical maneuvers.

</details>


### [15] [Energy-Constrained Resilient Multi-Robot Coverage Control](https://arxiv.org/abs/2506.22942)
*Kartik A. Pant,Jaehyeok Kim,James M. Goppert,Inseok Hwang*

Main category: cs.RO

TL;DR: 提出了一种多机器人覆盖控制的弹性网络设计与控制方法，解决机器人在充电时网络拓扑中断的问题。


<details>
  <summary>Details</summary>
Motivation: 多机器人同时离开任务空间充电会破坏通信和感知的网络拓扑，影响覆盖性能。

Method: 将多机器人系统的运动、能量和网络动态建模为混合系统，设计能量感知的轴承刚性网络以增强结构弹性。

Result: 通过数值模拟验证了方法的有效性，确保机器人在满足能量约束的同时保持网络连接。

Conclusion: 提出的方法能够有效维持多机器人系统的覆盖性能和网络弹性。

Abstract: The problem of multi-robot coverage control becomes significantly challenging
when multiple robots leave the mission space simultaneously to charge their
batteries, disrupting the underlying network topology for communication and
sensing. To address this, we propose a resilient network design and control
approach that allows robots to achieve the desired coverage performance while
satisfying energy constraints and maintaining network connectivity throughout
the mission. We model the combined motion, energy, and network dynamics of the
multirobot systems (MRS) as a hybrid system with three modes, i.e., coverage,
return-to-base, and recharge, respectively. We show that ensuring the energy
constraints can be transformed into designing appropriate guard conditions for
mode transition between each of the three modes. Additionally, we present a
systematic procedure to design, maintain, and reconfigure the underlying
network topology using an energy-aware bearing rigid network design, enhancing
the structural resilience of the MRS even when a subset of robots departs to
charge their batteries. Finally, we validate our proposed method using
numerical simulations.

</details>


### [16] [SPICE-HL3: Single-Photon, Inertial, and Stereo Camera dataset for Exploration of High-Latitude Lunar Landscapes](https://arxiv.org/abs/2506.22956)
*David Rodríguez-Martínez,Dave van der Meer,Junlin Song,Abishek Bera,C. J. Pérez-del-Pulgar,Miguel Angel Olivares-Mendez*

Main category: cs.RO

TL;DR: 论文介绍了一个独特的数据集，模拟高纬度月球环境，用于验证感知任务。


<details>
  <summary>Details</summary>
Motivation: 高纬度月球区域的视觉环境对机器人极具挑战性，需在地球上模拟这些条件以支持未来任务。

Method: 在LunaLab设施中记录数据集，包括图像、惯性测量和轮式里程数据，使用多种传感器。

Result: 数据集包含88个序列、130万张图像，涵盖多种光照条件和机器人速度。

Conclusion: 数据集为未来月球任务中的感知任务验证提供了宝贵资源。

Abstract: Exploring high-latitude lunar regions presents an extremely challenging
visual environment for robots. The low sunlight elevation angle and minimal
light scattering result in a visual field dominated by a high dynamic range
featuring long, dynamic shadows. Reproducing these conditions on Earth requires
sophisticated simulators and specialized facilities. We introduce a unique
dataset recorded at the LunaLab from the SnT - University of Luxembourg, an
indoor test facility designed to replicate the optical characteristics of
multiple lunar latitudes. Our dataset includes images, inertial measurements,
and wheel odometry data from robots navigating seven distinct trajectories
under multiple illumination scenarios, simulating high-latitude lunar
conditions from dawn to night time with and without the aid of headlights,
resulting in 88 distinct sequences containing a total of 1.3M images. Data was
captured using a stereo RGB-inertial sensor, a monocular monochrome camera, and
for the first time, a novel single-photon avalanche diode (SPAD) camera. We
recorded both static and dynamic image sequences, with robots navigating at
slow (5 cm/s) and fast (50 cm/s) speeds. All data is calibrated, synchronized,
and timestamped, providing a valuable resource for validating perception tasks
from vision-based autonomous navigation to scientific imaging for future lunar
missions targeting high-latitude regions or those intended for robots operating
across perceptually degraded environments. The dataset can be downloaded from
https://zenodo.org/records/13970078?preview=1, and a visual overview is
available at https://youtu.be/d7sPeO50_2I. All supplementary material can be
found at https://github.com/spaceuma/spice-hl3.

</details>


### [17] [Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making](https://arxiv.org/abs/2506.23023)
*M. Youssef Abdelhamid,Lennart Vater,Zlatan Ajanovic*

Main category: cs.RO

TL;DR: SAD-RL框架通过分层策略和场景化环境提升自动驾驶决策算法的泛化性和学习效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需在复杂开放环境中安全运行，现有强化学习方法在复杂任务中泛化性和效率不足。

Method: 提出SAD-RL框架，结合分层策略（高层选择模板，低层执行）和场景化环境，控制训练体验并引入挑战性场景。

Result: 实验表明SAD-RL能高效实现安全行为，消融研究证实分层策略和场景多样性是关键。

Conclusion: SAD-RL为复杂自动驾驶任务提供了有效的解决方案。

Abstract: Developing decision-making algorithms for highly automated driving systems
remains challenging, since these systems have to operate safely in an open and
complex environments. Reinforcement Learning (RL) approaches can learn
comprehensive decision policies directly from experience and already show
promising results in simple driving tasks. However, current approaches fail to
achieve generalizability for more complex driving tasks and lack learning
efficiency. Therefore, we present Scenario-based Automated Driving
Reinforcement Learning (SAD-RL), the first framework that integrates
Reinforcement Learning (RL) of hierarchical policy in a scenario-based
environment. A high-level policy selects maneuver templates that are evaluated
and executed by a low-level control logic. The scenario-based environment
allows to control the training experience for the agent and to explicitly
introduce challenging, but rate situations into the training process. Our
experiments show that an agent trained using the SAD-RL framework can achieve
safe behaviour in easy as well as challenging situations efficiently. Our
ablation studies confirmed that both HRL and scenario diversity are essential
for achieving these results.

</details>


### [18] [Event-based Stereo Visual-Inertial Odometry with Voxel Map](https://arxiv.org/abs/2506.23078)
*Zhaoxing Zhang,Xiaoxiang Wang,Chengliang Zhang,Yangyang Guo,Zikang Yuan,Xin Yang*

Main category: cs.RO

TL;DR: Voxel-ESVIO是一种基于事件相机的立体视觉惯性里程计系统，通过体素地图管理高效筛选高质量3D点，提升状态估计精度。


<details>
  <summary>Details</summary>
Motivation: 事件相机的高动态范围和优异时间分辨率使其成为视觉里程计的重要传感器，但事件流中的噪声影响了高质量地图点的选择，进而影响状态估计精度。

Method: 采用基于体素的点选择和体素感知的点管理策略，以体素为单位优化地图点的选择和更新，高效提取抗噪声的地图点。

Result: 在三个公开基准测试中，Voxel-ESVIO在精度和计算效率上均优于现有方法。

Conclusion: Voxel-ESVIO通过体素地图管理有效解决了事件流噪声问题，显著提升了视觉惯性里程计的性能。

Abstract: The event camera, renowned for its high dynamic range and exceptional
temporal resolution, is recognized as an important sensor for visual odometry.
However, the inherent noise in event streams complicates the selection of
high-quality map points, which critically determine the precision of state
estimation. To address this challenge, we propose Voxel-ESVIO, an event-based
stereo visual-inertial odometry system that utilizes voxel map management,
which efficiently filter out high-quality 3D points. Specifically, our
methodology utilizes voxel-based point selection and voxel-aware point
management to collectively optimize the selection and updating of map points on
a per-voxel basis. These synergistic strategies enable the efficient retrieval
of noise-resilient map points with the highest observation likelihood in
current frames, thereby ensureing the state estimation accuracy. Extensive
evaluations on three public benchmarks demonstrate that our Voxel-ESVIO
outperforms state-of-the-art methods in both accuracy and computational
efficiency.

</details>


### [19] [Minimizing Acoustic Noise: Enhancing Quiet Locomotion for Quadruped Robots in Indoor Applications](https://arxiv.org/abs/2506.23114)
*Zhanxiang Cao,Buqing Nie,Yang Zhang,Yue Gao*

Main category: cs.RO

TL;DR: 该研究通过优化步态设计和控制策略，降低四足机器人在运动中的噪音，平均减少约8 dBA，适用于噪声敏感的室内环境。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在复杂户外环境中的运动能力已显著提升，但其运动噪音在噪声敏感的室内环境（如服务和医疗场景）中被忽视，需要解决。

Method: 提出一种结合优化步态设计和定制控制策略的新方法，以减少噪音排放。

Result: 实验结果显示，该方法平均减少约8 dBA的噪音，适用于多种室内环境。

Conclusion: 该方法有效提升了四足机器人在噪声敏感环境中的适用性，展示了其安静运行的潜力。

Abstract: Recent advancements in quadruped robot research have significantly improved
their ability to traverse complex and unstructured outdoor environments.
However, the issue of noise generated during locomotion is generally
overlooked, which is critically important in noise-sensitive indoor
environments, such as service and healthcare settings, where maintaining low
noise levels is essential. This study aims to optimize the acoustic noise
generated by quadruped robots during locomotion through the development of
advanced motion control algorithms. To achieve this, we propose a novel
approach that minimizes noise emissions by integrating optimized gait design
with tailored control strategies. This method achieves an average noise
reduction of approximately 8 dBA during movement, thereby enhancing the
suitability of quadruped robots for deployment in noise-sensitive indoor
environments. Experimental results demonstrate the effectiveness of this
approach across various indoor settings, highlighting the potential of
quadruped robots for quiet operation in noise-sensitive environments.

</details>


### [20] [Learning Motion Skills with Adaptive Assistive Curriculum Force in Humanoid Robots](https://arxiv.org/abs/2506.23125)
*Zhanxiang Cao,Yang Zhang,Buqing Nie,Huangxuan Lin,Haoyang Li,Yue Gao*

Main category: cs.RO

TL;DR: A2CF方法通过自适应辅助力加速人形机器人复杂动作学习，比基线方法快30%，失败率降低40%。


<details>
  <summary>Details</summary>
Motivation: 受婴儿和运动员依赖外部支持学习复杂动作的启发，提出A2CF方法以解决人形机器人任务学习的挑战。

Method: A2CF训练双代理系统，辅助力代理根据状态施加力，逐步减少辅助以提升机器人熟练度。

Result: 在行走、跳舞和后空翻任务中，A2CF比基线方法快30%，失败率降低40%，生成无需支持的稳健策略。

Conclusion: 自适应辅助力显著加速高维机器人控制中复杂技能的获取，实验验证了其有效性。

Abstract: Learning policies for complex humanoid tasks remains both challenging and
compelling. Inspired by how infants and athletes rely on external support--such
as parental walkers or coach-applied guidance--to acquire skills like walking,
dancing, and performing acrobatic flips, we propose A2CF: Adaptive Assistive
Curriculum Force for humanoid motion learning. A2CF trains a dual-agent system,
in which a dedicated assistive force agent applies state-dependent forces to
guide the robot through difficult initial motions and gradually reduces
assistance as the robot's proficiency improves. Across three
benchmarks--bipedal walking, choreographed dancing, and backflip--A2CF achieves
convergence 30% faster than baseline methods, lowers failure rates by over 40%,
and ultimately produces robust, support-free policies. Real-world experiments
further demonstrate that adaptively applied assistive forces significantly
accelerate the acquisition of complex skills in high-dimensional robotic
control.

</details>


### [21] [ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation](https://arxiv.org/abs/2506.23126)
*Suning Huang,Qianzhong Chen,Xiaohan Zhang,Jiankai Sun,Mac Schwager*

Main category: cs.RO

TL;DR: ParticleFormer是一种基于Transformer的点云世界模型，用于多材料、多物体的机器人交互，无需复杂场景重建即可训练，并在动态预测和下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有3D世界模型局限于单材料动态且需要耗时3D重建，无法有效处理多材料、多物体的复杂交互。

Method: 提出ParticleFormer，结合Transformer和混合点云重建损失，直接利用真实机器人感知数据训练，捕捉多材料动态。

Result: 在仿真和真实实验中，模型在动态预测和下游任务中表现优于基线方法。

Conclusion: ParticleFormer为多材料、多物体的机器人交互提供了一种高效且通用的解决方案。

Abstract: 3D world models (i.e., learning-based 3D dynamics models) offer a promising
approach to generalizable robotic manipulation by capturing the underlying
physics of environment evolution conditioned on robot actions. However,
existing 3D world models are primarily limited to single-material dynamics
using a particle-based Graph Neural Network model, and often require
time-consuming 3D scene reconstruction to obtain 3D particle tracks for
training. In this work, we present ParticleFormer, a Transformer-based point
cloud world model trained with a hybrid point cloud reconstruction loss,
supervising both global and local dynamics features in multi-material,
multi-object robot interactions. ParticleFormer captures fine-grained
multi-object interactions between rigid, deformable, and flexible materials,
trained directly from real-world robot perception data without an elaborate
scene reconstruction. We demonstrate the model's effectiveness both in 3D scene
forecasting tasks, and in downstream manipulation tasks using a Model
Predictive Control (MPC) policy. In addition, we extend existing dynamics
learning benchmarks to include diverse multi-material, multi-object interaction
scenarios. We validate our method on six simulation and three real-world
experiments, where it consistently outperforms leading baselines by achieving
superior dynamics prediction accuracy and less rollout error in downstream
visuomotor tasks. Experimental videos are available at
https://particleformer.github.io/.

</details>


### [22] [Flatness-based Finite-Horizon Multi-UAV Formation Trajectory Planning and Directionally Aware Collision Avoidance Tracking](https://arxiv.org/abs/2506.23129)
*Hossein B. Jond,Logan Beaver,Martin Jiroušek,Naiemeh Ahmadlou,Veli Bakırcıoğlu,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种基于微分平坦性的无人机编队控制方案，避免了数值方法的依赖，并通过碰撞约束调节确保无碰撞跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有最优控制方法对初始猜测敏感，难以实现无碰撞的无人机编队控制。

Method: 利用无人机动力学的微分平坦性，提出有限时间最优控制问题，结合Pontryagin原理求解，并引入方向感知的碰撞避免策略。

Result: 仿真验证了四无人机编队问题的有效性。

Conclusion: 该方案为无人机编队控制提供了一种高效且无碰撞的解决方案。

Abstract: Collision-free optimal formation control of unmanned aerial vehicle (UAV)
teams is challenging. The state-of-the-art optimal control approaches often
rely on numerical methods sensitive to initial guesses. This paper presents an
innovative collision-free finite-time formation control scheme for multiple
UAVs leveraging the differential flatness of the UAV dynamics, eliminating the
need for numerical methods. We formulate a finite-time optimal control problem
to plan a formation trajectory for feasible initial states. This formation
trajectory planning optimal control problem involves a collective performance
index to meet the formation requirements of achieving relative positions and
velocity consensus. It is solved by applying Pontryagin's principle.
Subsequently, a collision-constrained regulating problem is addressed to ensure
collision-free tracking of the planned formation trajectory. The tracking
problem incorporates a directionally aware collision avoidance strategy that
prioritizes avoiding UAVs in the forward path and relative approach. It assigns
lower priority to those on the sides with an oblique relative approach and
disregards UAVs behind and not in the relative approach. The simulation results
for a four-UAV team (re)formation problem confirm the efficacy of the proposed
control scheme.

</details>


### [23] [DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover](https://arxiv.org/abs/2506.23152)
*Youzhuo Wang,Jiayi Ye,Chuyang Xiao,Yiming Zhong,Heng Tao,Hang Yu,Yumeng Liu,Jingyi Yu,Yuexin Ma*

Main category: cs.RO

TL;DR: 论文介绍了DexH2R数据集，用于人机交互中的动态灵巧抓取任务，并提出了DynamicGrasp解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有数据集主要关注静态物体或合成动作，缺乏真实世界的人机交互数据，限制了动态灵巧抓取方法的发展。

Method: 通过遥操作收集数据，构建DexH2R数据集，并提出DynamicGrasp解决方案，评估多种先进方法。

Result: 提供了高质量数据集和解决方案，并进行了全面比较分析。

Conclusion: DexH2R数据集和DynamicGrasp解决方案将推动人机交互研究的发展。

Abstract: Handover between a human and a dexterous robotic hand is a fundamental yet
challenging task in human-robot collaboration. It requires handling dynamic
environments and a wide variety of objects and demands robust and adaptive
grasping strategies. However, progress in developing effective dynamic
dexterous grasping methods is limited by the absence of high-quality,
real-world human-to-robot handover datasets. Existing datasets primarily focus
on grasping static objects or rely on synthesized handover motions, which
differ significantly from real-world robot motion patterns, creating a
substantial gap in applicability. In this paper, we introduce DexH2R, a
comprehensive real-world dataset for human-to-robot handovers, built on a
dexterous robotic hand. Our dataset captures a diverse range of interactive
objects, dynamic motion patterns, rich visual sensor data, and detailed
annotations. Additionally, to ensure natural and human-like dexterous motions,
we utilize teleoperation for data collection, enabling the robot's movements to
align with human behaviors and habits, which is a crucial characteristic for
intelligent humanoid robots. Furthermore, we propose an effective solution,
DynamicGrasp, for human-to-robot handover and evaluate various state-of-the-art
approaches, including auto-regressive models and diffusion policy methods,
providing a thorough comparison and analysis. We believe our benchmark will
drive advancements in human-to-robot handover research by offering a
high-quality dataset, effective solutions, and comprehensive evaluation
metrics.

</details>


### [24] [Mode Collapse Happens: Evaluating Critical Interactions in Joint Trajectory Prediction Models](https://arxiv.org/abs/2506.23164)
*Maarten Hugenholtz,Anna Meszaros,Jens Kober,Zlatan Ajanovic*

Main category: cs.RO

TL;DR: 提出了一种新的评估框架，用于检测多模态轨迹预测中的模式崩溃问题，重点关注安全关键交互。


<details>
  <summary>Details</summary>
Motivation: 现有模型可能忽视交互模式的多样性，且缺乏定量评估模式崩溃的指标。

Method: 引入模式崩溃、模式正确性和覆盖率的度量标准，强调预测的时序维度。

Result: 测试四种多智能体轨迹预测模型，发现模式崩溃确实存在，且某些情况下模型无法预测正确的交互模式。

Conclusion: 该框架有助于开发更一致和准确的预测模型，提升自动驾驶系统的安全性。

Abstract: Autonomous Vehicle decisions rely on multimodal prediction models that
account for multiple route options and the inherent uncertainty in human
behavior. However, models can suffer from mode collapse, where only the most
likely mode is predicted, posing significant safety risks. While existing
methods employ various strategies to generate diverse predictions, they often
overlook the diversity in interaction modes among agents. Additionally,
traditional metrics for evaluating prediction models are dataset-dependent and
do not evaluate inter-agent interactions quantitatively. To our knowledge, none
of the existing metrics explicitly evaluates mode collapse. In this paper, we
propose a novel evaluation framework that assesses mode collapse in joint
trajectory predictions, focusing on safety-critical interactions. We introduce
metrics for mode collapse, mode correctness, and coverage, emphasizing the
sequential dimension of predictions. By testing four multi-agent trajectory
prediction models, we demonstrate that mode collapse indeed happens. When
looking at the sequential dimension, although prediction accuracy improves
closer to interaction events, there are still cases where the models are unable
to predict the correct interaction mode, even just before the interaction mode
becomes inevitable. We hope that our framework can help researchers gain new
insights and advance the development of more consistent and accurate prediction
models, thus enhancing the safety of autonomous driving systems.

</details>


### [25] [InfGen: Scenario Generation as Next Token Group Prediction](https://arxiv.org/abs/2506.23316)
*Zhenghao Peng,Yuxin Liu,Bolei Zhou*

Main category: cs.RO

TL;DR: InfGen是一个基于Transformer的交通场景生成框架，支持动态、长时程场景模拟，并能持续插入新车辆。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的交通模拟方法依赖静态初始化或日志回放，难以模拟动态、长时程场景。

Method: 将整个场景表示为包含交通信号、车辆状态和运动向量的token序列，通过Transformer模型自回归生成交通状态。

Result: InfGen生成的行为真实、多样且自适应，强化学习策略在其场景中表现出更强的鲁棒性和泛化能力。

Conclusion: InfGen是一个高保真度的自动驾驶模拟环境，支持无限场景生成。

Abstract: Realistic and interactive traffic simulation is essential for training and
evaluating autonomous driving systems. However, most existing data-driven
simulation methods rely on static initialization or log-replay data, limiting
their ability to model dynamic, long-horizon scenarios with evolving agent
populations. We propose InfGen, a scenario generation framework that outputs
agent states and trajectories in an autoregressive manner. InfGen represents
the entire scene as a sequence of tokens, including traffic light signals,
agent states, and motion vectors, and uses a transformer model to simulate
traffic over time. This design enables InfGen to continuously insert new agents
into traffic, supporting infinite scene generation. Experiments demonstrate
that InfGen produces realistic, diverse, and adaptive traffic behaviors.
Furthermore, reinforcement learning policies trained in InfGen-generated
scenarios achieve superior robustness and generalization, validating its
utility as a high-fidelity simulation environment for autonomous driving. More
information is available at https://metadriverse.github.io/infgen/.

</details>


### [26] [Simplifying Data-Driven Modeling of the Volume-Flow-Pressure Relationship in Hydraulic Soft Robotic Actuators](https://arxiv.org/abs/2506.23326)
*Sang-Yoep Lee,Leonardo Zamora Yanez,Jacob Rogatinsky,Vi T. Vo,Tanvi Shingade,Tommaso Ranzani*

Main category: cs.RO

TL;DR: 研究探索了一种数据驱动的方法，用于建模液压软执行器的体积-流量-压力关系，重点关注低复杂度高精度模型。


<details>
  <summary>Details</summary>
Motivation: 传统物理模型难以捕捉软机器人系统的复杂非线性行为。

Method: 使用指数、多项式和神经网络模型（带或不带自回归输入）对堆叠气球执行器系统进行回归分析。

Result: 结果表明，较简单的模型（尤其是多元多项式）能以较少参数有效预测压力动态。

Conclusion: 该研究为实时软机器人应用提供了实用解决方案，平衡了模型复杂度和计算效率。

Abstract: Soft robotic systems are known for their flexibility and adaptability, but
traditional physics-based models struggle to capture their complex, nonlinear
behaviors. This study explores a data-driven approach to modeling the
volume-flow-pressure relationship in hydraulic soft actuators, focusing on
low-complexity models with high accuracy. We perform regression analysis on a
stacked balloon actuator system using exponential, polynomial, and neural
network models with or without autoregressive inputs. The results demonstrate
that simpler models, particularly multivariate polynomials, effectively predict
pressure dynamics with fewer parameters. This research offers a practical
solution for real-time soft robotics applications, balancing model complexity
and computational efficiency. Moreover, the approach may benefit various
techniques that require explicit analytical models.

</details>


### [27] [Moving Matter: Using a Single, Simple Robot to Reconfigure a Connected Set of Building Blocks](https://arxiv.org/abs/2506.23333)
*Javier Garcia,Jonas Friemel,Ramin Kosfeld,Michael Yannuzzi,Peter Kramer,Christian Rieck,Christian Scheffer,Arne Schmidt,Harm Kube,Dan Biediger,Sándor P. Fekete,Aaron T. Becker*

Main category: cs.RO

TL;DR: 论文研究了使用单个机器人重新配置连接瓷砖结构的方法，比较了基于直方图的算法与两种启发式算法的性能。


<details>
  <summary>Details</summary>
Motivation: 探索如何高效地将瓷砖结构从初始形状重新配置为目标形状，同时保持连接性。

Method: 实现并评估了Becker等人提出的基于直方图的算法，并与两种启发式算法在模拟和实际环境中进行比较。

Result: 基于直方图的算法在初始和目标配置分离良好的情况下，性能接近最优解。

Conclusion: 该算法在特定条件下表现优越，为瓷砖结构的重新配置提供了有效解决方案。

Abstract: We implement and evaluate different methods for the reconfiguration of a
connected arrangement of tiles into a desired target shape, using a single
active robot that can move along the tile structure. This robot can pick up,
carry, or drop off one tile at a time, but it must maintain a single connected
configuration at all times.
  Becker et al. (CCCG 2025) recently proposed an algorithm that uses histograms
as canonical intermediate configurations, guaranteeing performance within a
constant factor of the optimal solution if the start and target configuration
are well-separated. We implement and evaluate this algorithm, both in a
simulated and practical setting, using an inchworm type robot to compare it
with two existing heuristic algorithms.

</details>


### [28] [Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop](https://arxiv.org/abs/2506.23351)
*Tianxing Chen,Kaixuan Wang,Zhaohui Yang,Yuhao Zhang,Zanxin Chen,Baijun Chen,Wanxi Dong,Ziyuan Liu,Dong Chen,Tianshuo Yang,Haibao Yu,Xiaokang Yang,Yusen Qin,Zhiqiang Xie,Yao Mu,Ping Luo,Tian Nian,Weiliang Deng,Yiheng Ge,Yibin Liu,Zixuan Li,Dehui Wang,Zhixuan Liang,Haohui Xie,Rijie Zeng,Yunfei Ge,Peiqing Cong,Guannan He,Zhaoming Han,Ruocheng Yin,Jingxiang Guo,Lunkai Lin,Tianling Xu,Hongzhe Bi,Xuewu Lin,Tianwei Lin,Shujie Luo,Keyu Li,Ziyan Zhao,Ke Fan,Heyang Xu,Bo Peng,Wenlong Gao,Dongjiang Li,Feng Jin,Hui Shen,Jinming Li,Chaowei Cui,Yuchen,Yaxin Peng,Lingdong Zeng,Wenlong Dong,Tengfei Li,Weijie Ke,Jun Chen,Erdemt Bao,Tian Lan,Tenglong Liu,Jin Yang,Huiping Zhuang,Baozhi Jia,Shuai Zhang,Zhengfeng Zou,Fangheng Guan,Tianyi Jia,Ke Zhou,Hongjiu Zhang,Yating Han,Cheng Fang,Yixian Zou,Chongyang Xu,Qinglun Zhang,Shen Cheng,Xiaohe Wang,Ping Tan,Haoqiang Fan,Shuaicheng Liu,Jiaheng Chen,Chuxuan Huang,Chengliang Lin,Kaijun Luo,Boyu Yue,Yi Liu,Jinyu Chen,Zichang Tan,Liming Deng,Shuo Xu,Zijian Cai,Shilong Yin,Hao Wang,Hongshan Liu,Tianyang Li,Long Shi,Ran Xu,Huilin Xu,Zhengquan Zhang,Congsheng Xu,Jinchang Yang,Feng Xu*

Main category: cs.RO

TL;DR: 论文介绍了RoboTwin双臂协作挑战赛，旨在推动双臂机器人处理复杂任务的研究，吸引了全球团队参与，并提出了通用双臂策略学习的见解。


<details>
  <summary>Details</summary>
Motivation: 推动自主系统在复杂物理环境中的感知、推理和行动能力，特别是双臂协作在刚性、可变形和触觉敏感物体任务中的应用。

Method: 基于RoboTwin仿真平台和AgileX COBOT-Magic机器人平台，设计了三个阶段的比赛，涵盖17种双臂操作任务。

Result: 吸引了64个全球团队和400多名参与者，产生了如SEM和AnchorDP3等优秀解决方案，并提供了通用双臂策略学习的见解。

Conclusion: 挑战赛为未来研究提供了宝贵数据和方法，支持开发鲁棒且通用的双臂操作策略。

Abstract: Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in
robotics, driven by the need for autonomous systems that can perceive, reason,
and act in complex physical environments. While single-arm systems have shown
strong task performance, collaborative dual-arm systems are essential for
handling more intricate tasks involving rigid, deformable, and
tactile-sensitive objects. To advance this goal, we launched the RoboTwin
Dual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on
the RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot
platform, the competition consisted of three stages: Simulation Round 1,
Simulation Round 2, and a final Real-World Round. Participants totally tackled
17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based
scenarios. The challenge attracted 64 global teams and over 400 participants,
producing top-performing solutions like SEM and AnchorDP3 and generating
valuable insights into generalizable bimanual policy learning. This report
outlines the competition setup, task design, evaluation methodology, key
findings and future direction, aiming to support future research on robust and
generalizable bimanual manipulation policies. The Challenge Webpage is
available at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.

</details>


### [29] [GS-NBV: a Geometry-based, Semantics-aware Viewpoint Planning Algorithm for Avocado Harvesting under Occlusions](https://arxiv.org/abs/2506.23369)
*Xiao'ao Song,Konstantinos Karydis*

Main category: cs.RO

TL;DR: 提出了一种基于几何和语义感知的视点规划算法，用于高效识别不规则形状水果（如牛油果）的采摘点。


<details>
  <summary>Details</summary>
Motivation: 自动化水果采摘中，牛油果因其不规则形状、重量和非结构化生长环境，需要特定视点才能成功采摘。

Method: 算法分为视点采样、评估和执行三步，利用几何信息约束搜索空间为1D圆，并引入新的采摘评分指标。

Result: 在模拟实验中，与两种先进算法对比，实现了100%的成功率，证明了方法的效率和鲁棒性。

Conclusion: 该方法在遮挡严重的情况下仍能高效规划视点，适用于自动化水果采摘。

Abstract: Efficient identification of picking points is critical for automated fruit
harvesting. Avocados present unique challenges owing to their irregular shape,
weight, and less-structured growing environments, which require specific
viewpoints for successful harvesting. We propose a geometry-based,
semantics-aware viewpoint-planning algorithm to address these challenges. The
planning process involves three key steps: viewpoint sampling, evaluation, and
execution. Starting from a partially occluded view, the system first detects
the fruit, then leverages geometric information to constrain the viewpoint
search space to a 1D circle, and uniformly samples four points to balance the
efficiency and exploration. A new picking score metric is introduced to
evaluate the viewpoint suitability and guide the camera to the next-best view.
We validate our method through simulation against two state-of-the-art
algorithms. Results show a 100% success rate in two case studies with
significant occlusions, demonstrating the efficiency and robustness of our
approach. Our code is available at https://github.com/lineojcd/GSNBV

</details>


### [30] [Risk-Based Filtering of Valuable Driving Situations in the Waymo Open Motion Dataset](https://arxiv.org/abs/2506.23433)
*Tim Puphal,Vipul Ramtekkar,Kenji Nishimiya*

Main category: cs.RO

TL;DR: 提出一种基于风险的过滤方法，从大规模驾驶数据中识别有价值的交互场景，用于改进自动驾驶软件。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶软件的改进需要丰富的道路用户交互数据，但如何从海量数据中筛选出有价值的情境是关键问题。

Method: 使用概率风险模型检测高风险情境，包括直接影响的一阶情境和通过中介车辆传播影响的二阶情境。

Result: 在Waymo Open Motion Dataset上验证，该方法能有效筛选出复杂且互补的驾驶情境，优于基线方法。

Conclusion: 基于风险的过滤方法能显著提升自动驾驶测试数据的质量，相关数据已开源。

Abstract: Improving automated vehicle software requires driving data rich in valuable
road user interactions. In this paper, we propose a risk-based filtering
approach that helps identify such valuable driving situations from large
datasets. Specifically, we use a probabilistic risk model to detect high-risk
situations. Our method stands out by considering a) first-order situations
(where one vehicle directly influences another and induces risk) and b)
second-order situations (where influence propagates through an intermediary
vehicle). In experiments, we show that our approach effectively selects
valuable driving situations in the Waymo Open Motion Dataset. Compared to the
two baseline interaction metrics of Kalman difficulty and Tracks-To-Predict
(TTP), our filtering approach identifies complex and complementary situations,
enriching the quality in automated vehicle testing. The risk data is made
open-source: https://github.com/HRI-EU/RiskBasedFiltering.

</details>


### [31] [MGPRL: Distributed Multi-Gaussian Processes for Wi-Fi-based Multi-Robot Relative Localization in Large Indoor Environments](https://arxiv.org/abs/2506.23514)
*Sai Krishna Ghanta,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: MGPRL是一种基于Wi-Fi信号的多机器人相对定位框架，利用高斯过程和凸包对齐实现高效定位。


<details>
  <summary>Details</summary>
Motivation: 解决GPS缺失环境下多机器人系统依赖昂贵或短程传感器的问题。

Method: 使用多输出高斯过程预测RSSI场，结合凸包对齐进行相对位姿估计。

Result: MGPRL在定位精度和计算效率上优于现有方法。

Conclusion: MGPRL是一种无需预校准的高效分布式定位方案，已开源为ROS包。

Abstract: Relative localization is a crucial capability for multi-robot systems
operating in GPS-denied environments. Existing approaches for multi-robot
relative localization often depend on costly or short-range sensors like
cameras and LiDARs. Consequently, these approaches face challenges such as high
computational overhead (e.g., map merging) and difficulties in disjoint
environments. To address this limitation, this paper introduces MGPRL, a novel
distributed framework for multi-robot relative localization using convex-hull
of multiple Wi-Fi access points (AP). To accomplish this, we employ
co-regionalized multi-output Gaussian Processes for efficient Radio Signal
Strength Indicator (RSSI) field prediction and perform uncertainty-aware
multi-AP localization, which is further coupled with weighted convex hull-based
alignment for robust relative pose estimation. Each robot predicts the RSSI
field of the environment by an online scan of APs in its environment, which are
utilized for position estimation of multiple APs. To perform relative
localization, each robot aligns the convex hull of its predicted AP locations
with that of the neighbor robots. This approach is well-suited for devices with
limited computational resources and operates solely on widely available Wi-Fi
RSSI measurements without necessitating any dedicated pre-calibration or
offline fingerprinting. We rigorously evaluate the performance of the proposed
MGPRL in ROS simulations and demonstrate it with real-world experiments,
comparing it against multiple state-of-the-art approaches. The results showcase
that MGPRL outperforms existing methods in terms of localization accuracy and
computational efficiency. Finally, we open source MGPRL as a ROS package
https://github.com/herolab-uga/MGPRL.

</details>


### [32] [Online Human Action Detection during Escorting](https://arxiv.org/abs/2506.23573)
*Siddhartha Mondal,Avik Mitra,Chayan Sarkar*

Main category: cs.RO

TL;DR: 论文提出了一种新型神经网络架构，用于实时行人重识别和动作预测，以提升拥挤环境中机器人护送服务的效率。


<details>
  <summary>Details</summary>
Motivation: 现有护送机器人依赖导航策略，假设被护送者会顺利跟随，但在拥挤环境中常因人类动态行为（如分心、受阻）而失效。缺乏专门数据集和实时模型限制了机器人对护送对象动作的理解和调整。

Method: 提出一种新型神经网络架构，结合行人重识别和动作预测功能，使机器人能动态调整速度并应对中断。

Result: 对比实验表明，该系统在效率和效果上优于基线模型，显著提升了复杂场景中的护送服务。

Conclusion: 该研究为拥挤环境中的机器人护送服务提供了高效解决方案，具有实际应用潜力。

Abstract: The deployment of robot assistants in large indoor spaces has seen
significant growth, with escorting tasks becoming a key application. However,
most current escorting robots primarily rely on navigation-focused strategies,
assuming that the person being escorted will follow without issue. In crowded
environments, this assumption often falls short, as individuals may struggle to
keep pace, become obstructed, get distracted, or need to stop unexpectedly. As
a result, conventional robotic systems are often unable to provide effective
escorting services due to their limited understanding of human movement
dynamics. To address these challenges, an effective escorting robot must
continuously detect and interpret human actions during the escorting process
and adjust its movement accordingly. However, there is currently no existing
dataset designed specifically for human action detection in the context of
escorting. Given that escorting often occurs in crowded environments, where
other individuals may enter the robot's camera view, the robot also needs to
identify the specific human it is escorting (the subject) before predicting
their actions. Since no existing model performs both person re-identification
and action prediction in real-time, we propose a novel neural network
architecture that can accomplish both tasks. This enables the robot to adjust
its speed dynamically based on the escortee's movements and seamlessly resume
escorting after any disruption. In comparative evaluations against strong
baselines, our system demonstrates superior efficiency and effectiveness,
showcasing its potential to significantly improve robotic escorting services in
complex, real-world scenarios.

</details>


### [33] [Passage-traversing optimal path planning with sampling-based algorithms](https://arxiv.org/abs/2506.23614)
*Jing Huang,Hao Su,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: 提出了一种新的最优路径规划范式PTOPP，通过优化路径的通过通道来满足特定优化目标，特别适用于机器人路径规划中的自由空间优化。


<details>
  <summary>Details</summary>
Motivation: 传统路径规划方法在自由空间优化方面存在局限性，PTOPP旨在通过通道检测和自由空间分解，提供更优的路径规划解决方案。

Method: 提出了一种基于邻近图的通道检测和自由空间分解方法，并开发了采样算法以快速检查通道通过性。

Result: PTOPP在配置性、解决方案最优性和效率方面显著优于现有方法，如基于间隙的方法。

Conclusion: PTOPP为自由空间优化提供了一种高效且通用的解决方案，适用于广泛的路径规划问题。

Abstract: This paper introduces a new paradigm of optimal path planning, i.e.,
passage-traversing optimal path planning (PTOPP), that optimizes paths'
traversed passages for specified optimization objectives. In particular, PTOPP
is utilized to find the path with optimal accessible free space along its
entire length, which represents a basic requirement for paths in robotics. As
passages are places where free space shrinks and becomes constrained, the core
idea is to leverage the path's passage traversal status to characterize its
accessible free space comprehensively. To this end, a novel passage detection
and free space decomposition method using proximity graphs is proposed,
enabling fast detection of sparse but informative passages and environment
decompositions. Based on this preprocessing, optimal path planning with
accessible free space objectives or constraints is formulated as PTOPP problems
compatible with sampling-based optimal planners. Then, sampling-based
algorithms for PTOPP, including their dependent primitive procedures, are
developed leveraging partitioned environments for fast passage traversal check.
All these methods are implemented and thoroughly tested for effectiveness and
efficiency validation. Compared to existing approaches, such as clearance-based
methods, PTOPP demonstrates significant advantages in configurability, solution
optimality, and efficiency, addressing prior limitations and incapabilities. It
is believed to provide an efficient and versatile solution to accessible free
space optimization over conventional avenues and more generally, to a broad
class of path planning problems that can be formulated as PTOPP.

</details>


### [34] [A comprehensive control architecture for semi-autonomous dual-arm robots in agriculture settings](https://arxiv.org/abs/2506.23723)
*Jozsef Palmieri,Paolo Di Lillo,Stefano Chiaverini,Alessandro Marino*

Main category: cs.RO

TL;DR: 本文提出了一种用于复杂农业环境的移动机器人控制架构，采用分层二次规划（HQP）方法，实现了葡萄采摘的自主和半自主操作。


<details>
  <summary>Details</summary>
Motivation: 在复杂农业环境中，移动机器人需要灵活且高效的架构来整合感知与控制，同时完成多项任务，如葡萄采摘。

Method: 使用16自由度双臂移动机器人，通过HQP方法处理优先级不同的等式和不等式约束，并结合感知系统选择葡萄串。

Result: 在实验室和实际葡萄园中验证了自主和半自主采摘功能，成功处理了感知不确定性及环境交互力。

Conclusion: 提出的HQP框架有效支持复杂任务，如葡萄采摘，并实现了人机协作的半自主操作。

Abstract: The adoption of mobile robotic platforms in complex environments, such as
agricultural settings, requires these systems to exhibit a flexible yet
effective architecture that integrates perception and control. In such
scenarios, several tasks need to be accomplished simultaneously, ranging from
managing robot limits to performing operational tasks and handling human
inputs. The purpose of this paper is to present a comprehensive control
architecture for achieving complex tasks such as robotized harvesting in
vineyards within the framework of the European project CANOPIES. In detail, a
16-DOF dual-arm mobile robot is employed, controlled via a Hierarchical
Quadratic Programming (HQP) approach capable of handling both equality and
inequality constraints at various priorities to harvest grape bunches selected
by the perception system developed within the project. Furthermore, given the
complexity of the scenario and the uncertainty in the perception system, which
could potentially lead to collisions with the environment, the handling of
interaction forces is necessary. Remarkably, this was achieved using the same
HQP framework. This feature is further leveraged to enable semi-autonomous
operations, allowing a human operator to assist the robotic counterpart in
completing harvesting tasks. Finally, the obtained results are validated
through extensive testing conducted first in a laboratory environment to prove
individual functionalities, then in a real vineyard, encompassing both
autonomous and semi-autonomous grape harvesting operations.

</details>


### [35] [PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?](https://arxiv.org/abs/2506.23725)
*Atharva Gundawar,Som Sagar,Ransalu Senanayake*

Main category: cs.RO

TL;DR: PAC Bench是一个用于评估视觉语言模型（VLMs）在物理属性、功能性和约束理解上的基准测试，揭示了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs在机器人操作任务中广泛应用，但其对低层物理先决条件的理解能力尚未得到验证，这可能导致操作不可靠。

Method: 提出PAC Bench基准，包含多样化的数据集（30,000+标注、673张真实图像、100个真实场景和120个模拟场景），用于系统评估VLMs。

Result: 评估显示当前VLMs在基础物理概念理解上存在显著不足，不适合可靠的机器人操作。

Conclusion: PAC Bench为评估VLMs的物理推理能力提供了标准化基准，并指导开发更鲁棒的模型。

Abstract: Vision-Language Models (VLMs) are increasingly pivotal for generalist robot
manipulation, enabling tasks such as physical reasoning, policy generation, and
failure detection. However, their proficiency in these high-level applications
often assumes a deep understanding of low-level physical prerequisites, a
capability that remains largely unverified. For robots to perform actions
reliably, they must comprehend intrinsic object properties (e.g., material,
weight), action affordances (e.g., graspable, stackable), and physical
constraints (e.g., stability, reachability, or an object's state, such as being
closed). Despite the widespread use of VLMs in manipulation tasks, we argue
that off-the-shelf models may lack this granular, physically grounded
understanding, as such prerequisites are often overlooked during training.
  To address this critical gap, we introduce PAC Bench, a comprehensive
benchmark designed to systematically evaluate VLMs on their understanding of
core Properties, Affordances, and Constraints (PAC) from a task executability
perspective. PAC Bench features a diverse dataset with over 30,000 annotations,
comprising 673 real-world images (115 object classes, 15 property types, and 1
to 3 affordances defined per class), 100 real-world humanoid-view scenarios,
and 120 unique simulated constraint scenarios across four tasks.
  Our evaluations reveal significant gaps in the ability of current VLMs to
grasp fundamental physical concepts, highlighting limitations in their
suitability for reliable robot manipulation and pointing to key areas for
targeted research. PAC Bench also serves as a standardized benchmark for
rigorously evaluating physical reasoning in VLMs and guiding the development of
more robust, physically grounded models for robotic applications.
  Project Page: https://pacbench.github.io/

</details>


### [36] [Validation of AI-Based 3D Human Pose Estimation in a Cyber-Physical Environment](https://arxiv.org/abs/2506.23739)
*Lisa Marie Otto,Michael Kaiser,Daniel Seebacher,Steffen Müller*

Main category: cs.RO

TL;DR: 论文提出了一种结合车辆在环测试和运动实验室的测试环境，用于评估自动驾驶系统与弱势道路使用者的交互，验证了人体姿态估计方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 确保自动驾驶系统与弱势道路使用者在城市环境中的安全、真实交互需要先进的测试方法。

Method: 结合车辆在环测试和运动实验室，通过真实世界与虚拟场景的比较分析，验证人体姿态估计方法，并使用单目摄像头3D骨骼检测AI。

Result: 结果显示在稳定运动模式下，真实与虚拟场景的人体姿态估计高度一致，但在动态运动和遮挡情况下存在显著误差。

Conclusion: 研究为优化下一代基于AI的车辆感知测试方法提供了依据，并改进了自动驾驶车辆与弱势道路使用者在虚拟环境中的交互模型。

Abstract: Ensuring safe and realistic interactions between automated driving systems
and vulnerable road users (VRUs) in urban environments requires advanced
testing methodologies. This paper presents a test environment that combines a
Vehiclein-the-Loop (ViL) test bench with a motion laboratory, demonstrating the
feasibility of cyber-physical (CP) testing of vehicle-pedestrian and
vehicle-cyclist interactions. Building upon previous work focused on pedestrian
localization, we further validate a human pose estimation (HPE) approach
through a comparative analysis of real-world (RW) and virtual representations
of VRUs. The study examines the perception of full-body motion using a
commercial monocular camera-based 3Dskeletal detection AI. The virtual scene is
generated in Unreal Engine 5, where VRUs are animated in real time and
projected onto a screen to stimulate the camera. The proposed stimulation
technique ensures the correct perspective, enabling realistic vehicle
perception. To assess the accuracy and consistency of HPE across RW and CP
domains, we analyze the reliability of detections as well as variations in
movement trajectories and joint estimation stability. The validation includes
dynamic test scenarios where human avatars, both walking and cycling, are
monitored under controlled conditions. Our results show a strong alignment in
HPE between RW and CP test conditions for stable motion patterns, while notable
inaccuracies persist under dynamic movements and occlusions, particularly for
complex cyclist postures. These findings contribute to refining CP testing
approaches for evaluating next-generation AI-based vehicle perception and to
enhancing interaction models of automated vehicles and VRUs in CP environments.

</details>


### [37] [Motion Tracking with Muscles: Predictive Control of a Parametric Musculoskeletal Canine Model](https://arxiv.org/abs/2506.23768)
*Vittorio La Barbera,Steven Bohez,Leonard Hasenclever,Yuval Tassa,John R. Hutchinson*

Main category: cs.RO

TL;DR: 提出了一种基于3D肌肉网格的狗骨骼肌肉模型，并开发了兼容多种控制算法的运动捕捉任务和改进的肌肉动力学模型。通过模拟肌肉激活模式与实验EMG数据对比验证了模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在填补生物力学、机器人和计算神经科学之间的研究空白，为肌肉驱动和神经肌肉控制研究提供平台。

Method: 利用3D肌肉网格生成骨骼肌肉模型，结合运动捕捉任务和改进的肌肉动力学模型。

Result: 模拟肌肉激活模式与实验EMG数据一致，验证了模型的有效性。

Conclusion: 该模型为相关研究提供了可靠工具，未来将公开模型和运动捕捉数据以促进研究发展。

Abstract: We introduce a novel musculoskeletal model of a dog, procedurally generated
from accurate 3D muscle meshes. Accompanying this model is a motion
capture-based locomotion task compatible with a variety of control algorithms,
as well as an improved muscle dynamics model designed to enhance convergence in
differentiable control frameworks. We validate our approach by comparing
simulated muscle activation patterns with experimentally obtained
electromyography (EMG) data from previous canine locomotion studies. This work
aims to bridge gaps between biomechanics, robotics, and computational
neuroscience, offering a robust platform for researchers investigating muscle
actuation and neuromuscular control.We plan to release the full model along
with the retargeted motion capture clips to facilitate further research and
development.

</details>


### [38] [Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving](https://arxiv.org/abs/2506.23771)
*Guizhe Jin,Zhuoren Li,Bo Leng,Ran Yu,Lu Xiong*

Main category: cs.RO

TL;DR: 提出了一种多时间尺度的分层强化学习方法，用于自动驾驶，结合长短时间尺度的策略设计，提升驾驶效率、行为一致性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在自动驾驶中忽视策略结构设计，导致驾驶行为波动或无法统一优化驾驶行为与控制。

Method: 采用分层策略结构，高低层RL策略联合训练，分别生成长时间尺度运动指导和短时间尺度控制命令，并设计分层安全机制。

Result: 在仿真和HighD数据集的高速多车道场景中，显著提升自动驾驶性能，提高效率、行为一致性和安全性。

Conclusion: 多时间尺度分层强化学习方法有效解决了自动驾驶中的策略设计问题，实现了驾驶行为与控制的统一优化。

Abstract: Reinforcement Learning (RL) is increasingly used in autonomous driving (AD)
and shows clear advantages. However, most RL-based AD methods overlook policy
structure design. An RL policy that only outputs short-timescale vehicle
control commands results in fluctuating driving behavior due to fluctuations in
network outputs, while one that only outputs long-timescale driving goals
cannot achieve unified optimality of driving behavior and control. Therefore,
we propose a multi-timescale hierarchical reinforcement learning approach. Our
approach adopts a hierarchical policy structure, where high- and low-level RL
policies are unified-trained to produce long-timescale motion guidance and
short-timescale control commands, respectively. Therein, motion guidance is
explicitly represented by hybrid actions to capture multimodal driving
behaviors on structured road and support incremental low-level extend-state
updates. Additionally, a hierarchical safety mechanism is designed to ensure
multi-timescale safety. Evaluation in simulator-based and HighD dataset-based
highway multi-lane scenarios demonstrates that our approach significantly
improves AD performance, effectively increasing driving efficiency, action
consistency and safety.

</details>


### [39] [World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation](https://arxiv.org/abs/2506.23919)
*Haonan Chen,Bangjun Wang,Jingxiang Guo,Tianrui Zhang,Yiwen Hou,Xuchuan Huang,Chenrui Tie,Lin Shao*

Main category: cs.RO

TL;DR: 提出了一种利用预训练多模态图像生成模型作为世界模型来指导策略学习的新框架，实现了无需任务特定训练的高效机器人操作。


<details>
  <summary>Details</summary>
Motivation: 提高机器人操作的数据效率和泛化能力是核心挑战。

Method: 利用预训练多模态图像生成模型生成开放式的未来状态预测，结合零样本低级控制模块。

Result: 在仿真和真实环境中验证了方法的有效性，适用于多种操作任务，无需额外数据收集或微调。

Conclusion: 该方法为通用机器人操作提供了一种高效且泛化能力强的解决方案。

Abstract: Improving data efficiency and generalization in robotic manipulation remains
a core challenge. We propose a novel framework that leverages a pre-trained
multimodal image-generation model as a world model to guide policy learning. By
exploiting its rich visual-semantic representations and strong generalization
across diverse scenes, the model generates open-ended future state predictions
that inform downstream manipulation. Coupled with zero-shot low-level control
modules, our approach enables general-purpose robotic manipulation without
task-specific training. Experiments in both simulation and real-world
environments demonstrate that our method achieves effective performance across
a wide range of manipulation tasks with no additional data collection or
fine-tuning. Supplementary materials are available on our website:
https://world4omni.github.io/.

</details>


### [40] [Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning](https://arxiv.org/abs/2506.23944)
*Fuhang Kuang,Jiacheng You,Yingdong Hu,Tong Zhang,Chuan Wen,Yang Gao*

Main category: cs.RO

TL;DR: 论文提出了一种解决模仿学习中本体感觉偏移问题的方法，通过域适应框架和Wasserstein距离优化训练与部署分布的对齐。


<details>
  <summary>Details</summary>
Motivation: 模仿学习中直接使用所有本体感觉状态会导致性能下降，原因是训练与部署时的本体感觉分布存在显著差异。

Method: 提出基于Wasserstein距离的域适应框架，通过向专家和部署数据添加噪声来最小化分布差异。

Result: 实验证明该方法能有效利用本体感觉并缓解其负面影响，性能优于丢弃本体感觉的简单方案及其他基线方法。

Conclusion: 该方法成功解决了本体感觉偏移问题，提升了模仿学习在机器人任务中的性能。

Abstract: Imitation learning models for robotic tasks typically rely on multi-modal
inputs, such as RGB images, language, and proprioceptive states. While
proprioception is intuitively important for decision-making and obstacle
avoidance, simply incorporating all proprioceptive states leads to a surprising
degradation in imitation learning performance. In this work, we identify the
underlying issue as the proprioception shift problem, where the distributions
of proprioceptive states diverge significantly between training and deployment.
To address this challenge, we propose a domain adaptation framework that
bridges the gap by utilizing rollout data collected during deployment. Using
Wasserstein distance, we quantify the discrepancy between expert and rollout
proprioceptive states and minimize this gap by adding noise to both sets of
states, proportional to the Wasserstein distance. This strategy enhances
robustness against proprioception shifts by aligning the training and
deployment distributions. Experiments on robotic manipulation tasks demonstrate
the efficacy of our method, enabling the imitation policy to leverage
proprioception while mitigating its adverse effects. Our approach outperforms
the naive solution which discards proprioception, and other baselines designed
to address distributional shifts.

</details>


### [41] [Predictive Risk Analysis and Safe Trajectory Planning for Intelligent and Connected Vehicles](https://arxiv.org/abs/2506.23999)
*Zeyu Han,Mengchi Cai,Chaoyi Chen,Qingwen Meng,Guangwei Wang,Ying Liu,Qing Xu,Jianqiang Wang,Keqiang Li*

Main category: cs.RO

TL;DR: 提出了一种基于预测风险分析的智能网联车辆安全轨迹规划框架，通过预测未来轨迹和时空离散化风险分析生成安全轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有风险评估理论仅基于当前信息，忽略了未来预测，无法满足智能网联车辆的安全需求。

Method: 结合局部风险感知算法预测未来轨迹，进行时空离散化预测风险分析，并生成安全轨迹。

Result: 仿真和车辆实验验证了该方法的有效性和实时实用性。

Conclusion: 该框架为智能网联车辆的安全轨迹规划提供了新的解决方案。

Abstract: The safe trajectory planning of intelligent and connected vehicles is a key
component in autonomous driving technology. Modeling the environment risk
information by field is a promising and effective approach for safe trajectory
planning. However, existing risk assessment theories only analyze the risk by
current information, ignoring future prediction. This paper proposes a
predictive risk analysis and safe trajectory planning framework for intelligent
and connected vehicles. This framework first predicts future trajectories of
objects by a local risk-aware algorithm, following with a
spatiotemporal-discretised predictive risk analysis using the prediction
results. Then the safe trajectory is generated based on the predictive risk
analysis. Finally, simulation and vehicle experiments confirm the efficacy and
real-time practicability of our approach.

</details>


### [42] [Exploring Accelerated Skill Acquisition via Tandem Training for Colonoscopy](https://arxiv.org/abs/2506.24046)
*Olivia Richards,Keith L. Obstein,Nabil Simaan*

Main category: cs.RO

TL;DR: 提出了一种新型结肠镜训练系统，通过双控制机制实现专家实时指导，加速新手技能掌握。


<details>
  <summary>Details</summary>
Motivation: 当前结肠镜培训依赖工具交接，限制了新手对设备的多指同步控制技能的快速掌握，需要实时专家指导工具。

Method: 设计了一种双控制训练系统，通过远程操作专家结肠镜指导新手，支持专家和新手对标准结肠镜角度控制轮的双重控制切换。

Result: 初步用户研究表明，该系统作为技能获取工具有效。

Conclusion: 该系统有望加速结肠镜技能学习，未来可能通过双向驱动实现个性化教学。

Abstract: New endoscopists require a large volume of expert-proctored colonoscopies to
attain minimal competency. Developing multi-fingered, synchronized control of a
colonoscope requires significant time and exposure to the device. Current
training methods inhibit this development by relying on tool hand-off for
expert demonstrations. There is a need for colonoscopy training tools that
enable in-hand expert guidance in real-time. We present a new concept of a
tandem training system that uses a telemanipulated preceptor colonoscope to
guide novice users as they perform a colonoscopy. This system is capable of
dual-control and can automatically toggle between expert and novice control of
a standard colonoscope's angulation control wheels. Preliminary results from a
user study with novice and expert users show the effectiveness of this device
as a skill acquisition tool. We believe that this device has the potential to
accelerate skill acquisition for colonoscopy and, in the future, enable
individualized instruction and responsive teaching through bidirectional
actuation.

</details>
