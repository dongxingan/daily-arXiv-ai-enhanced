{"id": "2507.16458", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.16458", "abs": "https://arxiv.org/abs/2507.16458", "authors": ["Yang Xu", "Jesús Bautista", "José Hinojosa", "Héctor García de Marina"], "title": "Distributed Oscillatory Guidance for Formation Flight of Fixed-Wing Drones", "comment": "Yang Xu and Jes\\'us Bautista contributed equally to this work. In the\n  proceedings of the IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2025", "summary": "The autonomous formation flight of fixed-wing drones is hard when the\ncoordination requires the actuation over their speeds since they are critically\nbounded and aircraft are mostly designed to fly at a nominal airspeed. This\npaper proposes an algorithm to achieve formation flights of fixed-wing drones\nwithout requiring any actuation over their speed. In particular, we guide all\nthe drones to travel over specific paths, e.g., parallel straight lines, and we\nsuperpose an oscillatory behavior onto the guiding vector field that drives the\ndrones to the paths. This oscillation enables control over the average velocity\nalong the path, thereby facilitating inter-drone coordination. Each drone\nadjusts its oscillation amplitude distributively in a closed-loop manner by\ncommunicating with neighboring agents in an undirected and connected graph. A\nnovel consensus algorithm is introduced, leveraging a non-negative, asymmetric\nsaturation function. This unconventional saturation is justified since negative\namplitudes do not make drones travel backward or have a negative velocity along\nthe path. Rigorous theoretical analysis of the algorithm is complemented by\nvalidation through numerical simulations and a real-world formation flight.", "AI": {"tldr": "提出了一种不需要调节飞行速度的固定翼无人机编队飞行算法，通过在引导向量场上叠加振荡行为来控制沿路径的平均速度，实现无人机间的协调", "motivation": "固定翼无人机的编队飞行中，通过调节速度进行协调是困难的，因为飞机的速度受到严格限制且主要设计为以标称空速飞行", "method": "引导所有无人机沿特定路径飞行（如平行直线），在引导向量场上叠加振荡行为；每架无人机通过与邻近代理通信分布式地调整其振荡幅度；引入了一种新的共识算法，利用非负非对称饱和函数", "result": "通过严格的理论分析、数值仿真和真实世界编队飞行验证了算法的有效性", "conclusion": "成功开发了一种无需速度调节的固定翼无人机编队飞行算法，通过振荡幅度调节实现了有效的编队协调"}}
{"id": "2507.16480", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.ET", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.16480", "abs": "https://arxiv.org/abs/2507.16480", "authors": ["Sabrina Livanec", "Laura Londoño", "Michael Gorki", "Adrian Röfer", "Abhinav Valada", "Andrea Kiesel"], "title": "Designing for Difference: How Human Characteristics Shape Perceptions of Collaborative Robots", "comment": null, "summary": "The development of assistive robots for social collaboration raises critical\nquestions about responsible and inclusive design, especially when interacting\nwith individuals from protected groups such as those with disabilities or\nadvanced age. Currently, research is scarce on how participants assess varying\nrobot behaviors in combination with diverse human needs, likely since\nparticipants have limited real-world experience with advanced domestic robots.\nIn the current study, we aim to address this gap while using methods that\nenable participants to assess robot behavior, as well as methods that support\nmeaningful reflection despite limited experience. In an online study, 112\nparticipants (from both experimental and control groups) evaluated 7 videos\nfrom a total of 28 variations of human-robot collaboration types. The\nexperimental group first completed a cognitive-affective mapping (CAM) exercise\non human-robot collaboration before providing their ratings. Although CAM\nreflection did not significantly affect overall ratings, it led to more\npronounced assessments for certain combinations of robot behavior and human\ncondition. Most importantly, the type of human-robot collaboration influences\nthe assessment. Antisocial robot behavior was consistently rated as the lowest,\nwhile collaboration with aged individuals elicited more sensitive evaluations.\nScenarios involving object handovers were viewed more positively than those\nwithout them. These findings suggest that both human characteristics and\ninteraction paradigms influence the perceived acceptability of collaborative\nrobots, underscoring the importance of prosocial design. They also highlight\nthe potential of reflective methods, such as CAM, to elicit nuanced feedback,\nsupporting the development of user-centered and socially responsible robotic\nsystems tailored to diverse populations.", "AI": {"tldr": "研究通过在线实验探索了人机协作中不同机器人行为和人类需求组合的评估，发现反社会机器人行为评分最低，与老年人协作需要更敏感的评估，物体传递场景更受欢迎，强调了亲社会设计的重要性。", "motivation": "目前缺乏关于参与者如何评估不同机器人行为与多样化人类需求组合的研究，特别是在与残疾人或老年人等受保护群体互动时，需要解决负责任和包容性设计的关键问题。", "method": "采用在线研究方法，112名参与者（实验组和对照组）评估了28种人机协作类型变化中的7个视频。实验组在评分前先完成认知-情感映射（CAM）练习来反思人机协作。", "result": "CAM反思虽然没有显著影响整体评分，但对某些机器人行为和人类条件组合产生了更明显的评估。反社会机器人行为评分始终最低，与老年人协作引发更敏感的评估，涉及物体传递的场景比没有传递的场景评价更积极。", "conclusion": "人类特征和互动范式都会影响协作机器人的可接受性感知，强调了亲社会设计的重要性。反思性方法（如CAM）具有引出细致反馈的潜力，支持开发以用户为中心、社会负责的机器人系统，以适应不同人群。"}}
{"id": "2507.16481", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.16481", "abs": "https://arxiv.org/abs/2507.16481", "authors": ["Riccardo Bussola", "Michele Focchi", "Giulio Turrisi", "Claudio Semini", "Luigi Palopoli"], "title": "Guided Reinforcement Learning for Omnidirectional 3D Jumping in Quadruped Robots", "comment": null, "summary": "Jumping poses a significant challenge for quadruped robots, despite being\ncrucial for many operational scenarios. While optimisation methods exist for\ncontrolling such motions, they are often time-consuming and demand extensive\nknowledge of robot and terrain parameters, making them less robust in\nreal-world scenarios. Reinforcement learning (RL) is emerging as a viable\nalternative, yet conventional end-to-end approaches lack efficiency in terms of\nsample complexity, requiring extensive training in simulations, and\npredictability of the final motion, which makes it difficult to certify the\nsafety of the final motion. To overcome these limitations, this paper\nintroduces a novel guided reinforcement learning approach that leverages\nphysical intuition for efficient and explainable jumping, by combining B\\'ezier\ncurves with a Uniformly Accelerated Rectilinear Motion (UARM) model. Extensive\nsimulation and experimental results clearly demonstrate the advantages of our\napproach over existing alternatives.", "AI": {"tldr": "本文提出了一种新颖的引导强化学习方法，结合贝塞尔曲线和匀加速直线运动模型，用于实现四足机器人高效且可解释的跳跃动作，解决了传统优化方法耗时长、鲁棒性差以及端到端强化学习样本复杂度高、运动不可预测的问题。", "motivation": "四足机器人跳跃动作对许多操作场景至关重要，但现有的优化控制方法耗时且需要大量机器人和地形参数知识，在真实世界中鲁棒性差；而传统的端到端强化学习方法在样本复杂度和最终运动可预测性方面效率低下，难以保证运动安全性认证。", "method": "提出了一种新颖的引导强化学习方法，通过结合贝塞尔曲线和匀加速直线运动(UARM)模型来利用物理直觉，实现高效且可解释的跳跃控制。", "result": "通过广泛的仿真和实验结果清楚地证明了该方法相比现有替代方案的优势。", "conclusion": "引导强化学习方法成功解决了四足机器人跳跃控制中的关键挑战，在效率、可解释性和安全性方面表现优异，为四足机器人动态运动控制提供了新的解决方案。"}}
{"id": "2507.15975", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.15975", "abs": "https://arxiv.org/abs/2507.15975", "authors": ["Qiwei Du", "Bowen Li", "Yi Du", "Shaoshu Su", "Taimeng Fu", "Zitong Zhan", "Zhipeng Zhao", "Chen Wang"], "title": "Fast Task Planning with Neuro-Symbolic Relaxation", "comment": "8 pages, 6 figures", "summary": "Real-world task planning requires long-horizon reasoning over large sets of\nentities with complex relationships and attributes, leading to a combinatorial\nexplosion for classical symbolic planners. To prune the search space, recent\nmethods prioritize searching on a simplified task only containing a few\n\"important\" entities predicted by a neural network. However, such a simple\nneuro-symbolic (NeSy) integration risks omitting critical entities and wasting\nresources on unsolvable simplified tasks. To enable Fast and reliable planning,\nwe introduce a NeSy relaxation strategy (Flax), combining neural importance\nprediction with symbolic expansion. Specifically, we first learn a graph neural\nnetwork to predict entity importance to create a simplified task and solve it\nwith a symbolic planner. Then, we solve a rule-relaxed task to obtain a quick\nrough plan, and reintegrate all referenced entities into the simplified task to\nrecover any overlooked but essential elements. Finally, we apply complementary\nrules to refine the updated task, keeping it both reliable and compact.\nExtensive experiments are conducted on both synthetic and real-world maze\nnavigation benchmarks where a robot must traverse through a maze and interact\nwith movable objects. The results show that Flax boosts the average success\nrate by 20.82% and cuts mean wall-clock planning time by 17.65% compared with\nthe state-of-the-art NeSy baseline. We expect that Flax offers a practical path\ntoward fast, scalable, long-horizon task planning in complex environments.", "AI": {"tldr": "本文提出了Flax，一种神经符号松弛策略，通过结合神经重要性预测和符号扩展来实现快速可靠的长期任务规划，在迷宫导航基准测试中显著提升了成功率和规划效率。", "motivation": "现实世界的任务规划需要对具有复杂关系和属性的大量实体进行长期推理，这导致经典符号规划器面临组合爆炸问题。现有的神经符号集成方法通过神经网络预测\"重要\"实体来简化任务，但这种方法存在遗漏关键实体和在不可解的简化任务上浪费资源的风险。", "method": "Flax采用神经符号松弛策略，包含四个步骤：1）使用图神经网络预测实体重要性并创建简化任务；2）用符号规划器求解简化任务；3）求解规则松弛任务获得粗略计划，并将所有引用的实体重新整合到简化任务中；4）应用互补规则来完善更新后的任务，保持其可靠性和紧凑性。", "result": "在合成和真实世界迷宫导航基准测试中，Flax相比最先进的神经符号基线方法，将平均成功率提升了20.82%，将平均规划时间缩短了17.65%。", "conclusion": "Flax为复杂环境中的快速、可扩展、长期任务规划提供了一条实用的路径，有效解决了神经符号集成中的关键实体遗漏问题，实现了规划效率和可靠性的双重提升。"}}
{"id": "2507.16000", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16000", "abs": "https://arxiv.org/abs/2507.16000", "authors": ["Easton Potokar", "Michael Kaess"], "title": "A Comprehensive Evaluation of LiDAR Odometry Techniques", "comment": "Accepted to IROS 2025", "summary": "Light Detection and Ranging (LiDAR) sensors have become the sensor of choice\nfor many robotic state estimation tasks. Because of this, in recent years there\nhas been significant work done to fine the most accurate method to perform\nstate estimation using these sensors. In each of these prior works, an\nexplosion of possible technique combinations has occurred, with each work\ncomparing LiDAR Odometry (LO) \"pipelines\" to prior \"pipelines\". Unfortunately,\nlittle work up to this point has performed the significant amount of ablation\nstudies comparing the various building-blocks of a LO pipeline. In this work,\nwe summarize the various techniques that go into defining a LO pipeline and\nempirically evaluate these LO components on an expansive number of datasets\nacross environments, LiDAR types, and vehicle motions. Finally, we make\nempirically-backed recommendations for the design of future LO pipelines to\nprovide the most accurate and reliable performance.", "AI": {"tldr": "这篇论文对LiDAR里程计(LO)管道的各个组成部分进行了全面的消融研究和实证评估，并基于实验结果为未来LO管道设计提供了建议。", "motivation": "尽管LiDAR传感器在机器人状态估计中应用广泛，现有研究主要关注整体管道的比较，缺乏对LiDAR里程计管道中各个构建模块的详细消融研究，导致对各组件贡献度的理解不足。", "method": "总结了定义LiDAR里程计管道的各种技术，在跨环境、LiDAR类型和车辆运动的大量数据集上对这些LO组件进行实证评估和消融研究。", "result": "通过大规模实验评估了LiDAR里程计管道中不同组件的性能表现，获得了关于各构建模块有效性的实证数据。", "conclusion": "基于实证研究结果，为未来LiDAR里程计管道的设计提供了数据支撑的建议，以实现最准确和可靠的性能表现。"}}
{"id": "2507.16034", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.16034", "abs": "https://arxiv.org/abs/2507.16034", "authors": ["Xuying Huang", "Sicong Pan", "Olga Zatsarynna", "Juergen Gall", "Maren Bennewitz"], "title": "Improved Semantic Segmentation from Ultra-Low-Resolution RGB Images Applied to Privacy-Preserving Object-Goal Navigation", "comment": "Submitted to RA-L", "summary": "User privacy in mobile robotics has become a critical concern. Existing\nmethods typically prioritize either the performance of downstream robotic tasks\nor privacy protection, with the latter often constraining the effectiveness of\ntask execution. To jointly address both objectives, we study semantic-based\nrobot navigation in an ultra-low-resolution setting to preserve visual privacy.\nA key challenge in such scenarios is recovering semantic segmentation from\nultra-low-resolution RGB images. In this work, we introduce a novel fully\njoint-learning method that integrates an agglomerative feature extractor and a\nsegmentation-aware discriminator to solve ultra-low-resolution semantic\nsegmentation, thereby enabling privacy-preserving, semantic object-goal\nnavigation. Our method outperforms different baselines on ultra-low-resolution\nsemantic segmentation and our improved segmentation results increase the\nsuccess rate of the semantic object-goal navigation in a real-world\nprivacy-constrained scenario.", "AI": {"tldr": "该论文提出了一种在超低分辨率环境下实现隐私保护的语义机器人导航方法，通过联合学习特征提取器和分割感知判别器来解决超低分辨率语义分割问题，在保护视觉隐私的同时提高导航成功率。", "motivation": "移动机器人中的用户隐私保护已成为关键问题。现有方法通常优先考虑下游机器人任务性能或隐私保护其中之一，而隐私保护往往会限制任务执行的有效性。因此需要一种能够同时解决这两个目标的方法。", "method": "提出了一种新颖的完全联合学习方法，集成了聚合特征提取器和分割感知判别器，用于解决超低分辨率语义分割问题，从而实现隐私保护的语义对象目标导航。", "result": "该方法在超低分辨率语义分割任务上优于不同的基线方法，改进的分割结果提高了在真实世界隐私约束场景下语义对象目标导航的成功率。", "conclusion": "通过在超低分辨率设置下研究基于语义的机器人导航，成功实现了视觉隐私保护与任务性能的平衡，为隐私保护的机器人导航提供了有效解决方案。"}}
{"id": "2507.16059", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16059", "abs": "https://arxiv.org/abs/2507.16059", "authors": ["Emek Barış Küçüktabak", "Matthew R. Short", "Lorenzo Vianello", "Daniel Ludvig", "Levi Hargrove", "Kevin Lynch", "Jose Pons"], "title": "Therapist-Exoskeleton-Patient Interaction: An Immersive Gait Therapy", "comment": null, "summary": "Following a stroke, individuals often experience mobility and balance\nimpairments due to lower-limb weakness and loss of independent joint control.\nGait recovery is a key goal of rehabilitation, traditionally achieved through\nhigh-intensity therapist-led training. However, manual assistance can be\nphysically demanding and limits the therapist's ability to interact with\nmultiple joints simultaneously. Robotic exoskeletons offer multi-joint support,\nreduce therapist strain, and provide objective feedback, but current control\nstrategies often limit therapist involvement and adaptability.\n  We present a novel gait rehabilitation paradigm based on physical\nHuman-Robot-Human Interaction (pHRHI), where both the therapist and the\npost-stroke individual wear lower-limb exoskeletons virtually connected at the\nhips and knees via spring-damper elements. This enables bidirectional\ninteraction, allowing the therapist to guide movement and receive haptic\nfeedback. In a study with eight chronic stroke patients, pHRHI training\noutperformed conventional therapist-guided treadmill walking, leading to\nincreased joint range of motion, step metrics, muscle activation, and\nmotivation. These results highlight pHRHI's potential to combine robotic\nprecision with therapist intuition for improved rehabilitation outcomes.", "AI": {"tldr": "本研究提出了一种基于物理人-机器人-人交互(pHRHI)的新型步态康复范式，通过让治疗师和中风患者同时穿戴下肢外骨骼并通过弹簧阻尼元件虚拟连接，实现双向交互指导，在8名慢性中风患者的研究中显示出比传统治疗师引导步行更好的康复效果。", "motivation": "中风后患者常出现下肢无力和关节控制缺失导致的移动和平衡障碍。传统的高强度治疗师引导训练存在体力要求高、难以同时操控多个关节的局限性，而现有机器人外骨骼控制策略又限制了治疗师的参与度和适应性，因此需要开发结合机器人精度和治疗师直觉的新型康复方法。", "method": "提出基于物理人-机器人-人交互(pHRHI)的步态康复范式。治疗师和中风患者都穿戴下肢外骨骼，通过弹簧阻尼元件在髋关节和膝关节处虚拟连接，实现双向交互，使治疗师能够引导运动并接收触觉反馈。对8名慢性中风患者进行研究，比较pHRHI训练与传统治疗师引导跑步机步行的效果。", "result": "pHRHI训练在多个指标上优于传统治疗师引导跑步机步行，包括关节活动范围增加、步态指标改善、肌肉激活增强以及患者积极性提高。研究证明了pHRHI方法的有效性和优越性。", "conclusion": "pHRHI范式成功地将机器人的精确性与治疗师的直觉相结合，为中风患者步态康复提供了一种有前景的新方法。这种双向交互系统能够改善康复效果，同时保持治疗师的主动参与，为未来的康复技术发展指明了方向。"}}
{"id": "2507.16068", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.16068", "abs": "https://arxiv.org/abs/2507.16068", "authors": ["Zhehui Huang", "Guangyao Shi", "Yuwei Wu", "Vijay Kumar", "Gaurav S. Sukhatme"], "title": "Compositional Coordination for Multi-Robot Teams with Large Language Models", "comment": "9 pages, 4 figures", "summary": "Multi-robot coordination has traditionally relied on a task-specific and\nexpert-driven pipeline, where natural language mission descriptions are\nmanually translated by domain experts into mathematical formulation, algorithm\ndesign, and executable code. This conventional process is labor-intensive,\ninaccessible to non-experts, and inflexible to changes in mission requirements.\nHere, we propose LAN2CB (Language to Collective Behavior), a novel framework\nthat leverages large language models (LLMs) to streamline and generalize the\nmulti-robot coordination pipeline. LAN2CB directly converts natural language\nmission descriptions into executable Python code for multi-robot systems\nthrough two key components: (1) Mission Decomposition for Task Representation,\nwhich parses the mission into a task graph with dependencies, and (2) Code\nGeneration, which uses the task graph and a structured knowledge base to\ngenerate deployable robot control code. We further introduce a dataset of\nnatural language mission specifications to support development and\nbenchmarking. Experimental results in both simulation and real-world settings\nshow that LAN2CB enables effective and flexible multi-robot coordination from\nnatural language, significantly reducing the need for manual engineering while\nsupporting generalization across mission types. Website:\nhttps://sites.google.com/view/lan2cb.", "AI": {"tldr": "提出了LAN2CB框架，利用大语言模型将自然语言任务描述直接转换为多机器人系统的可执行Python代码，简化了传统的专家驱动的多机器人协调流程", "motivation": "传统的多机器人协调依赖于任务特定的专家驱动流程，需要领域专家手动将自然语言任务描述转换为数学公式、算法设计和可执行代码，这个过程劳动密集、非专业人员难以使用且对任务需求变化缺乏灵活性", "method": "提出LAN2CB框架，包含两个核心组件：(1)任务分解模块，将任务解析为带依赖关系的任务图；(2)代码生成模块，利用任务图和结构化知识库生成可部署的机器人控制代码。同时构建了自然语言任务规范数据集", "result": "在仿真和真实世界环境中的实验结果表明，LAN2CB能够从自然语言实现有效和灵活的多机器人协调，显著减少了手动工程的需求，同时支持跨任务类型的泛化", "conclusion": "LAN2CB框架成功实现了从自然语言到多机器人协调的自动化转换，为非专业人员提供了可访问的多机器人系统控制方法，并在保持灵活性的同时简化了开发流程"}}
{"id": "2507.16120", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16120", "abs": "https://arxiv.org/abs/2507.16120", "authors": ["Shanshan Zhang", "Qi Zhang", "Siyue Wang", "Tianshui Wen", "Ziheng Zhou", "Lingxiang Zheng", "Yu Yang"], "title": "FTIN: Frequency-Time Integration Network for Inertial Odometry", "comment": null, "summary": "In recent years, machine learning has achieved significant advancements in\ninertial odometry. However, most existing inertial odometry methods primarily\nrely on CNNs in the time domain. These methods often struggle to capture\nlong-term dependency in inertial measurement unit data, thereby constraining\nthe potential for further improvements in localization accuracy. To address\nthese issues, we propose a novel network architecture that integrates both\nfrequency-domain and time-domain information. Specifically, we leverage the\nglobal view and energy compaction properties of frequency-domain learning to\neffectively model long-term dependency and reduce redundancy in IMU data.\nAdditionally, we introduce a Scalar LSTM to capture sequential dependencies in\nthe time domain, enabling cross-domain information fusion and providing a\nstable and reliable reference for localization. Experimental evaluations on\nmultiple public datasets (e.g., RIDI, RoNIN, OxIOD, RNIN, TLIO, and IMUNet)\ndemonstrate the effectiveness of the proposed frequency-time domain fusion\nstrategy. Notably, on the RoNIN dataset, our method achieves a 43.0% reduction\nin absolute trajectory error and a 13.1% reduction in relative trajectory error\ncompared to RoNIN ResNet.", "AI": {"tldr": "本文提出了一种融合频域和时域信息的新型网络架构用于惯性里程计，通过频域学习建模长期依赖关系并结合Scalar LSTM捕获时序依赖，在多个公开数据集上显著提升了定位精度", "motivation": "现有的惯性里程计方法主要依赖时域CNN，难以捕获IMU数据中的长期依赖关系，限制了定位精度的进一步提升", "method": "提出融合频域和时域信息的网络架构：利用频域学习的全局视角和能量压缩特性建模长期依赖并减少IMU数据冗余；引入Scalar LSTM捕获时域序列依赖；实现跨域信息融合为定位提供稳定可靠的参考", "result": "在多个公开数据集（RIDI、RoNIN、OxIOD、RNIN、TLIO、IMUNet）上验证了频域-时域融合策略的有效性。在RoNIN数据集上，相比RoNIN ResNet，绝对轨迹误差降低43.0%，相对轨迹误差降低13.1%", "conclusion": "频域-时域融合的网络架构能够有效解决现有惯性里程计方法的长期依赖建模问题，显著提升定位精度，为惯性导航领域提供了新的技术路径"}}
{"id": "2507.16121", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16121", "abs": "https://arxiv.org/abs/2507.16121", "authors": ["Shanshan Zhang", "Qi Zhang", "Siyue Wang", "Tianshui Wen", "Ziheng Zhou", "Lingxiang Zheng", "Yu Yang"], "title": "DWSFormer: A Lightweight Inertial Odometry Network for Complex Motion Modeling", "comment": null, "summary": "Inertial odometry (IO) directly estimates the position of a carrier from\ninertial sensor measurements and serves as a core technology for the widespread\ndeployment of consumer grade localization systems. While existing IO methods\ncan accurately reconstruct simple and near linear motion trajectories, they\noften fail to account for drift errors caused by complex motion patterns such\nas turning. This limitation significantly degrades localization accuracy and\nrestricts the applicability of IO systems in real world scenarios. To address\nthese challenges, we propose a lightweight IO framework. Specifically, inertial\ndata is projected into a high dimensional implicit nonlinear feature space\nusing the Star Operation method, enabling the extraction of complex motion\nfeatures that are typically overlooked. We further introduce a collaborative\nattention mechanism that jointly models global motion dynamics across both\nchannel and temporal dimensions. In addition, we design Multi Scale Gated\nConvolution Units to capture fine grained dynamic variations throughout the\nmotion process, thereby enhancing the model's ability to learn rich and\nexpressive motion representations. Extensive experiments demonstrate that our\nproposed method consistently outperforms SOTA baselines across six widely used\ninertial datasets. Compared to baseline models on the RoNIN dataset, it\nachieves reductions in ATE ranging from 2.26% to 65.78%, thereby establishing a\nnew benchmark in the field.", "AI": {"tldr": "提出了一个轻量级惯性里程计(IO)框架，通过Star Operation方法将惯性数据投影到高维隐式非线性特征空间，结合协作注意力机制和多尺度门控卷积单元，有效解决复杂运动模式下的漂移误差问题，在六个惯性数据集上超越现有最先进方法。", "motivation": "现有惯性里程计方法在简单和近线性运动轨迹上表现良好，但在复杂运动模式（如转弯）下容易产生漂移误差，这严重降低了定位精度并限制了IO系统在现实场景中的应用。需要开发能够处理复杂运动模式的惯性里程计方法。", "method": "提出轻量级IO框架，包括：1）使用Star Operation方法将惯性数据投影到高维隐式非线性特征空间，提取通常被忽略的复杂运动特征；2）引入协作注意力机制，在通道和时间维度上联合建模全局运动动态；3）设计多尺度门控卷积单元，捕获运动过程中的细粒度动态变化。", "result": "在六个广泛使用的惯性数据集上，所提方法始终优于最先进的基线方法。在RoNIN数据集上，相比基线模型，绝对轨迹误差(ATE)降低了2.26%到65.78%，建立了该领域的新基准。", "conclusion": "通过将惯性数据投影到高维非线性特征空间并结合协作注意力机制和多尺度门控卷积，成功解决了惯性里程计在复杂运动模式下的漂移问题，显著提升了定位精度，为消费级定位系统的广泛部署提供了有效的核心技术。"}}
{"id": "2507.16124", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16124", "abs": "https://arxiv.org/abs/2507.16124", "authors": ["Dakota Sullivan", "Shirley Zhang", "Jennica Li", "Heather Kirkorian", "Bilge Mutlu", "Kassem Fawaz"], "title": "Benchmarking LLM Privacy Recognition for Social Robot Decision Making", "comment": "18 pages, 7 figures. Dakota Sullivan and Shirley Zhang contributed\n  equally to this work", "summary": "Social robots are embodied agents that interact with people while following\nhuman communication norms. These robots interact using verbal and non-verbal\ncues, and share the physical environments of people. While social robots have\npreviously utilized rule-based systems or probabilistic models for user\ninteraction, the rapid evolution of large language models (LLMs) presents new\nopportunities to develop LLM-empowered social robots for enhanced human-robot\ninteraction. To fully realize these capabilities, however, robots need to\ncollect data such as audio, fine-grained images, video, and locations. As a\nresult, LLMs often process sensitive personal information, particularly within\nhome environments. Given the tension between utility and privacy risks,\nevaluating how current LLMs manage sensitive data is critical. Specifically, we\naim to explore the extent to which out-of-the-box LLMs are privacy-aware in the\ncontext of household social robots. In this study, we present a set of\nprivacy-relevant scenarios crafted through the lens of Contextual Integrity\n(CI). We first survey users' privacy preferences regarding in-home social robot\nbehaviors and then examine how their privacy orientation affects their choices\nof these behaviors (N = 450). We then provide the same set of scenarios and\nquestions to state-of-the-art LLMs (N = 10) and find that the agreement between\nhumans and LLMs is low. To further investigate the capabilities of LLMs as a\npotential privacy controller, we implement four additional prompting strategies\nand compare their results. Finally, we discuss the implications and potential\nof AI privacy awareness in human-robot interaction.", "AI": {"tldr": "本研究探索了大语言模型(LLM)驱动的社交机器人在家庭环境中的隐私意识问题，通过对比人类和LLM在隐私相关场景中的选择差异，发现两者的一致性较低，并测试了不同提示策略来改善LLM的隐私控制能力。", "motivation": "随着大语言模型的快速发展，社交机器人在人机交互方面展现出新的机遇，但这些机器人需要收集音频、图像、视频等敏感个人信息，特别是在家庭环境中。因此，评估现有LLM在敏感数据管理方面的隐私意识能力变得至关重要，需要探索LLM在家庭社交机器人场景中的隐私感知程度。", "method": "研究采用情境完整性(Contextual Integrity, CI)理论框架设计隐私相关场景，首先调查用户对家庭社交机器人行为的隐私偏好(N=450)，然后将相同的场景和问题提供给最先进的LLM(N=10)进行对比分析。此外，还实施了四种额外的提示策略来测试LLM作为潜在隐私控制器的能力。", "result": "研究发现人类和LLM在隐私相关场景选择上的一致性较低，表明现有的开箱即用LLM在隐私意识方面存在不足。通过实施不同的提示策略，研究进一步评估了LLM在隐私控制方面的潜在能力和改进空间。", "conclusion": "研究揭示了当前LLM在家庭社交机器人应用中隐私意识的局限性，强调了在人机交互中发展AI隐私意识的重要性和潜力。这为未来开发更具隐私感知能力的社交机器人系统提供了重要启示。"}}
{"id": "2507.16139", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.16139", "abs": "https://arxiv.org/abs/2507.16139", "authors": ["Arsh Tangri", "Nichols Crawford Taylor", "Haojie Huang", "Robert Platt"], "title": "Equivariant Goal Conditioned Contrastive Reinforcement Learning", "comment": null, "summary": "Contrastive Reinforcement Learning (CRL) provides a promising framework for\nextracting useful structured representations from unlabeled interactions. By\npulling together state-action pairs and their corresponding future states,\nwhile pushing apart negative pairs, CRL enables learning nontrivial policies\nwithout manually designed rewards. In this work, we propose Equivariant CRL\n(ECRL), which further structures the latent space using equivariant\nconstraints. By leveraging inherent symmetries in goal-conditioned manipulation\ntasks, our method improves both sample efficiency and spatial generalization.\nSpecifically, we formally define Goal-Conditioned Group-Invariant MDPs to\ncharacterize rotation-symmetric robotic manipulation tasks, and build on this\nby introducing a novel rotation-invariant critic representation paired with a\nrotation-equivariant actor for Contrastive RL. Our approach consistently\noutperforms strong baselines across a range of simulated tasks in both\nstate-based and image-based settings. Finally, we extend our method to the\noffline RL setting, demonstrating its effectiveness across multiple tasks.", "AI": {"tldr": "本文提出了等变对比强化学习(ECRL)方法，通过利用目标条件操作任务中的旋转对称性来改进对比强化学习，在状态和图像环境下都显著提升了样本效率和空间泛化能力。", "motivation": "传统的对比强化学习虽然能从无标签交互中学习有用的结构化表示，但未能充分利用机器人操作任务中固有的对称性特征，限制了其样本效率和空间泛化能力。", "method": "提出等变对比强化学习(ECRL)框架，正式定义了目标条件群不变马尔可夫决策过程来刻画旋转对称的机器人操作任务，引入旋转不变的critic表示和旋转等变的actor，并将等变约束应用于对比强化学习的潜在空间结构化中。", "result": "在多个仿真任务的状态和图像设置下，该方法在样本效率和空间泛化方面均持续优于强基线方法，并成功扩展到离线强化学习设置中，在多个任务上展现了有效性。", "conclusion": "通过在对比强化学习中引入等变约束和利用任务对称性，ECRL方法能够显著改善学习效率和泛化能力，为无奖励设计的机器人操作任务提供了一个有效的学习框架。"}}
{"id": "2507.16175", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16175", "abs": "https://arxiv.org/abs/2507.16175", "authors": ["Euijeong Lee", "Kyung Min Han", "Young J. Kim"], "title": "Scanning Bot: Efficient Scan Planning using Panoramic Cameras", "comment": null, "summary": "Panoramic RGB-D cameras are known for their ability to produce high quality\n3D scene reconstructions. However, operating these cameras involves manually\nselecting viewpoints and physically transporting the camera, making the\ngeneration of a 3D model time consuming and tedious. Additionally, the process\ncan be challenging for novice users due to spatial constraints, such as\nensuring sufficient feature overlap between viewpoint frames. To address these\nchallenges, we propose a fully autonomous scan planning that generates an\nefficient tour plan for environment scanning, ensuring collision-free\nnavigation and adequate overlap between viewpoints within the plan. Extensive\nexperiments conducted in both synthetic and real-world environments validate\nthe performance of our planner against state-of-the-art view planners. In\nparticular, our method achieved an average scan coverage of 99 percent in the\nreal-world experiment, with our approach being up to 3 times faster than\nstate-of-the-art planners in total scan time.", "AI": {"tldr": "提出了一种全自主的扫描规划方法，用于全景RGB-D相机的3D场景重建，实现无碰撞导航和最优视点规划，在真实环境中达到99%的扫描覆盖率，扫描时间比现有方法快3倍。", "motivation": "传统全景RGB-D相机需要手动选择视点和物理移动设备来进行3D重建，过程耗时且繁琐；对新手用户来说存在空间约束挑战，如确保视点间有足够的特征重叠等问题。", "method": "提出了一种全自主的扫描规划系统，能够生成高效的环境扫描路径规划，确保无碰撞导航并在规划的视点之间保持充分的重叠覆盖。", "result": "在合成和真实环境中进行了大量实验验证，在真实世界实验中平均扫描覆盖率达到99%，总扫描时间比最先进的规划器快3倍。", "conclusion": "该方法成功解决了全景RGB-D相机3D重建中的视点规划问题，显著提高了扫描效率和覆盖率，为自主3D环境扫描提供了有效解决方案。"}}
{"id": "2507.16214", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16214", "abs": "https://arxiv.org/abs/2507.16214", "authors": ["Batu Candan", "Simone Servadio"], "title": "Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers", "comment": null, "summary": "Accurate and robust relative pose estimation is crucial for enabling\nchallenging Active Debris Removal (ADR) missions targeting tumbling derelict\nsatellites such as ESA's ENVISAT. This work presents a complete pipeline\nintegrating advanced computer vision techniques with adaptive nonlinear\nfiltering to address this challenge. A Convolutional Neural Network (CNN),\nenhanced with image preprocessing, detects structural markers (corners) from\nchaser imagery, whose 2D coordinates are converted to 3D measurements using\ncamera modeling. These measurements are fused within an Unscented Kalman Filter\n(UKF) framework, selected for its ability to handle nonlinear relative\ndynamics, to estimate the full relative pose. Key contributions include the\nintegrated system architecture and a dual adaptive strategy within the UKF:\ndynamic tuning of the measurement noise covariance compensates for varying CNN\nmeasurement uncertainty, while adaptive tuning of the process noise covariance,\nutilizing measurement residual analysis, accounts for unmodeled dynamics or\nmaneuvers online. This dual adaptation enhances robustness against both\nmeasurement imperfections and dynamic model uncertainties. The performance of\nthe proposed adaptive integrated system is evaluated through high-fidelity\nsimulations using a realistic ENVISAT model, comparing estimates against ground\ntruth under various conditions, including measurement outages. This\ncomprehensive approach offers an enhanced solution for robust onboard relative\nnavigation, significantly advancing the capabilities required for safe\nproximity operations during ADR missions.", "AI": {"tldr": "本文提出了一个完整的相对位姿估计管道，结合CNN和自适应无迹卡尔曼滤波器，用于主动碎片清除任务中对翻滚废弃卫星的鲁棒导航。", "motivation": "准确且鲁棒的相对位姿估计对于具有挑战性的主动碎片清除任务至关重要，特别是针对像ESA的ENVISAT这样翻滚的废弃卫星。需要解决测量不确定性和动态模型不确定性的问题。", "method": "提出了一个集成CNN和自适应无迹卡尔曼滤波器的完整管道：1）使用增强图像预处理的CNN从追踪器图像中检测结构标记（角点）；2）通过相机建模将2D坐标转换为3D测量；3）在UKF框架内融合这些测量来估计完整的相对位姿；4）实施双重自适应策略：动态调整测量噪声协方差和利用测量残差分析自适应调整过程噪声协方差。", "result": "通过使用真实ENVISAT模型的高保真仿真评估了所提出的自适应集成系统性能，在各种条件下（包括测量中断）将估计结果与地面真值进行比较，证明了系统的有效性。", "conclusion": "这种综合方法为鲁棒的机载相对导航提供了增强解决方案，显著提升了ADR任务中安全近距离操作所需的能力，通过双重自适应策略增强了对测量缺陷和动态模型不确定性的鲁棒性。"}}
{"id": "2507.16233", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16233", "abs": "https://arxiv.org/abs/2507.16233", "authors": ["Yue Lin", "Xiaoxuan Zhang", "Yang Liu", "Dong Wang", "Huchuan Lu"], "title": "GFM-Planner: Perception-Aware Trajectory Planning with Geometric Feature Metric", "comment": "Accepted by IROS 2025", "summary": "Like humans who rely on landmarks for orientation, autonomous robots depend\non feature-rich environments for accurate localization. In this paper, we\npropose the GFM-Planner, a perception-aware trajectory planning framework based\non the geometric feature metric, which enhances LiDAR localization accuracy by\nguiding the robot to avoid degraded areas. First, we derive the Geometric\nFeature Metric (GFM) from the fundamental LiDAR localization problem. Next, we\ndesign a 2D grid-based Metric Encoding Map (MEM) to efficiently store GFM\nvalues across the environment. A constant-time decoding algorithm is further\nproposed to retrieve GFM values for arbitrary poses from the MEM. Finally, we\ndevelop a perception-aware trajectory planning algorithm that improves LiDAR\nlocalization capabilities by guiding the robot in selecting trajectories\nthrough feature-rich areas. Both simulation and real-world experiments\ndemonstrate that our approach enables the robot to actively select trajectories\nthat significantly enhance LiDAR localization accuracy.", "AI": {"tldr": "本文提出了GFM-Planner，一个基于几何特征度量的感知感知轨迹规划框架，通过引导机器人避开退化区域来提高LiDAR定位精度", "motivation": "自主机器人像人类依赖地标定向一样，需要依赖特征丰富的环境进行准确定位。现有方法在特征稀少或退化的环境中定位精度不足，需要一种感知感知的轨迹规划方法来主动选择有利于LiDAR定位的路径", "method": "1) 从基础LiDAR定位问题推导出几何特征度量(GFM)；2) 设计基于2D网格的度量编码图(MEM)来高效存储环境中的GFM值；3) 提出常数时间解码算法从MEM中检索任意位姿的GFM值；4) 开发感知感知轨迹规划算法，通过引导机器人选择通过特征丰富区域的轨迹来改善LiDAR定位能力", "result": "仿真和真实世界实验均表明，该方法能够使机器人主动选择显著提高LiDAR定位精度的轨迹，有效避开特征退化区域，提升整体定位性能", "conclusion": "GFM-Planner框架成功实现了感知感知的轨迹规划，通过几何特征度量有效指导机器人选择有利于LiDAR定位的路径，为自主机器人在复杂环境中的可靠导航提供了重要解决方案"}}
{"id": "2507.16305", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16305", "abs": "https://arxiv.org/abs/2507.16305", "authors": ["Xiao Liu", "Weijun Wang", "Tianlun Huang", "Zhiyong Wang", "Wei Feng"], "title": "Trajectory Planning of a Curtain Wall Installation Robot Based on Biomimetic Mechanisms", "comment": null, "summary": "As the robotics market rapidly evolves, energy consumption has become a\ncritical issue, particularly restricting the application of construction\nrobots. To tackle this challenge, our study innovatively draws inspiration from\nthe mechanics of human upper limb movements during weight lifting, proposing a\nbio-inspired trajectory planning framework that incorporates human energy\nconversion principles. By collecting motion trajectories and electromyography\n(EMG) signals during dumbbell curls, we construct an anthropomorphic trajectory\nplanning that integrates human force exertion patterns and energy consumption\npatterns. Utilizing the Particle Swarm Optimization (PSO) algorithm, we achieve\ndynamic load distribution for robotic arm trajectory planning based on\nhuman-like movement features. In practical application, these bio-inspired\nmovement characteristics are applied to curtain wall installation tasks,\nvalidating the correctness and superiority of our trajectory planning method.\nSimulation results demonstrate a 48.4% reduction in energy consumption through\nintelligent conversion between kinetic and potential energy. This approach\nprovides new insights and theoretical support for optimizing energy use in\ncurtain wall installation robots during actual handling tasks.", "AI": {"tldr": "该研究提出了一种仿生轨迹规划框架，通过模仿人类上肢举重动作的力学原理，将人体运动特征应用于机器人臂轨迹规划，在幕墙安装任务中实现了48.4%的能耗降低。", "motivation": "随着机器人市场快速发展，能耗问题已成为关键挑战，特别是限制了建筑机器人的应用。为了解决这一问题，研究者需要寻找新的节能方法来优化机器人的能源使用效率。", "method": "该研究创新性地从人类上肢举重动作的力学原理中汲取灵感，通过收集哑铃弯举过程中的运动轨迹和肌电图(EMG)信号，构建融合人体发力模式和能耗模式的拟人化轨迹规划。利用粒子群优化(PSO)算法，基于类人运动特征实现机器人臂轨迹规划的动态负载分布。", "result": "仿真结果显示，通过动能和势能之间的智能转换，该方法实现了48.4%的能耗降低。在幕墙安装任务的实际应用中验证了轨迹规划方法的正确性和优越性。", "conclusion": "该仿生运动特征应用方法为幕墙安装机器人在实际搬运任务中的能源使用优化提供了新的见解和理论支持，证明了生物启发的轨迹规划在建筑机器人节能方面的有效性。"}}
{"id": "2507.16328", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16328", "abs": "https://arxiv.org/abs/2507.16328", "authors": ["Xiao Liu", "Xianlong Yang", "Weijun Wang", "Wei Feng"], "title": "Design and Dimensional Optimization of Legged Structures for Construction Robots", "comment": null, "summary": "Faced with complex and unstructured construction environments, wheeled and\ntracked robots exhibit significant limitations in terrain adaptability and\nflexibility, making it difficult to meet the requirements of autonomous\noperation. Inspired by ants in nature, this paper proposes a leg configuration\ndesign and optimization method tailored for construction scenarios, aiming to\nenhance the autonomous mobility of construction robots. This paper analyzes the\nfull operational motion performance of the leg during both swing and stance\nphases. First, based on kinematic modeling and multi-dimensional workspace\nanalysis, the concept of an \"improved workspace\" is introduced, and graphical\nmethods are used to optimize the leg dimensions during the swing phase.\nFurthermore, a new concept of \"average manipulability\" is introduced based on\nthe velocity Jacobian matrix, and numerical solutions are applied to obtain the\nleg segment ratio that maximizes manipulability. To overcome the difficulties\nassociated with traditional analytical methods, virtual prototype simulations\nare conducted in ADAMS to explore the relationship between the robot body's\noptimal flexibility and leg segment proportions. In summary, the leg segment\nproportions with the best comprehensive motion performance are obtained. This\nstudy presents the first multi-dimensional quantitative evaluation framework\nfor leg motion performance tailored for construction environments, providing a\nstructural design foundation for legged construction robots to achieve\nautonomous mobility in complex terrains.", "AI": {"tldr": "本文提出了一种针对建筑环境的仿蚁腿部构型设计和优化方法，通过多维工作空间分析、平均操作性概念和虚拟原型仿真，获得了具有最佳综合运动性能的腿部节段比例，为腿式建筑机器人在复杂地形中实现自主移动提供了结构设计基础。", "motivation": "轮式和履带式机器人在复杂非结构化建筑环境中表现出地形适应性和灵活性的显著局限性，难以满足自主作业要求。受自然界蚂蚁启发，需要开发适用于建筑场景的腿部构型设计方法，以提升建筑机器人的自主移动能力。", "method": "基于运动学建模和多维工作空间分析，引入\"改进工作空间\"概念，使用图形方法优化摆动相腿部尺寸；基于速度雅可比矩阵引入\"平均操作性\"概念，采用数值求解获得最大化操作性的腿段比例；在ADAMS中进行虚拟原型仿真，探索机器人本体最优灵活性与腿段比例的关系。", "result": "获得了具有最佳综合运动性能的腿部节段比例，建立了首个针对建筑环境的腿部运动性能多维定量评估框架。", "conclusion": "该研究为腿式建筑机器人在复杂地形中实现自主移动提供了结构设计基础，通过多维分析和优化方法成功解决了传统轮式和履带式机器人在建筑环境中的适应性问题。"}}
{"id": "2507.16335", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16335", "abs": "https://arxiv.org/abs/2507.16335", "authors": ["Xiao Liu", "Xianlong Yang", "Weijun Wang", "Wei Feng"], "title": "Topology Optimization of Leg Structures for Construction Robots Based on Variable Density Method", "comment": null, "summary": "In complex terrain construction environments, there are high demands for\nrobots to achieve both high payload capacity and mobility flexibility. As the\nkey load-bearing component, the optimization of robotic leg structures is of\nparticular importance. Therefore, this study focuses on the optimization of leg\nstructures for construction robots, proposing a topology optimization strategy\nbased on the SIMP (Solid Isotropic Microstructures with Penalization) variable\ndensity method along with a structural re-design approach. The design\nperformance is comprehensively validated through finite element analysis using\nANSYS. First, static and modal analyses are conducted to evaluate the\nrationality of the initial design. Then, topology optimization using the\nSIMP-based variable density method is applied to the femur section, which\naccounts for the largest proportion of the leg's weight. Based on iterative\ncalculations, the femur undergoes secondary structural reconstruction. After\noptimization, the mass of the femur is reduced by 19.45\\%, and the overall leg\nmass decreases by 7.92\\%, achieving the goal of lightweight design. Finally,\nstatic and modal analyses are conducted on the reconstructed leg. The results\ndemonstrate that the optimized leg still meets structural performance\nrequirements, validating the feasibility of lightweight design. This research\nprovides robust theoretical and technical support for lightweight construction\nrobot design and lays a foundation for their efficient operation in complex\nconstruction environments.", "AI": {"tldr": "本研究针对建筑机器人腿部结构提出了基于SIMP变密度方法的拓扑优化策略，通过对股骨部分的结构重设计，实现了股骨质量减轻19.45%，整体腿部质量减轻7.92%的轻量化目标，同时保持了结构性能要求。", "motivation": "在复杂地形建筑环境中，机器人需要同时具备高负载能力和移动灵活性，而腿部结构作为关键承重部件，其优化设计对机器人性能至关重要，因此需要开发有效的腿部结构优化方法。", "method": "采用基于SIMP（固体各向同性微结构惩罚）变密度方法的拓扑优化策略，结合结构重设计方法；使用ANSYS进行有限元分析验证；重点对占腿部重量最大比例的股骨部分进行拓扑优化和二次结构重构。", "result": "优化后股骨质量减少19.45%，整体腿部质量减少7.92%，实现了轻量化设计目标；静力学和模态分析结果表明优化后的腿部结构仍满足结构性能要求，验证了轻量化设计的可行性。", "conclusion": "研究成功开发了建筑机器人腿部结构的拓扑优化策略，实现了显著的轻量化效果同时保持结构性能，为轻量化建筑机器人设计提供了坚实的理论和技术支撑，为其在复杂建筑环境中的高效运行奠定了基础。"}}
{"id": "2507.16369", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16369", "abs": "https://arxiv.org/abs/2507.16369", "authors": ["Thanh D V Nguyen", "Vincent Bonnet", "Pierre Fernbach", "David Daney", "Florent Lamiraux"], "title": "Humanoid Robot Whole-body Geometric Calibration with Embedded Sensors and a Single Plane", "comment": null, "summary": "Whole-body geometric calibration of humanoid robots using classical robot\ncalibration methods is a timeconsuming and experimentally burdensome task.\nHowever, despite its significance for accurate control and simulation, it is\noften overlooked in the humanoid robotics community. To address this issue, we\npropose a novel practical method that utilizes a single plane, embedded force\nsensors, and an admittance controller to calibrate the whole-body kinematics of\nhumanoids without requiring manual intervention. Given the complexity of\nhumanoid robots, it is crucial to generate and determine a minimal set of\noptimal calibration postures. To do so, we propose a new algorithm called IROC\n(Information Ranking algorithm for selecting Optimal Calibration postures).\nIROC requires a pool of feasible candidate postures to build a normalized\nweighted information matrix for each posture. Then, contrary to other\nalgorithms from the literature, IROC will determine the minimal number of\noptimal postures that are to be played onto a robot for its calibration. Both\nIROC and the single-plane calibration method were experimentally validated on a\nTALOS humanoid robot. The total whole-body kinematics chain was calibrated\nusing solely 31 optimal postures with 3-point contacts on a table by the robot\ngripper. In a cross-validation experiment, the average root-mean-square (RMS)\nerror was reduced by a factor of 2.3 compared to the manufacturer's model.", "AI": {"tldr": "提出了一种利用单平面、嵌入式力传感器和导纳控制器的新型实用方法，通过IROC算法选择最优校准姿态，实现人形机器人全身运动学自动校准，无需人工干预", "motivation": "传统的人形机器人全身几何校准方法耗时且实验负担重，尽管对精确控制和仿真至关重要，但在人形机器人社区中经常被忽视，因此需要一种更实用高效的校准方法", "method": "提出IROC（信息排序算法）来选择最优校准姿态，该算法从可行候选姿态池中构建每个姿态的归一化加权信息矩阵，确定用于机器人校准的最少最优姿态数量；结合单平面校准方法，利用嵌入式力传感器和导纳控制器实现自动校准", "result": "在TALOS人形机器人上进行实验验证，仅使用31个最优姿态（机器人夹爪在桌面上3点接触）就完成了全身运动学链校准；交叉验证实验中，平均均方根误差相比制造商模型减少了2.3倍", "conclusion": "IROC算法和单平面校准方法能够有效实现人形机器人全身运动学的自动校准，显著减少所需姿态数量和校准时间，同时大幅提高校准精度，为人形机器人校准提供了实用的解决方案"}}
{"id": "2507.16382", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.16382", "abs": "https://arxiv.org/abs/2507.16382", "authors": ["Chenhao Yao", "Zike Yuan", "Xiaoxu Liu", "Chi Zhu"], "title": "Application of LLM Guided Reinforcement Learning in Formation Control with Collision Avoidance", "comment": "Accepted by IROS 2025", "summary": "Multi-Agent Systems (MAS) excel at accomplishing complex objectives through\nthe collaborative efforts of individual agents. Among the methodologies\nemployed in MAS, Multi-Agent Reinforcement Learning (MARL) stands out as one of\nthe most efficacious algorithms. However, when confronted with the complex\nobjective of Formation Control with Collision Avoidance (FCCA): designing an\neffective reward function that facilitates swift convergence of the policy\nnetwork to an optimal solution. In this paper, we introduce a novel framework\nthat aims to overcome this challenge. By giving large language models (LLMs) on\nthe prioritization of tasks and the observable information available to each\nagent, our framework generates reward functions that can be dynamically\nadjusted online based on evaluation outcomes by employing more advanced\nevaluation metrics rather than the rewards themselves. This mechanism enables\nthe MAS to simultaneously achieve formation control and obstacle avoidance in\ndynamic environments with enhanced efficiency, requiring fewer iterations to\nreach superior performance levels. Our empirical studies, conducted in both\nsimulation and real-world settings, validate the practicality and effectiveness\nof our proposed approach.", "AI": {"tldr": "本文提出了一个利用大语言模型(LLM)动态生成奖励函数的新框架，用于解决多智能体强化学习中编队控制与避碰(FCCA)问题，通过在线调整奖励函数实现更高效的策略学习。", "motivation": "在多智能体强化学习(MARL)中，设计有效的奖励函数来实现编队控制与避碰是一个挑战性问题。传统方法难以设计出能够使策略网络快速收敛到最优解的奖励函数，特别是在复杂的动态环境中同时实现编队控制和障碍物避让。", "method": "提出了一个基于大语言模型的新框架，通过让LLM理解任务优先级和每个智能体可观察到的信息，生成可动态调整的奖励函数。该框架采用先进的评估指标而非奖励本身来在线调整奖励函数，使系统能够根据评估结果动态优化。", "result": "实验结果表明，该方法能够让多智能体系统在动态环境中同时实现编队控制和障碍物避让，且效率显著提升，需要更少的迭代次数就能达到更优的性能水平。仿真和真实环境的实验都验证了方法的有效性。", "conclusion": "本文成功解决了MARL中编队控制与避碰问题的奖励函数设计难题，通过LLM动态生成和调整奖励函数的创新方法，实现了更高效的多智能体协作，为复杂多智能体任务提供了新的解决思路。"}}
{"id": "2507.16398", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.16398", "abs": "https://arxiv.org/abs/2507.16398", "authors": ["Lavinia Hriscu", "Alberto Sanfeliu", "Anais Garrell"], "title": "AI or Human? Understanding Perceptions of Embodied Robots with LLMs", "comment": null, "summary": "The pursuit of artificial intelligence has long been associated to the the\nchallenge of effectively measuring intelligence. Even if the Turing Test was\nintroduced as a means of assessing a system intelligence, its relevance and\napplication within the field of human-robot interaction remain largely\nunderexplored. This study investigates the perception of intelligence in\nembodied robots by performing a Turing Test within a robotic platform. A total\nof 34 participants were tasked with distinguishing between AI- and\nhuman-operated robots while engaging in two interactive tasks: an information\nretrieval and a package handover. These tasks assessed the robot perception and\nnavigation abilities under both static and dynamic conditions. Results indicate\nthat participants were unable to reliably differentiate between AI- and\nhuman-controlled robots beyond chance levels. Furthermore, analysis of\nparticipant responses reveals key factors influencing the perception of\nartificial versus human intelligence in embodied robotic systems. These\nfindings provide insights into the design of future interactive robots and\ncontribute to the ongoing discourse on intelligence assessment in AI-driven\nsystems.", "AI": {"tldr": "该研究通过在机器人平台上进行图灵测试，探索了人类对具身机器人智能感知的问题。34名参与者在信息检索和包裹交接任务中无法可靠区分AI控制和人类控制的机器人，为未来交互机器人设计提供了洞察。", "motivation": "图灵测试作为评估系统智能的手段，其在人机交互领域的相关性和应用仍未得到充分探索。研究希望通过具身机器人平台上的图灵测试来调查人类对机器人智能的感知。", "method": "招募34名参与者，让他们在两个交互任务（信息检索和包裹交接）中区分AI控制和人类控制的机器人。这些任务在静态和动态条件下评估机器人的感知和导航能力。", "result": "参与者无法可靠地区分AI控制和人类控制的机器人，其判断准确率仅为随机水平。通过分析参与者的反应，识别出影响人类对具身机器人系统中人工智能与人类智能感知的关键因素。", "conclusion": "研究结果为未来交互机器人的设计提供了重要洞察，并为AI驱动系统中智能评估的持续讨论做出了贡献。发现表明当前AI技术在具身机器人应用中已达到较高的仿人水平。"}}
{"id": "2507.16621", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.16621", "abs": "https://arxiv.org/abs/2507.16621", "authors": ["Lorenzo Gentilini", "Pierpaolo Serio", "Valentina Donzella", "Lorenzo Pollini"], "title": "A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System", "comment": null, "summary": "Extrinsic Calibration represents the cornerstone of autonomous driving. Its\naccuracy plays a crucial role in the perception pipeline, as any errors can\nhave implications for the safety of the vehicle. Modern sensor systems collect\ndifferent types of data from the environment, making it harder to align the\ndata. To this end, we propose a target-based extrinsic calibration system\ntailored for a multi-LiDAR and multi-camera sensor suite. This system enables\ncross-calibration between LiDARs and cameras with limited prior knowledge using\na custom ChArUco board and a tailored nonlinear optimization method. We test\nthe system with real-world data gathered in a warehouse. Results demonstrated\nthe effectiveness of the proposed method, highlighting the feasibility of a\nunique pipeline tailored for various types of sensors.", "AI": {"tldr": "提出了一种基于目标的多激光雷达和多相机传感器套件的外参标定系统，使用定制的ChArUco板和非线性优化方法实现传感器间的交叉标定", "motivation": "自动驾驶中外参标定的准确性对感知管道至关重要，任何误差都可能影响车辆安全。现代传感器系统收集不同类型的环境数据，使数据对齐变得更加困难，需要一种有效的多传感器标定方法", "method": "提出基于目标的外参标定系统，专门针对多激光雷达和多相机传感器套件设计。使用定制的ChArUco板作为标定目标，结合量身定制的非线性优化方法，在有限先验知识条件下实现激光雷达和相机之间的交叉标定", "result": "在仓库环境中使用真实世界数据测试系统，结果证明了所提方法的有效性，突出了针对各种类型传感器的独特管道的可行性", "conclusion": "该方法成功实现了多激光雷达和多相机系统的精确外参标定，为自动驾驶感知系统提供了可靠的传感器对齐解决方案，提高了系统的安全性和准确性"}}
{"id": "2507.16645", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.16645", "abs": "https://arxiv.org/abs/2507.16645", "authors": ["Zongzheng Zhang", "Jiawen Yang", "Ziqiao Peng", "Meng Yang", "Jianzhu Ma", "Lin Cheng", "Huazhe Xu", "Hang Zhao", "Hao Zhao"], "title": "Morpheus: A Neural-driven Animatronic Face with Hybrid Actuation and Diverse Emotion Control", "comment": "Accepted to RSS 2025, Project Page:\n  https://jiawenyang-ch.github.io/Morpheus-Hardware-Design/", "summary": "Previous animatronic faces struggle to express emotions effectively due to\nhardware and software limitations. On the hardware side, earlier approaches\neither use rigid-driven mechanisms, which provide precise control but are\ndifficult to design within constrained spaces, or tendon-driven mechanisms,\nwhich are more space-efficient but challenging to control. In contrast, we\npropose a hybrid actuation approach that combines the best of both worlds. The\neyes and mouth-key areas for emotional expression-are controlled using rigid\nmechanisms for precise movement, while the nose and cheek, which convey subtle\nfacial microexpressions, are driven by strings. This design allows us to build\na compact yet versatile hardware platform capable of expressing a wide range of\nemotions. On the algorithmic side, our method introduces a self-modeling\nnetwork that maps motor actions to facial landmarks, allowing us to\nautomatically establish the relationship between blendshape coefficients for\ndifferent facial expressions and the corresponding motor control signals\nthrough gradient backpropagation. We then train a neural network to map speech\ninput to corresponding blendshape controls. With our method, we can generate\ndistinct emotional expressions such as happiness, fear, disgust, and anger,\nfrom any given sentence, each with nuanced, emotion-specific control signals-a\nfeature that has not been demonstrated in earlier systems. We release the\nhardware design and code at https://github.com/ZZongzheng0918/Morpheus-Hardware\nand https://github.com/ZZongzheng0918/Morpheus-Software.", "AI": {"tldr": "本文提出了一种混合驱动的动画人脸系统，结合刚性和柔性驱动机制，并使用自建模网络实现从语音到情感表达的自动映射，能够生成多种细致的面部情感表达。", "motivation": "现有动画人脸系统在情感表达方面存在局限性：刚性驱动机制控制精确但难以在有限空间内设计，柔性驱动机制节省空间但控制困难。需要开发一种既紧凑又能表达丰富情感的动画人脸系统。", "method": "提出混合驱动方案：眼部和嘴部等关键情感表达区域使用刚性机制精确控制，鼻部和脸颊等微表情区域使用弦线驱动。算法方面引入自建模网络，将电机动作映射到面部关键点，通过梯度反向传播自动建立混合形状系数与电机控制信号的关系，并训练神经网络将语音输入映射到相应的混合形状控制。", "result": "系统能够从任意给定句子生成不同的情感表达，包括快乐、恐惧、厌恶和愤怒等，每种情感都具有细致入微的、特定于情感的控制信号，这是早期系统未能实现的功能。", "conclusion": "成功开发了一个紧凑且多功能的硬件平台，能够表达广泛的情感范围。通过混合驱动机制和自建模网络的结合，实现了从语音到精确情感面部表达的自动化控制，为动画人脸技术带来了显著进步。"}}
{"id": "2507.16713", "categories": ["cs.RO", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.16713", "abs": "https://arxiv.org/abs/2507.16713", "authors": ["Guowei Lan", "Kaixian Qu", "René Zurbrügg", "Changan Chen", "Christopher E. Mower", "Haitham Bou-Ammar", "Marco Hutter"], "title": "Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory", "comment": null, "summary": "Vision-language models (VLMs) have been widely adopted in robotics to enable\nautonomous planning. However, grounding VLMs, originally trained on internet\ndata, to diverse real-world robots remains a challenge. This paper presents\nExpTeach, a framework that grounds VLMs to physical robots by building a\nself-generated memory of real-world experiences. In ExpTeach, the VLM\nautonomously plans actions, verifies outcomes, reflects on failures, and adapts\nrobot behaviors in a closed loop. The self-generated experiences during this\nprocess are then summarized into a long-term memory, enabling retrieval of\nlearned knowledge to guide future tasks via retrieval-augmented generation\n(RAG). Additionally, ExpTeach enhances the spatial understanding of VLMs with\nan on-demand image annotation module. In experiments, we show that reflection\nimproves success rates from 36% to 84% on four challenging robotic tasks and\nobserve the emergence of intelligent object interactions, including creative\ntool use. Across extensive tests on 12 real-world scenarios (including eight\nunseen ones), we find that grounding with long-term memory boosts single-trial\nsuccess rates from 22% to 80%, demonstrating the effectiveness and\ngeneralizability of ExpTeach.", "AI": {"tldr": "ExpTeach是一个通过构建自生成真实世界经验记忆来将视觉语言模型(VLM)适配到物理机器人的框架，通过反思机制和长期记忆检索显著提高了机器人任务成功率", "motivation": "视觉语言模型虽然在机器人规划中被广泛采用，但将原本在互联网数据上训练的VLM适配到多样化的真实世界机器人仍然是一个挑战，需要一种有效的方法来弥合模型与物理世界之间的差距", "method": "提出ExpTeach框架，让VLM自主规划动作、验证结果、反思失败并在闭环中调整机器人行为；将自生成的经验总结为长期记忆，通过检索增强生成(RAG)指导未来任务；同时通过按需图像标注模块增强VLM的空间理解能力", "result": "反思机制将四个挑战性机器人任务的成功率从36%提升到84%，并观察到智能物体交互行为的涌现，包括创造性工具使用；在12个真实世界场景的广泛测试中，长期记忆适配将单次试验成功率从22%提升到80%", "conclusion": "ExpTeach框架有效解决了VLM到物理机器人的适配问题，通过自生成经验记忆和反思机制显著提高了机器人任务执行的成功率和泛化能力，为机器人自主学习和适应提供了新的解决方案"}}
