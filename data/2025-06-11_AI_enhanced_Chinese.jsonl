{"id": "2506.08039", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08039", "abs": "https://arxiv.org/abs/2506.08039", "authors": ["Ray Wai Man Kong"], "title": "AI Magnetic Levitation (Maglev) Conveyor for Automated Assembly Production", "comment": "12 pages, 9 Figures", "summary": "Efficiency, speed, and precision are essential in modern manufacturing. AI\nMaglev Conveyor system, combining magnetic levitation (maglev) technology with\nartificial intelligence (AI), revolutionizes automated production processes.\nThis system reduces maintenance costs and downtime by eliminating friction,\nenhancing operational efficiency. It transports goods swiftly with minimal\nenergy consumption, optimizing resource use and supporting sustainability. AI\nintegration enables real-time monitoring and adaptive control, allowing\nbusinesses to respond to production demand fluctuations and streamline supply\nchain operations.\n  The AI Maglev Conveyor offers smooth, silent operation, accommodating diverse\nproduct types and sizes for flexible manufacturing without extensive\nreconfiguration. AI algorithms optimize routing, reduce cycle times, and\nimprove throughput, creating an agile production line adaptable to market\nchanges.\n  This applied research paper introduces the Maglev Conveyor system, featuring\nan electromagnetic controller and multiple movers to enhance automation. It\noffers cost savings as an alternative to setups using six-axis robots or linear\nmotors, with precise adjustments for robotic arm loading. Operating at high\nspeeds minimizes treatment time for delicate components while maintaining\nprecision. Its adaptable design accommodates various materials, facilitating\nintegration of processing stations alongside electronic product assembly.\nPositioned between linear-axis and robotic systems in cost, the Maglev Conveyor\nis ideal for flat parts requiring minimal travel, transforming production\nefficiency across industries. It explores its technical advantages,\nflexibility, cost reductions, and overall benefits.", "AI": {"tldr": "AI Maglev Conveyor系统结合磁悬浮技术和AI，提升制造效率，降低成本，支持可持续生产。", "motivation": "现代制造需要高效、快速和精确的系统，传统方法存在摩擦和维护成本高的问题。", "method": "结合磁悬浮技术和AI，实现无摩擦运输、实时监控和自适应控制。", "result": "减少维护成本、提高效率、支持灵活生产，适应市场需求变化。", "conclusion": "AI Maglev Conveyor系统是高效、灵活且经济的制造解决方案，适用于多种行业。"}}
{"id": "2506.08045", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.08045", "abs": "https://arxiv.org/abs/2506.08045", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "title": "UAVs Meet Agentic AI: A Multidomain Survey of Autonomous Aerial Intelligence and Agentic UAVs", "comment": "40 pages, 6 Figures", "summary": "Agentic UAVs represent a new frontier in autonomous aerial intelligence,\nintegrating perception, decision-making, memory, and collaborative planning to\noperate adaptively in complex, real-world environments. Driven by recent\nadvances in Agentic AI, these systems surpass traditional UAVs by exhibiting\ngoal-driven behavior, contextual reasoning, and interactive autonomy. We\nprovide a comprehensive foundation for understanding the architectural\ncomponents and enabling technologies that distinguish Agentic UAVs from\ntraditional autonomous UAVs. Furthermore, a detailed comparative analysis\nhighlights advancements in autonomy with AI agents, learning, and mission\nflexibility. This study explores seven high-impact application domains\nprecision agriculture, construction & mining, disaster response, environmental\nmonitoring, infrastructure inspection, logistics, security, and wildlife\nconservation, illustrating the broad societal value of agentic aerial\nintelligence. Furthermore, we identify key challenges in technical constraints,\nregulatory limitations, and data-model reliability, and we present emerging\nsolutions across hardware innovation, learning architectures, and human-AI\ninteraction. Finally, a future roadmap is proposed, outlining pathways toward\nself-evolving aerial ecosystems, system-level collaboration, and sustainable,\nequitable deployments. This survey establishes a foundational framework for the\nfuture development, deployment, and governance of agentic aerial systems\n(Agentic UAVs) across diverse societal and industrial domains.", "AI": {"tldr": "本文综述了Agentic UAVs（自主智能无人机）的架构、技术优势、应用领域及未来挑战，提出了未来发展的路线图。", "motivation": "传统无人机在复杂环境中的自主性和适应性不足，而Agentic UAVs通过整合感知、决策、记忆和协作规划，展现出更强的智能性和灵活性。", "method": "通过比较分析Agentic UAVs与传统无人机的技术差异，探讨其在七个高影响力领域的应用，并分析技术、法规和数据可靠性方面的挑战。", "result": "Agentic UAVs在多个领域展现出广泛的社会价值，同时面临硬件、学习和人机交互等方面的挑战。", "conclusion": "本文为Agentic UAVs的未来发展、部署和治理提供了基础框架，并提出了自进化生态系统和可持续部署的未来方向。"}}
{"id": "2506.08061", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.08061", "abs": "https://arxiv.org/abs/2506.08061", "authors": ["Ali Abedi", "Fernando Cladera", "Mohsen Farajijalal", "Reza Ehsani"], "title": "Adaptive Per-Tree Canopy Volume Estimation Using Mobile LiDAR in Structured and Unstructured Orchards", "comment": "5 pages, 3 figures, Accepted to the Novel Approaches for Precision\n  Agriculture and Forestry with Autonomous Robots IEEE ICRA Workshop - 2025", "summary": "We present a real-time system for per-tree canopy volume estimation using\nmobile LiDAR data collected during routine robotic navigation. Unlike prior\napproaches that rely on static scans or assume uniform orchard structures, our\nmethod adapts to varying field geometries via an integrated pipeline of\nLiDAR-inertial odometry, adaptive segmentation, and geometric reconstruction.\nWe evaluate the system across two commercial orchards, one pistachio orchard\nwith regular spacing and one almond orchard with dense, overlapping crowns. A\nhybrid clustering strategy combining DBSCAN and spectral clustering enables\nrobust per-tree segmentation, achieving 93% success in pistachio and 80% in\nalmond, with strong agreement to drone derived canopy volume estimates. This\nwork advances scalable, non-intrusive tree monitoring for structurally diverse\norchard environments.", "AI": {"tldr": "提出了一种基于移动LiDAR数据的实时系统，用于估计单棵树冠体积，适用于结构多样的果园环境。", "motivation": "现有方法依赖静态扫描或假设果园结构均匀，无法适应多样化的田间几何形状。", "method": "结合LiDAR-惯性里程计、自适应分割和几何重建的集成流程，采用DBSCAN和谱聚类的混合聚类策略。", "result": "在两种商业果园中测试，成功率为93%（开心果）和80%（杏仁），与无人机数据一致。", "conclusion": "该系统为结构多样的果园提供了可扩展、非侵入式的树木监测方案。"}}
{"id": "2506.08149", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.08149", "abs": "https://arxiv.org/abs/2506.08149", "authors": ["Hang Wang", "Dechen Gao", "Junshan Zhang"], "title": "Ego-centric Learning of Communicative World Models for Autonomous Driving", "comment": null, "summary": "We study multi-agent reinforcement learning (MARL) for tasks in complex\nhigh-dimensional environments, such as autonomous driving. MARL is known to\nsuffer from the \\textit{partial observability} and \\textit{non-stationarity}\nissues. To tackle these challenges, information sharing is often employed,\nwhich however faces major hurdles in practice, including overwhelming\ncommunication overhead and scalability concerns. By making use of generative AI\nembodied in world model together with its latent representation, we develop\n{\\it CALL}, \\underline{C}ommunic\\underline{a}tive Wor\\underline{l}d\nMode\\underline{l}, for MARL, where 1) each agent first learns its world model\nthat encodes its state and intention into low-dimensional latent representation\nwith smaller memory footprint, which can be shared with other agents of\ninterest via lightweight communication; and 2) each agent carries out\nego-centric learning while exploiting lightweight information sharing to enrich\nher world model, and then exploits its generalization capacity to improve\nprediction for better planning. We characterize the gain on the prediction\naccuracy from the information sharing and its impact on performance gap.\nExtensive experiments are carried out on the challenging local trajectory\nplanning tasks in the CARLA platform to demonstrate the performance gains of\nusing \\textit{CALL}.", "AI": {"tldr": "论文提出CALL方法，通过生成式AI和世界模型的潜在表示，解决多智能体强化学习中的部分可观测性和非平稳性问题，同时减少通信开销。", "motivation": "多智能体强化学习（MARL）在复杂高维环境中（如自动驾驶）面临部分可观测性和非平稳性问题，信息共享虽常用但存在通信开销和可扩展性问题。", "method": "CALL方法利用世界模型的潜在表示，将智能体的状态和意图编码为低维表示，通过轻量级通信共享，并结合自我中心学习提升预测和规划能力。", "result": "实验在CARLA平台上进行，证明了CALL在局部轨迹规划任务中的性能提升。", "conclusion": "CALL通过轻量级信息共享和潜在表示，有效提升了MARL的性能，同时解决了通信开销问题。"}}
{"id": "2506.08291", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08291", "abs": "https://arxiv.org/abs/2506.08291", "authors": ["Won Kyung Do", "Matthew Strong", "Aiden Swann", "Boshu Lei", "Monroe Kennedy III"], "title": "TensorTouch: Calibration of Tactile Sensors for High Resolution Stress Tensor and Deformation for Dexterous Manipulation", "comment": null, "summary": "Advanced dexterous manipulation involving multiple simultaneous contacts\nacross different surfaces, like pinching coins from ground or manipulating\nintertwined objects, remains challenging for robotic systems. Such tasks exceed\nthe capabilities of vision and proprioception alone, requiring high-resolution\ntactile sensing with calibrated physical metrics. Raw optical tactile sensor\nimages, while information-rich, lack interpretability and cross-sensor\ntransferability, limiting their real-world utility. TensorTouch addresses this\nchallenge by integrating finite element analysis with deep learning to extract\ncomprehensive contact information from optical tactile sensors, including\nstress tensors, deformation fields, and force distributions at pixel-level\nresolution. The TensorTouch framework achieves sub-millimeter position accuracy\nand precise force estimation while supporting large sensor deformations crucial\nfor manipulating soft objects. Experimental validation demonstrates 90% success\nin selectively grasping one of two strings based on detected motion, enabling\nnew contact-rich manipulation capabilities previously inaccessible to robotic\nsystems.", "AI": {"tldr": "TensorTouch通过结合有限元分析和深度学习，从光学触觉传感器中提取高分辨率接触信息，解决了多触点操作的挑战。", "motivation": "多触点操作（如从地面捏硬币或操作交织物体）对机器人系统仍具挑战性，需要高分辨率触觉传感。", "method": "TensorTouch框架结合有限元分析和深度学习，提取应力张量、变形场和力分布等接触信息。", "result": "实验验证显示，TensorTouch在选择性抓取任务中达到90%成功率，支持大变形操作。", "conclusion": "TensorTouch为机器人系统提供了新的高精度触觉操作能力。"}}
{"id": "2506.08296", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08296", "abs": "https://arxiv.org/abs/2506.08296", "authors": ["Hongjun Wu", "Heng Zhang", "Pengsong Zhang", "Jin Wang", "Cong Wang"], "title": "HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation", "comment": "31 pages,5 figures", "summary": "Recent advances in multimodal vision-language-action (VLA) models have\nrevolutionized traditional robot learning, enabling systems to interpret\nvision, language, and action in unified frameworks for complex task planning.\nHowever, mastering complex manipulation tasks remains an open challenge,\nconstrained by limitations in persistent contextual memory, multi-agent\ncoordination under uncertainty, and dynamic long-horizon planning across\nvariable sequences. To address this challenge, we propose \\textbf{HiBerNAC}, a\n\\textbf{Hi}erarchical \\textbf{B}rain-\\textbf{e}mulated \\textbf{r}obotic\n\\textbf{N}eural \\textbf{A}gent \\textbf{C}ollective, inspired by breakthroughs\nin neuroscience, particularly in neural circuit mechanisms and hierarchical\ndecision-making. Our framework combines: (1) multimodal VLA planning and\nreasoning with (2) neuro-inspired reflection and multi-agent mechanisms,\nspecifically designed for complex robotic manipulation tasks. By leveraging\nneuro-inspired functional modules with decentralized multi-agent collaboration,\nour approach enables robust and enhanced real-time execution of complex\nmanipulation tasks. In addition, the agentic system exhibits scalable\ncollective intelligence via dynamic agent specialization, adapting its\ncoordination strategy to variable task horizons and complexity. Through\nextensive experiments on complex manipulation tasks compared with\nstate-of-the-art VLA models, we demonstrate that \\textbf{HiBerNAC} reduces\naverage long-horizon task completion time by 23\\%, and achieves non-zero\nsuccess rates (12\\textendash 31\\%) on multi-path tasks where prior\nstate-of-the-art VLA models consistently fail. These results provide indicative\nevidence for bridging biological cognition and robotic learning mechanisms.", "AI": {"tldr": "HiBerNAC是一种基于神经科学启发的分层多智能体框架，通过结合多模态VLA规划和神经启发的反射机制，显著提升了复杂机器人操作任务的执行效率和成功率。", "motivation": "解决复杂机器人操作任务中的持久上下文记忆、多智能体协调和动态长时规划等挑战。", "method": "结合多模态VLA规划和神经启发的多智能体机制，采用分层决策和动态智能体专业化。", "result": "相比现有VLA模型，HiBerNAC将长时任务完成时间减少23%，并在多路径任务中实现12-31%的成功率。", "conclusion": "HiBerNAC为生物认知与机器人学习机制的融合提供了初步证据。"}}
{"id": "2506.08344", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.08344", "abs": "https://arxiv.org/abs/2506.08344", "authors": ["Neşet Ünver Akmandor", "Sarvesh Prajapati", "Mark Zolotas", "Taşkın Padır"], "title": "Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning", "comment": "Accepted to the 2025 IEEE International Conference on Automation\n  Science and Engineering (CASE)", "summary": "Traditional motion planning methods for robots with many degrees-of-freedom,\nsuch as mobile manipulators, are often computationally prohibitive for\nreal-world settings. In this paper, we propose a novel multi-model motion\nplanning pipeline, termed Re4MPC, which computes trajectories using Nonlinear\nModel Predictive Control (NMPC). Re4MPC generates trajectories in a\ncomputationally efficient manner by reactively selecting the model, cost, and\nconstraints of the NMPC problem depending on the complexity of the task and\nrobot state. The policy for this reactive decision-making is learned via a Deep\nReinforcement Learning (DRL) framework. We introduce a mathematical formulation\nto integrate NMPC into this DRL framework. To validate our methodology and\ndesign choices, we evaluate DRL training and test outcomes in a physics-based\nsimulation involving a mobile manipulator. Experimental results demonstrate\nthat Re4MPC is more computationally efficient and achieves higher success rates\nin reaching end-effector goals than the NMPC baseline, which computes\nwhole-body trajectories without our learning mechanism.", "AI": {"tldr": "提出了一种名为Re4MPC的新型多模型运动规划方法，通过结合非线性模型预测控制（NMPC）和深度强化学习（DRL），实现了高效的运动轨迹规划。", "motivation": "传统的高自由度机器人运动规划方法计算成本高，难以应用于实际场景，因此需要一种更高效的方法。", "method": "Re4MPC通过动态选择NMPC的模型、成本和约束条件，结合DRL学习决策策略，实现了高效轨迹规划。", "result": "实验表明，Re4MPC在计算效率和任务成功率上均优于传统NMPC方法。", "conclusion": "Re4MPC为高自由度机器人的运动规划提供了一种高效且可靠的解决方案。"}}
{"id": "2506.08416", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08416", "abs": "https://arxiv.org/abs/2506.08416", "authors": ["Bolin Li", "Linwei Sun", "Xuecong Huang", "Yuzhi Jiang", "Lijun Zhu"], "title": "Periodic Bipedal Gait Learning Using Reward Composition Based on a Novel Gait Planner for Humanoid Robots", "comment": null, "summary": "This paper presents a periodic bipedal gait learning method using reward\ncomposition, integrated with a real-time gait planner for humanoid robots.\nFirst, we introduce a novel gait planner that incorporates dynamics to design\nthe desired joint trajectory. In the gait design process, the 3D robot model is\ndecoupled into two 2D models, which are then approximated as hybrid inverted\npendulums (H-LIP) for trajectory planning. The gait planner operates in\nparallel in real time within the robot's learning environment. Second, based on\nthis gait planner, we design three effective reward functions within a\nreinforcement learning framework, forming a reward composition to achieve\nperiodic bipedal gait. This reward composition reduces the robot's learning\ntime and enhances locomotion performance. Finally, a gait design example and\nperformance comparison are presented to demonstrate the effectiveness of the\nproposed method.", "AI": {"tldr": "提出一种基于奖励组合的周期性双足步态学习方法，结合实时步态规划器，用于人形机器人。", "motivation": "旨在通过奖励组合和实时步态规划，减少机器人学习时间并提升运动性能。", "method": "1. 引入新型步态规划器，将3D模型解耦为两个2D模型并近似为混合倒立摆（H-LIP）进行轨迹规划；2. 在强化学习框架中设计三种奖励函数，形成奖励组合以实现周期性步态。", "result": "通过步态设计示例和性能对比验证了方法的有效性。", "conclusion": "该方法显著减少了学习时间并提升了运动性能，适用于人形机器人的周期性步态学习。"}}
{"id": "2506.08434", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08434", "abs": "https://arxiv.org/abs/2506.08434", "authors": ["Rui Zhao", "Xingjian Zhang", "Yuhong Cao", "Yizhuo Wang", "Guillaume Sartoretti"], "title": "Attention-based Learning for 3D Informative Path Planning", "comment": null, "summary": "In this work, we propose an attention-based deep reinforcement learning\napproach to address the adaptive informative path planning (IPP) problem in 3D\nspace, where an aerial robot equipped with a downward-facing sensor must\ndynamically adjust its 3D position to balance sensing footprint and accuracy,\nand finally obtain a high-quality belief of an underlying field of interest\nover a given domain (e.g., presence of specific plants, hazardous gas,\ngeological structures, etc.). In adaptive IPP tasks, the agent is tasked with\nmaximizing information collected under time/distance constraints, continuously\nadapting its path based on newly acquired sensor data. To this end, we leverage\nattention mechanisms for their strong ability to capture global spatial\ndependencies across large action spaces, allowing the agent to learn an\nimplicit estimation of environmental transitions. Our model builds a contextual\nbelief representation over the entire domain, guiding sequential movement\ndecisions that optimize both short- and long-term search objectives.\nComparative evaluations against state-of-the-art planners demonstrate that our\napproach significantly reduces environmental uncertainty within constrained\nbudgets, thus allowing the agent to effectively balance exploration and\nexploitation. We further show our model generalizes well to environments of\nvarying sizes, highlighting its potential for many real-world applications.", "AI": {"tldr": "提出了一种基于注意力的深度强化学习方法，用于解决3D空间中的自适应信息路径规划问题，通过平衡感知范围和精度，优化信息收集。", "motivation": "解决自适应信息路径规划问题，使空中机器人能够在时间和距离约束下动态调整路径，最大化信息收集。", "method": "利用注意力机制捕捉全局空间依赖关系，构建上下文信念表示，优化短期和长期搜索目标。", "result": "在有限预算下显著降低环境不确定性，平衡探索与利用，并在不同规模环境中表现良好。", "conclusion": "该方法在自适应路径规划中表现优异，具有广泛的实际应用潜力。"}}
{"id": "2506.08440", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08440", "abs": "https://arxiv.org/abs/2506.08440", "authors": ["Zengjue Chen", "Runliang Niu", "He Kong", "Qi Wang"], "title": "TGRPO :Fine-tuning Vision-Language-Action Model via Trajectory-wise Group Relative Policy Optimization", "comment": null, "summary": "Recent advances in Vision-Language-Action (VLA) model have demonstrated\nstrong generalization capabilities across diverse scenes, tasks, and robotic\nplatforms when pretrained at large-scale datasets. However, these models still\nrequire task-specific fine-tuning in novel environments, a process that relies\nalmost exclusively on supervised fine-tuning (SFT) using static trajectory\ndatasets. Such approaches neither allow robot to interact with environment nor\ndo they leverage feedback from live execution. Also, their success is\ncritically dependent on the size and quality of the collected trajectories.\nReinforcement learning (RL) offers a promising alternative by enabling\nclosed-loop interaction and aligning learned policies directly with task\nobjectives. In this work, we draw inspiration from the ideas of GRPO and\npropose the Trajectory-wise Group Relative Policy Optimization (TGRPO) method.\nBy fusing step-level and trajectory-level advantage signals, this method\nimproves GRPO's group-level advantage estimation, thereby making the algorithm\nmore suitable for online reinforcement learning training of VLA. Experimental\nresults on ten manipulation tasks from the libero-object benchmark demonstrate\nthat TGRPO consistently outperforms various baseline methods, capable of\ngenerating more robust and efficient policies across multiple tested scenarios.\nOur source codes are available at: https://github.com/hahans/TGRPO", "AI": {"tldr": "论文提出了一种名为TGRPO的方法，通过结合步级和轨迹级优势信号，改进了GRPO的组级优势估计，适用于VLA模型的在线强化学习训练。", "motivation": "现有的VLA模型在新环境中仍需任务特定的微调，且依赖静态轨迹数据集，无法利用实时交互和反馈。强化学习提供了一种闭环交互的替代方案。", "method": "提出TGRPO方法，融合步级和轨迹级优势信号，改进GRPO的组级优势估计。", "result": "在十个操作任务上的实验表明，TGRPO优于多种基线方法，能生成更稳健和高效的政策。", "conclusion": "TGRPO是一种有效的在线强化学习方法，适用于VLA模型的训练，具有广泛的应用潜力。"}}
{"id": "2506.08459", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.08459", "abs": "https://arxiv.org/abs/2506.08459", "authors": ["Juanran Wang", "Marc R. Schlichting", "Harrison Delecki", "Mykel J. Kochenderfer"], "title": "Diffusion Models for Safety Validation of Autonomous Driving Systems", "comment": null, "summary": "Safety validation of autonomous driving systems is extremely challenging due\nto the high risks and costs of real-world testing as well as the rarity and\ndiversity of potential failures. To address these challenges, we train a\ndenoising diffusion model to generate potential failure cases of an autonomous\nvehicle given any initial traffic state. Experiments on a four-way intersection\nproblem show that in a variety of scenarios, the diffusion model can generate\nrealistic failure samples while capturing a wide variety of potential failures.\nOur model does not require any external training dataset, can perform training\nand inference with modest computing resources, and does not assume any prior\nknowledge of the system under test, with applicability to safety validation for\ntraffic intersections.", "AI": {"tldr": "使用去噪扩散模型生成自动驾驶系统的潜在故障案例，无需外部数据集，适用于交通路口安全验证。", "motivation": "自动驾驶系统的安全验证因高风险、高成本及潜在故障的罕见性和多样性而极具挑战性。", "method": "训练去噪扩散模型，根据初始交通状态生成自动驾驶车辆的潜在故障案例。", "result": "实验表明，该模型能生成多样且真实的故障样本，适用于多种场景。", "conclusion": "该方法无需外部数据集，计算资源需求低，适用于交通路口的安全验证。"}}
{"id": "2506.08578", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08578", "abs": "https://arxiv.org/abs/2506.08578", "authors": ["Boyang Chen", "Xizhe Zang", "Chao Song", "Yue Zhang", "Xuehe Zhang", "Jie Zhao"], "title": "Noise Analysis and Hierarchical Adaptive Body State Estimator For Biped Robot Walking With ESVC Foot", "comment": null, "summary": "The ESVC(Ellipse-based Segmental Varying Curvature) foot, a robot foot design\ninspired by the rollover shape of the human foot, significantly enhances the\nenergy efficiency of the robot walking gait. However, due to the tilt of the\nsupporting leg, the error of the contact model are amplified, making robot\nstate estimation more challenging. Therefore, this paper focuses on the noise\nanalysis and state estimation for robot walking with the ESVC foot. First,\nthrough physical robot experiments, we investigate the effect of the ESVC foot\non robot measurement noise and process noise. and a noise-time regression model\nusing sliding window strategy is developed. Then, a hierarchical adaptive state\nestimator for biped robots with the ESVC foot is proposed. The state estimator\nconsists of two stages: pre-estimation and post-estimation. In the\npre-estimation stage, a data fusion-based estimation is employed to process the\nsensory data. During post-estimation, the acceleration of center of mass is\nfirst estimated, and then the noise covariance matrices are adjusted based on\nthe regression model. Following that, an EKF(Extended Kalman Filter) based\napproach is applied to estimate the centroid state during robot walking.\nPhysical experiments demonstrate that the proposed adaptive state estimator for\nbiped robot walking with the ESVC foot not only provides higher precision than\nboth EKF and Adaptive EKF, but also converges faster under varying noise\nconditions.", "AI": {"tldr": "论文提出了一种针对ESVC脚的机器人状态估计方法，通过噪声分析和分层自适应状态估计器提高了行走效率和精度。", "motivation": "ESVC脚虽然提升了机器人行走的能量效率，但由于支撑腿倾斜导致接触模型误差放大，增加了状态估计的难度。", "method": "通过物理实验分析噪声影响，建立噪声-时间回归模型，并提出分层自适应状态估计器（包括预估计和后估计阶段）。", "result": "提出的状态估计器在精度和收敛速度上优于EKF和自适应EKF。", "conclusion": "分层自适应状态估计器有效解决了ESVC脚机器人行走中的状态估计问题，提升了性能。"}}
{"id": "2506.08639", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.08639", "abs": "https://arxiv.org/abs/2506.08639", "authors": ["Amir Hossein Barjini", "Seyed Adel Alizadeh Kolagar", "Sadeq Yaqubi", "Jouni Mattila"], "title": "Deep Reinforcement Learning-Based Motion Planning and PDE Control for Flexible Manipulators", "comment": null, "summary": "This article presents a motion planning and control framework for flexible\nrobotic manipulators, integrating deep reinforcement learning (DRL) with a\nnonlinear partial differential equation (PDE) controller. Unlike conventional\napproaches that focus solely on control, we demonstrate that the desired\ntrajectory significantly influences endpoint vibrations. To address this, a DRL\nmotion planner, trained using the soft actor-critic (SAC) algorithm, generates\noptimized trajectories that inherently minimize vibrations. The PDE nonlinear\ncontroller then computes the required torques to track the planned trajectory\nwhile ensuring closed-loop stability using Lyapunov analysis. The proposed\nmethodology is validated through both simulations and real-world experiments,\ndemonstrating superior vibration suppression and tracking accuracy compared to\ntraditional methods. The results underscore the potential of combining\nlearning-based motion planning with model-based control for enhancing the\nprecision and stability of flexible robotic manipulators.", "AI": {"tldr": "提出了一种结合深度强化学习（DRL）和非线性偏微分方程（PDE）控制器的柔性机械臂运动规划与控制框架，显著减少振动并提高跟踪精度。", "motivation": "传统方法仅关注控制，而忽略了期望轨迹对端点振动的影响，因此需要一种新的方法来优化轨迹并抑制振动。", "method": "使用软演员-评论家（SAC）算法的DRL运动规划器生成优化轨迹，结合非线性PDE控制器计算扭矩并确保闭环稳定性。", "result": "通过仿真和实验验证，该方法在振动抑制和跟踪精度上优于传统方法。", "conclusion": "结合学习型运动规划与基于模型的控制，可显著提升柔性机械臂的精度和稳定性。"}}
{"id": "2506.08706", "categories": ["cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.08706", "abs": "https://arxiv.org/abs/2506.08706", "authors": ["Tomasz Winiarski", "Jan Kaniuka", "Daniel Giełdowski", "Jakub Ostrysz", "Krystian Radlak", "Dmytro Kushnir"], "title": "ROS-related Robotic Systems Development with V-model-based Application of MeROS Metamodel", "comment": "19 pages", "summary": "As robotic systems grow increasingly complex, heterogeneous, and\nsafety-critical, the need for structured development methodologies becomes\nparamount. Although frameworks like the Robot Operating System (ROS) and\nModel-Based Systems Engineering (MBSE) offer foundational tools, they often\nlack integration when used together. This paper addresses that gap by aligning\nthe widely recognized V-model development paradigm with the MeROS metamodel\nSysML-based modeling language tailored for ROS-based systems.\n  We propose a domain-specific methodology that bridges ROS-centric modelling\nwith systems engineering practices. Our approach formalises the structure,\nbehaviour, and validation processes of robotic systems using MeROS, while\nextending it with a generalized, adaptable V-model compatible with both ROS and\nROS 2. Rather than prescribing a fixed procedure, the approach supports\nproject-specific flexibility and reuse, offering guidance across all stages of\ndevelopment.\n  The approach is validated through a comprehensive case study on HeROS, a\nheterogeneous multi-robot platform comprising manipulators, mobile units, and\ndynamic test environments. This example illustrates how the MeROS-compatible\nV-model enhances traceability and system consistency while remaining accessible\nand extensible for future adaptation. The work contributes a structured,\ntool-agnostic foundation for developers and researchers seeking to apply MBSE\npractices in ROS-based projects.", "AI": {"tldr": "本文提出了一种结合ROS和MBSE的方法，通过MeROS和V模型提升机器人系统开发的规范性和可追溯性。", "motivation": "随着机器人系统复杂性和安全关键性的增加，现有工具如ROS和MBSE缺乏有效整合，亟需一种结构化开发方法。", "method": "提出了一种基于MeROS和V模型的领域特定方法，支持ROS和ROS 2，强调灵活性和可重用性。", "result": "通过HeROS平台的案例验证了方法的有效性，提升了系统一致性和可追溯性。", "conclusion": "该方法为ROS项目提供了结构化、工具无关的MBSE实践基础，具有扩展性和适应性。"}}
{"id": "2506.08708", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.08708", "abs": "https://arxiv.org/abs/2506.08708", "authors": ["Liang Ma", "Jiajun Wen", "Min Lin", "Rongtao Xu", "Xiwen Liang", "Bingqian Lin", "Jun Ma", "Yongxin Wang", "Ziming Wei", "Haokun Lin", "Mingfei Han", "Meng Cao", "Bokui Chen", "Ivan Laptev", "Xiaodan Liang"], "title": "PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly", "comment": null, "summary": "While vision-language models (VLMs) have demonstrated promising capabilities\nin reasoning and planning for embodied agents, their ability to comprehend\nphysical phenomena, particularly within structured 3D environments, remains\nseverely limited. To close this gap, we introduce PhyBlock, a progressive\nbenchmark designed to assess VLMs on physical understanding and planning\nthrough robotic 3D block assembly tasks. PhyBlock integrates a novel four-level\ncognitive hierarchy assembly task alongside targeted Visual Question Answering\n(VQA) samples, collectively aimed at evaluating progressive spatial reasoning\nand fundamental physical comprehension, including object properties, spatial\nrelationships, and holistic scene understanding. PhyBlock includes 2600 block\ntasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three\nkey dimensions: partial completion, failure diagnosis, and planning robustness.\nWe benchmark 21 state-of-the-art VLMs, highlighting their strengths and\nlimitations in physically grounded, multi-step planning. Our empirical findings\nindicate that the performance of VLMs exhibits pronounced limitations in\nhigh-level planning and reasoning capabilities, leading to a notable decline in\nperformance for the growing complexity of the tasks. Error analysis reveals\npersistent difficulties in spatial orientation and dependency reasoning.\nSurprisingly, chain-of-thought prompting offers minimal improvements,\nsuggesting spatial tasks heavily rely on intuitive model comprehension. We\nposition PhyBlock as a unified testbed to advance embodied reasoning, bridging\nvision-language understanding and real-world physical problem-solving.", "AI": {"tldr": "PhyBlock是一个评估视觉语言模型（VLMs）在物理理解和规划能力的基准测试，通过3D积木组装任务和视觉问答（VQA）任务，揭示了VLMs在高级规划和空间推理上的局限性。", "motivation": "现有VLMs在理解物理现象和结构化3D环境中的能力有限，需要一种评估工具来推动其发展。", "method": "提出PhyBlock基准，包含2600个任务（400个组装任务和2200个VQA任务），评估模型在部分完成、故障诊断和规划鲁棒性三个维度上的表现。", "result": "测试21个先进VLMs，发现其在高级规划和空间推理上表现显著不足，任务复杂度增加时性能下降明显。", "conclusion": "PhyBlock为提升VLMs在物理问题解决和空间推理能力提供了统一测试平台。"}}
{"id": "2506.08756", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.08756", "abs": "https://arxiv.org/abs/2506.08756", "authors": ["Octavio Arriaga", "Rebecca Adam", "Melvin Laux", "Lisa Gutzeit", "Marco Ragni", "Jan Peters", "Frank Kirchner"], "title": "Bayesian Inverse Physics for Neuro-Symbolic Robot Learning", "comment": null, "summary": "Real-world robotic applications, from autonomous exploration to assistive\ntechnologies, require adaptive, interpretable, and data-efficient learning\nparadigms. While deep learning architectures and foundation models have driven\nsignificant advances in diverse robotic applications, they remain limited in\ntheir ability to operate efficiently and reliably in unknown and dynamic\nenvironments. In this position paper, we critically assess these limitations\nand introduce a conceptual framework for combining data-driven learning with\ndeliberate, structured reasoning. Specifically, we propose leveraging\ndifferentiable physics for efficient world modeling, Bayesian inference for\nuncertainty-aware decision-making, and meta-learning for rapid adaptation to\nnew tasks. By embedding physical symbolic reasoning within neural models,\nrobots could generalize beyond their training data, reason about novel\nsituations, and continuously expand their knowledge. We argue that such hybrid\nneuro-symbolic architectures are essential for the next generation of\nautonomous systems, and to this end, we provide a research roadmap to guide and\naccelerate their development.", "AI": {"tldr": "论文提出了一种结合数据驱动学习与结构化推理的混合神经符号架构，以解决机器人在未知动态环境中高效可靠运行的挑战。", "motivation": "现实机器人应用需要自适应、可解释且数据高效的学习方法，但现有深度学习模型在未知动态环境中表现不足。", "method": "提出利用可微分物理建模、贝叶斯推理和元学习，将物理符号推理嵌入神经模型。", "result": "这种混合架构有望使机器人泛化训练数据之外、推理新情境并持续扩展知识。", "conclusion": "混合神经符号架构是下一代自主系统的关键，并提供了研究路线图以加速其发展。"}}
{"id": "2506.08795", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.08795", "abs": "https://arxiv.org/abs/2506.08795", "authors": ["Kaijie Shi", "Wanglong Lu", "Hanli Zhao", "Vinicius Prado da Fonseca", "Ting Zou", "Xianta Jiang"], "title": "Towards Biosignals-Free Autonomous Prosthetic Hand Control via Imitation Learning", "comment": null, "summary": "Limb loss affects millions globally, impairing physical function and reducing\nquality of life. Most traditional surface electromyographic (sEMG) and\nsemi-autonomous methods require users to generate myoelectric signals for each\ncontrol, imposing physically and mentally taxing demands. This study aims to\ndevelop a fully autonomous control system that enables a prosthetic hand to\nautomatically grasp and release objects of various shapes using only a camera\nattached to the wrist. By placing the hand near an object, the system will\nautomatically execute grasping actions with a proper grip force in response to\nthe hand's movements and the environment. To release the object being grasped,\njust naturally place the object close to the table and the system will\nautomatically open the hand. Such a system would provide individuals with limb\nloss with a very easy-to-use prosthetic control interface and greatly reduce\nmental effort while using. To achieve this goal, we developed a teleoperation\nsystem to collect human demonstration data for training the prosthetic hand\ncontrol model using imitation learning, which mimics the prosthetic hand\nactions from human. Through training the model using only a few objects' data\nfrom one single participant, we have shown that the imitation learning\nalgorithm can achieve high success rates, generalizing to more individuals and\nunseen objects with a variation of weights. The demonstrations are available at\n\\href{https://sites.google.com/view/autonomous-prosthetic-hand}{https://sites.google.com/view/autonomous-prosthetic-hand}", "AI": {"tldr": "开发了一种基于摄像头和模仿学习的全自主假手控制系统，无需用户生成肌电信号，自动抓取和释放物体。", "motivation": "传统肌电信号方法对用户身体和心理负担大，需简化假手控制，提高生活质量。", "method": "通过摄像头和模仿学习训练模型，利用人类示范数据实现自主控制。", "result": "模型仅需少量数据即可高成功率运行，并能泛化到不同用户和未见物体。", "conclusion": "该系统显著降低了使用假手的心理负担，提供了一种易用的控制接口。"}}
{"id": "2506.08822", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.08822", "abs": "https://arxiv.org/abs/2506.08822", "authors": ["Yifei Su", "Ning Liu", "Dong Chen", "Zhen Zhao", "Kun Wu", "Meng Li", "Zhiyuan Xu", "Zhengping Che", "Jian Tang"], "title": "FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency", "comment": null, "summary": "Generative modeling-based visuomotor policies have been widely adopted in\nrobotic manipulation attributed to their ability to model multimodal action\ndistributions. However, the high inference cost of multi-step sampling limits\ntheir applicability in real-time robotic systems. To address this issue,\nexisting approaches accelerate the sampling process in generative\nmodeling-based visuomotor policies by adapting acceleration techniques\noriginally developed for image generation. Despite this progress, a major\ndistinction remains: image generation typically involves producing independent\nsamples without temporal dependencies, whereas robotic manipulation involves\ngenerating time-series action trajectories that require continuity and temporal\ncoherence. To effectively exploit temporal information in robotic manipulation,\nwe propose FreqPolicy, a novel approach that first imposes frequency\nconsistency constraints on flow-based visuomotor policies. Our work enables the\naction model to capture temporal structure effectively while supporting\nefficient, high-quality one-step action generation. We introduce a frequency\nconsistency constraint that enforces alignment of frequency-domain action\nfeatures across different timesteps along the flow, thereby promoting\nconvergence of one-step action generation toward the target distribution. In\naddition, we design an adaptive consistency loss to capture structural temporal\nvariations inherent in robotic manipulation tasks. We assess FreqPolicy on 53\ntasks across 3 simulation benchmarks, proving its superiority over existing\none-step action generators. We further integrate FreqPolicy into the\nvision-language-action (VLA) model and achieve acceleration without performance\ndegradation on the 40 tasks of Libero. Besides, we show efficiency and\neffectiveness in real-world robotic scenarios with an inference frequency\n93.5Hz. The code will be publicly available.", "AI": {"tldr": "FreqPolicy通过频率一致性约束提升基于生成模型的视觉运动策略的效率，支持高质量的一步动作生成，并在仿真和实际机器人任务中表现优异。", "motivation": "生成模型在机器人操作中因能建模多模态动作分布而被广泛采用，但其多步采样的高推理成本限制了实时应用。现有方法虽加速采样，但忽略了动作轨迹的时间依赖性。", "method": "提出FreqPolicy，通过频率一致性约束和自适应一致性损失，有效捕捉时间结构，实现高效高质量的一步动作生成。", "result": "在3个仿真基准的53个任务中表现优异，集成到VLA模型后在40个任务中实现加速且无性能损失，实际机器人任务中推理频率达93.5Hz。", "conclusion": "FreqPolicy通过频率一致性约束显著提升生成模型在实时机器人系统中的适用性，兼具高效性和有效性。"}}
{"id": "2506.08840", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08840", "abs": "https://arxiv.org/abs/2506.08840", "authors": ["Dewei Wang", "Xinmiao Wang", "Xinzhe Liu", "Jiyuan Shi", "Yingnan Zhao", "Chenjia Bai", "Xuelong Li"], "title": "MoRE: Mixture of Residual Experts for Humanoid Lifelike Gaits Learning on Complex Terrains", "comment": "9 pages, 5 figures", "summary": "Humanoid robots have demonstrated robust locomotion capabilities using\nReinforcement Learning (RL)-based approaches. Further, to obtain human-like\nbehaviors, existing methods integrate human motion-tracking or motion prior in\nthe RL framework. However, these methods are limited in flat terrains with\nproprioception only, restricting their abilities to traverse challenging\nterrains with human-like gaits. In this work, we propose a novel framework\nusing a mixture of latent residual experts with multi-discriminators to train\nan RL policy, which is capable of traversing complex terrains in controllable\nlifelike gaits with exteroception. Our two-stage training pipeline first\nteaches the policy to traverse complex terrains using a depth camera, and then\nenables gait-commanded switching between human-like gait patterns. We also\ndesign gait rewards to adjust human-like behaviors like robot base height.\nSimulation and real-world experiments demonstrate that our framework exhibits\nexceptional performance in traversing complex terrains, and achieves seamless\ntransitions between multiple human-like gait patterns.", "AI": {"tldr": "提出了一种基于混合潜在残差专家和多判别器的RL框架，用于训练能够在复杂地形中以可控、逼真步态行走的人形机器人。", "motivation": "现有方法仅适用于平坦地形且依赖本体感知，无法在复杂地形中实现逼真步态。", "method": "采用两阶段训练流程，先通过深度相机训练策略适应复杂地形，再实现步态切换；设计了步态奖励以调整行为。", "result": "仿真和实际实验表明，该框架在复杂地形中表现优异，并能无缝切换多种步态。", "conclusion": "该框架显著提升了人形机器人在复杂地形中的行走能力和步态逼真度。"}}
{"id": "2506.08851", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08851", "abs": "https://arxiv.org/abs/2506.08851", "authors": ["Sepehr Samavi", "Garvish Bhutani", "Florian Shkurti", "Angela P. Schoellig"], "title": "Deploying SICNav in the Field: Safe and Interactive Crowd Navigation using MPC and Bilevel Optimization", "comment": "Presented at the 2025 IEEE ICRA Workshop on Field Robotics\n  (non-archival)", "summary": "Safe and efficient navigation in crowded environments remains a critical\nchallenge for robots that provide a variety of service tasks such as food\ndelivery or autonomous wheelchair mobility. Classical robot crowd navigation\nmethods decouple human motion prediction from robot motion planning, which\nneglects the closed-loop interactions between humans and robots. This lack of a\nmodel for human reactions to the robot plan (e.g. moving out of the way) can\ncause the robot to get stuck. Our proposed Safe and Interactive Crowd\nNavigation (SICNav) method is a bilevel Model Predictive Control (MPC)\nframework that combines prediction and planning into one optimization problem,\nexplicitly modeling interactions among agents. In this paper, we present a\nsystems overview of the crowd navigation platform we use to deploy SICNav in\npreviously unseen indoor and outdoor environments. We provide a preliminary\nanalysis of the system's operation over the course of nearly 7 km of autonomous\nnavigation over two hours in both indoor and outdoor environments.", "AI": {"tldr": "SICNav是一种双层MPC框架，将预测和规划结合为一个优化问题，显式建模人机交互，解决了传统方法因忽略闭环交互而导致的机器人卡顿问题。", "motivation": "在拥挤环境中安全高效导航是机器人服务任务（如送餐或自主轮椅移动）的关键挑战，传统方法因忽略人机闭环交互而存在缺陷。", "method": "提出SICNav方法，通过双层MPC框架将预测与规划结合为一个优化问题，显式建模人机交互。", "result": "在室内外环境中进行了近7公里、两小时的自主导航测试，系统运行良好。", "conclusion": "SICNav通过显式建模交互，有效解决了传统方法在拥挤环境中的导航问题。"}}
{"id": "2506.08856", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08856", "abs": "https://arxiv.org/abs/2506.08856", "authors": ["Jonathan P. King", "Harnoor Ahluwalia", "Michael Zhang", "Nancy S. Pollard"], "title": "Fast Estimation of Globally Optimal Independent Contact Regions for Robust Grasping and Manipulation", "comment": "Submitted to IEEE Conference on Humanoid Robots", "summary": "This work presents a fast anytime algorithm for computing globally optimal\nindependent contact regions (ICRs). ICRs are regions such that one contact\nwithin each region enables a valid grasp. Locations of ICRs can provide\nguidance for grasp and manipulation planning, learning, and policy transfer.\nHowever, ICRs for modern applications have been little explored, in part due to\nthe expense of computing them, as they have a search space exponential in the\nnumber of contacts. We present a divide and conquer algorithm based on\nincremental n-dimensional Delaunay triangulation that produces results with\nbounded suboptimality in times sufficient for real-time planning. This paper\npresents the base algorithm for grasps where contacts lie within a plane. Our\nexperiments show substantial benefits over competing grasp quality metrics and\nspeedups of 100X and more for competing approaches to computing ICRs. We\nexplore robustness of a policy guided by ICRs and outline a path to general 3D\nimplementation. Code will be released on publication to facilitate further\ndevelopment and applications.", "AI": {"tldr": "提出了一种快速算法，用于计算全局最优的独立接触区域（ICRs），该算法基于增量n维Delaunay三角剖分，适用于实时规划。", "motivation": "ICRs的位置可以为抓取和操作规划、学习及策略迁移提供指导，但现有方法计算成本高，限制了其应用。", "method": "采用分治法，基于增量n维Delaunay三角剖分，计算具有有界次优性的ICRs。", "result": "实验显示，该方法在速度和性能上显著优于现有方法，速度提升达100倍以上。", "conclusion": "该方法为实时规划提供了高效工具，并为进一步扩展到3D实现奠定了基础。"}}
{"id": "2506.08868", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08868", "abs": "https://arxiv.org/abs/2506.08868", "authors": ["Marco Ruggia"], "title": "MOMAV: A highly symmetrical fully-actuated multirotor drone using optimizing control allocation", "comment": "12 pages, 12 figures, preprint", "summary": "MOMAV (Marco's Omnidirectional Micro Aerial Vehicle) is a multirotor drone\nthat is fully actuated, meaning it can control its orientation independently of\nits position. MOMAV is also highly symmetrical, making its flight efficiency\nlargely unaffected by its current orientation. These characteristics are\nachieved by a novel drone design where six rotor arms align with the vertices\nof an octahedron, and where each arm can actively rotate along its long axis.\nVarious standout features of MOMAV are presented: The high flight efficiency\ncompared to arm configuration of other fully-actuated drones, the design of an\noriginal rotating arm assembly featuring slip-rings used to enable continuous\narm rotation, and a novel control allocation algorithm based on sequential\nquadratic programming (SQP) used to calculate throttle and arm-angle setpoints\nin flight. Flight tests have shown that MOMAV is able to achieve remarkably low\nmean position/orientation errors of 6.6mm, 2.1{\\deg} ({\\sigma}: 3.0mm,\n1.0{\\deg}) when sweeping position setpoints, and 11.8mm, 3.3{\\deg} ({\\sigma}:\n8.6mm, 2.0{\\deg}) when sweeping orientation setpoints.", "AI": {"tldr": "MOMAV是一种全驱动、高度对称的多旋翼无人机，通过独特的八面体转子臂设计和主动旋转臂实现高效飞行，采用SQP控制算法，飞行测试显示其位置和姿态误差极低。", "motivation": "设计一种能够独立控制位置和方向的高效全驱动无人机，解决传统无人机在飞行效率和控制灵活性上的限制。", "method": "采用八面体排列的六转子臂设计，每个臂可主动旋转，配备滑环实现连续旋转，并使用基于SQP的控制分配算法计算油门和臂角设定点。", "result": "飞行测试显示，MOMAV在位置和姿态控制上表现出色，位置误差平均6.6mm，姿态误差平均2.1度，标准差分别为3.0mm和1.0度。", "conclusion": "MOMAV通过创新的设计和控制算法，实现了高效且精确的全驱动飞行，为无人机技术提供了新的可能性。"}}
{"id": "2506.08890", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.08890", "abs": "https://arxiv.org/abs/2506.08890", "authors": ["Tauhid Tanjim", "Promise Ekpo", "Huajie Cao", "Jonathan St. George", "Kevin Ching", "Hee Rin Lee", "Angelique Taylor"], "title": "Human-Robot Teaming Field Deployments: A Comparison Between Verbal and Non-verbal Communication", "comment": "This is the author's original submitted version of the paper accepted\n  to the 2025 IEEE International Conference on Robot and Human Interactive\n  Communication (RO-MAN). \\c{opyright} 2025 IEEE. Personal use of this material\n  is permitted. For any other use, please contact IEEE", "summary": "Healthcare workers (HCWs) encounter challenges in hospitals, such as\nretrieving medical supplies quickly from crash carts, which could potentially\nresult in medical errors and delays in patient care. Robotic crash carts (RCCs)\nhave shown promise in assisting healthcare teams during medical tasks through\nguided object searches and task reminders. Limited exploration has been done to\ndetermine what communication modalities are most effective and least disruptive\nto patient care in real-world settings. To address this gap, we conducted a\nbetween-subjects experiment comparing the RCC's verbal and non-verbal\ncommunication of object search with a standard crash cart in resuscitation\nscenarios to understand the impact of robot communication on workload and\nattitudes toward using robots in the workplace. Our findings indicate that\nverbal communication significantly reduced mental demand and effort compared to\nvisual cues and with a traditional crash cart. Although frustration levels were\nslightly higher during collaborations with the robot compared to a traditional\ncart, these research insights provide valuable implications for human-robot\nteamwork in high-stakes environments.", "AI": {"tldr": "研究比较了机器人急救车（RCC）的语音与非语音通信方式对医护人员工作负荷和态度的影响，发现语音通信显著降低心理需求和努力。", "motivation": "医护人员在急救中快速获取医疗用品面临挑战，机器人急救车可能提供帮助，但通信方式的有效性尚未充分研究。", "method": "通过对比实验，比较RCC的语音与非语音通信方式与传统急救车在复苏场景中的表现。", "result": "语音通信显著降低心理需求和努力，尽管与机器人合作时挫折感略有增加。", "conclusion": "研究结果为高风险环境中人机协作提供了重要启示。"}}
{"id": "2506.08931", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08931", "abs": "https://arxiv.org/abs/2506.08931", "authors": ["Yixuan Li", "Yutang Lin", "Jieming Cui", "Tengyu Liu", "Wei Liang", "Yixin Zhu", "Siyuan Huang"], "title": "CLONE: Closed-Loop Whole-Body Humanoid Teleoperation for Long-Horizon Tasks", "comment": "18 pages, 13 figures", "summary": "Humanoid teleoperation plays a vital role in demonstrating and collecting\ndata for complex humanoid-scene interactions. However, current teleoperation\nsystems face critical limitations: they decouple upper- and lower-body control\nto maintain stability, restricting natural coordination, and operate open-loop\nwithout real-time position feedback, leading to accumulated drift. The\nfundamental challenge is achieving precise, coordinated whole-body\nteleoperation over extended durations while maintaining accurate global\npositioning. Here we show that an MoE-based teleoperation system, CLONE, with\nclosed-loop error correction enables unprecedented whole-body teleoperation\nfidelity, maintaining minimal positional drift over long-range trajectories\nusing only head and hand tracking from an MR headset. Unlike previous methods\nthat either sacrifice coordination for stability or suffer from unbounded\ndrift, CLONE learns diverse motion skills while preventing tracking error\naccumulation through real-time feedback, enabling complex coordinated movements\nsuch as ``picking up objects from the ground.'' These results establish a new\nmilestone for whole-body humanoid teleoperation for long-horizon humanoid-scene\ninteraction tasks.", "AI": {"tldr": "CLONE是一种基于MoE的远程操作系统，通过闭环误差校正实现高保真全身远程操作，解决了现有系统在协调性和漂移问题上的限制。", "motivation": "当前远程操作系统存在上下半身控制分离和开环操作导致的漂移问题，限制了自然协调和长时间精确操作。", "method": "采用MoE框架和闭环误差校正技术，仅需MR头显的手部和头部跟踪数据，实现长时间低漂移的全身远程操作。", "result": "CLONE系统在长距离轨迹上保持最小位置漂移，支持复杂协调动作（如从地面拾取物体），显著提升了操作保真度。", "conclusion": "CLONE为长时间全身人形远程操作设立了新标杆，适用于复杂人形-场景交互任务。"}}
{"id": "2506.08039", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08039", "abs": "https://arxiv.org/abs/2506.08039", "authors": ["Ray Wai Man Kong"], "title": "AI Magnetic Levitation (Maglev) Conveyor for Automated Assembly Production", "comment": "12 pages, 9 Figures", "summary": "Efficiency, speed, and precision are essential in modern manufacturing. AI\nMaglev Conveyor system, combining magnetic levitation (maglev) technology with\nartificial intelligence (AI), revolutionizes automated production processes.\nThis system reduces maintenance costs and downtime by eliminating friction,\nenhancing operational efficiency. It transports goods swiftly with minimal\nenergy consumption, optimizing resource use and supporting sustainability. AI\nintegration enables real-time monitoring and adaptive control, allowing\nbusinesses to respond to production demand fluctuations and streamline supply\nchain operations.\n  The AI Maglev Conveyor offers smooth, silent operation, accommodating diverse\nproduct types and sizes for flexible manufacturing without extensive\nreconfiguration. AI algorithms optimize routing, reduce cycle times, and\nimprove throughput, creating an agile production line adaptable to market\nchanges.\n  This applied research paper introduces the Maglev Conveyor system, featuring\nan electromagnetic controller and multiple movers to enhance automation. It\noffers cost savings as an alternative to setups using six-axis robots or linear\nmotors, with precise adjustments for robotic arm loading. Operating at high\nspeeds minimizes treatment time for delicate components while maintaining\nprecision. Its adaptable design accommodates various materials, facilitating\nintegration of processing stations alongside electronic product assembly.\nPositioned between linear-axis and robotic systems in cost, the Maglev Conveyor\nis ideal for flat parts requiring minimal travel, transforming production\nefficiency across industries. It explores its technical advantages,\nflexibility, cost reductions, and overall benefits.", "AI": {"tldr": "AI Maglev Conveyor系统结合磁悬浮技术和人工智能，提升现代制造业的效率、速度和精度，减少维护成本，优化资源使用。", "motivation": "现代制造业对效率、速度和精度的需求日益增长，传统系统存在摩擦和维护成本高的问题。", "method": "结合磁悬浮技术和AI，实现无摩擦运输、实时监控和自适应控制，优化路由和吞吐量。", "result": "系统运行平稳、静音，适应多样化产品，减少周期时间，提高生产效率，降低成本。", "conclusion": "AI Maglev Conveyor系统为制造业提供了高效、灵活且经济的解决方案，适用于多种行业。"}}
{"id": "2506.08045", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.08045", "abs": "https://arxiv.org/abs/2506.08045", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "title": "UAVs Meet Agentic AI: A Multidomain Survey of Autonomous Aerial Intelligence and Agentic UAVs", "comment": "40 pages, 6 Figures", "summary": "Agentic UAVs represent a new frontier in autonomous aerial intelligence,\nintegrating perception, decision-making, memory, and collaborative planning to\noperate adaptively in complex, real-world environments. Driven by recent\nadvances in Agentic AI, these systems surpass traditional UAVs by exhibiting\ngoal-driven behavior, contextual reasoning, and interactive autonomy. We\nprovide a comprehensive foundation for understanding the architectural\ncomponents and enabling technologies that distinguish Agentic UAVs from\ntraditional autonomous UAVs. Furthermore, a detailed comparative analysis\nhighlights advancements in autonomy with AI agents, learning, and mission\nflexibility. This study explores seven high-impact application domains\nprecision agriculture, construction & mining, disaster response, environmental\nmonitoring, infrastructure inspection, logistics, security, and wildlife\nconservation, illustrating the broad societal value of agentic aerial\nintelligence. Furthermore, we identify key challenges in technical constraints,\nregulatory limitations, and data-model reliability, and we present emerging\nsolutions across hardware innovation, learning architectures, and human-AI\ninteraction. Finally, a future roadmap is proposed, outlining pathways toward\nself-evolving aerial ecosystems, system-level collaboration, and sustainable,\nequitable deployments. This survey establishes a foundational framework for the\nfuture development, deployment, and governance of agentic aerial systems\n(Agentic UAVs) across diverse societal and industrial domains.", "AI": {"tldr": "Agentic UAVs integrate advanced AI for autonomous operation in complex environments, surpassing traditional UAVs with goal-driven behavior and contextual reasoning. The paper covers their architecture, applications, challenges, and future directions.", "motivation": "To provide a comprehensive understanding of Agentic UAVs, highlighting their advancements over traditional UAVs and their potential societal impact.", "method": "A detailed comparative analysis of architectural components, enabling technologies, and application domains, along with challenges and emerging solutions.", "result": "Identifies seven high-impact application domains and key challenges, proposing solutions and a future roadmap for Agentic UAVs.", "conclusion": "The study establishes a framework for the future development and governance of Agentic UAVs, emphasizing their broad societal value."}}
{"id": "2506.08061", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.08061", "abs": "https://arxiv.org/abs/2506.08061", "authors": ["Ali Abedi", "Fernando Cladera", "Mohsen Farajijalal", "Reza Ehsani"], "title": "Adaptive Per-Tree Canopy Volume Estimation Using Mobile LiDAR in Structured and Unstructured Orchards", "comment": "5 pages, 3 figures, Accepted to the Novel Approaches for Precision\n  Agriculture and Forestry with Autonomous Robots IEEE ICRA Workshop - 2025", "summary": "We present a real-time system for per-tree canopy volume estimation using\nmobile LiDAR data collected during routine robotic navigation. Unlike prior\napproaches that rely on static scans or assume uniform orchard structures, our\nmethod adapts to varying field geometries via an integrated pipeline of\nLiDAR-inertial odometry, adaptive segmentation, and geometric reconstruction.\nWe evaluate the system across two commercial orchards, one pistachio orchard\nwith regular spacing and one almond orchard with dense, overlapping crowns. A\nhybrid clustering strategy combining DBSCAN and spectral clustering enables\nrobust per-tree segmentation, achieving 93% success in pistachio and 80% in\nalmond, with strong agreement to drone derived canopy volume estimates. This\nwork advances scalable, non-intrusive tree monitoring for structurally diverse\norchard environments.", "AI": {"tldr": "提出了一种基于移动LiDAR数据的实时系统，用于估计单棵树冠体积，适用于结构多样的果园环境。", "motivation": "现有方法依赖静态扫描或假设果园结构均匀，无法适应多样化的田间几何形状。", "method": "结合LiDAR-惯性里程计、自适应分割和几何重建的集成流程，采用DBSCAN和谱聚类的混合聚类策略。", "result": "在两种商业果园中测试，成功率为93%（开心果）和80%（杏仁），与无人机估计结果一致。", "conclusion": "该系统为结构多样的果园环境提供了可扩展、非侵入式的树木监测方案。"}}
{"id": "2506.08149", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.08149", "abs": "https://arxiv.org/abs/2506.08149", "authors": ["Hang Wang", "Dechen Gao", "Junshan Zhang"], "title": "Ego-centric Learning of Communicative World Models for Autonomous Driving", "comment": null, "summary": "We study multi-agent reinforcement learning (MARL) for tasks in complex\nhigh-dimensional environments, such as autonomous driving. MARL is known to\nsuffer from the \\textit{partial observability} and \\textit{non-stationarity}\nissues. To tackle these challenges, information sharing is often employed,\nwhich however faces major hurdles in practice, including overwhelming\ncommunication overhead and scalability concerns. By making use of generative AI\nembodied in world model together with its latent representation, we develop\n{\\it CALL}, \\underline{C}ommunic\\underline{a}tive Wor\\underline{l}d\nMode\\underline{l}, for MARL, where 1) each agent first learns its world model\nthat encodes its state and intention into low-dimensional latent representation\nwith smaller memory footprint, which can be shared with other agents of\ninterest via lightweight communication; and 2) each agent carries out\nego-centric learning while exploiting lightweight information sharing to enrich\nher world model, and then exploits its generalization capacity to improve\nprediction for better planning. We characterize the gain on the prediction\naccuracy from the information sharing and its impact on performance gap.\nExtensive experiments are carried out on the challenging local trajectory\nplanning tasks in the CARLA platform to demonstrate the performance gains of\nusing \\textit{CALL}.", "AI": {"tldr": "论文提出了一种名为CALL的多智能体强化学习方法，通过生成式AI和世界模型的潜在表示，解决了部分可观测性和非平稳性问题，同时减少了通信开销。", "motivation": "多智能体强化学习（MARL）在复杂高维环境中（如自动驾驶）面临部分可观测性和非平稳性问题，传统信息共享方法存在通信开销大和可扩展性问题。", "method": "CALL方法利用世界模型的潜在表示，将状态和意图编码为低维表示，通过轻量级通信共享信息，并结合自我中心学习提升预测和规划能力。", "result": "实验在CARLA平台上进行，证明了CALL在局部轨迹规划任务中的性能提升，并分析了信息共享对预测准确性和性能差距的影响。", "conclusion": "CALL通过轻量级信息共享和潜在表示学习，有效解决了MARL中的挑战，并在复杂任务中表现出优越性能。"}}
{"id": "2506.08291", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08291", "abs": "https://arxiv.org/abs/2506.08291", "authors": ["Won Kyung Do", "Matthew Strong", "Aiden Swann", "Boshu Lei", "Monroe Kennedy III"], "title": "TensorTouch: Calibration of Tactile Sensors for High Resolution Stress Tensor and Deformation for Dexterous Manipulation", "comment": null, "summary": "Advanced dexterous manipulation involving multiple simultaneous contacts\nacross different surfaces, like pinching coins from ground or manipulating\nintertwined objects, remains challenging for robotic systems. Such tasks exceed\nthe capabilities of vision and proprioception alone, requiring high-resolution\ntactile sensing with calibrated physical metrics. Raw optical tactile sensor\nimages, while information-rich, lack interpretability and cross-sensor\ntransferability, limiting their real-world utility. TensorTouch addresses this\nchallenge by integrating finite element analysis with deep learning to extract\ncomprehensive contact information from optical tactile sensors, including\nstress tensors, deformation fields, and force distributions at pixel-level\nresolution. The TensorTouch framework achieves sub-millimeter position accuracy\nand precise force estimation while supporting large sensor deformations crucial\nfor manipulating soft objects. Experimental validation demonstrates 90% success\nin selectively grasping one of two strings based on detected motion, enabling\nnew contact-rich manipulation capabilities previously inaccessible to robotic\nsystems.", "AI": {"tldr": "TensorTouch通过结合有限元分析和深度学习，从光学触觉传感器中提取全面的接触信息，解决了多触点操作的挑战。", "motivation": "高级灵巧操作（如从地面捏硬币或操作交织物体）需要高分辨率触觉感知，但现有光学触觉传感器的原始图像缺乏可解释性和跨传感器可转移性。", "method": "TensorTouch框架整合有限元分析和深度学习，提取应力张量、变形场和力分布等接触信息。", "result": "实验验证显示，TensorTouch在选择性抓取两根绳子中的一根时达到90%的成功率，并支持大变形操作。", "conclusion": "TensorTouch为机器人系统提供了以前无法实现的丰富接触操作能力。"}}
{"id": "2506.08296", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08296", "abs": "https://arxiv.org/abs/2506.08296", "authors": ["Hongjun Wu", "Heng Zhang", "Pengsong Zhang", "Jin Wang", "Cong Wang"], "title": "HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation", "comment": "31 pages,5 figures", "summary": "Recent advances in multimodal vision-language-action (VLA) models have\nrevolutionized traditional robot learning, enabling systems to interpret\nvision, language, and action in unified frameworks for complex task planning.\nHowever, mastering complex manipulation tasks remains an open challenge,\nconstrained by limitations in persistent contextual memory, multi-agent\ncoordination under uncertainty, and dynamic long-horizon planning across\nvariable sequences. To address this challenge, we propose \\textbf{HiBerNAC}, a\n\\textbf{Hi}erarchical \\textbf{B}rain-\\textbf{e}mulated \\textbf{r}obotic\n\\textbf{N}eural \\textbf{A}gent \\textbf{C}ollective, inspired by breakthroughs\nin neuroscience, particularly in neural circuit mechanisms and hierarchical\ndecision-making. Our framework combines: (1) multimodal VLA planning and\nreasoning with (2) neuro-inspired reflection and multi-agent mechanisms,\nspecifically designed for complex robotic manipulation tasks. By leveraging\nneuro-inspired functional modules with decentralized multi-agent collaboration,\nour approach enables robust and enhanced real-time execution of complex\nmanipulation tasks. In addition, the agentic system exhibits scalable\ncollective intelligence via dynamic agent specialization, adapting its\ncoordination strategy to variable task horizons and complexity. Through\nextensive experiments on complex manipulation tasks compared with\nstate-of-the-art VLA models, we demonstrate that \\textbf{HiBerNAC} reduces\naverage long-horizon task completion time by 23\\%, and achieves non-zero\nsuccess rates (12\\textendash 31\\%) on multi-path tasks where prior\nstate-of-the-art VLA models consistently fail. These results provide indicative\nevidence for bridging biological cognition and robotic learning mechanisms.", "AI": {"tldr": "HiBerNAC是一种分层脑模拟机器人神经代理集体，结合多模态VLA规划和神经启发的反射机制，显著提升了复杂机器人操作任务的性能。", "motivation": "当前多模态VLA模型在复杂操作任务中存在局限性，如持久上下文记忆不足、多代理协调困难等，HiBerNAC旨在解决这些问题。", "method": "结合多模态VLA规划和神经启发的反射机制，采用分散式多代理协作，实现动态任务规划和实时执行。", "result": "相比现有VLA模型，HiBerNAC将长时任务完成时间减少23%，并在多路径任务中实现12-31%的成功率。", "conclusion": "HiBerNAC通过神经启发机制和多代理协作，为复杂机器人操作任务提供了高效解决方案，并展示了生物认知与机器人学习的潜在联系。"}}
{"id": "2506.08344", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.08344", "abs": "https://arxiv.org/abs/2506.08344", "authors": ["Neşet Ünver Akmandor", "Sarvesh Prajapati", "Mark Zolotas", "Taşkın Padır"], "title": "Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning", "comment": "Accepted to the 2025 IEEE International Conference on Automation\n  Science and Engineering (CASE)", "summary": "Traditional motion planning methods for robots with many degrees-of-freedom,\nsuch as mobile manipulators, are often computationally prohibitive for\nreal-world settings. In this paper, we propose a novel multi-model motion\nplanning pipeline, termed Re4MPC, which computes trajectories using Nonlinear\nModel Predictive Control (NMPC). Re4MPC generates trajectories in a\ncomputationally efficient manner by reactively selecting the model, cost, and\nconstraints of the NMPC problem depending on the complexity of the task and\nrobot state. The policy for this reactive decision-making is learned via a Deep\nReinforcement Learning (DRL) framework. We introduce a mathematical formulation\nto integrate NMPC into this DRL framework. To validate our methodology and\ndesign choices, we evaluate DRL training and test outcomes in a physics-based\nsimulation involving a mobile manipulator. Experimental results demonstrate\nthat Re4MPC is more computationally efficient and achieves higher success rates\nin reaching end-effector goals than the NMPC baseline, which computes\nwhole-body trajectories without our learning mechanism.", "AI": {"tldr": "提出了一种名为Re4MPC的多模型运动规划方法，结合非线性模型预测控制（NMPC）和深度强化学习（DRL），显著提高了计算效率和任务成功率。", "motivation": "传统的高自由度机器人运动规划方法计算成本高，难以适用于实际场景。", "method": "通过DRL框架学习反应性决策策略，动态选择NMPC的模型、成本和约束条件。", "result": "实验表明，Re4MPC比传统NMPC更高效且成功率更高。", "conclusion": "Re4MPC为复杂机器人运动规划提供了一种高效且可靠的解决方案。"}}
{"id": "2506.08416", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08416", "abs": "https://arxiv.org/abs/2506.08416", "authors": ["Bolin Li", "Linwei Sun", "Xuecong Huang", "Yuzhi Jiang", "Lijun Zhu"], "title": "Periodic Bipedal Gait Learning Using Reward Composition Based on a Novel Gait Planner for Humanoid Robots", "comment": null, "summary": "This paper presents a periodic bipedal gait learning method using reward\ncomposition, integrated with a real-time gait planner for humanoid robots.\nFirst, we introduce a novel gait planner that incorporates dynamics to design\nthe desired joint trajectory. In the gait design process, the 3D robot model is\ndecoupled into two 2D models, which are then approximated as hybrid inverted\npendulums (H-LIP) for trajectory planning. The gait planner operates in\nparallel in real time within the robot's learning environment. Second, based on\nthis gait planner, we design three effective reward functions within a\nreinforcement learning framework, forming a reward composition to achieve\nperiodic bipedal gait. This reward composition reduces the robot's learning\ntime and enhances locomotion performance. Finally, a gait design example and\nperformance comparison are presented to demonstrate the effectiveness of the\nproposed method.", "AI": {"tldr": "提出了一种基于奖励组合的周期性双足步态学习方法，结合实时步态规划器，用于人形机器人。", "motivation": "通过结合动态规划和强化学习，提高双足步态的周期性和性能，减少学习时间。", "method": "1. 设计新型步态规划器，将3D模型解耦为2D模型并用混合倒立摆（H-LIP）规划轨迹；2. 在强化学习框架中设计三种奖励函数，组合成奖励组合。", "result": "实验展示了步态设计实例和性能对比，验证了方法的有效性。", "conclusion": "该方法通过奖励组合和实时规划器，显著提升了双足步态的学习效率和运动性能。"}}
{"id": "2506.08434", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08434", "abs": "https://arxiv.org/abs/2506.08434", "authors": ["Rui Zhao", "Xingjian Zhang", "Yuhong Cao", "Yizhuo Wang", "Guillaume Sartoretti"], "title": "Attention-based Learning for 3D Informative Path Planning", "comment": null, "summary": "In this work, we propose an attention-based deep reinforcement learning\napproach to address the adaptive informative path planning (IPP) problem in 3D\nspace, where an aerial robot equipped with a downward-facing sensor must\ndynamically adjust its 3D position to balance sensing footprint and accuracy,\nand finally obtain a high-quality belief of an underlying field of interest\nover a given domain (e.g., presence of specific plants, hazardous gas,\ngeological structures, etc.). In adaptive IPP tasks, the agent is tasked with\nmaximizing information collected under time/distance constraints, continuously\nadapting its path based on newly acquired sensor data. To this end, we leverage\nattention mechanisms for their strong ability to capture global spatial\ndependencies across large action spaces, allowing the agent to learn an\nimplicit estimation of environmental transitions. Our model builds a contextual\nbelief representation over the entire domain, guiding sequential movement\ndecisions that optimize both short- and long-term search objectives.\nComparative evaluations against state-of-the-art planners demonstrate that our\napproach significantly reduces environmental uncertainty within constrained\nbudgets, thus allowing the agent to effectively balance exploration and\nexploitation. We further show our model generalizes well to environments of\nvarying sizes, highlighting its potential for many real-world applications.", "AI": {"tldr": "提出一种基于注意力的深度强化学习方法，用于解决3D空间中的自适应信息路径规划问题，通过动态调整无人机位置以优化感知覆盖和精度。", "motivation": "解决自适应信息路径规划问题，无人机需在时间和距离约束下最大化信息收集，同时根据新获取的传感器数据动态调整路径。", "method": "利用注意力机制捕捉全局空间依赖关系，构建上下文信念表示，指导优化短期和长期搜索目标的序列移动决策。", "result": "在约束预算内显著降低环境不确定性，有效平衡探索与利用，且模型能泛化到不同规模的环境。", "conclusion": "该方法在多种实际应用中具有潜力，尤其在需要动态路径规划和环境感知的场景中表现优异。"}}
{"id": "2506.08440", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08440", "abs": "https://arxiv.org/abs/2506.08440", "authors": ["Zengjue Chen", "Runliang Niu", "He Kong", "Qi Wang"], "title": "TGRPO :Fine-tuning Vision-Language-Action Model via Trajectory-wise Group Relative Policy Optimization", "comment": null, "summary": "Recent advances in Vision-Language-Action (VLA) model have demonstrated\nstrong generalization capabilities across diverse scenes, tasks, and robotic\nplatforms when pretrained at large-scale datasets. However, these models still\nrequire task-specific fine-tuning in novel environments, a process that relies\nalmost exclusively on supervised fine-tuning (SFT) using static trajectory\ndatasets. Such approaches neither allow robot to interact with environment nor\ndo they leverage feedback from live execution. Also, their success is\ncritically dependent on the size and quality of the collected trajectories.\nReinforcement learning (RL) offers a promising alternative by enabling\nclosed-loop interaction and aligning learned policies directly with task\nobjectives. In this work, we draw inspiration from the ideas of GRPO and\npropose the Trajectory-wise Group Relative Policy Optimization (TGRPO) method.\nBy fusing step-level and trajectory-level advantage signals, this method\nimproves GRPO's group-level advantage estimation, thereby making the algorithm\nmore suitable for online reinforcement learning training of VLA. Experimental\nresults on ten manipulation tasks from the libero-object benchmark demonstrate\nthat TGRPO consistently outperforms various baseline methods, capable of\ngenerating more robust and efficient policies across multiple tested scenarios.\nOur source codes are available at: https://github.com/hahans/TGRPO", "AI": {"tldr": "论文提出了一种名为TGRPO的方法，通过结合步级和轨迹级优势信号，改进了GRPO的组级优势估计，适用于VLA模型的在线强化学习训练。实验表明，TGRPO在多个任务中表现优于基线方法。", "motivation": "现有的VLA模型在新环境中仍需任务特定的微调，且依赖静态轨迹数据集，无法利用实时执行反馈。强化学习（RL）提供了一种闭环交互的替代方案。", "method": "提出TGRPO方法，融合步级和轨迹级优势信号，改进GRPO的组级优势估计，适用于VLA模型的在线强化学习训练。", "result": "在十个操作任务上，TGRPO表现优于基线方法，生成更鲁棒和高效的政策。", "conclusion": "TGRPO通过改进优势估计，为VLA模型的在线强化学习训练提供了有效方法，实验验证了其优越性。"}}
{"id": "2506.08459", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.08459", "abs": "https://arxiv.org/abs/2506.08459", "authors": ["Juanran Wang", "Marc R. Schlichting", "Harrison Delecki", "Mykel J. Kochenderfer"], "title": "Diffusion Models for Safety Validation of Autonomous Driving Systems", "comment": null, "summary": "Safety validation of autonomous driving systems is extremely challenging due\nto the high risks and costs of real-world testing as well as the rarity and\ndiversity of potential failures. To address these challenges, we train a\ndenoising diffusion model to generate potential failure cases of an autonomous\nvehicle given any initial traffic state. Experiments on a four-way intersection\nproblem show that in a variety of scenarios, the diffusion model can generate\nrealistic failure samples while capturing a wide variety of potential failures.\nOur model does not require any external training dataset, can perform training\nand inference with modest computing resources, and does not assume any prior\nknowledge of the system under test, with applicability to safety validation for\ntraffic intersections.", "AI": {"tldr": "使用去噪扩散模型生成自动驾驶系统的潜在故障案例，无需外部数据集，适用于交通路口的安全验证。", "motivation": "自动驾驶系统的安全验证成本高且风险大，潜在故障案例稀少且多样，需要一种高效的方法生成故障案例。", "method": "训练去噪扩散模型，根据初始交通状态生成自动驾驶车辆的潜在故障案例。", "result": "实验表明，该模型能在多种场景下生成真实的故障样本，并捕捉多种潜在故障。", "conclusion": "该模型无需外部数据集，计算资源需求低，适用于交通路口的安全验证。"}}
{"id": "2506.08578", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08578", "abs": "https://arxiv.org/abs/2506.08578", "authors": ["Boyang Chen", "Xizhe Zang", "Chao Song", "Yue Zhang", "Xuehe Zhang", "Jie Zhao"], "title": "Noise Analysis and Hierarchical Adaptive Body State Estimator For Biped Robot Walking With ESVC Foot", "comment": null, "summary": "The ESVC(Ellipse-based Segmental Varying Curvature) foot, a robot foot design\ninspired by the rollover shape of the human foot, significantly enhances the\nenergy efficiency of the robot walking gait. However, due to the tilt of the\nsupporting leg, the error of the contact model are amplified, making robot\nstate estimation more challenging. Therefore, this paper focuses on the noise\nanalysis and state estimation for robot walking with the ESVC foot. First,\nthrough physical robot experiments, we investigate the effect of the ESVC foot\non robot measurement noise and process noise. and a noise-time regression model\nusing sliding window strategy is developed. Then, a hierarchical adaptive state\nestimator for biped robots with the ESVC foot is proposed. The state estimator\nconsists of two stages: pre-estimation and post-estimation. In the\npre-estimation stage, a data fusion-based estimation is employed to process the\nsensory data. During post-estimation, the acceleration of center of mass is\nfirst estimated, and then the noise covariance matrices are adjusted based on\nthe regression model. Following that, an EKF(Extended Kalman Filter) based\napproach is applied to estimate the centroid state during robot walking.\nPhysical experiments demonstrate that the proposed adaptive state estimator for\nbiped robot walking with the ESVC foot not only provides higher precision than\nboth EKF and Adaptive EKF, but also converges faster under varying noise\nconditions.", "AI": {"tldr": "本文提出了一种针对ESVC脚双足机器人的分层自适应状态估计器，通过噪声分析和回归模型改进状态估计精度和收敛速度。", "motivation": "ESVC脚虽提升机器人行走能效，但因支撑腿倾斜导致接触模型误差放大，状态估计更具挑战性。", "method": "1. 通过实验分析ESVC脚对噪声的影响，建立噪声-时间回归模型；2. 提出两阶段分层状态估计器（预估计和后估计），结合数据融合和EKF。", "result": "实验表明，该估计器比EKF和自适应EKF精度更高，且在变化噪声条件下收敛更快。", "conclusion": "分层自适应状态估计器有效解决了ESVC脚机器人的状态估计问题，提升了性能和适应性。"}}
{"id": "2506.08639", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.08639", "abs": "https://arxiv.org/abs/2506.08639", "authors": ["Amir Hossein Barjini", "Seyed Adel Alizadeh Kolagar", "Sadeq Yaqubi", "Jouni Mattila"], "title": "Deep Reinforcement Learning-Based Motion Planning and PDE Control for Flexible Manipulators", "comment": null, "summary": "This article presents a motion planning and control framework for flexible\nrobotic manipulators, integrating deep reinforcement learning (DRL) with a\nnonlinear partial differential equation (PDE) controller. Unlike conventional\napproaches that focus solely on control, we demonstrate that the desired\ntrajectory significantly influences endpoint vibrations. To address this, a DRL\nmotion planner, trained using the soft actor-critic (SAC) algorithm, generates\noptimized trajectories that inherently minimize vibrations. The PDE nonlinear\ncontroller then computes the required torques to track the planned trajectory\nwhile ensuring closed-loop stability using Lyapunov analysis. The proposed\nmethodology is validated through both simulations and real-world experiments,\ndemonstrating superior vibration suppression and tracking accuracy compared to\ntraditional methods. The results underscore the potential of combining\nlearning-based motion planning with model-based control for enhancing the\nprecision and stability of flexible robotic manipulators.", "AI": {"tldr": "本文提出了一种结合深度强化学习（DRL）和非线性偏微分方程（PDE）控制器的柔性机械臂运动规划与控制框架，通过优化轨迹显著减少振动。", "motivation": "传统方法仅关注控制，忽略了期望轨迹对端点振动的影响，因此需要一种更全面的方法。", "method": "使用软演员-评论家（SAC）算法训练的DRL运动规划器生成优化轨迹，结合PDE非线性控制器计算扭矩并确保闭环稳定性。", "result": "仿真和实验验证了该方法在振动抑制和跟踪精度上优于传统方法。", "conclusion": "结合学习型运动规划和模型控制可显著提升柔性机械臂的精度和稳定性。"}}
{"id": "2506.08706", "categories": ["cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.08706", "abs": "https://arxiv.org/abs/2506.08706", "authors": ["Tomasz Winiarski", "Jan Kaniuka", "Daniel Giełdowski", "Jakub Ostrysz", "Krystian Radlak", "Dmytro Kushnir"], "title": "ROS-related Robotic Systems Development with V-model-based Application of MeROS Metamodel", "comment": "19 pages", "summary": "As robotic systems grow increasingly complex, heterogeneous, and\nsafety-critical, the need for structured development methodologies becomes\nparamount. Although frameworks like the Robot Operating System (ROS) and\nModel-Based Systems Engineering (MBSE) offer foundational tools, they often\nlack integration when used together. This paper addresses that gap by aligning\nthe widely recognized V-model development paradigm with the MeROS metamodel\nSysML-based modeling language tailored for ROS-based systems.\n  We propose a domain-specific methodology that bridges ROS-centric modelling\nwith systems engineering practices. Our approach formalises the structure,\nbehaviour, and validation processes of robotic systems using MeROS, while\nextending it with a generalized, adaptable V-model compatible with both ROS and\nROS 2. Rather than prescribing a fixed procedure, the approach supports\nproject-specific flexibility and reuse, offering guidance across all stages of\ndevelopment.\n  The approach is validated through a comprehensive case study on HeROS, a\nheterogeneous multi-robot platform comprising manipulators, mobile units, and\ndynamic test environments. This example illustrates how the MeROS-compatible\nV-model enhances traceability and system consistency while remaining accessible\nand extensible for future adaptation. The work contributes a structured,\ntool-agnostic foundation for developers and researchers seeking to apply MBSE\npractices in ROS-based projects.", "AI": {"tldr": "本文提出了一种结合ROS和MBSE的方法，通过MeROS和V模型提升机器人系统开发的集成性和灵活性。", "motivation": "随着机器人系统复杂性和安全需求的增加，ROS和MBSE工具的集成不足成为问题，本文旨在填补这一空白。", "method": "提出了一种基于MeROS和V模型的领域特定方法，支持ROS和ROS 2的灵活开发。", "result": "通过HeROS平台的案例研究验证了方法的有效性，增强了系统一致性和可追溯性。", "conclusion": "为ROS项目提供了一种结构化的MBSE实践基础，具有灵活性和扩展性。"}}
{"id": "2506.08708", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.08708", "abs": "https://arxiv.org/abs/2506.08708", "authors": ["Liang Ma", "Jiajun Wen", "Min Lin", "Rongtao Xu", "Xiwen Liang", "Bingqian Lin", "Jun Ma", "Yongxin Wang", "Ziming Wei", "Haokun Lin", "Mingfei Han", "Meng Cao", "Bokui Chen", "Ivan Laptev", "Xiaodan Liang"], "title": "PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly", "comment": null, "summary": "While vision-language models (VLMs) have demonstrated promising capabilities\nin reasoning and planning for embodied agents, their ability to comprehend\nphysical phenomena, particularly within structured 3D environments, remains\nseverely limited. To close this gap, we introduce PhyBlock, a progressive\nbenchmark designed to assess VLMs on physical understanding and planning\nthrough robotic 3D block assembly tasks. PhyBlock integrates a novel four-level\ncognitive hierarchy assembly task alongside targeted Visual Question Answering\n(VQA) samples, collectively aimed at evaluating progressive spatial reasoning\nand fundamental physical comprehension, including object properties, spatial\nrelationships, and holistic scene understanding. PhyBlock includes 2600 block\ntasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three\nkey dimensions: partial completion, failure diagnosis, and planning robustness.\nWe benchmark 21 state-of-the-art VLMs, highlighting their strengths and\nlimitations in physically grounded, multi-step planning. Our empirical findings\nindicate that the performance of VLMs exhibits pronounced limitations in\nhigh-level planning and reasoning capabilities, leading to a notable decline in\nperformance for the growing complexity of the tasks. Error analysis reveals\npersistent difficulties in spatial orientation and dependency reasoning.\nSurprisingly, chain-of-thought prompting offers minimal improvements,\nsuggesting spatial tasks heavily rely on intuitive model comprehension. We\nposition PhyBlock as a unified testbed to advance embodied reasoning, bridging\nvision-language understanding and real-world physical problem-solving.", "AI": {"tldr": "PhyBlock是一个用于评估视觉语言模型（VLMs）在物理理解和规划能力的渐进式基准测试，通过3D积木组装任务和视觉问答（VQA）任务，揭示了VLMs在高级规划和空间推理方面的局限性。", "motivation": "现有视觉语言模型在物理现象理解和结构化3D环境中的规划能力有限，需要一种新的评估方法来填补这一空白。", "method": "提出PhyBlock基准测试，包含2600个任务（400个组装任务和2200个VQA任务），评估模型在部分完成、故障诊断和规划鲁棒性三个维度的表现。", "result": "21个先进VLMs的测试结果显示，它们在高级规划和空间推理方面表现不佳，任务复杂度增加时性能显著下降。", "conclusion": "PhyBlock为提升具身推理能力提供了统一测试平台，揭示了VLMs在物理问题解决中的关键挑战。"}}
{"id": "2506.08756", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.08756", "abs": "https://arxiv.org/abs/2506.08756", "authors": ["Octavio Arriaga", "Rebecca Adam", "Melvin Laux", "Lisa Gutzeit", "Marco Ragni", "Jan Peters", "Frank Kirchner"], "title": "Bayesian Inverse Physics for Neuro-Symbolic Robot Learning", "comment": null, "summary": "Real-world robotic applications, from autonomous exploration to assistive\ntechnologies, require adaptive, interpretable, and data-efficient learning\nparadigms. While deep learning architectures and foundation models have driven\nsignificant advances in diverse robotic applications, they remain limited in\ntheir ability to operate efficiently and reliably in unknown and dynamic\nenvironments. In this position paper, we critically assess these limitations\nand introduce a conceptual framework for combining data-driven learning with\ndeliberate, structured reasoning. Specifically, we propose leveraging\ndifferentiable physics for efficient world modeling, Bayesian inference for\nuncertainty-aware decision-making, and meta-learning for rapid adaptation to\nnew tasks. By embedding physical symbolic reasoning within neural models,\nrobots could generalize beyond their training data, reason about novel\nsituations, and continuously expand their knowledge. We argue that such hybrid\nneuro-symbolic architectures are essential for the next generation of\nautonomous systems, and to this end, we provide a research roadmap to guide and\naccelerate their development.", "AI": {"tldr": "论文提出了一种结合数据驱动学习和结构化推理的混合神经符号架构，以提高机器人在未知和动态环境中的适应性和效率。", "motivation": "当前深度学习在机器人应用中存在效率低和可靠性不足的问题，特别是在未知和动态环境中。", "method": "提出了一个框架，结合可微分物理、贝叶斯推理和元学习，将物理符号推理嵌入神经模型中。", "result": "这种架构有望使机器人超越训练数据泛化，适应新任务，并持续扩展知识。", "conclusion": "混合神经符号架构是下一代自主系统的关键，并提供了研究路线图以加速其发展。"}}
{"id": "2506.08795", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.08795", "abs": "https://arxiv.org/abs/2506.08795", "authors": ["Kaijie Shi", "Wanglong Lu", "Hanli Zhao", "Vinicius Prado da Fonseca", "Ting Zou", "Xianta Jiang"], "title": "Towards Biosignals-Free Autonomous Prosthetic Hand Control via Imitation Learning", "comment": null, "summary": "Limb loss affects millions globally, impairing physical function and reducing\nquality of life. Most traditional surface electromyographic (sEMG) and\nsemi-autonomous methods require users to generate myoelectric signals for each\ncontrol, imposing physically and mentally taxing demands. This study aims to\ndevelop a fully autonomous control system that enables a prosthetic hand to\nautomatically grasp and release objects of various shapes using only a camera\nattached to the wrist. By placing the hand near an object, the system will\nautomatically execute grasping actions with a proper grip force in response to\nthe hand's movements and the environment. To release the object being grasped,\njust naturally place the object close to the table and the system will\nautomatically open the hand. Such a system would provide individuals with limb\nloss with a very easy-to-use prosthetic control interface and greatly reduce\nmental effort while using. To achieve this goal, we developed a teleoperation\nsystem to collect human demonstration data for training the prosthetic hand\ncontrol model using imitation learning, which mimics the prosthetic hand\nactions from human. Through training the model using only a few objects' data\nfrom one single participant, we have shown that the imitation learning\nalgorithm can achieve high success rates, generalizing to more individuals and\nunseen objects with a variation of weights. The demonstrations are available at\n\\href{https://sites.google.com/view/autonomous-prosthetic-hand}{https://sites.google.com/view/autonomous-prosthetic-hand}", "AI": {"tldr": "研究开发了一种基于摄像头和模仿学习的全自主假手控制系统，能够自动抓取和释放物体，减少用户的心理负担。", "motivation": "传统肌电信号控制方法对用户要求高且繁琐，本研究旨在提供一种更易用的假手控制方案。", "method": "通过模仿学习训练假手控制模型，利用摄像头和人类示范数据实现自主抓取与释放。", "result": "模型仅需少量数据即可实现高成功率，并能泛化到不同用户和未见过的物体。", "conclusion": "该系统显著简化了假手控制，提升了用户体验，具有广泛应用潜力。"}}
{"id": "2506.08822", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.08822", "abs": "https://arxiv.org/abs/2506.08822", "authors": ["Yifei Su", "Ning Liu", "Dong Chen", "Zhen Zhao", "Kun Wu", "Meng Li", "Zhiyuan Xu", "Zhengping Che", "Jian Tang"], "title": "FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency", "comment": null, "summary": "Generative modeling-based visuomotor policies have been widely adopted in\nrobotic manipulation attributed to their ability to model multimodal action\ndistributions. However, the high inference cost of multi-step sampling limits\ntheir applicability in real-time robotic systems. To address this issue,\nexisting approaches accelerate the sampling process in generative\nmodeling-based visuomotor policies by adapting acceleration techniques\noriginally developed for image generation. Despite this progress, a major\ndistinction remains: image generation typically involves producing independent\nsamples without temporal dependencies, whereas robotic manipulation involves\ngenerating time-series action trajectories that require continuity and temporal\ncoherence. To effectively exploit temporal information in robotic manipulation,\nwe propose FreqPolicy, a novel approach that first imposes frequency\nconsistency constraints on flow-based visuomotor policies. Our work enables the\naction model to capture temporal structure effectively while supporting\nefficient, high-quality one-step action generation. We introduce a frequency\nconsistency constraint that enforces alignment of frequency-domain action\nfeatures across different timesteps along the flow, thereby promoting\nconvergence of one-step action generation toward the target distribution. In\naddition, we design an adaptive consistency loss to capture structural temporal\nvariations inherent in robotic manipulation tasks. We assess FreqPolicy on 53\ntasks across 3 simulation benchmarks, proving its superiority over existing\none-step action generators. We further integrate FreqPolicy into the\nvision-language-action (VLA) model and achieve acceleration without performance\ndegradation on the 40 tasks of Libero. Besides, we show efficiency and\neffectiveness in real-world robotic scenarios with an inference frequency\n93.5Hz. The code will be publicly available.", "AI": {"tldr": "FreqPolicy通过频率一致性约束改进基于生成模型的视觉运动策略，实现高效的一步动作生成，并在仿真和实际机器人任务中表现优异。", "motivation": "生成模型在机器人操作中因能建模多模态动作分布而被广泛应用，但其多步采样的高推理成本限制了实时性。现有方法虽加速采样，但忽视了动作轨迹的时间连续性。", "method": "提出FreqPolicy，通过频率一致性约束和自适应一致性损失，使动作模型有效捕捉时间结构，支持高效高质量的一步动作生成。", "result": "在3个仿真基准的53个任务中优于现有一步动作生成器，集成到VLA模型后在40个任务上实现加速且性能无损，实际机器人任务中推理频率达93.5Hz。", "conclusion": "FreqPolicy通过频率一致性约束显著提升生成模型在机器人操作中的效率和性能，适用于实时系统。"}}
{"id": "2506.08840", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08840", "abs": "https://arxiv.org/abs/2506.08840", "authors": ["Dewei Wang", "Xinmiao Wang", "Xinzhe Liu", "Jiyuan Shi", "Yingnan Zhao", "Chenjia Bai", "Xuelong Li"], "title": "MoRE: Mixture of Residual Experts for Humanoid Lifelike Gaits Learning on Complex Terrains", "comment": "9 pages, 5 figures", "summary": "Humanoid robots have demonstrated robust locomotion capabilities using\nReinforcement Learning (RL)-based approaches. Further, to obtain human-like\nbehaviors, existing methods integrate human motion-tracking or motion prior in\nthe RL framework. However, these methods are limited in flat terrains with\nproprioception only, restricting their abilities to traverse challenging\nterrains with human-like gaits. In this work, we propose a novel framework\nusing a mixture of latent residual experts with multi-discriminators to train\nan RL policy, which is capable of traversing complex terrains in controllable\nlifelike gaits with exteroception. Our two-stage training pipeline first\nteaches the policy to traverse complex terrains using a depth camera, and then\nenables gait-commanded switching between human-like gait patterns. We also\ndesign gait rewards to adjust human-like behaviors like robot base height.\nSimulation and real-world experiments demonstrate that our framework exhibits\nexceptional performance in traversing complex terrains, and achieves seamless\ntransitions between multiple human-like gait patterns.", "AI": {"tldr": "提出了一种基于混合潜在残差专家和多判别器的RL框架，用于训练能够在复杂地形中以可控仿人步态行走的机器人。", "motivation": "现有方法在平坦地形中表现良好，但在复杂地形中难以实现仿人步态。", "method": "采用两阶段训练流程，先通过深度相机训练策略适应复杂地形，再实现步态切换。", "result": "仿真和实物实验表明，该框架在复杂地形中表现优异，并能无缝切换多种仿人步态。", "conclusion": "该框架显著提升了机器人在复杂地形中的仿人步态行走能力。"}}
{"id": "2506.08851", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08851", "abs": "https://arxiv.org/abs/2506.08851", "authors": ["Sepehr Samavi", "Garvish Bhutani", "Florian Shkurti", "Angela P. Schoellig"], "title": "Deploying SICNav in the Field: Safe and Interactive Crowd Navigation using MPC and Bilevel Optimization", "comment": "Presented at the 2025 IEEE ICRA Workshop on Field Robotics\n  (non-archival)", "summary": "Safe and efficient navigation in crowded environments remains a critical\nchallenge for robots that provide a variety of service tasks such as food\ndelivery or autonomous wheelchair mobility. Classical robot crowd navigation\nmethods decouple human motion prediction from robot motion planning, which\nneglects the closed-loop interactions between humans and robots. This lack of a\nmodel for human reactions to the robot plan (e.g. moving out of the way) can\ncause the robot to get stuck. Our proposed Safe and Interactive Crowd\nNavigation (SICNav) method is a bilevel Model Predictive Control (MPC)\nframework that combines prediction and planning into one optimization problem,\nexplicitly modeling interactions among agents. In this paper, we present a\nsystems overview of the crowd navigation platform we use to deploy SICNav in\npreviously unseen indoor and outdoor environments. We provide a preliminary\nanalysis of the system's operation over the course of nearly 7 km of autonomous\nnavigation over two hours in both indoor and outdoor environments.", "AI": {"tldr": "SICNav是一种双层MPC框架，将预测和规划结合为一个优化问题，解决了机器人导航中忽略人机交互的问题。", "motivation": "解决拥挤环境中机器人导航的挑战，避免因忽略人机闭环交互而导致机器人卡住。", "method": "提出SICNav方法，结合预测与规划，显式建模多智能体交互。", "result": "在室内外环境中进行了近7公里的自主导航测试，初步验证了系统的可行性。", "conclusion": "SICNav通过显式建模交互，提高了机器人在拥挤环境中的导航安全性和效率。"}}
{"id": "2506.08856", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08856", "abs": "https://arxiv.org/abs/2506.08856", "authors": ["Jonathan P. King", "Harnoor Ahluwalia", "Michael Zhang", "Nancy S. Pollard"], "title": "Fast Estimation of Globally Optimal Independent Contact Regions for Robust Grasping and Manipulation", "comment": "Submitted to IEEE Conference on Humanoid Robots", "summary": "This work presents a fast anytime algorithm for computing globally optimal\nindependent contact regions (ICRs). ICRs are regions such that one contact\nwithin each region enables a valid grasp. Locations of ICRs can provide\nguidance for grasp and manipulation planning, learning, and policy transfer.\nHowever, ICRs for modern applications have been little explored, in part due to\nthe expense of computing them, as they have a search space exponential in the\nnumber of contacts. We present a divide and conquer algorithm based on\nincremental n-dimensional Delaunay triangulation that produces results with\nbounded suboptimality in times sufficient for real-time planning. This paper\npresents the base algorithm for grasps where contacts lie within a plane. Our\nexperiments show substantial benefits over competing grasp quality metrics and\nspeedups of 100X and more for competing approaches to computing ICRs. We\nexplore robustness of a policy guided by ICRs and outline a path to general 3D\nimplementation. Code will be released on publication to facilitate further\ndevelopment and applications.", "AI": {"tldr": "提出了一种快速算法，用于计算全局最优的独立接触区域（ICRs），适用于实时规划。", "motivation": "ICRs的位置为抓取和操作规划、学习及策略迁移提供指导，但现有方法计算成本高。", "method": "基于增量n维Delaunay三角剖分的分治算法，支持平面接触。", "result": "实验显示比竞争方法快100倍以上，且抓取质量更优。", "conclusion": "算法高效且鲁棒，未来将扩展到3D实现，代码将开源。"}}
{"id": "2506.08868", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08868", "abs": "https://arxiv.org/abs/2506.08868", "authors": ["Marco Ruggia"], "title": "MOMAV: A highly symmetrical fully-actuated multirotor drone using optimizing control allocation", "comment": "12 pages, 12 figures, preprint", "summary": "MOMAV (Marco's Omnidirectional Micro Aerial Vehicle) is a multirotor drone\nthat is fully actuated, meaning it can control its orientation independently of\nits position. MOMAV is also highly symmetrical, making its flight efficiency\nlargely unaffected by its current orientation. These characteristics are\nachieved by a novel drone design where six rotor arms align with the vertices\nof an octahedron, and where each arm can actively rotate along its long axis.\nVarious standout features of MOMAV are presented: The high flight efficiency\ncompared to arm configuration of other fully-actuated drones, the design of an\noriginal rotating arm assembly featuring slip-rings used to enable continuous\narm rotation, and a novel control allocation algorithm based on sequential\nquadratic programming (SQP) used to calculate throttle and arm-angle setpoints\nin flight. Flight tests have shown that MOMAV is able to achieve remarkably low\nmean position/orientation errors of 6.6mm, 2.1{\\deg} ({\\sigma}: 3.0mm,\n1.0{\\deg}) when sweeping position setpoints, and 11.8mm, 3.3{\\deg} ({\\sigma}:\n8.6mm, 2.0{\\deg}) when sweeping orientation setpoints.", "AI": {"tldr": "MOMAV是一种全驱动、高度对称的多旋翼无人机，通过独特的八面体转子臂设计和主动旋转机制实现高效飞行，控制算法基于SQP，飞行测试显示其位置和姿态误差极低。", "motivation": "设计一种能够独立控制位置和姿态的全驱动无人机，同时保持高飞行效率。", "method": "采用六转子臂八面体排列设计，每个臂可主动旋转，结合基于SQP的控制分配算法。", "result": "飞行测试显示位置误差6.6mm、姿态误差2.1°，性能优于其他全驱动无人机。", "conclusion": "MOMAV通过创新设计和控制算法，实现了高效、精确的全驱动飞行。"}}
{"id": "2506.08890", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.08890", "abs": "https://arxiv.org/abs/2506.08890", "authors": ["Tauhid Tanjim", "Promise Ekpo", "Huajie Cao", "Jonathan St. George", "Kevin Ching", "Hee Rin Lee", "Angelique Taylor"], "title": "Human-Robot Teaming Field Deployments: A Comparison Between Verbal and Non-verbal Communication", "comment": "This is the author's original submitted version of the paper accepted\n  to the 2025 IEEE International Conference on Robot and Human Interactive\n  Communication (RO-MAN). \\c{opyright} 2025 IEEE. Personal use of this material\n  is permitted. For any other use, please contact IEEE", "summary": "Healthcare workers (HCWs) encounter challenges in hospitals, such as\nretrieving medical supplies quickly from crash carts, which could potentially\nresult in medical errors and delays in patient care. Robotic crash carts (RCCs)\nhave shown promise in assisting healthcare teams during medical tasks through\nguided object searches and task reminders. Limited exploration has been done to\ndetermine what communication modalities are most effective and least disruptive\nto patient care in real-world settings. To address this gap, we conducted a\nbetween-subjects experiment comparing the RCC's verbal and non-verbal\ncommunication of object search with a standard crash cart in resuscitation\nscenarios to understand the impact of robot communication on workload and\nattitudes toward using robots in the workplace. Our findings indicate that\nverbal communication significantly reduced mental demand and effort compared to\nvisual cues and with a traditional crash cart. Although frustration levels were\nslightly higher during collaborations with the robot compared to a traditional\ncart, these research insights provide valuable implications for human-robot\nteamwork in high-stakes environments.", "AI": {"tldr": "研究比较了机器人急救车（RCC）的语音与非语音通信方式对医护人员工作负荷和态度的影响，发现语音通信显著降低心理需求和努力。", "motivation": "医护人员在急救场景中快速获取医疗用品时面临挑战，机器人急救车可能通过有效通信方式减少干扰并提高效率。", "method": "采用被试间实验设计，比较RCC的语音与非语音通信方式与传统急救车在复苏场景中的效果。", "result": "语音通信显著降低心理需求和努力，尽管与机器人合作时挫败感略高。", "conclusion": "研究为高风险环境中人机协作提供了有价值的见解，支持语音通信在机器人辅助医疗中的应用。"}}
{"id": "2506.08931", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2506.08931", "abs": "https://arxiv.org/abs/2506.08931", "authors": ["Yixuan Li", "Yutang Lin", "Jieming Cui", "Tengyu Liu", "Wei Liang", "Yixin Zhu", "Siyuan Huang"], "title": "CLONE: Closed-Loop Whole-Body Humanoid Teleoperation for Long-Horizon Tasks", "comment": "18 pages, 13 figures", "summary": "Humanoid teleoperation plays a vital role in demonstrating and collecting\ndata for complex humanoid-scene interactions. However, current teleoperation\nsystems face critical limitations: they decouple upper- and lower-body control\nto maintain stability, restricting natural coordination, and operate open-loop\nwithout real-time position feedback, leading to accumulated drift. The\nfundamental challenge is achieving precise, coordinated whole-body\nteleoperation over extended durations while maintaining accurate global\npositioning. Here we show that an MoE-based teleoperation system, CLONE, with\nclosed-loop error correction enables unprecedented whole-body teleoperation\nfidelity, maintaining minimal positional drift over long-range trajectories\nusing only head and hand tracking from an MR headset. Unlike previous methods\nthat either sacrifice coordination for stability or suffer from unbounded\ndrift, CLONE learns diverse motion skills while preventing tracking error\naccumulation through real-time feedback, enabling complex coordinated movements\nsuch as ``picking up objects from the ground.'' These results establish a new\nmilestone for whole-body humanoid teleoperation for long-horizon humanoid-scene\ninteraction tasks.", "AI": {"tldr": "CLONE是一种基于MoE的遥操作系统，通过闭环误差校正实现高保真全身遥操作，解决了现有系统协调性和漂移问题。", "motivation": "当前遥操作系统存在上下肢控制分离和开环操作导致的协调性不足和漂移问题，需要一种能实现精确、协调且长时间稳定的全身遥操作方案。", "method": "采用MoE架构和闭环误差校正技术，仅需MR头显的手部和头部跟踪数据，实现实时反馈和误差控制。", "result": "CLONE系统在长距离轨迹中保持极低的位置漂移，支持复杂协调动作（如从地面拾取物体），显著提升了遥操作性能。", "conclusion": "CLONE为长时间全身人形遥操作设立了新标准，适用于复杂人形场景交互任务。"}}
