<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 29]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning](https://arxiv.org/abs/2508.18397)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: 本文通过系统比较六种数据筛选策略，解决了离线强化学习中数据不平衡问题，发现基于模型不确定性的方法能显著提升自动驾驶安全性，碰撞率降低近三倍。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶离线强化学习面临数据极度不平衡的挑战，普通驾驶场景远多于罕见的长尾事件，导致标准均匀采样训练出的策略脆弱且不安全。

Method: 研究六种关键性加权方案（启发式、不确定性、行为式三类），在两个时间尺度（单时间步和完整场景）评估，使用目标条件CQL和注意力架构训练七个代理，在Waymax模拟器中测试。

Result: 所有数据筛选方法均显著优于基线，基于模型不确定性的方法安全性提升最显著，碰撞率从16.0%降至5.5%。时间步级加权擅长反应性安全，场景级加权改善长期规划。

Conclusion: 智能非均匀采样是构建安全可靠自动驾驶代理的关键组件，为离线RL数据筛选提供了全面框架。

Abstract: Offline Reinforcement Learning (RL) presents a promising paradigm for
training autonomous vehicle (AV) planning policies from large-scale, real-world
driving logs. However, the extreme data imbalance in these logs, where mundane
scenarios vastly outnumber rare "long-tail" events, leads to brittle and unsafe
policies when using standard uniform data sampling. In this work, we address
this challenge through a systematic, large-scale comparative study of data
curation strategies designed to focus the learning process on information-rich
samples. We investigate six distinct criticality weighting schemes which are
categorized into three families: heuristic-based, uncertainty-based, and
behavior-based. These are evaluated at two temporal scales, the individual
timestep and the complete scenario. We train seven goal-conditioned
Conservative Q-Learning (CQL) agents with a state-of-the-art, attention-based
architecture and evaluate them in the high-fidelity Waymax simulator. Our
results demonstrate that all data curation methods significantly outperform the
baseline. Notably, data-driven curation using model uncertainty as a signal
achieves the most significant safety improvements, reducing the collision rate
by nearly three-fold (from 16.0% to 5.5%). Furthermore, we identify a clear
trade-off where timestep-level weighting excels at reactive safety while
scenario-level weighting improves long-horizon planning. Our work provides a
comprehensive framework for data curation in Offline RL and underscores that
intelligent, non-uniform sampling is a critical component for building safe and
reliable autonomous agents.

</details>


### [2] [Maintenance automation: methods for robotics manipulation planning and execution](https://arxiv.org/abs/2508.18399)
*Christian Friedrich,Ralf Gulde,Armin Lechler,Alexander Verl*

Main category: cs.RO

TL;DR: 提出基于CAD和RGBD数据的机器人维护自动化系统，能够在环境不确定性下执行拆卸和组装操作


<details>
  <summary>Details</summary>
Motivation: 自动化复杂维护任务需要解决规划、控制和执行的集成问题，特别是在存在环境偏差等不确定性的情况下

Method: 采用基于CAD和RGBD数据的规划方法，将符号化计划转换为可执行的机器人指令

Result: 通过真实应用场景进行实验评估，验证了系统的可行性

Conclusion: 这是将理论成果转化为实际机器人解决方案的重要第一步

Abstract: Automating complex tasks using robotic systems requires skills for planning,
control and execution. This paper proposes a complete robotic system for
maintenance automation, which can automate disassembly and assembly operations
under environmental uncertainties (e.g. deviations between prior plan
information). The cognition of the robotic system is based on a planning
approach (using CAD and RGBD data) and includes a method to interpret a
symbolic plan and transform it to a set of executable robot instructions. The
complete system is experimentally evaluated using real-world applications. This
work shows the first step to transfer these theoretical results into a
practical robotic solution.

</details>


### [3] [Efficient task and path planning for maintenance automation using a robot system](https://arxiv.org/abs/2508.18400)
*Christian Friedrich,Akos Csiszar,Armin Lechler,Alexander Verl*

Main category: cs.RO

TL;DR: 本文提出了一种用于维护自动化的自主机器人系统方案，结合CAD离线数据和RGBD视觉系统在线数据，通过概率滤波器补偿不确定性，并使用符号描述和采样基方法进行任务规划和路径规划。


<details>
  <summary>Details</summary>
Motivation: 工厂未来的智能自动化需要自主机器人系统来自动化维护任务，这需要算法具有低计算复杂度并能处理环境不确定性。

Method: 结合CAD离线数据和RGBD视觉系统在线数据，使用概率滤波器补偿不确定性；采用符号描述和新题采样基方法计算解体空间进行任务规划；使用全局先进路径规划算法并通过调整探索步长来减少规划时间。

Result: 所有方法都通过实验进行了验证和讨论，证明了方案的可行性和效果。

Conclusion: 该方法特别适合解决维护自动化问题，能够有效处理环境不确定性并提高规划效率。

Abstract: The research and development of intelligent automation solutions is a
ground-breaking point for the factory of the future. A promising and
challenging mission is the use of autonomous robot systems to automate tasks in
the field of maintenance. For this purpose, the robot system must be able to
plan autonomously the different manipulation tasks and the corresponding paths.
Basic requirements are the development of algorithms with a low computational
complexity and the possibility to deal with environmental uncertainties. In
this work, an approach is presented, which is especially suited to solve the
problem of maintenance automation. For this purpose, offline data from CAD is
combined with online data from an RGBD vision system via a probabilistic
filter, to compensate uncertainties from offline data. For planning the
different tasks, a method is explained, which use a symbolic description,
founded on a novel sampling-based method to compute the disassembly space. For
path planning we use global state-of-the art algorithms with a method that
allows the adaption of the exploration stepsize in order to reduce the planning
time. Every method is experimentally validated and discussed.

</details>


### [4] [PneuGelSight: Soft Robotic Vision-Based Proprioception and Tactile Sensing](https://arxiv.org/abs/2508.18443)
*Ruohan Zhang,Uksang Yoo,Yichen Li,Arpit Argawal,Wenzhen Yuan*

Main category: cs.RO

TL;DR: 这篇论文提出了一种新题的视觉基于感知方法PneuGelSight，通过嵌入摄像头实现软体机器人的高分辨率体感和触觉感知，并使用模拟到实际的经验迁移流程优化性能。


<details>
  <summary>Details</summary>
Motivation: 软体气动机器人虽然具有优秀的程度和灵活性，但在实际应用中需要充分的触觉反馈和体感能力。需要一种简单易行、稳健的感知方案来推动软体机器人的实际部署。

Method: 设计了PneuGelSight软体机器人，通过嵌入摄像头实现高分辨率体感和触觉感知。开发了一个综合性的模拟到实际迁移流程，准确模拟传感器的光学和动力学特性，支持零样本知识迁移。

Result: PneuGelSight成功实现了高分辨率的体感和触觉感知能力，模拟到实际迁移流程有效优化了传感器性能，无需实际调试即可直接应用于实际场景。

Conclusion: 该研究提供了一种新题、简单易行且稳健的软体机器人感知方案，为开发具有更强感官能力的进阶软体机器人掌平了道路。

Abstract: Soft pneumatic robot manipulators are popular in industrial and
human-interactive applications due to their compliance and flexibility.
However, deploying them in real-world scenarios requires advanced sensing for
tactile feedback and proprioception. Our work presents a novel vision-based
approach for sensorizing soft robots. We demonstrate our approach on
PneuGelSight, a pioneering pneumatic manipulator featuring high-resolution
proprioception and tactile sensing via an embedded camera. To optimize the
sensor's performance, we introduce a comprehensive pipeline that accurately
simulates its optical and dynamic properties, facilitating a zero-shot
knowledge transition from simulation to real-world applications. PneuGelSight
and our sim-to-real pipeline provide a novel, easily implementable, and robust
sensing methodology for soft robots, paving the way for the development of more
advanced soft robots with enhanced sensory capabilities.

</details>


### [5] [Mimicking associative learning of rats via a neuromorphic robot in open field maze using spatial cell models](https://arxiv.org/abs/2508.18460)
*Tianze Liu,Md Abu Bakr Siddique,Hongyu An*

Main category: cs.RO

TL;DR: 本文提出通过模拟动物联想学习机制来增强神经形态机器人的自主能力，以解决传统AI方法在功耗和适应性方面的限制


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动的AI方法依赖大数据集和神经网络，存在高功耗和适应性有限的问题，特别是在SWaP受限的应用中如行星探索

Method: 模拟啮齿类动物的联想学习机制，在开放场地迷宫环境中使用神经形态机器人，整合位置细胞和网格细胞等空间细胞模型

Result: 实现了在线联想学习机制，使机器人能够在动态环境中自主导航并通过交互学习优化性能

Conclusion: 该方法成功将生物空间认知与机器人技术相结合，为自主系统的进步提供了新途径，特别是在资源受限的环境中

Abstract: Data-driven Artificial Intelligence (AI) approaches have exhibited remarkable
prowess across various cognitive tasks using extensive training data. However,
the reliance on large datasets and neural networks presents challenges such as
highpower consumption and limited adaptability, particularly in
SWaP-constrained applications like planetary exploration. To address these
issues, we propose enhancing the autonomous capabilities of intelligent robots
by emulating the associative learning observed in animals. Associative learning
enables animals to adapt to their environment by memorizing concurrent events.
By replicating this mechanism, neuromorphic robots can navigate dynamic
environments autonomously, learning from interactions to optimize performance.
This paper explores the emulation of associative learning in rodents using
neuromorphic robots within open-field maze environments, leveraging insights
from spatial cells such as place and grid cells. By integrating these models,
we aim to enable online associative learning for spatial tasks in real-time
scenarios, bridging the gap between biological spatial cognition and robotics
for advancements in autonomous systems.

</details>


### [6] [AgriChrono: A Multi-modal Dataset Capturing Crop Growth and Lighting Variability with a Field Robot](https://arxiv.org/abs/2508.18694)
*Jaehwan Jeong,Tuan-Anh Vu,Mohammad Jony,Shahab Ahmad,Md. Mukhlesur Rahman,Sangpil Kim,M. Khalid Jawed*

Main category: cs.RO

TL;DR: AgriChrono是一个新颖的机器人数据收集平台和多模态数据集，专门设计用于捕捉真实农业环境的动态条件，解决了现有数据集在静态环境中收集、传感器多样性有限和缺乏时间跨度的问题。


<details>
  <summary>Details</summary>
Motivation: 现有精准农业数据集主要在静态或受控环境中收集，无法反映真实农田的动态特性（如光照变化、作物生长变化和自然干扰），导致训练出的模型在真实场景中缺乏鲁棒性和泛化能力。

Method: 开发了一个集成多传感器的机器人数据收集平台，支持远程、时间同步采集RGB、深度、LiDAR和IMU数据，能够在不同光照和作物生长阶段进行高效、可重复的长期数据收集。

Result: 在AgriChrono数据集上对多种最先进的3D重建模型进行了基准测试，证明了在真实农田环境中进行重建的困难性，并展示了该数据集作为研究资产的价值。

Conclusion: AgriChrono数据集和平台为在动态条件下推进模型泛化研究提供了重要资源，代码和数据集已公开可用。

Abstract: Existing datasets for precision agriculture have primarily been collected in
static or controlled environments such as indoor labs or greenhouses, often
with limited sensor diversity and restricted temporal span. These conditions
fail to reflect the dynamic nature of real farmland, including illumination
changes, crop growth variation, and natural disturbances. As a result, models
trained on such data often lack robustness and generalization when applied to
real-world field scenarios. In this paper, we present AgriChrono, a novel
robotic data collection platform and multi-modal dataset designed to capture
the dynamic conditions of real-world agricultural environments. Our platform
integrates multiple sensors and enables remote, time-synchronized acquisition
of RGB, Depth, LiDAR, and IMU data, supporting efficient and repeatable
long-term data collection across varying illumination and crop growth stages.
We benchmark a range of state-of-the-art 3D reconstruction models on the
AgriChrono dataset, highlighting the difficulty of reconstruction in real-world
field environments and demonstrating its value as a research asset for
advancing model generalization under dynamic conditions. The code and dataset
are publicly available at: https://github.com/StructuresComp/agri-chrono

</details>


### [7] [SignLoc: Robust Localization using Navigation Signs and Public Maps](https://arxiv.org/abs/2508.18606)
*Nicky Zimmerman,Joel Loo,Ayush Agrawal,David Hsu*

Main category: cs.RO

TL;DR: SignLoc是一种利用导航标志进行全局定位的方法，无需先验传感器建图，仅需观察1-2个标志即可在公开地图上实现鲁棒的拓扑语义定位


<details>
  <summary>Details</summary>
Motivation: 导航标志和地图（如平面图和街道地图）在人类环境中广泛可用，但很少被机器人系统使用。本文旨在利用这些现成的导航标志来实现机器人的全局定位

Method: 首先从输入地图中提取导航图，然后使用概率观测模型将检测到的标志的方向和位置线索与图进行匹配，在蒙特卡洛框架内实现鲁棒的拓扑语义定位

Result: 在多种大规模环境（大学校园、购物中心、医院综合体）中进行评估，实验结果显示SignLoc在仅观察1-2个标志后就能可靠地定位机器人

Conclusion: SignLoc方法成功证明了利用现成导航标志和公开地图进行机器人全局定位的可行性，为机器人导航提供了一种新颖且实用的解决方案

Abstract: Navigation signs and maps, such as floor plans and street maps, are widely
available and serve as ubiquitous aids for way-finding in human environments.
Yet, they are rarely used by robot systems. This paper presents SignLoc, a
global localization method that leverages navigation signs to localize the
robot on publicly available maps -- specifically floor plans and OpenStreetMap
(OSM) graphs -- without prior sensor-based mapping. SignLoc first extracts a
navigation graph from the input map. It then employs a probabilistic
observation model to match directional and locational cues from the detected
signs to the graph, enabling robust topo-semantic localization within a Monte
Carlo framework. We evaluated SignLoc in diverse large-scale environments: part
of a university campus, a shopping mall, and a hospital complex. Experimental
results show that SignLoc reliably localizes the robot after observing only one
to two signs.

</details>


### [8] [Real-time Testing of Satellite Attitude Control With a Reaction Wheel Hardware-In-the-Loop Platform](https://arxiv.org/abs/2508.19164)
*Morokot Sakal,George Nehma,Camilo Riano-Rios,Madhur Tiwari*

Main category: cs.RO

TL;DR: 确定卫星姿态控制系统的硬件在环测试方案，包括反应轮健康估计和故障模拟方法


<details>
  <summary>Details</summary>
Motivation: 之前的仿真和软件在环测试推动了进一步实验，以验证控制器在真实动量交换设备环境下的有效性

Method: 构建硬件在环测试平台，包含CAN总线通信的无刷直流电机、执行控制算法的嵌入式计算机、以及生成仿真传感器数据的卫星模拟器

Result: 提出了人工引发反应轮故障的方法，并总结了相关问题和经验教训

Conclusion: 这项工作是建立完整太空船姿态控制算法验证框架的重要步骤

Abstract: We propose the Hardware-in-the-Loop (HIL) test of an adaptive satellite
attitude control system with reaction wheel health estimation capabilities.
Previous simulations and Software-in-the-Loop testing have prompted further
experiments to explore the validity of the controller with real momentum
exchange devices in the loop. This work is a step toward a comprehensive
testing framework for validation of spacecraft attitude control algorithms. The
proposed HIL testbed includes brushless DC motors and drivers that communicate
using a CAN bus, an embedded computer that executes control and adaptation
laws, and a satellite simulator that produces simulated sensor data, estimated
attitude states, and responds to actions of the external actuators. We propose
methods to artificially induce failures on the reaction wheels, and present
related issues and lessons learned.

</details>


### [9] [Integration of Robot and Scene Kinematics for Sequential Mobile Manipulation Planning](https://arxiv.org/abs/2508.18627)
*Ziyuan Jiao,Yida Niu,Zeyu Zhang,Yangyang Wu,Yao Su,Yixin Zhu,Hangxin Liu,Song-Chun Zhu*

Main category: cs.RO

TL;DR: 提出了一种序列移动操作规划框架(SMMP)，通过构建增强配置空间(A-Space)来统一导航和操作任务约束，实现长期望多步骤移动操作任务的高效规划。


<details>
  <summary>Details</summary>
Motivation: 解决长期望多步骤移动操作任务中导航和操作约束分离的问题，提高机器人在处理关节式物体时的整体运动协调性和任务成功率。

Method: 构建增强配置空间(A-Space)，将环境结构抽象为运动学模型并与机器人运动学集成，采用三层框架：任务规划器生成符号动作序列，优化基于运动规划器计算连续轨迹，中间规划精细阶段选择保证长期望可行性的动作目标。

Result: 模拟实验显示在A-Space中规划的任务成功率比基线方法提高84.6%，真实机器人系统验证了在17个不同场景中处理7种类型的刚体和关节式物体，完成了达到14个序列步骤的长期望任务。

Conclusion: 将场景运动学模型化为规划实体，而非编码任务特定约束，提供了一种可扩展和通用的处理复杂机器人操作任务的方法。

Abstract: We present a Sequential Mobile Manipulation Planning (SMMP) framework that
can solve long-horizon multi-step mobile manipulation tasks with coordinated
whole-body motion, even when interacting with articulated objects. By
abstracting environmental structures as kinematic models and integrating them
with the robot's kinematics, we construct an Augmented Configuration Apace
(A-Space) that unifies the previously separate task constraints for navigation
and manipulation, while accounting for the joint reachability of the robot
base, arm, and manipulated objects. This integration facilitates efficient
planning within a tri-level framework: a task planner generates symbolic action
sequences to model the evolution of A-Space, an optimization-based motion
planner computes continuous trajectories within A-Space to achieve desired
configurations for both the robot and scene elements, and an intermediate plan
refinement stage selects action goals that ensure long-horizon feasibility. Our
simulation studies first confirm that planning in A-Space achieves an 84.6\%
higher task success rate compared to baseline methods. Validation on real
robotic systems demonstrates fluid mobile manipulation involving (i) seven
types of rigid and articulated objects across 17 distinct contexts, and (ii)
long-horizon tasks of up to 14 sequential steps. Our results highlight the
significance of modeling scene kinematics into planning entities, rather than
encoding task-specific constraints, offering a scalable and generalizable
approach to complex robotic manipulation.

</details>


### [10] [Engineering Automotive Digital Twins on Standardized Architectures: A Case Study](https://arxiv.org/abs/2508.18662)
*Stefan Ramdhan,Winnie Trandinh,Istvan David,Vera Pantelic,Mark Lawford*

Main category: cs.RO

TL;DR: 本研究评估ISO 23247数字孪生参考架构在汽车领域的适用性，通过自适应巡航控制数字孪生案例研究，识别该架构的优势与局限


<details>
  <summary>Details</summary>
Motivation: 汽车行业对数字孪生技术需求增长，但缺乏专门的架构指导。ISO 23247是当前唯一的数字孪生架构标准，虽非针对汽车系统开发，却是可行的起点

Method: 通过为1/10比例自动驾驶车辆开发自适应巡航控制数字孪生的案例研究，分析ISO 23247参考架构的适用性

Result: 识别了该参考架构在汽车数字孪生开发中的优势与局限性

Conclusion: 为研究人员、从业者和标准制定者提炼了未来发展方向，指出了汽车数字孪生架构需要改进的方向

Abstract: Digital twin (DT) technology has become of interest in the automotive
industry. There is a growing need for smarter services that utilize the unique
capabilities of DTs, ranging from computer-aided remote control to cloud-based
fleet coordination. Developing such services starts with the software
architecture. However, the scarcity of DT architectural guidelines poses a
challenge for engineering automotive DTs. Currently, the only DT architectural
standard is the one defined in ISO 23247. Though not developed for automotive
systems, it is one of the few feasible starting points for automotive DTs. In
this work, we investigate the suitability of the ISO 23247 reference
architecture for developing automotive DTs. Through the case study of
developing an Adaptive Cruise Control DT for a 1/10\textsuperscript{th}-scale
autonomous vehicle, we identify some strengths and limitations of the reference
architecture and begin distilling future directions for researchers,
practitioners, and standard developers.

</details>


### [11] [Deep Sensorimotor Control by Imitating Predictive Models of Human Motion](https://arxiv.org/abs/2508.18691)
*Himanshu Gaurav Singh,Pieter Abbeel,Jitendra Malik,Antonio Loquercio*

Main category: cs.RO

TL;DR: 提出一种通过模仿人类运动预测模型来训练机器人传感器运动策略的新方法，无需梯度运动重定向或对抗损失，直接在机器人上零样本应用人类数据训练的模型。


<details>
  <summary>Details</summary>
Motivation: 随着机器人与人类之间的体现差距缩小，可以利用人类与环境交互的大规模数据集进行机器人学习，但现有方法受限于运动重定向和对抗损失，无法充分利用人类数据的规模和多样性。

Method: 利用人体关键点与机器人末端执行器关键点运动的相似性，使用人类数据训练的预测模型在机器人数据上零样本应用，训练传感器运动策略来跟踪模型预测，同时优化稀疏任务奖励。

Result: 该方法在不同机器人和任务上都能有效工作，大幅超越现有基线方法，并且能够替代精心设计的密集奖励和课程学习。

Conclusion: 通过直接利用人类运动预测模型，可以绕过传统限制，充分利用大规模人类交互数据集，为机器人学习提供新的有效途径。

Abstract: As the embodiment gap between a robot and a human narrows, new opportunities
arise to leverage datasets of humans interacting with their surroundings for
robot learning. We propose a novel technique for training sensorimotor policies
with reinforcement learning by imitating predictive models of human motions.
Our key insight is that the motion of keypoints on human-inspired robot
end-effectors closely mirrors the motion of corresponding human body keypoints.
This enables us to use a model trained to predict future motion on human data
\emph{zero-shot} on robot data. We train sensorimotor policies to track the
predictions of such a model, conditioned on a history of past robot states,
while optimizing a relatively sparse task reward. This approach entirely
bypasses gradient-based kinematic retargeting and adversarial losses, which
limit existing methods from fully leveraging the scale and diversity of modern
human-scene interaction datasets. Empirically, we find that our approach can
work across robots and tasks, outperforming existing baselines by a large
margin. In addition, we find that tracking a human motion model can substitute
for carefully designed dense rewards and curricula in manipulation tasks. Code,
data and qualitative results available at
https://jirl-upenn.github.io/track_reward/.

</details>


### [12] [Enhancing Video-Based Robot Failure Detection Using Task Knowledge](https://arxiv.org/abs/2508.18705)
*Santosh Thoduka,Sebastian Houben,Juergen Gall,Paul G. Plöger*

Main category: cs.RO

TL;DR: 提出了一种基于视频的机器人执行失败检测方法，利用动作信息和任务相关物体的时空知识，通过数据增强技术提升检测性能


<details>
  <summary>Details</summary>
Motivation: 现有失败检测方法在真实场景中性能有限，需要更可靠的检测机制来触发安全操作模式和恢复策略

Method: 使用机器人执行的动作和视野中任务相关物体的时空信息，提出可变帧率的数据增强方法

Result: 在ARMBench数据集上F1分数从77.9提升到80.0，测试时增强后达到81.4，无需额外计算开销

Conclusion: 时空信息对失败检测至关重要，未来应进一步研究合适的启发式方法

Abstract: Robust robotic task execution hinges on the reliable detection of execution
failures in order to trigger safe operation modes, recovery strategies, or task
replanning. However, many failure detection methods struggle to provide
meaningful performance when applied to a variety of real-world scenarios. In
this paper, we propose a video-based failure detection approach that uses
spatio-temporal knowledge in the form of the actions the robot performs and
task-relevant objects within the field of view. Both pieces of information are
available in most robotic scenarios and can thus be readily obtained. We
demonstrate the effectiveness of our approach on three datasets that we amend,
in part, with additional annotations of the aforementioned task-relevant
knowledge. In light of the results, we also propose a data augmentation method
that improves performance by applying variable frame rates to different parts
of the video. We observe an improvement from 77.9 to 80.0 in F1 score on the
ARMBench dataset without additional computational expense and an additional
increase to 81.4 with test-time augmentation. The results emphasize the
importance of spatio-temporal information during failure detection and suggest
further investigation of suitable heuristics in future implementations. Code
and annotations are available.

</details>


### [13] [HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation](https://arxiv.org/abs/2508.18802)
*Li Sun,Jiefeng Wu,Feng Chen,Ruizhe Liu,Yanchao Yang*

Main category: cs.RO

TL;DR: HyperTASR是一个超网络驱动的框架，通过任务目标和执行阶段动态调制场景表示，提升机器人操作任务中的策略学习效果。


<details>
  <summary>Details</summary>
Motivation: 当前方法使用任务无关的表示提取，无法模拟人类认知中的动态感知适应，需要能够根据任务上下文选择性捕捉相关环境特征的表示方法。

Method: 采用超网络架构，根据任务规范和进展状态动态生成表示变换参数，使表示在任务执行过程中上下文演化，同时保持与现有策略学习框架的架构兼容性。

Result: 在仿真和真实环境中的综合评估显示，该方法在不同表示范式中均取得显著性能提升，通过消融研究和注意力可视化证实了其选择性关注任务相关信息的能力。

Conclusion: HyperTASR通过计算分离任务上下文和状态依赖处理路径，提高了学习效率和表示质量，更接近人类在操作任务中的自适应感知模式。

Abstract: Effective policy learning for robotic manipulation requires scene
representations that selectively capture task-relevant environmental features.
Current approaches typically employ task-agnostic representation extraction,
failing to emulate the dynamic perceptual adaptation observed in human
cognition. We present HyperTASR, a hypernetwork-driven framework that modulates
scene representations based on both task objectives and the execution phase.
Our architecture dynamically generates representation transformation parameters
conditioned on task specifications and progression state, enabling
representations to evolve contextually throughout task execution. This approach
maintains architectural compatibility with existing policy learning frameworks
while fundamentally reconfiguring how visual features are processed. Unlike
methods that simply concatenate or fuse task embeddings with task-agnostic
representations, HyperTASR establishes computational separation between
task-contextual and state-dependent processing paths, enhancing learning
efficiency and representational quality. Comprehensive evaluations in both
simulation and real-world environments demonstrate substantial performance
improvements across different representation paradigms. Through ablation
studies and attention visualization, we confirm that our approach selectively
prioritizes task-relevant scene information, closely mirroring human adaptive
perception during manipulation tasks. The project website is at
\href{https://lisunphil.github.io/HyperTASR_projectpage/}{lisunphil.github.io/HyperTASR\_projectpage}.

</details>


### [14] [Learning Real-World Acrobatic Flight from Human Preferences](https://arxiv.org/abs/2508.18817)
*Colin Merk,Ismail Geles,Jiaxu Xing,Angel Romero,Giorgia Ramponi,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 基于偏好的强化学习用于无人机特技飞行控制，提出Reward Ensemble under Confidence方法提升偏好建模和学习稳定性，在仿真和真实无人机上成功实现特技动作


<details>
  <summary>Details</summary>
Motivation: 特技飞行具有复杂动力学和快速运动特性，传统手动设计奖励函数难以捕捉人类偏好的风格化运动质量，需要基于偏好的学习方法

Method: 基于Preference PPO提出Reward Ensemble under Confidence扩展，改进奖励学习目标，提升偏好建模和学习稳定性

Result: 达到88.4%的成型奖励性能（标准方法仅55.2%），成功将仿真训练的策略迁移到真实无人机，实现多种特技动作，手动设计奖励仅60.7%符合人类偏好

Conclusion: 基于偏好的强化学习能有效捕捉复杂的人类中心目标，在物理和仿真领域都表现出色，证明了其在难以形式化任务中的有效性

Abstract: Preference-based reinforcement learning (PbRL) enables agents to learn
control policies without requiring manually designed reward functions, making
it well-suited for tasks where objectives are difficult to formalize or
inherently subjective. Acrobatic flight poses a particularly challenging
problem due to its complex dynamics, rapid movements, and the importance of
precise execution. In this work, we explore the use of PbRL for agile drone
control, focusing on the execution of dynamic maneuvers such as powerloops.
Building on Preference-based Proximal Policy Optimization (Preference PPO), we
propose Reward Ensemble under Confidence (REC), an extension to the reward
learning objective that improves preference modeling and learning stability.
Our method achieves 88.4% of the shaped reward performance, compared to 55.2%
with standard Preference PPO. We train policies in simulation and successfully
transfer them to real-world drones, demonstrating multiple acrobatic maneuvers
where human preferences emphasize stylistic qualities of motion. Furthermore,
we demonstrate the applicability of our probabilistic reward model in a
representative MuJoCo environment for continuous control. Finally, we highlight
the limitations of manually designed rewards, observing only 60.7% agreement
with human preferences. These results underscore the effectiveness of PbRL in
capturing complex, human-centered objectives across both physical and simulated
domains.

</details>


### [15] [AS2FM: Enabling Statistical Model Checking of ROS 2 Systems for Robust Autonomy](https://arxiv.org/abs/2508.18820)
*Christian Henkel,Marco Lampacrescia,Michaela Klauck,Matteo Morelli*

Main category: cs.RO

TL;DR: 提出AS2FM工具，将自主机器人系统模型转换为JANI格式，使用统计模型检验(SMC)在设计时验证系统属性，相比现有方法支持更全面的系统特性且验证时间线性增长。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在不可预见环境中运行时面临挑战，需要设计时验证系统属性以确保安全性和可靠性。

Method: 扩展SCXML格式建模ROS 2和行为树组件，开发AS2FM工具将系统模型转换为标准JANI格式，利用现成SMC工具进行验证。

Result: 成功识别ROS 2机械臂用例中的问题，验证时间少于1秒，验证运行时间随模型大小线性增长而非指数增长。

Conclusion: AS2FM工具实用性强，能有效验证真实自主机器人控制系统，验证效率高且可扩展性好。

Abstract: Designing robotic systems to act autonomously in unforeseen environments is a
challenging task. This work presents a novel approach to use formal
verification, specifically Statistical Model Checking (SMC), to verify system
properties of autonomous robots at design-time. We introduce an extension of
the SCXML format, designed to model system components including both Robot
Operating System 2 (ROS 2) and Behavior Tree (BT) features. Further, we
contribute Autonomous Systems to Formal Models (AS2FM), a tool to translate the
full system model into JANI. The use of JANI, a standard format for
quantitative model checking, enables verification of system properties with
off-the-shelf SMC tools. We demonstrate the practical usability of AS2FM both
in terms of applicability to real-world autonomous robotic control systems, and
in terms of verification runtime scaling. We provide a case study, where we
successfully identify problems in a ROS 2-based robotic manipulation use case
that is verifiable in less than one second using consumer hardware.
Additionally, we compare to the state of the art and demonstrate that our
method is more comprehensive in system feature support, and that the
verification runtime scales linearly with the size of the model, instead of
exponentially.

</details>


### [16] [VisionSafeEnhanced VPC: Cautious Predictive Control with Visibility Constraints under Uncertainty for Autonomous Robotic Surgery](https://arxiv.org/abs/2508.18937)
*Wang Jiayin,Wei Yanran,Jiang Lei,Guo Xiaoyu,Zheng Ayong,Zhao Weidong,Li Zhongkui*

Main category: cs.RO

TL;DR: 提出VisionSafeEnhanced VPC框架，用于机器人辅助微创手术中腹腔镜的自主控制，通过高斯过程回归量化不确定性并保证视野安全


<details>
  <summary>Details</summary>
Motivation: 解决现有基于图像的视觉伺服控制中连续可见性要求和复杂干扰（参数化误差、测量噪声、负载不确定性）导致外科医生视觉体验下降和手术安全性受损的问题

Method: 使用高斯过程回归进行混合（确定性+随机性）不确定性量化，提出具有概率保证的安全感知轨迹优化框架，包括基于不确定性传播的自适应安全控制屏障函数条件和机会约束

Result: 在商业手术机器人平台上验证，相比基线方法保持接近完美的目标可见性（>99.9%），减少跟踪误差

Conclusion: 该框架能够在不确定性下保证视野安全，实现自适应控制努力分配，在保持鲁棒性的同时最小化不必要的相机运动

Abstract: Autonomous control of the laparoscope in robot-assisted Minimally Invasive
Surgery (MIS) has received considerable research interest due to its potential
to improve surgical safety. Despite progress in pixel-level Image-Based Visual
Servoing (IBVS) control, the requirement of continuous visibility and the
existence of complex disturbances, such as parameterization error, measurement
noise, and uncertainties of payloads, could degrade the surgeon's visual
experience and compromise procedural safety. To address these limitations, this
paper proposes VisionSafeEnhanced Visual Predictive Control (VPC), a robust and
uncertainty-adaptive framework for autonomous laparoscope control that
guarantees Field of View (FoV) safety under uncertainty. Firstly, Gaussian
Process Regression (GPR) is utilized to perform hybrid (deterministic +
stochastic) quantification of operational uncertainties including residual
model uncertainties, stochastic uncertainties, and external disturbances. Based
on uncertainty quantification, a novel safety aware trajectory optimization
framework with probabilistic guarantees is proposed, where a
uncertainty-adaptive safety Control Barrier Function (CBF) condition is given
based on uncertainty propagation, and chance constraints are simultaneously
formulated based on probabilistic approximation. This uncertainty aware
formulation enables adaptive control effort allocation, minimizing unnecessary
camera motion while maintaining robustness. The proposed method is validated
through comparative simulations and experiments on a commercial surgical robot
platform (MicroPort MedBot Toumai) performing a sequential multi-target lymph
node dissection. Compared with baseline methods, the framework maintains
near-perfect target visibility (>99.9%), reduces tracking e

</details>


### [17] [Enhanced UAV Path Planning Using the Tangent Intersection Guidance (TIG) Algorithm](https://arxiv.org/abs/2508.18967)
*Hichem Cheriet,Khellat Kihel Badra,Chouraqui Samira*

Main category: cs.RO

TL;DR: 提出Tangent Intersection Guidance (TIG)算法，用于无人机在静态和动态环境中的高效路径规划，通过椭圆切线交点方法生成可行路径，在时间和路径质量上优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 无人机的高效安全导航对于作战支持、包裹投递和搜救行动等应用至关重要，需要一种能够在静态和动态环境中进行实时路径规划的先进算法。

Method: 使用椭圆切线交点方法生成可行路径，为每个威胁生成两条子路径，基于启发式规则选择最优路线，并迭代优化路径。采用基于二次贝塞尔曲线的改进平滑技术来满足无人机运动学约束。

Result: 实验结果显示，TIG算法在静态环境中能在0.01秒内生成最短路径，转弯角度更少，性能优于A*、PRM、RRT*等算法。在未知和部分已知环境中，实时避障能力优于APF和Dynamic APPATT算法。

Conclusion: TIG算法是一种高效的无人机路径规划方法，在静态和动态环境中都能提供实时、平滑且最优的路径规划解决方案。

Abstract: Efficient and safe navigation of Unmanned Aerial Vehicles (UAVs) is critical
for various applications, including combat support, package delivery and Search
and Rescue Operations. This paper introduces the Tangent Intersection Guidance
(TIG) algorithm, an advanced approach for UAV path planning in both static and
dynamic environments. The algorithm uses the elliptic tangent intersection
method to generate feasible paths. It generates two sub-paths for each threat,
selects the optimal route based on a heuristic rule, and iteratively refines
the path until the target is reached. Considering the UAV kinematic and dynamic
constraints, a modified smoothing technique based on quadratic B\'ezier curves
is adopted to generate a smooth and efficient route. Experimental results show
that the TIG algorithm can generate the shortest path in less time, starting
from 0.01 seconds, with fewer turning angles compared to A*, PRM, RRT*, Tangent
Graph, and Static APPATT algorithms in static environments. Furthermore, in
completely unknown and partially known environments, TIG demonstrates efficient
real-time path planning capabilities for collision avoidance, outperforming APF
and Dynamic APPATT algorithms.

</details>


### [18] [HuBE: Cross-Embodiment Human-like Behavior Execution for Humanoid Robots](https://arxiv.org/abs/2508.19002)
*Shipeng Lyu,Fangyuan Wang,Weiwei Lin,Luhao Zhu,David Navarro-Alarcon,Guodong Guo*

Main category: cs.RO

TL;DR: HuBE是一个双层闭环框架，通过整合机器人状态、目标姿态和情境信息来生成类人行为，解决了人形机器人运动生成中行为相似性和适当性的挑战，并实现了跨异构机器人的毫米级兼容性。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人运动生成中同时实现行为相似性和适当性的开放挑战，以及缺乏跨体现适应性的问题。

Method: 提出HuBE双层闭环框架，整合机器人状态、目标姿态和情境信息；构建HPose情境丰富数据集；引入基于骨骼缩放的数据增强策略确保跨异构人形机器人的毫米级兼容性。

Result: 在多个商业平台上的综合评估显示，HuBE在运动相似性、行为适当性和计算效率方面显著优于现有最先进基线方法。

Conclusion: HuBE为跨多样人形机器人的可转移和类人行为执行奠定了坚实基础。

Abstract: Achieving both behavioral similarity and appropriateness in human-like motion
generation for humanoid robot remains an open challenge, further compounded by
the lack of cross-embodiment adaptability. To address this problem, we propose
HuBE, a bi-level closed-loop framework that integrates robot state, goal poses,
and contextual situations to generate human-like behaviors, ensuring both
behavioral similarity and appropriateness, and eliminating structural
mismatches between motion generation and execution. To support this framework,
we construct HPose, a context-enriched dataset featuring fine-grained
situational annotations. Furthermore, we introduce a bone scaling-based data
augmentation strategy that ensures millimeter-level compatibility across
heterogeneous humanoid robots. Comprehensive evaluations on multiple commercial
platforms demonstrate that HuBE significantly improves motion similarity,
behavioral appropriateness, and computational efficiency over state-of-the-art
baselines, establishing a solid foundation for transferable and human-like
behavior execution across diverse humanoid robots.

</details>


### [19] [An LLM-powered Natural-to-Robotic Language Translation Framework with Correctness Guarantees](https://arxiv.org/abs/2508.19074)
*ZhenDong Chen,ZhanShang Nie,ShiXing Wan,JunYi Li,YongTian Cheng,Shuai Zhao*

Main category: cs.RO

TL;DR: 提出NRTrans框架，通过机器人技能语言(RSL)和编译器验证机制，为LLM生成的机器人控制程序提供正确性保证和反馈优化


<details>
  <summary>Details</summary>
Motivation: 现有方法直接让LLM从自然语言生成可执行程序，但由于LLM不一致性和任务复杂性，经常产生大量编程错误，特别是在轻量级LLM应用中效果不佳

Method: 提出机器人技能语言(RSL)抽象控制程序细节，构建RSL编译器和调试器验证LLM生成的程序并提供错误反馈，通过反馈微调优化LLM输出

Result: 实验表明NRTrans在多种LLM和任务下优于现有方法，对轻量级LLM实现了高成功率

Conclusion: 该框架为LLM生成的程序提供执行前正确性保证，显著提升了LLM驱动的机器人应用效果

Abstract: The Large Language Models (LLM) are increasingly being deployed in robotics
to generate robot control programs for specific user tasks, enabling embodied
intelligence. Existing methods primarily focus on LLM training and prompt
design that utilize LLMs to generate executable programs directly from user
tasks in natural language. However, due to the inconsistency of the LLMs and
the high complexity of the tasks, such best-effort approaches often lead to
tremendous programming errors in the generated code, which significantly
undermines the effectiveness especially when the light-weight LLMs are applied.
This paper introduces a natural-robotic language translation framework that (i)
provides correctness verification for generated control programs and (ii)
enhances the performance of LLMs in program generation via feedback-based
fine-tuning for the programs. To achieve this, a Robot Skill Language (RSL) is
proposed to abstract away from the intricate details of the control programs,
bridging the natural language tasks with the underlying robot skills. Then, the
RSL compiler and debugger are constructed to verify RSL programs generated by
the LLM and provide error feedback to the LLM for refining the outputs until
being verified by the compiler. This provides correctness guarantees for the
LLM-generated programs before being offloaded to the robots for execution,
significantly enhancing the effectiveness of LLM-powered robotic applications.
Experiments demonstrate NRTrans outperforms the existing method under a range
of LLMs and tasks, and achieves a high success rate for light-weight LLMs.

</details>


### [20] [DELIVER: A System for LLM-Guided Coordinated Multi-Robot Pickup and Delivery using Voronoi-Based Relay Planning](https://arxiv.org/abs/2508.19114)
*Alkesh K. Srivastava,Jared Michael Levin,Alexander Derrico,Philip Dames*

Main category: cs.RO

TL;DR: DELIVER是一个基于自然语言指令的多机器人协作拾取配送框架，通过语言理解、空间分解、中继规划和运动执行实现可扩展的无碰撞协调


<details>
  <summary>Details</summary>
Motivation: 为了解决多机器人系统在现实环境中基于自然语言指令进行协作拾取配送的挑战，需要开发一个集成框架来实现可扩展、无碰撞的协调

Method: 使用LLaMA3进行自然语言理解提取位置信息，Voronoi图进行空间分区定义机器人操作区域，计算最优中继点协调交接，有限状态机控制机器人行为

Result: 在MultiTRAIL仿真平台和TurtleBot3机器人上验证，相比单机器人系统减少55%的单体工作量，团队规模增大时活跃中继机器人数量保持低位

Conclusion: DELIVER展示了模块化和可扩展的架构，推动了语言引导的多机器人协调和网络物理系统集成的发展

Abstract: We present DELIVER (Directed Execution of Language-instructed Item Via
Engineered Relay), a fully integrated framework for cooperative multi-robot
pickup and delivery driven by natural language commands. DELIVER unifies
natural language understanding, spatial decomposition, relay planning, and
motion execution to enable scalable, collision-free coordination in real-world
settings. Given a spoken or written instruction, a lightweight instance of
LLaMA3 interprets the command to extract pickup and delivery locations. The
environment is partitioned using a Voronoi tessellation to define
robot-specific operating regions. Robots then compute optimal relay points
along shared boundaries and coordinate handoffs. A finite-state machine governs
each robot's behavior, enabling robust execution. We implement DELIVER on the
MultiTRAIL simulation platform and validate it in both ROS2-based Gazebo
simulations and real-world hardware using TurtleBot3 robots. Empirical results
show that DELIVER maintains consistent mission cost across varying team sizes
while reducing per-agent workload by up to 55% compared to a single-agent
system. Moreover, the number of active relay agents remains low even as team
size increases, demonstrating the system's scalability and efficient agent
utilization. These findings underscore DELIVER's modular and extensible
architecture for language-guided multi-robot coordination, advancing the
frontiers of cyber-physical system integration.

</details>


### [21] [ZeST: an LLM-based Zero-Shot Traversability Navigation for Unknown Environments](https://arxiv.org/abs/2508.19131)
*Shreya Gummadi,Mateus V. Gasparino,Gianluca Capezzuto,Marcelo Becker,Girish Chowdhary*

Main category: cs.RO

TL;DR: ZeST利用大型语言模型的视觉推理能力，实现零样本地形可通行性预测，无需将机器人置于危险环境中即可创建实时可通行性地图。


<details>
  <summary>Details</summary>
Motivation: 传统的地形可通行性预测方法需要将机器人置于危险环境中收集数据，存在设备损坏和安全风险。需要一种更安全、成本效益更高的解决方案。

Method: 利用大型语言模型（LLMs）的视觉推理能力，通过零样本学习方式实时生成地形可通行性地图，避免实际环境中的风险数据收集。

Result: 在受控室内和非结构化室外环境中的导航实验表明，该方法相比其他最先进方法提供更安全的导航，能够持续到达最终目标。

Conclusion: ZeST方法为零样本地形可通行性预测提供了一种安全、成本效益高且可扩展的解决方案，加速了先进导航系统的开发。

Abstract: The advancement of robotics and autonomous navigation systems hinges on the
ability to accurately predict terrain traversability. Traditional methods for
generating datasets to train these prediction models often involve putting
robots into potentially hazardous environments, posing risks to equipment and
safety. To solve this problem, we present ZeST, a novel approach leveraging
visual reasoning capabilities of Large Language Models (LLMs) to create a
traversability map in real-time without exposing robots to danger. Our approach
not only performs zero-shot traversability and mitigates the risks associated
with real-world data collection but also accelerates the development of
advanced navigation systems, offering a cost-effective and scalable solution.
To support our findings, we present navigation results, in both controlled
indoor and unstructured outdoor environments. As shown in the experiments, our
method provides safer navigation when compared to other state-of-the-art
methods, constantly reaching the final goal.

</details>


### [22] [Uncertainty-Resilient Active Intention Recognition for Robotic Assistants](https://arxiv.org/abs/2508.19150)
*Juan Carlos Saborío,Marc Vinci,Oscar Lima,Sebastian Stock,Lennart Niecksch,Martin Günther,Alexander Sung,Joachim Hertzberg,Martin Atzmüller*

Main category: cs.RO

TL;DR: 提出了一个基于POMDP的意图识别框架，用于处理机器人助手中的不确定性和感知错误，实现协作规划与行动。


<details>
  <summary>Details</summary>
Motivation: 现有机器人助手系统要么依赖显式提示限制了自主性，要么基于完美信息假设过于简化，未能解决人类意图识别中的不确定结果和感知错误这一关键挑战。

Method: 开发了一个以意图识别POMDP为中心的框架，整合实时传感器数据和多种规划器，旨在对不确定性和传感器噪声具有鲁棒性。

Result: 该集成框架已在物理机器人上成功测试，并取得了有希望的结果。

Conclusion: 该研究为解决机器人助手中人类意图识别的不确定性问题提供了一个有效的POMDP-based框架，在实际机器人应用中展现出良好潜力。

Abstract: Purposeful behavior in robotic assistants requires the integration of
multiple components and technological advances. Often, the problem is reduced
to recognizing explicit prompts, which limits autonomy, or is oversimplified
through assumptions such as near-perfect information. We argue that a critical
gap remains unaddressed -- specifically, the challenge of reasoning about the
uncertain outcomes and perception errors inherent to human intention
recognition. In response, we present a framework designed to be resilient to
uncertainty and sensor noise, integrating real-time sensor data with a
combination of planners. Centered around an intention-recognition POMDP, our
approach addresses cooperative planning and acting under uncertainty. Our
integrated framework has been successfully tested on a physical robot with
promising results.

</details>


### [23] [QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning](https://arxiv.org/abs/2508.19153)
*Allen Wang,Gavin Tao*

Main category: cs.RO

TL;DR: 提出了QuadKAN框架，使用样条参数化的KAN网络结合本体感觉和视觉输入，通过强化学习实现四足机器人鲁棒运动控制，在多种地形和障碍物场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决视觉引导的四足运动控制问题，强调需要结合本体感觉和视觉信息来实现鲁棒控制，现有方法在样本效率、动作抖动和能耗方面存在不足。

Method: 提出QuadKAN框架，使用样条参数化的Kolmogorov-Arnold Networks（KANs），包含样条编码器处理本体感觉输入和样条融合头处理多模态输入，采用多模态延迟随机化和PPO算法进行端到端训练。

Result: 在包括平坦/不平坦地形和静态/动态障碍物的多种场景评估中，QuadKAN相比最先进基线方法获得了更高的回报、更长的移动距离和更少的碰撞。

Conclusion: 样条参数化策略为鲁棒的视觉引导运动控制提供了一种简单、有效且可解释的替代方案，能够改善样本效率、减少动作抖动和能耗，并提供可解释的姿态-动作敏感性。

Abstract: We address vision-guided quadruped motion control with reinforcement learning
(RL) and highlight the necessity of combining proprioception with vision for
robust control. We propose QuadKAN, a spline-parameterized cross-modal policy
instantiated with Kolmogorov-Arnold Networks (KANs). The framework incorporates
a spline encoder for proprioception and a spline fusion head for
proprioception-vision inputs. This structured function class aligns the
state-to-action mapping with the piecewise-smooth nature of gait, improving
sample efficiency, reducing action jitter and energy consumption, and providing
interpretable posture-action sensitivities. We adopt Multi-Modal Delay
Randomization (MMDR) and perform end-to-end training with Proximal Policy
Optimization (PPO). Evaluations across diverse terrains, including both even
and uneven surfaces and scenarios with static or dynamic obstacles, demonstrate
that QuadKAN achieves consistently higher returns, greater distances, and fewer
collisions than state-of-the-art (SOTA) baselines. These results show that
spline-parameterized policies offer a simple, effective, and interpretable
alternative for robust vision-guided locomotion. A repository will be made
available upon acceptance.

</details>


### [24] [Direction Informed Trees (DIT*): Optimal Path Planning via Direction Filter and Direction Cost Heuristic](https://arxiv.org/abs/2508.19168)
*Liding Zhang,Kejia Chen,Kuanqi Cai,Yu Zhang,Yixuan Dang,Yansong Wu,Zhenshan Bing,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: DIT*是一种基于采样的路径规划算法，通过优化搜索方向和方向成本启发式，比现有算法在R^4到R^16空间中收敛更快


<details>
  <summary>Details</summary>
Motivation: 现有路径规划算法（如EIT*）使用effort启发式来指导搜索，但准确性和计算效率往往难以兼顾，需要更好的启发式方法

Method: 将边定义为广义向量，集成相似性索引建立方向过滤器来选择最近邻和估计方向成本，在边评估中使用方向成本启发式

Result: DIT*在R^4到R^16的测试问题上比现有单查询采样规划器收敛更快，并在各种实际规划任务中得到验证

Conclusion: 通过优化搜索方向和有效共享方向信息，DIT*实现了更快的收敛性能，适用于高维空间的路径规划问题

Abstract: Optimal path planning requires finding a series of feasible states from the
starting point to the goal to optimize objectives. Popular path planning
algorithms, such as Effort Informed Trees (EIT*), employ effort heuristics to
guide the search. Effective heuristics are accurate and computationally
efficient, but achieving both can be challenging due to their conflicting
nature. This paper proposes Direction Informed Trees (DIT*), a sampling-based
planner that focuses on optimizing the search direction for each edge,
resulting in goal bias during exploration. We define edges as generalized
vectors and integrate similarity indexes to establish a directional filter that
selects the nearest neighbors and estimates direction costs. The estimated
direction cost heuristics are utilized in edge evaluation. This strategy allows
the exploration to share directional information efficiently. DIT* convergence
faster than existing single-query, sampling-based planners on tested problems
in R^4 to R^16 and has been demonstrated in real-world environments with
various planning tasks. A video showcasing our experimental results is
available at: https://youtu.be/2SX6QT2NOek

</details>


### [25] [From Tabula Rasa to Emergent Abilities: Discovering Robot Skills via Real-World Unsupervised Quality-Diversity](https://arxiv.org/abs/2508.19172)
*Luca Grillotti,Lisa Coiffard,Oscar Pang,Maxence Faldor,Antoine Cully*

Main category: cs.RO

TL;DR: URSA是一种无监督真实世界技能获取方法，扩展了QDAC算法，使机器人能够在真实环境中自主发现和掌握多样化高性能技能，无需手动定义技能空间或精心调整启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法如QDAC需要手动定义技能空间和精心调整启发式方法，限制了在真实世界中的适用性。学习直接在物理硬件上的行为由于安全和数据效率限制仍然具有挑战性。

Method: 提出URSA方法，扩展QDAC算法，支持启发式驱动技能发现和完全无监督设置，使机器人能够在真实世界中自主发现多样化技能。

Result: 在Unitree A1四足机器人上成功发现多样化运动技能，在仿真和真实世界中都有效。在9个仿真损坏场景中5个、5个真实世界损坏场景中3个都优于所有基线方法。

Conclusion: URSA为真实世界机器人学习建立了新框架，实现了有限人工干预下的持续技能发现，是迈向更自主和适应性机器人系统的重要一步。

Abstract: Autonomous skill discovery aims to enable robots to acquire diverse behaviors
without explicit supervision. Learning such behaviors directly on physical
hardware remains challenging due to safety and data efficiency constraints.
Existing methods, including Quality-Diversity Actor-Critic (QDAC), require
manually defined skill spaces and carefully tuned heuristics, limiting
real-world applicability. We propose Unsupervised Real-world Skill Acquisition
(URSA), an extension of QDAC that enables robots to autonomously discover and
master diverse, high-performing skills directly in the real world. We
demonstrate that URSA successfully discovers diverse locomotion skills on a
Unitree A1 quadruped in both simulation and the real world. Our approach
supports both heuristic-driven skill discovery and fully unsupervised settings.
We also show that the learned skill repertoire can be reused for downstream
tasks such as real-world damage adaptation, where URSA outperforms all
baselines in 5 out of 9 simulated and 3 out of 5 real-world damage scenarios.
Our results establish a new framework for real-world robot learning that
enables continuous skill discovery with limited human intervention,
representing a significant step toward more autonomous and adaptable robotic
systems. Demonstration videos are available at
http://adaptive-intelligent-robotics.github.io/URSA .

</details>


### [26] [Real-Time Model Checking for Closed-Loop Robot Reactive Planning](https://arxiv.org/abs/2508.19186)
*Christopher Chandler,Bernd Porr,Giulia Lafratta,Alice Miller*

Main category: cs.RO

TL;DR: 基于模型检查的实时多步规划技术，在低力量设备上实现自主机器人的障碍物避免和多步规划


<details>
  <summary>Details</summary>
Motivation: 仿照生物代理的"6838心"知识和注意力机制，开发能够在实时环境中进行多步规划的方法，改善只能做单步规划的反应式算法

Method: 使用专门设计的小型模型检查算法，基于链式临时控制系统来对抗局部环境干扰；采用对局部环境有界变化敏感的2D LiDAR数据离散化方法；通过前向深度优先搜索进行多步规划

Result: 在小均上和游戏场场景中验证了方法的有效性，证明模型检查能够为局部障碍物避免创建高效的多步计划，性能超过只能进行单步规划的反应式代理

Conclusion: 该方法为自主车辆领域开发安全、可靠和可解释的规划系统提供了教学案例研究，证明了模型检查在实时多步规划中的应用价值

Abstract: We present a new application of model checking which achieves real-time
multi-step planning and obstacle avoidance on a real autonomous robot. We have
developed a small, purpose-built model checking algorithm which generates plans
in situ based on "core" knowledge and attention as found in biological agents.
This is achieved in real-time using no pre-computed data on a low-powered
device. Our approach is based on chaining temporary control systems which are
spawned to counteract disturbances in the local environment that disrupt an
autonomous agent from its preferred action (or resting state). A novel
discretization of 2D LiDAR data sensitive to bounded variations in the local
environment is used. Multi-step planning using model checking by forward
depth-first search is applied to cul-de-sac and playground scenarios. Both
empirical results and informal proofs of two fundamental properties of our
approach demonstrate that model checking can be used to create efficient
multi-step plans for local obstacle avoidance, improving on the performance of
a reactive agent which can only plan one step. Our approach is an instructional
case study for the development of safe, reliable and explainable planning in
the context of autonomous vehicles.

</details>


### [27] [AutoRing: Imitation Learning--based Autonomous Intraocular Foreign Body Removal Manipulation with Eye Surgical Robot](https://arxiv.org/abs/2508.19191)
*Yue Wang,Wenjie Deng,Haotian Xue,Di Cui,Yiqi Chen,Mingchuan Zhou,Haochao Ying,Jian Wu*

Main category: cs.RO

TL;DR: AutoRing是一个基于模仿学习的自主眼内异物环操作框架，通过动态RCM校准和RCM-ACT架构解决运动缩放和RCM点变化带来的运动学不确定性，仅使用立体视觉数据和专家演示即可完成精确操作。


<details>
  <summary>Details</summary>
Motivation: 眼内异物移除需要在有限空间内实现毫米级精度，现有机器人系统主要依赖手动遥操作，学习曲线陡峭，需要解决自主操作中的运动学不确定性挑战。

Method: 提出AutoRing模仿学习框架，整合动态RCM校准解决坐标系不一致问题，引入结合动作分块变换器和实时运动学重对齐的RCM-ACT架构，仅使用立体视觉数据和专家演示的仪器运动学数据进行训练。

Result: 在未经校准的显微镜条件下实现了端到端自主操作，成功完成了环抓取和定位任务，无需显式深度感知。

Conclusion: 该研究为开发能够执行复杂眼内手术的智能眼外科系统提供了可行框架。

Abstract: Intraocular foreign body removal demands millimeter-level precision in
confined intraocular spaces, yet existing robotic systems predominantly rely on
manual teleoperation with steep learning curves. To address the challenges of
autonomous manipulation (particularly kinematic uncertainties from variable
motion scaling and variation of the Remote Center of Motion (RCM) point), we
propose AutoRing, an imitation learning framework for autonomous intraocular
foreign body ring manipulation. Our approach integrates dynamic RCM calibration
to resolve coordinate-system inconsistencies caused by intraocular instrument
variation and introduces the RCM-ACT architecture, which combines
action-chunking transformers with real-time kinematic realignment. Trained
solely on stereo visual data and instrument kinematics from expert
demonstrations in a biomimetic eye model, AutoRing successfully completes ring
grasping and positioning tasks without explicit depth sensing. Experimental
validation demonstrates end-to-end autonomy under uncalibrated microscopy
conditions. The results provide a viable framework for developing intelligent
eye-surgical systems capable of complex intraocular procedures.

</details>


### [28] [Planning-Query-Guided Model Generation for Model-Based Deformable Object Manipulation](https://arxiv.org/abs/2508.19199)
*Alex LaGrassa,Zixuan Huang,Dmitry Berenson,Oliver Kroemer*

Main category: cs.RO

TL;DR: 这篇论文提出了一种自动生成任务特定、空间适配性动力学模型的方法，通过学习识别对象哪些区域需要高分辨率建模来提高规划效率。该方法在树林操纵任务上实现了规划速度倍增且任务性能仅有轻微下降。


<details>
  <summary>Details</summary>
Motivation: 在高维度空间（如可变形对象）中进行高效规划需要计算可处理但充分表达的动力学模型。传统方法使用固定分辨率的模型导致计算资源浪费或性能不足。

Method: 提出基于涵渗模型的模型生成器，根据规划查询的起始和目标点云预测各区域的模型分辨率。采用两阶段数据收集过程：首先使用预测动力学作为先验优化分辨率，然后直接使用闭环性能进行优化。

Result: 在树林操纵任务上，该方法实现了规划速度倍增，而任务性能仅比使用全分辨率模型有轻微下降。

Conclusion: 这种方法为利用历史规划和控制数据生成计算高效但充分表达的动力学模型提供了新的路径，适用于新任务。

Abstract: Efficient planning in high-dimensional spaces, such as those involving
deformable objects, requires computationally tractable yet sufficiently
expressive dynamics models. This paper introduces a method that automatically
generates task-specific, spatially adaptive dynamics models by learning which
regions of the object require high-resolution modeling to achieve good task
performance for a given planning query. Task performance depends on the complex
interplay between the dynamics model, world dynamics, control, and task
requirements. Our proposed diffusion-based model generator predicts per-region
model resolutions based on start and goal pointclouds that define the planning
query. To efficiently collect the data for learning this mapping, a two-stage
process optimizes resolution using predictive dynamics as a prior before
directly optimizing using closed-loop performance. On a tree-manipulation task,
our method doubles planning speed with only a small decrease in task
performance over using a full-resolution model. This approach informs a path
towards using previous planning and control data to generate computationally
efficient yet sufficiently expressive dynamics models for new tasks.

</details>


### [29] [MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation](https://arxiv.org/abs/2508.19236)
*Hao Shi,Bin Xie,Yingfei Liu,Lin Sun,Fengrong Liu,Tiancai Wang,Erjin Zhou,Haoqiang Fan,Xiangyu Zhang,Gao Huang*

Main category: cs.RO

TL;DR: MemoryVLA是一个受人类记忆机制启发的机器人操作框架，通过工作记忆和长期记忆系统处理时序上下文，在长时程任务中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 主流VLA模型忽视时序上下文，难以处理长时程、时序依赖的任务。受认知科学启发，人类利用工作记忆和长期记忆系统来处理时序信息

Method: 提出Cognition-Memory-Action框架：预训练VLM编码观测为感知和认知token形成工作记忆，感知-认知记忆库存储低层细节和高层语义，工作记忆从库中检索相关条目并与当前token融合，记忆条件扩散动作专家生成时序感知动作序列

Result: 在150+仿真和真实任务中验证：SimpletEnv-Bridge(71.9%)、Fractal(72.7%)、LIBERO-5(96.5%)，均优于CogACT和pi-0，Bridge任务提升14.6%；真实世界12个任务达到84.0%成功率，长时程任务提升26%

Conclusion: MemoryVLA通过模拟人类记忆机制有效处理机器人操作中的时序上下文问题，在长时程任务中表现出色，为时序感知的机器人控制提供了新思路

Abstract: Temporal context is essential for robotic manipulation because such tasks are
inherently non-Markovian, yet mainstream VLA models typically overlook it and
struggle with long-horizon, temporally dependent tasks. Cognitive science
suggests that humans rely on working memory to buffer short-lived
representations for immediate control, while the hippocampal system preserves
verbatim episodic details and semantic gist of past experience for long-term
memory. Inspired by these mechanisms, we propose MemoryVLA, a
Cognition-Memory-Action framework for long-horizon robotic manipulation. A
pretrained VLM encodes the observation into perceptual and cognitive tokens
that form working memory, while a Perceptual-Cognitive Memory Bank stores
low-level details and high-level semantics consolidated from it. Working memory
retrieves decision-relevant entries from the bank, adaptively fuses them with
current tokens, and updates the bank by merging redundancies. Using these
tokens, a memory-conditioned diffusion action expert yields temporally aware
action sequences. We evaluate MemoryVLA on 150+ simulation and real-world tasks
across three robots. On SimplerEnv-Bridge, Fractal, and LIBERO-5 suites, it
achieves 71.9%, 72.7%, and 96.5% success rates, respectively, all outperforming
state-of-the-art baselines CogACT and pi-0, with a notable +14.6 gain on
Bridge. On 12 real-world tasks spanning general skills and long-horizon
temporal dependencies, MemoryVLA achieves 84.0% success rate, with long-horizon
tasks showing a +26 improvement over state-of-the-art baseline. Project Page:
https://shihao1895.github.io/MemoryVLA

</details>
